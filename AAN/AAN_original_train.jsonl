{"orig_sents": ["0", "1"], "shuf_sents": ["There is experimental evidence that cortical neurons show avalanche activity with the intensity of firing events being distributed as a power-law .", "We present a biologically plausible extension of a neural network which exhibits a power-law avalanche distribution for a wide range of connectivity parameters ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["We present results from two datasets demonstrating the algorithms 's ability to synthesize novel data from learned correspondences .", "The observation spaces are linked via a single , reduced-dimensionality latent variable space .", "We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations .", "We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot , allowing robotic imitation of human poses from motion capture data .", "We first show that the method can learn the nonlinear mapping between corresponding views of objects , filling in missing data as needed to synthesize novel views ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["This role of norepinephrine can be understood through the metaphor of neural interrupts .", "Experimental data indicate that norepinephrine is critically involved in aspects of vigilance and attention .", "However , norepinephrine is also known to be activated phasically by familiar stimuli in welllearned tasks .", "Previously , we considered the function of this neuromodulatory system on a time scale of minutes and longer , and suggested that it signals global uncertainty arising from gross changes in environmental contingencies .", "Here , we extend our uncertainty-based treatment of norepinephrine to this phasic mode , proposing that it is involved in the detection and reaction to state uncertainty within a task ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["Nested sampling is a new Monte Carlo method by Skilling intended for general Bayesian computation .", "We provide a demonstration with the Potts model , an undirected graphical model .", "The key technical requirement is an ability to draw samples uniformly from the prior subject to a constraint on the likelihood .", "It can also generate estimates of other quantities such as posterior expectations .", "Nested sampling provides a robust alternative to annealing-based methods for computing normalizing constants ."]}
{"orig_sents": ["3", "1", "5", "2", "0", "4"], "shuf_sents": ["In some sense DCS is a framework for distributed compression of sources with memory , which has remained a challenging problem in information theory for some time .", "In this paper we introduce a new theory for distributed compressed sensing ( DCS ) that enables new distributed coding algorithms for multi-signal ensembles that exploit both intra- and inter-signal correlation structures .", "We study three simple models for jointly sparse signals , propose algorithms for joint recovery of multiple signals from incoherent projections , and characterize theoretically and empirically the number of measurements per sensor required for accurate reconstruction .", "Compressed sensing is an emerging field based on the revelation that a small group of linear projections of a sparse signal contains enough information for reconstruction .", "DCS is immediately applicable to a range of problems in sensor networks and arrays .", "The DCS theory rests on a new concept that we term the joint sparsity of a signal ensemble ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["It is well-known that everything that is learnable in the difficult online setting , where an arbitrary sequences of examples must be labeled one at a time , is also learnable in the batch setting , where examples are drawn independently from a distribution .", "This demonstrates the equivalence between what is properly and efficiently learnable in a batch model and a transductive online model .", "We show a result in the opposite direction .", "We give an efficient conversion algorithm from batch to online that is transductive : it uses future unlabeled data ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Non-asymptotic convergence bounds to this limit in the L2 sense are provided , together with upper bounds on the classification error that is shown to converge to the Bayes risk , therefore proving the Bayes-consistency of a variety of methods although the regularization term does not vanish .", "We determine the asymptotic limit of the function computed by support vector machines ( SVM ) and related algorithms that minimize a regularized empirical convex loss function in the reproducing kernel Hilbert space of the Gaussian RBF kernel , in the situation where the number of examples tends to infinity , the bandwidth of the Gaussian kernel tends to 0 , and the regularization parameter is held fixed .", "These results are particularly relevant to the one-class SVM , for which the regularization can not vanish by construction , and which is shown for the first time to be a consistent density level set estimator ."]}
{"orig_sents": ["2", "4", "1", "5", "3", "6", "0"], "shuf_sents": ["Further , some interesting extensions to the use of `` link '' functions for modeling nonlinear relationships are also discussed .", "Despite these numerous applications , the algorithmic development for computing the NNMA factors has been relatively deficient .", "Nonnegative matrix approximation ( NNMA ) is a recent technique for dimensionality reduction and data analysis that yields a parts based , sparse nonnegative representation for nonnegative input data .", "The multiplicative update formulae in the pioneering work by Lee and Seung arise as a special case of our algorithms .", "NNMA has found a wide variety of applications , including text analysis , document clustering , face/image recognition , language modeling , speech processing and many others .", "This paper makes algorithmic progress by modeling and solving ( using multiplicative updates ) new generalized NNMA problems that minimize Bregman divergences between the input matrix and its lowrank approximation .", "In addition , the paper shows how to use penalty functions for incorporating constraints other than nonnegativity into the problem ."]}
{"orig_sents": ["3", "7", "2", "4", "1", "0", "6", "5"], "shuf_sents": ["We demonstrate the approach on detecting cats , horses , and hands .", "The method works rapidly , in under a second , on 320 x 240 images .", "The algorithm uses a hierarchical tree where the root of the tree corresponds to the full object and lower-level elements of the tree correspond to simpler features .", "We describe a hierarchical compositional system for detecting deformable objects in images .", "The algorithm proceeds by passing simple messages up and down the tree .", "Our approach is contrasted with more traditional methods such as dynamic programming and belief propagation .", "The method works in the presence of background clutter and occlusions .", "Objects are represented by graphical models ."]}
{"orig_sents": ["0", "4", "2", "3", "1", "5"], "shuf_sents": ["We consider a framework for semi-supervised learning using spectral decomposition based un-supervised kernel design .", "Based on the theoretical analysis , we are able to demonstrate why spectral kernel design based methods can often improve the predictive performance .", "We examine various theoretical properties of such methods .", "In particular , we derive a generalization performance bound , and obtain the optimal kernel design by minimizing the bound .", "This approach subsumes a class of previously proposed semi-supervised learning methods on data graphs .", "Experiments are used to illustrate the main consequences of our analysis ."]}
{"orig_sents": ["1", "0", "4", "6", "7", "2", "5", "3"], "shuf_sents": ["Two specific criteria that we consider in this paper are the single linkage and the minimum description length criteria .", "We show that Queyranne 's algorithm for minimizing symmetric submodular functions can be used for clustering with a variety of different objective functions .", "We show that the optimal partitioning into 2 clusters , and approximate partitioning ( guaranteed to be within a factor of 2 of the the optimal ) for more clusters can be computed .", "Besides the optimality result for the MDL criterion , the chief contribution of this paper is to show that the same algorithm can be used to optimize a broad class of criteria , and hence can be used for many application specific criterion for which efficient algorithm are not known .", "The first criterion tries to maximize the minimum distance between elements of different clusters , and is inherently `` discriminative '' .", "To the best of our knowledge , this is the first time that a tractable algorithm for finding the optimal clustering with respect to the MDL criterion for 2 clusters has been given .", "It is known that optimal clusterings into k clusters for any given k in polynomial time for this criterion can be computed .", "The second criterion seeks to minimize the description length of the clusters given a probabilistic generative model ."]}
{"orig_sents": ["4", "2", "1", "0", "3"], "shuf_sents": ["In particular , we faithfully model recent results showing that confidence in estimation can be systematically affected by the same aspects of images that affect bias .", "We adopt a Bayesian approach to perceptual tilt estimation , showing how a smoothness prior offers a powerful way of addressing much confusing data .", "A wealth of findings has attracted many mechanistic models , but few clear computational principles .", "Confidence is central to Bayesian modeling approaches , and is applicable in many other perceptual domains .", "The misjudgement of tilt in images lies at the heart of entertaining visual illusions and rigorous perceptual psychophysics ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We prove an upper bound depending on the spacing between eigenvalues but not on the dimensionality of the eigenspace .", "Here instead of considering the reconstruction error of KPCA we are interested in approximation error bounds for the eigenspaces themselves .", "This paper presents a non-asymptotic statistical analysis of Kernel-PCA with a focus different from the one proposed in previous work on this topic .", "As a consequence this allows to infer stability results for these estimated spaces ."]}
{"orig_sents": ["1", "2", "3", "5", "4", "0"], "shuf_sents": ["Experiments show improvements over state-of-the-art procedures .", "In this paper , we show that the hinge loss can be interpreted as the neg-log-likelihood of a semi-parametric model of posterior probabilities .", "From this point of view , SVMs represent the parametric component of a semi-parametric model fitted by a maximum a posteriori estimation procedure .", "This connection enables to derive a mapping from SVM scores to estimated posterior probabilities .", "This framework offers a new way to adapt the SVM optimization problem to unbalanced classification , when decisions result in unequal ( asymmetric ) losses .", "Unlike previous proposals , the suggested mapping is interval-valued , providing a set of posterior probabilities compatible with each SVM score ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["The paper derives the algorithm formally and provides comparative results using data obtained by a real-world camera array and by a large-scale sensor network simulation .", "The key innovation is a representation of the data association posterior in information form , in which the `` proximity '' of objects and tracks are expressed by numerical links .", "Updating these links requires linear time , compared to exponential time required for computing the exact posterior probabilities .", "This paper presents a new filter for online data association problems in high-dimensional spaces ."]}
{"orig_sents": ["1", "2", "4", "5", "8", "0", "6", "3", "7"], "shuf_sents": ["The network can complete the whole by filling in missing parts .", "There is little consensus about the computational function of top-down synaptic connections in the visual system .", "Here we explore the hypothesis that top-down connections , like bottom-up connections , reflect partwhole relationships .", "Parameter regimes in which these behaviors happen are identified using the theory of permitted and forbidden sets .", "We analyze a recurrent network with bidirectional synaptic interactions between a layer of neurons representing parts and a layer of neurons representing wholes .", "Within each layer , there is lateral inhibition .", "The network can refuse to recognize a whole , if the activated parts do not conform to a stored part-whole relationship .", "The network behaviors are illustrated by recreating Rumelhart and McClelland 's `` interactive activation '' model .", "When the network detects a whole , it can rigorously enforce part-whole relationships by ignoring parts that do not belong ."]}
{"orig_sents": ["2", "3", "1", "4", "0"], "shuf_sents": ["These balance problems , which occur even though the spectral method 's quotient-style objective function does encourage balance , can be fixed with a stricter balance constraint that turns the spectral mathematical program into an SDP that can be solved for million-node graphs by a method of Burer and Monteiro .", "Rather than cleaning up the resulting suboptimal cuts with local search , we recommend the adoption of flow-based rounding .", "We discuss two intrinsic weaknesses of the spectral graph partitioning method , both of which have practical consequences .", "The first is that spectral embeddings tend to hide the best cuts from the commonly used hyperplane rounding method .", "The second weakness is that for many `` power law '' graphs , the spectral method produces cuts that are highly unbalanced , thus decreasing the usefulness of the method for visualization ( see figure 4 ( b ) ) or as a basis for divide-and-conquer algorithms ."]}
{"orig_sents": ["3", "1", "4", "0", "2"], "shuf_sents": ["This paper introduces recognizers and their potential advantages , then develops a full algorithm for linear function approximation and proves that its updates are in the same direction as on-policy TD updates , which implies asymptotic convergence .", "We develop the notion of a recognizer , a filter on actions that distorts the behavior policy to produce a related target policy with low-variance importance-sampling corrections .", "Even though our algorithm is based on importance sampling , we prove that it requires absolutely no knowledge of the behavior policy for the case of state-aggregation function approximators .", "We introduce a new algorithm for off-policy temporal-difference learning with function approximation that has lower variance and requires less knowledge of the behavior policy than prior methods .", "We also consider target policies that are deviations from the state distribution of the behavior policy , such as potential temporally abstract options , which further reduces variance ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["The work is similar to that by Rasmussen and Ghahramani ; however , we use a full generative model over input and output space rather than just a conditional model .", "This allows us to deal with incomplete data , to perform inference over inverse functional mappings as well as for regression , and also leads to a more powerful and consistent Bayesian specification of the effective `gating network ' for the different experts .", "Our model is neatly able to deal with non-stationary covariance functions , discontinuities , multimodality and overlapping output signals .", "We present an infinite mixture model in which each component comprises a multivariate Gaussian distribution over an input space , and a Gaussian Process model over an output space ."]}
{"orig_sents": ["5", "1", "6", "4", "3", "0", "2", "7"], "shuf_sents": ["In addition , this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reflexive controller in real-time during walking .", "The goal of this study is to combine neuronal mechanisms with biomechanics to obtain very fast speed and the on-line learning of circuit parameters .", "This way RunBot can reach a relative speed of 3.5 leg-lengths per second after a few minutes of online learning , which is faster than that of any other biped robot , and is also comparable to the fastest relative speed of human walking .", "To our knowledge , this is the first time that dynamic biped walking is achieved using only a pure reflexive controller .", "Instead , this reflexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle .", "In this paper , we present our design and experiments of a planar biped robot ( `` RunBot '' ) under pure reflexive neuronal control .", "Our controller is built with biologically inspired sensor- and motor-neuron models , including local reflexes and not employing any kind of position or trajectory-tracking control algorithm .", "In addition , the stability domain of stable walking is quite large supporting this design strategy ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["We propose a solution that approximates this problem under a far field approximation defined in the calculus of affine geometry , and that relies on singular value decomposition ( SVD ) to recover the affine structure of the problem .", "We then define low-dimensional optimization techniques for embedding the solution into Euclidean geometry , and further techniques for recovering the locations and emission times of the acoustic events .", "We consider the problem of localizing a set of microphones together with a set of external acoustic events ( e.g. , hand claps ) , emitted at unknown times and unknown locations .", "The approach is useful for the calibration of ad-hoc microphone arrays and sensor networks ."]}
{"orig_sents": ["1", "3", "4", "2", "0", "5"], "shuf_sents": ["Finally , we motivate the worst-case scenario for SBL and demonstrate that it is still better than the most widely used sparse representation algorithms .", "Given a redundant dictionary of basis vectors ( or atoms ) , our goal is to find maximally sparse representations of signals .", "We also prove that if these nonzero weights are drawn from an approximate Jeffreys prior , then with probability approaching one , our equivalence condition is satisfied .", "Previously , we have argued that a sparse Bayesian learning ( SBL ) framework is particularly well-suited for this task , showing that it has far fewer local minima than other Bayesian-inspired strategies .", "In this paper , we provide further evidence for this claim by proving a restricted equivalence condition , based on the distribution of the nonzero generating model weights , whereby the SBL solution will equal the maximally sparse representation .", "These include Basis Pursuit ( BP ) , which is based on a convex relaxation of the 0 ( quasi ) -norm , and Orthogonal Matching Pursuit ( OMP ) , a simple greedy strategy that iteratively selects basis vectors most aligned with the current residual ."]}
{"orig_sents": ["1", "4", "3", "5", "0", "2"], "shuf_sents": ["Learning and inference in the TDP , which has many potential applications beyond computer vision , is based on an empirically effective Gibbs sampler .", "Motivated by the problem of learning to detect and recognize objects with minimal supervision , we develop a hierarchical probabilistic model for the spatial structure of visual scenes .", "Applied to a dataset of partially labeled street scenes , we show that the TDP 's inclusion of spatial structure improves detection performance , flexibly exploiting partially labeled training images .", "Our scene model is based on the transformed Dirichlet process ( TDP ) , a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data .", "In contrast with most existing models , our approach explicitly captures uncertainty in the number of object instances depicted in a given image .", "For visual scenes , mixture components describe the spatial structure of visual features in an object-centered coordinate frame , while transformations model the object positions in a particular image ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We demonstrate the first fully hardware implementation of retinotopic self-organization , from photon transduction to neural map formation .", "A silicon retina transduces patterned illumination into correlated spike trains that drive a population of silicon growth cones to automatically wire a topographic mapping by migrating toward sources of a diffusible guidance cue that is released by postsynaptic spikes .", "We varied the pattern of illumination to steer growth cones projected by different retinal ganglion cell types to self-organize segregated or coordinated retinotopic maps ."]}
{"orig_sents": ["2", "0", "3", "1", "5", "4"], "shuf_sents": ["In our model the task parameters are assumed to be generated from independent sources which account for the relatedness of the tasks .", "Furthermore , our model enjoys a sparsity property which makes it both parsimonious and robust .", "We propose a probabilistic model based on Independent Component Analysis for learning multiple related tasks .", "We use Laplace distributions to model hidden sources which makes it possible to identify the hidden , independent components instead of just modeling correlations .", "Our experimental results on two multi-label text classification data sets show that the proposed approach is promising .", "We also propose efficient algorithms for both empirical Bayes method and point estimation ."]}
{"orig_sents": ["1", "3", "2", "5", "0", "4", "6"], "shuf_sents": ["We then build upon these data-independent conversions to derive and analyze data-driven conversions .", "Online learning algorithms are typically fast , memory efficient , and simple to implement .", "The power of online learning algorithms can be exploited in batch settings by using online-to-batch conversions techniques which build a new batch algorithm from an existing online algorithm .", "However , many common learning problems fit more naturally in the batch learning setting .", "Our conversions find hypotheses with a small risk by explicitly minimizing datadependent generalization bounds .", "We first give a unified overview of three existing online-to-batch conversion techniques which do not use training data in the conversion process .", "We experimentally demonstrate the usefulness of our approach and in particular show that the data-driven conversions consistently outperform the data-independent conversions ."]}
{"orig_sents": ["0", "6", "2", "3", "1", "7", "5", "4"], "shuf_sents": ["Probabilistic modeling of correlated neural population firing activity is central to understanding the neural code and building practical decoding algorithms .", "We evaluate the method using real data recorded from a population of motor cortical neurons .", "To address these problems we propose an energy-based model in which the joint probability of neural activity is represented using learned functions of the 1D marginal histograms of the data .", "The parameters of the model are learned using contrastive divergence and an optimization procedure for finding appropriate marginal directions .", "Our rich probabilistic model of neural population activity is a step towards both measurement of the importance of correlations in neural coding and improved decoding of population activity .", "These results suggest that our model captures correlations in the firing activity .", "No parametric models currently exist for modeling multivariate correlated neural data and the high dimensional nature of the data makes fully non-parametric methods impractical .", "In particular , we model the joint probability of population spiking times and 2D hand position and show that the likelihood of test data under our model is significantly higher than under other models ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["The technique is based on a probabilistic graphical model , which describes the data in terms of underlying evoked and interference sources , and explicitly models the stimulus evoked paradigm .", "This paper presents a novel technique for analyzing electromagnetic imaging data obtained using the stimulus evoked experimental paradigm .", "A variational Bayesian EM algorithm infers the model from data , suppresses interference sources , and reconstructs the activity of separated individual brain sources .", "The new algorithm outperforms existing techniques on two real datasets , as well as on simulated data ."]}
{"orig_sents": ["0", "5", "3", "1", "4", "2"], "shuf_sents": ["This paper proposes an algorithm to convert a T -stage stochastic decision problem with a continuous state space to a sequence of supervised learning problems .", "Thus the algorithm converts a reinforcement learning problem into simpler supervised learning subproblems .", "The implication of the proposed algorithm is that a plethora of classification methods can be applied to find policies in the reinforcement learning problem .", "The algorithm breaks a multistage reinforcement learning problem into a sequence of single-stage reinforcement learning subproblems , each of which is solved via an exact reduction to a weighted-classification problem that can be solved using off-the-self methods .", "It is shown that the method converges in a finite number of steps to a solution that can not be further improved by componentwise optimization .", "The optimization problem associated with the trajectory tree and random trajectory methods of Kearns , Mansour , and Ng , 2000 , is solved using the Gauss-Seidel method ."]}
{"orig_sents": ["5", "2", "4", "1", "3", "0"], "shuf_sents": ["The main result of the paper is the upper bound on the convergence rate for the generalization error .", "Mirror descent algorithms have been developed in different contexts and they are known to be particularly efficient in high dimensional problems .", "For this purpose , we propose a stochastic procedure , the mirror descent , which performs gradient descent in the dual space .", "Moreover their implementation is adapted to the online setting .", "The generated estimates are additionally averaged in a recursive fashion with specific weights .", "We consider the problem of constructing an aggregated estimator from a finite class of base functions which approximately minimizes a convex risk functional under the 1 constraint ."]}
{"orig_sents": ["5", "1", "2", "4", "0", "3"], "shuf_sents": ["Moreover , the exact methodology used reveals a simple renormalization step that improves approximate solutions obtained by any continuous method .", "As a cardinality-constrained and non-convex optimization problem , it is NP-hard and is encountered in a wide range of applied fields , from bio-informatics to finance .", "Recent progress has focused mainly on continuous approximation and convex relaxation of the hard cardinality constraint .", "The resulting performance gain of discrete algorithms is demonstrated on real-world benchmark data and in extensive Monte Carlo evaluation trials .", "In contrast , we consider an alternative discrete spectral formulation based on variational eigenvalue bounds and provide an effective greedy strategy as well as provably optimal solutions using branch-and-bound search .", "Sparse PCA seeks approximate sparse `` eigenvectors '' whose projections capture the maximal variance of data ."]}
{"orig_sents": ["1", "2", "7", "6", "5", "3", "4", "0"], "shuf_sents": ["Our new concept of interacting source analysis ( ISA ) is successfully demonstrated on MEG data .", "When trying to understand the brain , it is of fundamental importance to analyse ( e.g .", "from EEG/MEG measurements ) what parts of the cortex interact with each other in order to infer more accurate models of brain activity .", "For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization .", "The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction .", "Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction , this work aims to contribute by distinguishing these effects .", "However , physiologically interesting brain sources typically interact , so BSS will -- by construction -- fail to characterize them properly .", "Common techniques like Blind Source Separation ( BSS ) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence ."]}
{"orig_sents": ["1", "5", "7", "0", "6", "3", "4", "2", "8"], "shuf_sents": ["We use dendritic ( D- ) and back-propagating ( BP- ) spikes as post-synaptic signals in the learning rule and investigate how their interaction will influence plasticity .", "Recent experimental results suggest that dendritic and back-propagating spikes can influence synaptic plasticity in different ways .", "This way a winner-take-all-mechanism emerges in a two-stage process , enhancing the best-correlated inputs .", "Starting with weak synapses , which only elicit local D-spikes , a slow , unspecific growth process is induced .", "As soon as the soma begins to spike this process is replaced by fast synaptic changes as the consequence of the much stronger and sharper BP-spike , which now dominates the plasticity rule .", "In this study we investigate how these signals could temporally interact at dendrites leading to changing plasticity properties at local synapse clusters .", "We will analyze a situation where synapse plasticity characteristics change in the course of time , depending on the type of post-synaptic activity momentarily elicited .", "Similar to a previous study , we employ a differential Hebbian plasticity rule to emulate spike-timing dependent plasticity .", "These results suggest that synaptic plasticity is a temporal changing process by which the computational properties of dendrites or complete neurons can be substantially augmented ."]}
{"orig_sents": ["0", "2", "3", "4", "1", "5", "6"], "shuf_sents": ["This paper introduces Gaussian Process Dynamical Models ( GPDM ) for nonlinear time series analysis .", "We demonstrate the approach on human motion capture data in which each pose is 62-dimensional .", "A GPDM comprises a low-dimensional latent space with associated dynamics , and a map from the latent space to an observation space .", "We marginalize out the model parameters in closed-form , using Gaussian Process ( GP ) priors for both the dynamics and the observation mappings .", "This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model .", "Despite the use of small data sets , the GPDM learns an effective representation of the nonlinear dynamics in these spaces .", "Webpage : http : //www.dgp.toronto.edu/ jmwang/gpdm/"]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We apply this model to clinical time series data and show it to be effective in identifying a number of artifactual and physiological patterns .", "The observed physiological dynamics of an infant receiving intensive care are affected by many possible factors , including interventions to the baby , the operation of the monitoring equipment and the state of health .", "The Factorial Switching Kalman Filter can be used to infer the presence of such factors from a sequence of observations , and to estimate the true values where these observations have been corrupted ."]}
{"orig_sents": ["5", "4", "6", "0", "7", "3", "1", "2"], "shuf_sents": ["Robotic arms based on the same mechanical principles may render present day robotic arms obsolete .", "Even with the simplifications inherent to this model , the state space we face is a high-dimensional one .", "We apply a GPTDbased algorithm to this domain , and demonstrate its operation on several learning tasks of varying degrees of difficulty .", "Our substitute for the real arm is a computer simulation of a 2-dimensional model of an Octopus arm .", "How the Octopus controls such a hyper-redundant arm ( not to mention eight of them ! )", "The Octopus arm is a highly versatile and complex limb .", "is as yet unknown .", "In this paper , we tackle this control problem using an online reinforcement learning algorithm , based on a Bayesian approach to policy evaluation known as Gaussian process temporal difference ( GPTD ) learning ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["We then derive a performance bound to assess how well the approximation performs for any given number of agents .", "We apply our method to an important class of problems in applied microeconomics .", "We provide conditions that guarantee our method approximates an equilibrium as the number of agents grow .", "We show with numerical experiments that we are able to greatly expand the set of economic problems that can be analyzed computationally .", "We propose a mean-field approximation that dramatically reduces the computational complexity of solving stochastic dynamic games ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["Experiments on extracting protein interactions from biomedical corpora and top-level relations from newspaper corpora demonstrate the advantages of this approach .", "We present a new kernel method for extracting semantic relations between entities in natural language text , based on a generalization of subsequence kernels .", "This kernel uses three types of subsequence patterns that are typically employed in natural language to assert relationships between two entities ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We present experimental results on inference and estimation of the partition function for sparse and densely-connected graphs .", "While the idea of using `` tempered '' proposals is known , we construct a novel sequence of target distributions where , rather than dropping a global temperature parameter , we sequentially couple individual pairs of variables that are , initially , sampled exactly from a spanning tree of the variables .", "The algorithm fits into the framework of sequential Monte Carlo methods rather than the more widely used MCMC , and relies on constructing a sequence of intermediate distributions which get closer to the desired one .", "This paper presents a new sampling algorithm for approximating functions of variables representable as undirected graphical models of arbitrary connectivity with pairwise potentials , as well as for estimating the notoriously difficult partition function of the graph ."]}
{"orig_sents": ["2", "0", "4", "3", "1"], "shuf_sents": ["This decomposition , based on a recursive pruning of the least connected vertices , allows to disentangle the hierarchical structure of networks by progressively focusing on their central cores .", "We show how the proposed visualization tool allows to find specific structural fingerprints of networks .", "We use the k-core decomposition to develop algorithms for the analysis of large scale complex networks .", "The low computational complexity of the algorithm , O ( n + e ) , where n is the size of the network , and e is the number of edges , makes it suitable for the visualization of very large sparse networks .", "By using this strategy we develop a general visualization algorithm that can be used to compare the structural properties of various networks and highlight their hierarchical structure ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["When compared to the i.i.d .", "but come from empirical processes of stationary -mixing sequences .", "case , the nature of sampling manifests in the consistency result only through generalization of the original condition on the growth of the regularization parameter .", "Utilizing a technique that constructs a sequence of independent blocks close in distribution to the original samples , we prove the consistency of the composite classifiers resulting from a regularization achieved by restricting the 1-norm of the base classifiers ' weights .", "We study the statistical convergence and consistency of regularized Boosting methods , where the samples are not independent and identically distributed ( i.i.d . )"]}
{"orig_sents": ["1", "6", "5", "2", "4", "3", "0"], "shuf_sents": ["We also include some experiments to illustrate that other nonlinear detectors such as those based on Support Vector Machines ( SVMs ) exhibit a worse performance .", "In this paper we propose a new receiver for digital communications .", "While usual approaches minimize the mean square error ( MMSE ) to linearly retrieve the user of interest , we exploit the same criteria but in the design of a nonlinear MUD .", "Furthermore , the GP based MUD achieves excellent interference suppression even for short training sequences .", "Since the optimal solution is known to be nonlinear , the performance of this novel method clearly improves that of the MMSE detectors .", "Hence , we aim to reduce the interference from other users sharing the same frequency band .", "We focus on the application of Gaussian Processes ( GPs ) to the multiuser detection ( MUD ) in code division multiple access ( CDMA ) systems to solve the near-far problem ."]}
{"orig_sents": ["5", "0", "4", "2", "3", "1"], "shuf_sents": ["Robust Fisher LDA can systematically alleviate the sensitivity problem by explicitly incorporating a model of data uncertainty in a classification problem and optimizing for the worst-case scenario under this model .", "Finally , we show how to extend these results to robust kernel Fisher discriminant analysis , i.e. , robust Fisher LDA in a high dimensional feature space .", "For a certain type of product form uncertainty model , robust Fisher LDA can be carried out at a cost comparable to standard Fisher LDA .", "The method is demonstrated with some numerical examples .", "The main contribution of this paper is show that with general convex uncertainty models on the problem data , robust Fisher LDA can be carried out using convex optimization .", "Fisher linear discriminant analysis ( LDA ) can be sensitive to the problem data ."]}
{"orig_sents": ["1", "2", "6", "3", "7", "5", "0", "4"], "shuf_sents": ["Curiously enough this expected variance calculation is a quantum measurement where the co-variance matrix specifies the instrument and the prior density matrix the mixture state of the particle .", "The classical Bayes rule computes the posterior model probability from the prior probability and the data likelihood .", "We generalize this rule to the case when the prior is a density matrix ( symmetric positive definite and trace one ) and the data likelihood a covariance matrix .", "In the classical setting , the calculation of the probability of the data is an expected likelihood , where the expectation is over the prior distribution .", "We motivate both the classical and the generalized Bayes rule with a minimum relative entropy principle , where the Kullbach-Leibler version gives the classical Bayes rule and Umegaki 's quantum relative entropy the new Bayes rule for density matrices .", "The variances along any direction is determined by the covariance matrix .", "The classical Bayes rule is retained as the special case when the matrices are diagonal .", "In the generalized setting , this is replaced by an expected variance calculation where the variance is computed along the eigenvectors of the prior density matrix and the expectation is over the eigenvalues of the density matrix ( which form a probability vector ) ."]}
{"orig_sents": ["4", "3", "0", "1", "2"], "shuf_sents": ["The projection step can be solved using combinatorial algorithms for min-cost quadratic flow .", "This makes the approach an efficient alternative to formulations based on reductions to a quadratic program ( QP ) .", "We present experiments on two very different structured prediction tasks : 3D image segmentation and word alignment , illustrating the favorable scaling properties of our algorithm .", "We formulate the estimation problem as a convex-concave saddle-point problem and apply the extragradient method , yielding an algorithm with linear convergence using simple gradient and projection calculations .", "We present a simple and scalable algorithm for large-margin estimation of structured models , including an important class of Markov networks and combinatorial models ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["The metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin .", "On seven data sets of varying size and difficulty , we find that metrics trained in this way lead to significant improvements in kNN classification -- for example , achieving a test error rate of 1.3 % on the MNIST handwritten digits .", "We show how to learn a Mahanalobis distance metric for k-nearest neighbor ( kNN ) classification by semidefinite programming .", "As in support vector machines ( SVMs ) , the learning problem reduces to a convex optimization based on the hinge loss .", "Unlike learning in SVMs , however , our framework requires no modification or extension for problems in multiway ( as opposed to binary ) classification ."]}
{"orig_sents": ["2", "5", "1", "6", "3", "0", "4"], "shuf_sents": ["Our model has been carefully tested on standard datasets ; we compare with a number of recent template models .", "The complexity of the model in the number of features is low , meaning our model is much more efficient to train than comparative methods .", "We describe a novel method for learning templates for recognition and localization of objects drawn from categories .", "This results in both accuracy and localization improvements .", "In particular , we demonstrate state-of-the-art results for detection and localization .", "A generative model represents the configuration of multiple object parts with respect to an object coordinate system ; these parts in turn generate image features .", "Moreover , a variational approximation is introduced that allows learning to be orders of magnitude faster than previous approaches while incorporating many more features ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["Images represent an important and abundant source of data .", "In this paper we propose a particular kind of probabilistic model , dubbed the `` products of edge-perts model '' to describe the structure of wavelet transformed images .", "We develop a practical denoising algorithm based on a single edge-pert and show state-ofthe-art denoising performance on benchmark images .", "Understanding their statistical structure has important applications such as image compression and restoration ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["We present a competitive analysis of some non-parametric Bayesian algorithms in a worst-case online learning setting , where no probabilistic assumptions about the generation of the data are made .", "Here , we show precisely how Bayesian Gaussian regression is a minimax strategy .", "These bounds explicitly handle the infinite dimensionality of these non-parametric classes in a natural way .", "We also make formal connections to the minimax and minimum description length ( MDL ) framework .", "We consider models which use a Gaussian process prior ( over the space of all functions ) and provide bounds on the regret ( under the log loss ) for commonly used non-parametric Bayesian algorithms -- including Gaussian regression and logistic regression -- which show how these algorithms can perform favorably under rather general conditions ."]}
{"orig_sents": ["4", "0", "5", "6", "1", "7", "3", "2"], "shuf_sents": ["It has yet to be seen whether object identity can be inferred from this activity .", "Since this approach is sensitive to the inclusion of noisy voxels , we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity .", "The mutual information metric is less efficient at this task , likely due to constraints in fMRI data .", "We find that both metrics can identify subsets of the data which reliably encode object identity , even when noisy measurements are artificially added to the data .", "The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex .", "We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images .", "We use a simple winner-take-all classifier , using half the data from each recording session as a training set , to evaluate encoding of object identity across fMRI voxels .", "One method characterizes the reliability of each voxel within subsets of the data , while another estimates the mutual information of each voxel with the stimulus set ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["This problem involves an infinite number of variables , but can be solved by incrementally inserting a hidden unit at a time , each time finding a linear classifier that minimizes a weighted sum of errors .", "We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem .", "Convexity has recently received a lot of attention in the machine learning community , and the lack of convexity has been seen as a major disadvantage of many learning algorithms , such as multi-layer artificial neural networks ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["In our system model , a data center acquires data from a bunch of L sensors which each independently encode their noisy observations of an original binary sequence , and transmit their encoded data sequences to the data center at a combined rate R , which is limited .", "Supposing that the sensors use independent LDGM rate distortion codes , we show that the system performance can be evaluated for any given finite R when the number of sensors L goes to infinity .", "The analysis shows how the optimal strategy for the distributed sensing problem changes at critical values of the data rate R or the noise level .", "This paper provides a system-level analysis of a scalable distributed sensing model for networked sensors ."]}
{"orig_sents": ["5", "2", "0", "1", "4", "3"], "shuf_sents": ["We formally obtain the optimal cue selection strategy by maximizing the signal to noise ratio ( SN R ) between a search target and surrounding distractors .", "This optimal strategy successfully accounts for several phenomena in visual search behavior , including the effect of target-distractor discriminability , uncertainty in target 's features , distractor heterogeneity , and linear separability .", "We investigate whether our visual system selects cues that guide search in an optimal manner .", "Our results provide direct experimental evidence that humans select visual cues so as to maximize SN R between the targets and surrounding clutter .", "Furthermore , the theory generates a new prediction , which we verify through psychophysical experiments with human subjects .", "Survival in the natural world demands the selection of relevant visual cues to rapidly and reliably guide attention towards prey and predators in cluttered environments ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["We present an analogue very large scale integrated ( aVLSI ) circuit model of this process and show that results from testing the circuit agree with simulation and what is known from the behaviour and physiology of the cricket auditory system .", "Female crickets can locate males by phonotaxis to the mating song they produce .", "The aVLSI circuitry is now being extended to use on a robot along with previously modelled neural circuitry to better understand the complete sensorimotor pathway .", "The behaviour and underlying physiology has been studied in some depth showing that the cricket auditory system solves this complex problem in a unique manner ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["We propose efficient algorithms for learning ranking functions from order constraints between sets -- i.e .", "Experiments on public benchmarks indicate that : ( a ) the proposed algorithm is at least as accurate as the current state-of-the-art ; ( b ) computationally , it is several orders of magnitude faster and -- unlike current methods -- it is easily able to handle even large datasets with over 20,000 samples .", "Our algorithms may be used for maximizing the generalized Wilcoxon Mann Whitney statistic that accounts for the partial ordering of the classes : special cases include maximizing the area under the ROC curve for binary classification and its generalization for ordinal regression .", "classes -- of training samples ."]}
{"orig_sents": ["2", "0", "1", "4", "6", "5", "3"], "shuf_sents": ["The model is biologically plausible and implements an artificial retina and a neuronal population code .", "The BU component is based on featurecontrast .", "To investigate how top-down ( TD ) and bottom-up ( BU ) information is weighted in the guidance of human search behavior , we manipulated the proportions of BU and TD components in a saliency-based model .", "Only when biological constraints are removed ( e.g. , eliminating the retina ) did a BU/TD mixture model begin to approximate human behavior .", "The TD component is defined by a feature-template match to a stored target representation .", "We found that a purely TD model provides a much closer match to human behavior than any mixture model using BU information .", "We compared the model 's behavior at different mixtures of TD and BU components to the eye movement behavior of human observers performing the identical search task ."]}
{"orig_sents": ["4", "5", "2", "0", "1", "3"], "shuf_sents": ["In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a fixed memory budget .", "To our knowledge , this is the first online learning algorithm which , on one hand , maintains a strict limit on the number of examples it stores while , on the other hand , entertains a relative mistake bound .", "However , a common difficulty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis , which may grow unboundedly .", "In addition to the formal results , we also present experiments with real datasets which underscore the merits of our approach .", "The Perceptron algorithm , despite its simplicity , often performs well on online classification tasks .", "The Perceptron becomes especially effective when it is used in conjunction with kernels ."]}
{"orig_sents": ["1", "2", "5", "3", "4", "0"], "shuf_sents": ["We perform more psychophysical experiments which are consistent with humans using a Slow-and-Smooth model and which rule out an alternative model using Slowness .", "We derive a Bayesian Ideal Observer ( BIO ) for detecting motion and solving the correspondence problem .", "We obtain Barlow and Tripathy 's classic model as an approximation .", "We investigate ways to degrade the Bayesian Ideal but show that even extreme degradations do not approach human performance .", "Instead we propose that humans perform motion tasks using generic , general purpose , models of motion .", "Our psychophysical experiments show that the trends of human performance are similar to the Bayesian Ideal , but overall human performance is far worse ."]}
{"orig_sents": ["4", "1", "3", "2", "0"], "shuf_sents": ["A modified version that replaces hard with soft thresholding effectively solves a sequence of lasso problems .", "The approach is based on the technique of incrementally decreasing the bandwidth in directions where the gradient of the estimator with respect to bandwidth is large .", "The method -- called rodeo ( regularization of derivative expectation operator ) -- conducts a sequence of hypothesis tests , and is easy to implement .", "When the unknown function satisfies a sparsity condition , our approach avoids the curse of dimensionality , achieving the optimal minimax rate of convergence , up to logarithmic factors , as if the relevant variables were known in advance .", "We present a method for nonparametric regression that performs bandwidth selection and variable selection simultaneously ."]}
{"orig_sents": ["5", "2", "1", "4", "3", "0"], "shuf_sents": ["Previous results can be used to determine convergence and to estimate convergence rates .", "Our results involve genericity assumptions on the distributions of causes .", "Our approach involves augmenting variables to deal with conjunctions of causes , similar to the agumented model of Rescorla .", "Moreover , a nonlinear Rescorla-Wagner is able to estimate the parameters directly to within arbitrary accuracy .", "If these assumptions are violated , for example for the Cheng causal power theory , then we show that a linear Rescorla-Wagner can estimate the parameters of the model up to a nonlinear transformtion .", "We show that linear generalizations of Rescorla-Wagner can perform Maximum Likelihood estimation of the parameters of all generative models for causal reasoning ."]}
{"orig_sents": ["1", "4", "0", "3", "5", "2", "6"], "shuf_sents": ["These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set .", "We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality , or more precisely to the variability of the target .", "their Kolmogorov complexity may be low .", "This makes them sensitive to the curse of dimensionality , well studied for classical non-parametric statistical learning .", "Our discussion covers supervised , semisupervised and unsupervised learning algorithms .", "We show in the case of the Gaussian kernel that when the function to be learned has many variations , these algorithms require a number of training examples proportional to the number of variations , which could be large even though there may exist short descriptions of the target function , i.e .", "This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions ( because locally they have many variations ) , while not using very specific prior domain knowledge ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["The approach leads to a novel message-passing algorithm to be executed offline , or before observations are realized , which mitigates the performance loss by iteratively coupling all rules in a manner implicitly driven by global statistics .", "Given a directed graphical model with binary-valued hidden nodes and real-valued noisy observations , consider deciding upon the maximum a-posteriori ( MAP ) or the maximum posterior-marginal ( MPM ) assignment under the restriction that each node broadcasts only to its children exactly one single-bit message .", "We present a variational formulation , viewing the processing rules local to all nodes as degrees-of-freedom , that minimizes the loss in expected ( MAP or MPM ) performance subject to such online communication constraints .", "We also provide ( i ) illustrative examples , ( ii ) assumptions that guarantee convergence and efficiency and ( iii ) connections to active research areas ."]}
{"orig_sents": ["3", "4", "2", "0", "1"], "shuf_sents": ["Experiments demonstrate perceptually clear ( 12dB ) separation and precise localization of two speech sources presented through speakers positioned at 1.5m from the array on a conference room table .", "Analysis of the multipath residuals shows that they are spectrally diffuse , and void of the direct path .", "The gradient flow and ICA processors each measure 3mm x 3mm in 0.5 m CMOS , and consume 54 W and 180 W power , respectively , from a 3 V supply at 16 ks/s sampling rate .", "We present micropower mixed-signal VLSI hardware for real-time blind separation and localization of acoustic sources .", "Gradient flow representation of the traveling wave signals acquired over a miniature ( 1cm diameter ) array of four microphones yields linearly mixed instantaneous observations of the time-differentiated sources , separated and localized by independent component analysis ( ICA ) ."]}
{"orig_sents": ["0", "2", "6", "5", "4", "1", "3"], "shuf_sents": ["Fast and frugal heuristics are well studied models of bounded rationality .", "We further consider a greedy approach for building lexicographic strategies and derive tight bounds for the performance ratio of a new and simple algorithm .", "Psychological research has proposed the take-the-best heuristic as a successful strategy in decision making with limited resources .", "This algorithm is proven to perform better than take-the-best .", "We show that no efficient algorithm can approximate the optimum to within any constant factor , if P = NP .", "We investigate the complexity of the problem of approximating optimal cue permutations for lexicographic strategies .", "Take-thebest searches for a sufficiently good ordering of cues ( features ) in a task where objects are to be compared lexicographically ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["Our model includes potentials that capture low-level similarity , mid-level curvilinear continuity and high-level object shape .", "We present a model of edge and region grouping using a conditional random field built over a scale-invariant representation of images to integrate multiple cues .", "Using held out test data , we quantify the information gained by incorporating generic mid-level cues and high-level shape .", "Maximum likelihood parameters for the model are learned from human labeled groundtruth on a large collection of horse images using belief propagation ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We present a Bayesian framework for explaining how people reason about and predict the actions of an intentional agent , based on observing its behavior .", "Action-understanding is cast as a problem of inverting a probabilistic generative model , which assumes that agents tend to act rationally in order to achieve their goals given the constraints of their environment .", "The model provides a qualitative account of several kinds of inferences that preverbal infants have been shown to perform , and also fits quantitative predictions that adult observers make in a new experiment .", "Working in a simple sprite-world domain , we show how this model can be used to infer the goal of an agent and predict how the agent will act in novel situations or when environmental constraints change ."]}
{"orig_sents": ["1", "4", "2", "3", "5", "0"], "shuf_sents": ["Experiments on real NLP tasks confirm the problem in the conventional method and compare the performance of a conventional method to that of the proposed method .", "This paper proposes a new approach to feature selection based on a statistical feature mining technique for sequence and tree kernels .", "However , experiments have shown that the best results can only be achieved when limited small sub-structures are dealt with by these kernels .", "This paper discusses this issue of convolution kernels and then proposes a statistical feature selection that enable us to use larger sub-structures effectively .", "Since natural language data take discrete structures , convolution kernels , such as sequence and tree kernels , are advantageous for both the concept and accuracy of many natural language processing tasks .", "The proposed method , in order to execute efficiently , can be embedded into an original kernel calculation process by using sub-structure mining algorithms ."]}
{"orig_sents": ["4", "0", "5", "3", "6", "2", "1"], "shuf_sents": ["We formulate this as a Bayesian inference problem and describe a very simple algorithm for solving it .", "We compare to GoogleTM Sets and show that Bayesian Sets gives very reasonable set completions .", "We evaluate our algorithm on three datasets : retrieving movies from EachMovie , finding completions of author sets from the NIPS dataset , and finding completions of sets of words appearing in the Grolier encyclopedia .", "For exponential family models with conjugate priors this marginal probability is a simple function of sufficient statistics .", "Inspired by `` GoogleTM Sets '' , we consider the problem of retrieving items from a concept or cluster , given a query consisting of a few items from that cluster .", "Our algorithm uses a modelbased concept of a cluster and ranks items using a score which evaluates the marginal probability that each item belongs to a cluster containing the query items .", "We focus on sparse binary data and show that our score can be evaluated exactly using a single sparse matrix multiplication , making it possible to apply our algorithm to very large datasets ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["Numerical examples are given to illustrate the efficiency and effectiveness of the proposed methods .", "We provide a detailed analysis to assess the errors produced by the gluing process using matrix perturbation theory .", "We propose a fast manifold learning algorithm based on the methodology of domain decomposition .", "Starting with the set of sample points partitioned into two subdomains , we develop the solution of the interface problem that can glue the embeddings on the two subdomains into an embedding on the whole domain ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["We demonstrate that the Bayesian statistic has several advantages over the frequentist approach , including increased power to detect clusters and ( since randomization testing is unnecessary ) much faster runtime .", "We evaluate the Bayesian and frequentist methods on the task of prospective disease surveillance : detecting spatial clusters of disease cases resulting from emerging disease outbreaks .", "We propose a new Bayesian method for spatial cluster detection , the `` Bayesian spatial scan statistic , '' and compare this method to the standard ( frequentist ) scan statistic approach .", "We demonstrate that our Bayesian methods are successful in rapidly detecting outbreaks while keeping number of false positives low ."]}
{"orig_sents": ["0", "2", "5", "1", "4", "3"], "shuf_sents": ["We present a probabilistic generative model of entity relationships and their attributes that simultaneously discovers groups among the entities and topics among the corresponding textual attributes .", "Significantly , joint inference allows the discovery of topics to be guided by the emerging groups , and vice-versa .", "Block-models of relationship data have been studied in social network analysis for some time .", "We show that in comparison with traditional , separate latent-variable models for words , or Blockstructures for votes , the Group-Topic model 's joint inference discovers more cohesive groups and improved topics .", "We present experimental results on two large data sets : sixteen years of bills put before the U.S. Senate , comprising their corresponding text and voting records , and thirteen years of similar data from the United Nations .", "Here we simultaneously cluster in several modalities at once , incorporating the attributes ( here , words ) associated with certain relationships ."]}
{"orig_sents": ["3", "1", "0", "5", "6", "2", "4"], "shuf_sents": ["Unlike standard generalization error , this off-training-set error may differ significantly from the empirical error with high probability even with large sample sizes .", "cases that are different from those in the training set .", "As we demonstrate on UCI data-sets , our bound gives nontrivial generalization guarantees in many practical cases .", "We analyze classification error on unseen cases , i.e .", "In light of these results , we show that certain claims made in the No Free Lunch literature are overly pessimistic .", "We derive a datadependent bound on the difference between off-training-set and standard generalization error .", "Our result is based on a new bound on the missing mass , which for small samples is stronger than existing bounds based on Good-Turing estimators ."]}
{"orig_sents": ["2", "4", "0", "5", "6", "3", "1"], "shuf_sents": ["We describe a formal Bayesian definition of surprise that is the only consistent formulation under minimal axiomatic assumptions .", "The resulting theory of surprise is applicable across different spatio-temporal scales , modalities , and levels of abstraction .", "The concept of surprise is central to sensory processing , adaptation , learning , and attention .", "We find that subjects are strongly attracted towards surprising locations , with 72 % of all human gaze shifts directed towards locations more surprising than the average , a figure which rises to 84 % when considering only gaze targets simultaneously selected by all subjects .", "Yet , no widely-accepted mathematical theory currently exists to quantitatively characterize surprise elicited by a stimulus or event , for observers that range from single neurons to complex natural or engineered systems .", "Surprise quantifies how data affects a natural or artificial observer , by measuring the difference between posterior and prior beliefs of the observer .", "Using this framework we measure the extent to which humans direct their gaze towards surprising items while watching television and video games ."]}
{"orig_sents": ["0", "4", "2", "5", "3", "1"], "shuf_sents": ["Spiking activity from neurophysiological experiments often exhibits dynamics beyond that driven by external stimulation , presumably reflecting the extensive recurrence of neural circuitry .", "These methods are applied to characterize the dynamics in PMd data recorded from a chronically-implanted 96-electrode array while monkeys perform delayed-reach tasks .", "For example , the activity of premotor cortex ( PMd ) neurons during an instructed delay period separating movement-target specification and a movementinitiation cue is believed to be involved in motor planning .", "We present and validate latent variable methods that simultaneously estimate the system parameters and the trial-by-trial dynamical trajectories .", "Characterizing these dynamics may reveal important features of neural computation , particularly during internally-driven cognitive operations .", "We show that the dynamics underlying this activity can be captured by a lowdimensional non-linear dynamical systems model , with underlying recurrent structure and stochastic point-process output ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We investigate under what conditions a neuron can learn by experimentally supported rules for spike timing dependent plasticity ( STDP ) to predict the arrival times of strong `` teacher inputs '' to the same neuron .", "This criterion is reminiscent of the linear separability criterion of the Perceptron Convergence Theorem , but it applies here to the rows of a correlation matrix related to the spike inputs .", "It turns out that in contrast to the famous Perceptron Convergence Theorem , which predicts convergence of the perceptron learning rule for a simplified neuron model whenever a stable solution exists , no equally strong convergence guarantee can be given for spiking neurons with STDP .", "But we derive a criterion on the statistical dependency structure of input spike trains which characterizes exactly when learning with STDP will converge on average for a simple model of a spiking neuron .", "In addition we show through computer simulations for more realistic neuron models that the resulting analytically predicted positive learning results not only hold for the common interpretation of STDP where STDP changes the weights of synapses , but also for a more realistic interpretation suggested by experimental data where STDP modulates the initial release probability of dynamic synapses ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["In our experiments the resulting algorithms outperform previously employed online stochastic , offline conjugate , and natural policy gradient methods .", "Reinforcement learning by direct policy gradient estimation is attractive in theory but in practice leads to notoriously ill-behaved optimization problems .", "We improve its robustness and speed of convergence with stochastic meta-descent , a gain vector adaptation method that employs fast Hessian-vector products ."]}
{"orig_sents": ["3", "1", "2", "6", "0", "5", "4"], "shuf_sents": ["Our generalization is based on the options framework for temporal abstraction .", "Temporal-difference ( TD ) networks have been proposed as a way of representing and learning a wide variety of predictions about the interaction between an agent and its environment .", "These predictions are compositional in that their targets are defined in terms of other predictions , and subjunctive in that that they are about what would happen if an action or sequence of actions were taken .", "We present a generalization of temporal-difference networks to include temporally abstract options on the links of the question network .", "We present empirical examples of our algorithm 's effectiveness and of the greater representational expressiveness of temporallyabstract TD networks .", "The primary contribution of this paper is to introduce a new algorithm for intra-option learning in TD networks with function approximation and eligibility traces .", "In conventional TD networks , the inter-related predictions are at successive time steps and contingent on a single action ; here we generalize them to accommodate extended time intervals and contingency on whole ways of behaving ."]}
{"orig_sents": ["3", "6", "1", "0", "7", "5", "4", "2"], "shuf_sents": ["We propose an alternative , acceleration based , parameterization that does not suffer from this deficiency , and that can be learned as efficiently from data .", "First , we consider the linear models such as learned by CIFER ( the industry standard in helicopter identification ) , and show that the linear parameterization makes certain properties of dynamical systems , such as inertia , fundamentally difficult to capture .", "Although this work was motivated by the problem of modeling helicopters , the ideas presented here are general , and can be applied to modeling large classes of vehicular dynamics .", "We consider the problem of modeling a helicopter 's dynamics based on state-action trajectories collected from it .", "We present empirical results on two different helicopters .", "In this paper , we present an efficient algorithm for ( approximately ) minimizing the prediction error over long time scales .", "The contribution of this paper is two-fold .", "Second , a Markov decision process model of a helicopter 's dynamics would explicitly model only the one-step transitions , but we are often interested in a model 's predictive performance over longer timescales ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We illustrate the result with an example .", "We prove that if we let the Gaussian bandwidth while letting the regularization parameter 0 , the RLS solution tends to a polynomial whose order is controlled by the rielative rates of decay of 12 and : if = - ( 2k+1 ) , then , as , the RLS solution tends to the kth order polynomial with minimal empirical error .", "We consider regularized least-squares ( RLS ) with a Gaussian kernel ."]}
{"orig_sents": ["4", "2", "1", "0", "3"], "shuf_sents": ["This paper takes this observation to its logical conclusion and proposes a method that combines this two stage learning ( KCCA followed by SVM ) into a single optimisation termed SVM-2K .", "When two views of the same phenomenon are available kernel Canonical Correlation Analysis ( KCCA ) has been shown to be an effective preprocessing step that can improve the performance of classification algorithms such as the Support Vector Machine ( SVM ) .", "This raises the question of how we can identify the relevant subspaces for a particular learning task .", "We present both experimental and theoretical analysis of the approach showing encouraging results and insights .", "Kernel methods make it relatively easy to define complex highdimensional feature spaces ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["The proposed operation is based on Shannon 's self-information measure and is achieved in a neural circuit , which is demonstrated as having close ties with the circuitry existent in the primate visual cortex .", "Resu lts on natural images are compared with experimental eye tracking data revealing the efficacy of the model in predicting the deployment of overt attention as compared with existing efforts .", "It is further shown that the proposed saliency measure may be extended to address issues that currently elude explanation in the domain of saliency based models .", "A model of bottom-up overt attention is proposed based on the principle of maximizing information sampled from a scene ."]}
{"orig_sents": ["4", "3", "2", "5", "0", "1"], "shuf_sents": ["In addition to examining the theoretical potential of active learning , this paper describes a practical algorithm capable of exploiting the extra flexibility of the active setting and provably improving upon the classical passive techniques .", "Our active learning theory and methods show promise in a number of applications , including field estimation using wireless sensor networks and fault line detection .", "In some regimes , this extra flexibility leads to significantly faster rates of error decay than those possible in classical passive learning settings .", "Active learning algorithms are able to make queries or select sample locations in an online fashion , depending on the results of the previous queries .", "This paper presents a rigorous statistical analysis characterizing regimes in which active learning significantly outperforms classical passive learning .", "The nature of these regimes is explored by studying fundamental performance limits of active and passive learning in two illustrative nonparametric function classes ."]}
{"orig_sents": ["4", "1", "0", "2", "3"], "shuf_sents": ["In this work , we introduce the layered dynamic texture model , which addresses this problem .", "One problem associated with the dynamic texture is that it can not model video where there are multiple regions of distinct motion .", "We also introduce a variant of the model , and present the EM algorithm for learning each of the models .", "Finally , we demonstrate the efficacy of the proposed model for the tasks of segmentation and synthesis of video .", "A dynamic texture is a video model that treats a video as a sample from a spatio-temporal stochastic process , specifically a linear dynamical system ."]}
{"orig_sents": ["3", "4", "2", "0", "1"], "shuf_sents": ["We provide a walk-sum interpretation of Gaussian belief propagation in trees and of the approximate method of loopy belief propagation in graphs with cycles .", "This perspective leads to a better understanding of Gaussian belief propagation and of its convergence in loopy graphs .", "The weight of each walk is given by a product of edgewise partial correlations .", "This paper presents a new framework based on walks in a graph for analysis and inference in Gaussian graphical models .", "The key idea is to decompose correlations between variables as a sum over all walks between those variables in the graph ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["In this paper , we demonstrate by construction that existing variants of value iteration can not find stationary equilibrium policies in arbitrary general-sum Markov games .", "Although variants of value iteration have been proposed for finding Nash or correlated equilibria in general-sum Markov games , these variants have not been shown to be effective in general .", "We also demonstrate empirically that value iteration finds cyclic equilibria in nearly all examples drawn from a random distribution of Markov games .", "Instead , we propose an alternative interpretation of the output of value iteration based on a new ( non-stationary ) equilibrium concept that we call `` cyclic equilibria . ''", "We prove that value iteration identifies cyclic equilibria in a class of games in which it fails to find stationary equilibria ."]}
{"orig_sents": ["3", "0", "1", "5", "4", "2"], "shuf_sents": ["Therefore they could provide a new communication and control option for paralyzed patients .", "Modern BCI technology is essentially based on techniques for the classification of single-trial brain signals .", "Apart from the enhanced classification , the spatial and/or the spectral filter that are determined by the algorithm can also be used for further analysis of the data , e.g. , for source localization of the respective brain rhythms .", "Brain-Computer Interface ( BCI ) systems create a novel communication channel from the brain to an output device by bypassing conventional motor output pathways of nerves and muscles .", "The evaluation of 60 experiments involving 22 different subjects demonstrates the superiority of the proposed algorithm .", "Here we present a novel technique that allows the simultaneous optimization of a spatial and a spectral filter enhancing discriminability of multi-channel EEG single-trials ."]}
{"orig_sents": ["0", "1", "4", "2", "3"], "shuf_sents": ["This paper describes a highly successful application of MRFs to the problem of generating high-resolution range images .", "A new generation of range sensors combines the capture of low-resolution range images with the acquisition of registered high-resolution camera images .", "This enables it to generate high-resolution , low-noise range images by integrating regular camera images into the range data .", "We show that by using such an MRF , we can substantially improve over existing range imaging technology .", "The MRF in this paper exploits the fact that discontinuities in range and coloring tend to co-align ."]}
{"orig_sents": ["7", "3", "6", "4", "2", "1", "0", "5"], "shuf_sents": ["Given two images , the responses of the split predictors are combined with a Bayesian rule into a posterior probability of similarity .", "Those splits are extended to the complete image space with a simple learning algorithm .", "It relies on hundreds of random binary splits of the training set chosen to keep together the images of any given object .", "Instead of using a large number of pictures of the object to recognize , we use a labeled reference database of pictures of other objects to learn invariance to noise and variations in pose and illumination .", "We propose a generic scheme called chopping to address this task .", "Experiments with the COIL-100 database and with a database of 150 degraded LATEX symbols compare our method to a classical learning with several examples of the positive class and to a direct learning of the similarity .", "This acquired knowledge is then used to predict if two pictures of new objects , which do not appear on the training pictures , actually display the same object .", "We investigate the learning of the appearance of an object from a single image of it ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We prove the strongest known bound for the risk of hypotheses selected from the ensemble generated by running a learning algorithm incrementally on the training data .", "Our result is based on proof techniques that are remarkably different from the standard risk analysis based on uniform convergence arguments ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We present a novel cochlear model implemented in analog very large scale integration ( VLSI ) technology that emulates nonlinear active cochlear behavior .", "This silicon cochlea includes outer hair cell ( OHC ) electromotility through active bidirectional coupling ( ABC ) , a mechanism we proposed in which OHC motile forces , through the microanatomical organization of the organ of Corti , realize the cochlear amplifier .", "Our chip measurements demonstrate that frequency responses become larger and more sharply tuned when ABC is turned on ; the degree of the enhancement decreases with input intensity as ABC includes saturation of OHC forces ."]}
{"orig_sents": ["3", "0", "4", "2", "1", "5"], "shuf_sents": ["Linear analysis techniques remain prevalent in such cases , but classical linear regression approaches are often numerically too fragile in high dimensions .", "In comparison with ordinary least squares , stepwise regression , partial least squares , LASSO regression and a brute force combinatorial search for the most predictive input features in the data , we demonstrate that the new Bayesian method offers a superior mixture of characteristics in terms of regularization against overfitting , computational efficiency and ease of use , demonstrating its potential as a drop-in replacement for other linear regression techniques .", "To achieve robust data analysis , we develop a full Bayesian approach to linear regression that automatically detects and excludes irrelevant features in the data , regularizing against overfitting .", "An increasing number of projects in neuroscience requires the statistical analysis of high dimensional data sets , as , for instance , in predicting behavior from neural firing or in operating artificial devices from brain recordings in brain-machine interfaces .", "In this paper , we address the question of whether EMG data collected from arm movements of monkeys can be faithfully reconstructed with linear approaches from neural activity in primary motor cortex ( M1 ) .", "As neuroscientific results , our analyses demonstrate that EMG data can be well predicted from M1 neurons , further opening the path for possible real-time interfaces between brains and machines ."]}
{"orig_sents": ["7", "1", "4", "2", "3", "6", "5", "0"], "shuf_sents": ["Finally , we suggest that tonic levels of dopamine may be involved in the computation linking motivational state to optimal responding , thereby explaining the complex vigor-related effects of pharmacological manipulation of dopamine .", "However , the bulk of data on animal conditioning comes from free-operant experiments measuring how fast animals will work for reinforcement .", "They thus fail to address the simple observation that hungrier animals will work harder for food , as well as stranger facts such as their sometimes greater productivity even when working for irrelevant outcomes such as water .", "Here , we develop an RL framework for free-operant behavior , suggesting that subjects choose how vigorously to perform selected actions by optimally balancing the costs and benefits of quick responding .", "Existing reinforcement learning ( RL ) models are silent about these tasks , because they lack any notion of vigor .", "This accounts normatively for the effects of motivation on response rates , as well as many other classic findings .", "Motivational states such as hunger shift these factors , skewing the tradeoff .", "Reinforcement learning models have long promised to unify computational , psychological and neural accounts of appetitively conditioned behavior ."]}
{"orig_sents": ["4", "0", "5", "1", "2", "3"], "shuf_sents": ["In many such algorithms , including naive Bayes and most TFIDF variants , the parameters are determined by some simple , closed-form , function of training set statistics ; we call this mapping mapping from statistics to parameters , the parameter function .", "In this paper , we propose an algorithm for automatically learning this function from related classification problems .", "The parameter function found by our algorithm then defines a new learning algorithm for text classification , which we can apply to novel classification tasks .", "We find that our learned classifier outperforms existing methods on a variety of multiclass text classification tasks .", "Linear text classification algorithms work by computing an inner product between a test document vector and a parameter vector .", "Much research in text classification over the last few decades has consisted of manual efforts to identify better parameter functions ."]}
{"orig_sents": ["0"], "shuf_sents": ["We design a new learning algorithm for the Set Covering Machine from a PAC-Bayes perspective and propose a PAC-Bayes risk bound which is minimized for classifiers achieving a non trivial margin-sparsity trade-off ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["We have derived an evolution equation of the membrane potential density function with synaptic depression , and obtain the formulas for analytic computing the response of instantaneous re rate .", "Through a technical analysis , we arrive at several signi cant conclusions : The background inputs play an important role in information processing and act as a switch betwee temporal integration and coincidence detection .", "The instantaneous input frequency can affect the response amplitude and phase delay .", "In this paper , we aim at analyzing the characteristic of neuronal population responses to instantaneous or time-dependent inputs and the role of synapses in neural information processing .", "the role of synapses can be regarded as a spatio-temporal lter ; it is important in neural information processing for the spatial distribution of synapses and the spatial and temporal relation of inputs ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["This paper is an attempt at empirically verifying how these tests compare with more classical tests , on various conditions .", "The main result is that providing big enough evaluation sets non-parametric tests are relatively reliable in all conditions .", "More precisely , using a very large dataset to estimate the whole `` population '' , we analyzed the behavior of several statistical test , varying the class unbalance , the compared models , the performance measure , and the sample size .", "Although non-parametric tests have already been proposed for that purpose , statistical significance tests for non-standard measures ( different from the classification error ) are less often used in the literature ."]}
{"orig_sents": ["1", "2", "6", "5", "0", "4", "3"], "shuf_sents": ["A remote computer processes the video and controls the robot via radio .", "We describe a vision-based obstacle avoidance system for off-road mobile robots .", "The system is trained from end to end to map raw input images to steering angles .", "The robot exhibits an excellent ability to detect obstacles and navigate around them in real time at speeds of 2 m/s .", "The learning system is a large 6-layer convolutional network whose input is a single left/right pair of unprocessed low-resolution images .", "The robot is a 50cm off-road truck , with two forwardpointing wireless color cameras .", "It is trained in supervised mode to predict the steering angles provided by a human driver during training runs collected in a wide variety of terrains , weather conditions , lighting conditions , and obstacle types ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["Our algorithm involves a feature-weighted version of the k-nearest-neighbor algorithm .", "We present a non-linear , simple , yet effective , feature subset selection method for regression and use it in analyzing cortical neural activity .", "By applying feature selection we are able to improve prediction quality and suggest a novel way of exploring neural data .", "It is able to capture complex dependency of the target function on its input and makes use of the leave-one-out error as a natural regularization .", "We explain the characteristics of our algorithm on synthetic problems and use it in the context of predicting hand velocity from spikes recorded in motor cortex of a behaving monkey ."]}
{"orig_sents": ["2", "3", "7", "1", "5", "6", "4", "0"], "shuf_sents": ["It is further observed that , for 3 subjects , phase is more discriminative than amplitude in the first 1.5-2.0 s , which suggests that phase has the potential to boost the information transfer rate in BCIs .", "This study reports on a BCI method based on phase synchrony rate ( SR ) .", "Motor imagery attenuates EEG and rhythms over sensorimotor cortices .", "These amplitude changes are most successfully captured by the method of Common Spatial Patterns ( CSP ) and widely used in braincomputer interfaces ( BCI ) .", "Classifiers trained on SRs consistently demonstrate satisfactory results for all 5 subjects .", "SR , computed from binarized phase locking value , describes the number of discrete synchronization events within a window .", "Statistical nonparametric tests show that SRs contain significant differences between 2 types of motor imageries .", "BCI methods based on amplitude information , however , have not incoporated the rich phase dynamics in the EEG rhythm ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["We present a discriminative approach that utilizes the intrinsic geometry of input patterns revealed by unlabeled data points and we derive a maximum-margin formulation of semi-supervised learning for structured variables .", "Many real-world classification problems involve the prediction of multiple inter-dependent variables forming some structural dependency .", "Recent progress in machine learning has mainly focused on supervised classification of such structured variables .", "In this paper , we investigate structured classification in a semi-supervised setting .", "Unlike transductive algorithms , our formulation naturally extends to new test points ."]}
{"orig_sents": ["7", "3", "4", "1", "8", "6", "0", "2", "5"], "shuf_sents": ["Thus we obtain finite sample size performance bounds in terms of VC dimension and related quantities .", "Other than these samples , no other information is available regarding P , but the reference measure is assumed to be known .", "We also demonstrate strong universal consistency and an oracle inequality .", "Minimum volume sets of this type summarize the regions of greatest probability mass of P , and are useful for detecting anomalies and constructing confidence regions .", "This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P .", "Estimators based on histograms and dyadic partitions illustrate the proposed rules .", "As in classification , we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn .", "Given a probability measure P and a reference measure , one is often interested in the minimum -measure set with P -measure at least .", "We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classification ."]}
{"orig_sents": ["4", "2", "0", "1", "3", "5"], "shuf_sents": ["We present results of this winner-take-all computation on a network of integrate-and-fire neurons which receives spike trains as inputs .", "We show how we can configure the connectivity in the network so that the winner is selected after a pre-determined number of input spikes .", "Although some of these studies include spiking networks , they consider only analog input rates .", "We discuss spiking inputs with both regular frequencies and Poisson-distributed rates .", "Recurrent networks that perform a winner-take-all computation have been studied extensively .", "The robustness of the computation was tested by implementing the winner-take-all network on an analog VLSI array of 64 integrate-and-fire neurons which have an innate variance in their operating parameters ."]}
{"orig_sents": ["3", "5", "6", "0", "1", "2", "4"], "shuf_sents": ["The main idea of harmonic structure modeling is that the harmonic structure of a music signal is stable , so a music signal can be represented by a harmonic structure model .", "Accordingly , a corresponding separation algorithm is proposed .", "The main idea is to learn a harmonic structure model for each music signal in the mixture , and then separate signals by using these models to distinguish harmonic structures of different signals .", "Separation of music signals is an interesting but difficult problem .", "Experimental results show that the algorithm can separate signals and obtain not only a very high Signalto-Noise Ratio ( SNR ) but also a rather good subjective audio quality .", "It is helpful for many other music researches such as audio content analysis .", "In this paper , a new music signal separation method is proposed , which is based on harmonic structure modeling ."]}
{"orig_sents": ["2", "1", "4", "0", "3", "5"], "shuf_sents": ["We show that the estimation error of finding the non-Gaussian components tends to zero at a parametric rate .", "Our method , NGCA ( non-Gaussian component analysis ) , uses a very general semi-parametric framework .", "We propose a new linear method for dimension reduction to identify nonGaussian components in high dimensional data .", "Once NGCA components are identified and extracted , various tasks can be applied in the data analysis process , like data visualization , clustering , denoising or classification .", "In contrast to existing projection methods we define what is uninteresting ( Gaussian ) : by projecting out uninterestingness , we can estimate the relevant non-Gaussian subspace .", "A numerical study demonstrates the usefulness of our method ."]}
{"orig_sents": ["8", "9", "5", "0", "11", "2", "4", "1", "10", "3", "7", "6"], "shuf_sents": ["This framework is applied to modeling of neuronal circuits associated with reward .", "Moreover , we propose and compare two schemes of learning DML-HMMs .", "Such interactivity models which are derived from fMRI data are then validated through a group classification task .", "We also demonstrate that , by using the proposed learning algorithms , different DBN structures characterize drug addicted subjects vs. control subjects .", "We employ and compare four different types of DBNs : Parallel Hidden Markov Models , Coupled Hidden Markov Models , Fully-linked Hidden Markov Models and Dynamically MultiLinked HMMs ( DML-HMM ) .", "In this paper , we contribute a novel framework for modeling the interactions between multiple active brain regions , using Dynamic Bayesian Networks ( DBNs ) as generative models for brain activation patterns .", "In general , we demonstrate that incorporation of computer science principles into functional neuroimaging clinical studies provides a novel approach for probing human brain function .", "This finding provides an independent test for the effect of psychopathology on brain function .", "Functional Magnetic Resonance Imaging ( fMRI ) has enabled scientists to look into the active brain .", "However , interactivity between functional brain regions , is still little studied .", "Experimental results show that by using DBNs , group classification can be performed even if the DBNs are constructed from as few as 5 brain regions .", "The novelty of our framework from a Machine Learning perspective lies in the use of DBNs to reveal the brain connectivity and interactivity ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["We also propose an unbiased estimate for the degrees of freedom of the SVR model , which allows convenient selection of the regularization parameter .", "In this paper we derive an algorithm that computes the entire solution path of the support vector regression , with essentially the same computational cost as fitting one SVR model ."]}
{"orig_sents": ["3", "0", "6", "5", "4", "2", "1", "7"], "shuf_sents": ["We take M N , where N is the number of real data points , and hence obtain a sparse regression method which has O ( M 2 N ) training cost and O ( M 2 ) prediction cost per test case .", "We show that our method can match full GP performance with small M , i.e .", "We finally demonstrate its performance on some large data sets , and make a direct comparison to other sparse GP methods .", "We present a new Gaussian process ( GP ) regression model whose covariance is parameterized by the the locations of M pseudo-input points , which we learn by a gradient based optimization .", "The method turns out to be closely related to several other sparse GP approaches , and we discuss the relation in detail .", "The method can be viewed as a Bayesian regression model with particular input dependent noise .", "We also find hyperparameters of the covariance function in the same joint optimization .", "very sparse solutions , and it significantly outperforms other approaches in this regime ."]}
{"orig_sents": ["3", "1", "5", "4", "0", "2"], "shuf_sents": ["In in vivo-like regimes , predicted and recorded traces are almost indistinguishable and a significant part of the spikes can be predicted at the correct timing .", "On the other hand , the Integrate-and-Fire model is the basis of most of the theoretical studies on spiking neuron models .", "Slow processes like spike-frequency adaptation are shown to be a key feature in this context since they are necessary for the model to connect between different driving regimes .", "Integrate-and-Fire-type models are usually criticized because of their simplicity .", "We find that the resulting effective model is sufficient to predict the spike train of the real pyramidal neuron with high accuracy .", "Here , we develop a sequential procedure to quantitatively evaluate an equivalent Integrate-and-Fire-type model based on intracellular recordings of cortical pyramidal neurons ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["Specifically , STDP preferentially potentiates ( turns on ) synapses that project from excitable neurons , which spike early , to lethargic neurons , which spike late .", "Once learned , an entire pattern can be recalled by stimulating a subset .", "The additional excitatory synaptic current makes lethargic neurons spike earlier , thereby causing neurons that belong to the same pattern to spike in synchrony .", "We describe a neuromorphic chip that uses binary synapses with spike timing-dependent plasticity ( STDP ) to learn stimulated patterns of activity and to compensate for variability in excitability ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["In this paper we propose a general framework to study the generalization properties of binary classifiers trained with data which may be dependent , but are deterministically generated upon a sample of independent examples .", "It provides generalization bounds for binary classification and some cases of ranking problems , and clarifies the relationship between these learning tasks ."]}
{"orig_sents": ["2", "0", "1", "4", "3", "5"], "shuf_sents": ["The kernels incorporate progressively more information , with the most complex kernel accounting for a multiple alignment of orthologous regions , the phylogenetic tree relating the species , and the prior knowledge that relevant sequence patterns occur in conserved motif blocks .", "These kernels can be used in the presence of a library of known transcription factor binding sites , or de novo by iterating over all k-mers of a given length .", "We describe a hierarchy of motif-based kernels for multiple alignments of biological sequences , particularly suitable to process regulatory regions of genes .", "We demonstrate the utility of the motif-based multiple alignment kernels by using a collection of aligned promoter regions from five yeast species to recognize classes of cell-cycle regulated genes .", "In the latter mode , a discriminative classifier built from such a kernel not only recognizes a given class of promoter regions , but as a side effect simultaneously identifies a collection of relevant , discriminative sequence motifs .", "Supplementary data is available at http : //noble.gs.washington.edu/proj/pkernel ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["Our algorithm is much faster than that of Smola and Bartlett , while , in generalization it greatly outperforms the information gain approach proposed by Seeger et al , especially on the quality of predictive distributions .", "In this paper we propose a new basis selection criterion for building sparse GP regression models that provides promising gains in accuracy as well as efficiency over previous methods ."]}
{"orig_sents": ["1", "3", "5", "0", "2", "6", "4", "7"], "shuf_sents": ["However , such approaches require to solve hard non-convex optimization problems .", "Lasso regression tends to assign zero weights to most irrelevant or redundant features , and hence is a promising technique for feature selection .", "This paper proposes a new approach named the Feature Vector Machine ( FVM ) .", "Its limitation , however , is that it only offers solutions to linear models .", "FVM generates sparse solutions in the nonlinear feature space and it is much more tractable compared to feature scaling kernel machines .", "Kernel machines with feature scaling techniques have been studied for feature selection with non-linear models .", "It reformulates the standard Lasso regression into a form isomorphic to SVM , and this form can be easily extended for feature selection with non-linear models by introducing kernels defined on feature vectors .", "Our experiments with FVM on simulated data show encouraging results in identifying the small number of dominating features that are non-linearly correlated to the response , a task the standard Lasso fails to complete ."]}
{"orig_sents": ["2", "5", "3", "4", "1", "6", "0"], "shuf_sents": ["We show that they are applicable to circuits of conductance-based Hodgkin-Huxley ( HH ) neurons with high levels of noise that reflect experimental data on invivo conditions .", "In contrast to previous attractor-based computational models for neural networks , these flexible internal states are high-dimensional attractors of the circuit dynamics , that still allow the circuit state to absorb new information from online input streams .", "The network topology of neurons in the brain exhibits an abundance of feedback connections , but the computational function of these feedback connections is largely unknown .", "It implies that many such systems acquire through feedback universal computational capabilities for analog computing with a non-fading memory .", "In particular , we show that feedback enables such systems to process time-varying input streams in diverse ways according to rules that are implemented through internal states of the dynamical system .", "We present a computational theory that characterizes the gain in computational power achieved through feedback in dynamical systems with fading memory .", "In this way one arrives at novel models for working memory , integration of evidence , and reward expectation in cortical circuits ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["This paper addresses the issue of numerical computation in machine learning domains based on similarity metrics , such as kernel methods , spectral techniques and Gaussian processes .", "The experiments show significant gains in computation and storage on datasets arising in image segmentation , object detection and dimensionality reduction .", "It presents a general solution strategy based on Krylov subspace iteration and fast N-body learning methods .", "The paper also presents theoretical bounds on the stability of these methods ."]}
{"orig_sents": ["3", "5", "6", "2", "7", "4", "0", "1"], "shuf_sents": ["We study several predictors and empirically show that the proposed algorithm positively compares with techniques based on regression , Kernel Dependency Estimation ( KDE ) or PCA alone , and gives results competitive to those of high-dimensional mixture predictors at a fraction of their computational cost .", "We show that the method successfully reconstructs the complex 3D motion of humans in real monocular video sequences .", "This is necessary for accurate , inverse , visual perception inferences , where several probable , distant 3D solutions exist due to noise or the uncertainty of monocular perspective projection .", "We present a conditional temporal probabilistic framework for reconstructing 3D human motion in monocular video based on descriptors encoding image silhouette observations .", "The learned predictors are temporally combined within a conditional graphical model in order to allow a principled propagation of uncertainty .", "For computational efficiency we restrict visual inference to low-dimensional kernel induced non-linear state spaces .", "Our methodology ( kBME ) combines kernel PCA-based non-linear dimensionality reduction ( kPCA ) and Conditional Bayesian Mixture of Experts ( BME ) in order to learn complex multivalued predictors between observations and model hidden states .", "Low-dimensional models are appropriate because many visual processes exhibit strong non-linear correlations in both the image observations and the target , hidden state variables ."]}
{"orig_sents": ["6", "1", "3", "0", "2", "5", "4"], "shuf_sents": ["Here , we present a theoretical analysis that characterizes the optimal linear coder and decoder for one- and twodimensional data .", "This problem can be expressed in information theoretic terms as coding and transmitting a multi-dimensional , analog signal over a set of noisy channels .", "The analysis allows for an arbitrary number of coding units , thus including both under- and over-complete representations , and provides a number of important insights into optimal coding strategies .", "Previously , we have shown that robust , overcomplete codes can be learned by minimizing the reconstruction error with a constraint on the channel capacity .", "We also report numerical solutions for robust coding of highdimensional image data and show that these codes are substantially more robust compared against other image codes such as ICA and wavelets .", "In particular , we show how the form of the code adapts to the number of coding units and to different data and noise conditions to achieve robustness .", "Biological sensory systems are faced with the problem of encoding a high-fidelity sensory signal with a population of noisy , low-fidelity neurons ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["We find in experiments that humans learn subtle statistical properties of visual scenes in a completely unsupervised manner .", "We argue that Bayesian model selection is ideal for inferring similar and even more complex model structures from experience .", "Computations underlying such optimal behavior have been shown to rely on probabilistic inference according to generative models whose structure is usually taken to be known a priori .", "Humans make optimal perceptual decisions in noisy and ambiguous conditions .", "We show that these findings are well captured by Bayesian model learning within a class of models that seek to explain observed variables by independent hidden causes ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["symmetric stable output weights , and more generally with weights distributed from the normal domain of attraction of a stable variable , that the neural functions converge in distribution to stable processes .", "Conditions are also investigated under which Gaussian limits do occur when the weights are independent but not identically distributed .", "A general analysis of the limiting distribution of neural network functions is performed , with emphasis on non-Gaussian limits .", "We show that with i.i.d .", "Some particularly tractable classes of stable distributions are examined , and the possibility of learning with such processes ."]}
{"orig_sents": ["1", "4", "3", "2", "7", "0", "5", "6", "8"], "shuf_sents": ["The method learns a mixture model of the data by recursively propagating affinity messages .", "Clustering is a fundamental problem in machine learning and has been approached in many ways .", "However , many applications require that each cluster of data be accurately described by a prototype or model , so affinity-based clustering - and its benefits - can not be directly realized .", "Pair-wise clustering algorithms need not compute sufficient statistics and avoid poor solutions by directly placing similar examples in the same cluster .", "Two general and quite different approaches include iteratively fitting a mixture model ( e.g. , using EM ) and linking together pairs of training cases that have high affinity ( e.g. , using spectral methods ) .", "We demonstrate affinity propagation on the problems of clustering image patches for image segmentation and learning mixtures of gene expression models from microarray data .", "We find that affinity propagation obtains better solutions than mixtures of Gaussians , the K-medoids algorithm , spectral clustering and hierarchical clustering , and is both able to find a pre-specified number of clusters and is able to automatically determine the number of clusters .", "We describe a technique called `` affinity propagation '' , which combines the advantages of both approaches .", "Interestingly , affinity propagation can be viewed as belief propagation in a graphical model that accounts for pairwise training case likelihood functions and the identification of cluster centers ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["In particular , two novel approaches to value function approximation are explored based on automatically constructing basis functions on state spaces that can be represented as graphs or manifolds : one approach uses the eigenfunctions of the Laplacian , in effect performing a global Fourier analysis on the graph ; the second approach is based on diffusion wavelets , which generalize classical wavelets to graphs using multiscale dilations induced by powers of a diffusion operator or random walk on the graph .", "Together , these approaches form the foundation of a new generation of methods for solving large Markov decision processes , in which the underlying representation and policies are simultaneously learned .", "We investigate the problem of automatically constructing efficient representations or basis functions for approximating value functions based on analyzing the structure and topology of the state space ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We give an overview on these algorithms and compare them with SE-HMM/EM learning on synthetic and real-life data .", "A standard method to obtain stochastic models for symbolic time series is to train state-emitting hidden Markov models ( SE-HMMs ) with the Baum-Welch algorithm .", "Based on observable operator models ( OOMs ) , in the last few months a number of novel learning algorithms for similar purposes have been developed : ( 1,2 ) two versions of an `` efficiency sharpening '' ( ES ) algorithm , which iteratively improves the statistical efficiency of a sequence of OOM estimators , ( 3 ) a constrained gradient descent ML estimator for transition-emitting HMMs ( TE-HMMs ) ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["There is a long-standing controversy on the site of the cerebellar motor learning .", "Different theories and experimental results suggest that either the cerebellar flocculus or the brainstem learns the task and stores the memory .", "With a dynamical system approach , we clarify the mechanism of transferring the memory generated in the flocculus to the brainstem and that of so-called savings phenomena .", "The brainstem learning must comply with a sort of Hebbian rule depending on Purkinje-cell activities .", "In contrast to earlier numerical models , our model is simple but it accommodates explanations and predictions of experimental situations as qualitative features of trajectories in the phase space of synaptic weights , without fine parameter tuning ."]}
{"orig_sents": ["6", "8", "7", "1", "5", "2", "4", "3", "0"], "shuf_sents": ["Our results could also suggest that the power-law might be derived not from smoothness or smoothness-inducing mechanisms operating on the noise inherent in our motor system but rather from the correlated noise which is inherent in this motor system .", "In these it was generally attributed either to smoothness in hand- or joint-space or to the result of mechanisms that damp noise inherent in the motor system to produce the smooth trajectories evident in healthy human motion .", "Analysis of signal and noise combinations shows that trajectories that were synthetically created not to comply with the power-law are transformed to power-law compliant ones after combination with low levels of noise .", "These results suggest caution when running experiments aimed at verifying the power-law or assuming its underlying existence without proper analysis of the noise .", "Furthermore , there exist colored noise types that drive non-power-law trajectories to power-law compliance and are not affected by smoothing .", "We show here that white Gaussian noise also obeys this power-law .", "The two-thirds power law , an empirical law stating an inverse non-linear relationship between the tangential hand speed and the curvature of its trajectory during curved motion , is widely acknowledged to be an invariant of upper-limb movement .", "This ubiquity has fostered various attempts to uncover the origins of this empirical relationship .", "It has also been shown to exist in eyemotion , locomotion and was even demonstrated in motion perception and prediction ."]}
{"orig_sents": ["8", "3", "4", "0", "5", "2", "1", "6", "7"], "shuf_sents": ["A key source of data concerning attentional control comes from behavioral studies in which the effect of recent experience is examined as individuals repeatedly perform a perceptual discrimination task ( e.g. , `` what shape is the odd-colored object ? `` ) .", "We propose a probabilistic model of the environment that is updated after each trial .", "We view this facilitation as an adaptation to the statistical structure of the environment .", "These features are then combined into a saliency map , and attention is directed to the most salient regions first .", "Top-down attentional control is achieved by modulating the contribution of different feature types to the saliency map .", "The robust finding is that repetition of features of recent trials ( e.g. , target color ) facilitates performance .", "Under the assumption that attentional control operates so as to make performance more efficient for more likely environmental states , we obtain parsimonious explanations for data from four different experiments .", "Further , our model provides a rational explanation for why the influence of past experience on attentional control is short lived .", "Theories of visual attention commonly posit that early parallel processes extract conspicuous features such as color contrast and motion from the visual field ."]}
{"orig_sents": ["7", "5", "1", "3", "6", "0", "4", "2"], "shuf_sents": ["To find the dynamical states , we use a recently-introduced algorithm which reconstructs effective state spaces from stochastic time series .", "Since multiple electrode recordings are now a standard tool in neuroscience research , it is important to have a measure of such network-wide behavioral coordination and information sharing , applicable to multiple neural spike train data .", "We illustrate our method by testing it on a detailed model of the transition from gamma to beta rhythms .", "We propose a new statistic , informational coherence , which measures how much better one unit can be predicted by knowing the dynamical state of another .", "We then extend the pairwise measure to a multivariate analysis of the network by estimating the network multi-information .", "This activity often manifests itself as dynamically coordinated sequences of action potentials .", "We argue informational coherence is a measure of association and shared information which is superior to traditional pairwise measures of synchronization and correlation .", "Most nervous systems encode information about stimuli in the responding activity of large neuronal networks ."]}
{"orig_sents": ["0", "1", "4", "2", "3"], "shuf_sents": ["We consider approximate value iteration with a parameterized approximator in which the state space is partitioned and the optimal cost-to-go function over each partition is approximated by a constant .", "We establish performance loss bounds for policies derived from approximations associated with fixed points .", "Such projection weighting leads to the same fixed points as TD ( 0 ) .", "Our analysis also leads to the first performance loss bound for approximate value iteration with an average cost objective .", "These bounds identify benefits to having projection weights equal to the invariant distribution of the resulting policy ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["The problem of computing a resample estimate for the reconstruction error in PCA is reformulated as an inference problem with the help of the replica method .", "A perturbative correction to the result is computed and an alternative simplified derivation is also presented .", "Using the expectation consistent ( EC ) approximation , the intractable inference problem can be solved efficiently using only two variational parameters ."]}
{"orig_sents": ["3", "4", "5", "7", "0", "6", "8", "9", "1", "2"], "shuf_sents": ["The points can move as time progresses but large moves in latent space are improbable .", "We also illustrate the system operating on twelve years of NIPS co-publication data .", "We present a detailed version of this work in .", "This paper explores two aspects of social network modeling .", "First , we generalize a successful static model of relationships into a dynamic model that accounts for friendships drifting over time .", "Second , we show how to make it tractable to learn such models from data , even as the number of entities n gets large .", "Observed links between entities are more likely if the entities are close in latent space .", "The generalized model associates each entity with a point in p-dimensional Euclidian latent space .", "We show how to make such a model tractable ( subquadratic in the number of entities ) by the use of appropriate kernel functions for similarity in latent space ; the use of low dimensional kd-trees ; a new efficient dynamic adaptation of multidimensional scaling for a first pass of approximate projection of entities into latent space ; and an efficient conjugate gradient update rule for non-linear local optimization in which amortized time per entity during an update is O ( log n ) .", "We use both synthetic and real-world data on upto 11,000 entities which indicate linear scaling in computation time and improved performance over four alternative approaches ."]}
{"orig_sents": ["0", "3", "6", "4", "2", "1", "5"], "shuf_sents": ["Fusing multiple information sources can yield significant benefits to successfully accomplish learning tasks .", "For the purpose of model selection , a stability-based approach is employed to ensure the selection of the most self-consistent hypothesis .", "The tradeoff between the informativeness of data sources and the sparseness of their mixture is controlled by an entropy-based weighting mechanism .", "Many studies have focussed on fusing information in supervised learning contexts .", "Based on similarity information , the clustering task is phrased as a non-negative matrix factorization problem of a mixture of similarity measurements .", "The experiments demonstrate the performance of the method on toy as well as real world data sets .", "We present an approach to utilize multiple information sources in the form of similarity data for unsupervised learning ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["This holds , for instance , for certain graph and string kernels .", "Transduction is achieved by variational inference over the unlabeled data subject to a balancing constraint .", "We present a method for performing transductive inference on very large datasets .", "Our algorithm is based on multiclass Gaussian processes and is effective whenever the multiplication of the kernel matrix or its inverse with a vector can be computed sufficiently fast ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We define a probability distribution over equivalence classes of binary matrices with a finite number of rows and an unbounded number of columns .", "We illustrate the use of this distribution as a prior in an infinite latent feature model , deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset .", "This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features .", "We identify a simple generative process that results in the same distribution over equivalence classes , which we call the Indian buffet process ."]}
{"orig_sents": ["4", "3", "2", "0", "6", "5", "1"], "shuf_sents": ["In this paper , we present a new algorithm for discovery and learning of PSRs that uses a gradient descent approach to compute the predictions for the current state .", "We give empirical results to show that our constrained gradient algorithm is able to discover core tests using very small amounts of data , and with larger amounts of data can compute accurate predictions of the system dynamics .", "The best existing techniques for discovery and learning of PSRs use a Monte Carlo approach to explicitly estimate these outcome probabilities .", "PSRs use predictions about the outcome of future tests to summarize the system state .", "Predictive state representations ( PSRs ) are a method of modeling dynamical systems using only observable data , such as actions and observations , to describe their model .", "Furthermore , the algorithm can be used online by an agent to constantly improve its prediction quality ; something that current state of the art discovery and learning algorithms are unable to do .", "The algorithm takes advantage of the large amount of structure inherent in a valid prediction matrix to constrain its predictions ."]}
{"orig_sents": ["0", "3", "5", "2", "4", "1"], "shuf_sents": ["There has been a surge of interest in learning non-linear manifold models to approximate high-dimensional data .", "Experimental results with synthetic and real data illustrate the algorithm .", "This paper presents an algorithm for selecting landmarks , based on LASSO regression , which is well known to favor sparse approximations because it uses regularization with an l1 norm .", "Both for computational complexity reasons and for generalization capability , sparsity is a desired feature in such models .", "As an added benefit , a continuous manifold parameterization , based on the landmarks , is also found .", "This usually means dimensionality reduction , which naturally implies estimating the intrinsic dimension , but it can also mean selecting a subset of the data to use as landmarks , which is especially important because many existing algorithms have quadratic complexity in the number of observations ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We observe a rich variety of mechanisms for the phenomenon and analyze them based on the relative gain of excitatory and inhibitory synaptic inputs .", "Based on a large scale spiking neuron model of the input layers 4C and of macaque , we identify neural mechanisms for the observed contrast dependent receptive field size of V1 cells .", "However , contrary to phenomenological models , our simulation results suggest this is neither sufficient nor necessary to explain the phenomenon .", "We observe an average growth in the spatial extent of excitation and inhibition for low contrast , as predicted from phenomenological models ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["To estimate the time course of such state dynamics from single- or multiple neuron recordings , we have developed an algorithm that maximizes the likelihood of observed spike trains by optimizing the state lifetimes and the state-conditional interspike-interval ( ISI ) distributions .", "Neurons can have rapidly changing spike train statistics dictated by the underlying network excitability or behavioural state of an animal .", "Our nonparametric algorithm is free of time-binning and spike-counting problems and has the computational complexity of a Mixed-state Markov Model operating on a state sequence of length equal to the total number of recorded spikes .", "We find that the two state-conditional ISI functions are highly similar to the ones measured during waking and singing , respectively .", "As an example , we fit a two-state model to paired recordings of premotor neurons in the sleeping songbird ."]}
{"orig_sents": ["4", "2", "3", "1", "0"], "shuf_sents": ["Experiments on the BNC corpus showed consistent improvement over previous methods involving no chronological order .", "We propose an online inference algorithm using particle filters to recognize topic shifts to employ the most appropriate length of context automatically .", "However , the problem of context length has almost been neglected so far and a naive bag-of-words history has been employed in natural language processing .", "In contrast , in this paper we view topic shifts within a text as a latent stochastic process to give an explicit probabilistic generative model that has partial exchangeability .", "Long-distance language modeling is important not only in speech recognition and machine translation , but also in high-dimensional discrete sequence modeling in general ."]}
{"orig_sents": ["4", "7", "1", "6", "2", "3", "0", "5"], "shuf_sents": ["The noise level 5 ) may also be estimated by standard techniques .", "Here we propose a simple and well-founded method for automatic estimation of many of these key parameters : 1 ) the spatial distribution of channel densities on the cell 's membrane ; 2 ) the spatiotemporal pattern of synaptic input ; 3 ) the channels ' reversal potentials ; 4 ) the intercompartmental conductances ; and 5 ) the noise level in each compartment .", "via voltage sensitive imaging techniques ) , b ) an approximate kinetic description of the channels and synapses present in each compartment , and c ) the morphology of the part of the neuron under investigation .", "The key observation is that , given data a ) -c ) , all of the parameters 1 ) -4 ) may be simultaneously inferred by a version of constrained linear regression ; this regression , in turn , is efficiently solved using standard algorithms , without any `` local minima '' problems despite the large number of parameters and complex dynamics .", "Our understanding of the input-output function of single cells has been substantially advanced by biophysically accurate multi-compartmental models .", "We demonstrate the method 's accuracy on several model datasets , and describe techniques for quantifying the uncertainty in our estimates .", "We assume experimental access to : a ) the spatiotemporal voltage signal in the dendrite ( or some contiguous subpart thereof , e.g .", "The large number of parameters needing hand tuning in these models has , however , somewhat hampered their applicability and interpretability ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["The system includes a retina chip , two convolution chips , a 2D winner-take-all chip , a delay line chip , a learning classifier chip , and a set of PCBs for computer interfacing and address space remappings .", "A complete experimental setup and measurements results are shown .", "A 5-layer neuromorphic vision processor whose components communicate spike events asychronously using the address-eventrepresentation ( AER ) is demonstrated .", "The components use a mixture of analog and digital computation and will learn to classify trajectories of a moving object ."]}
{"orig_sents": ["2", "0", "4", "3", "5", "1"], "shuf_sents": ["Lankriet et al .", "Experimental results show that the proposed algorithm helps for automatic model selection , improving the interpretability of the learning result and works for hundred thousands of examples or hundreds of kernels to be combined .", "While classical kernel-based learning algorithms are based on a single kernel , in practice it is often desirable to use multiple kernels .", "We show that it can be rewritten as a semi-infinite linear program that can be efficiently solved by recycling the standard SVM implementations .", "( 2004 ) considered conic combinations of kernel matrices for classification , leading to a convex quadratically constraint quadratic program .", "Moreover , we generalize the formulation and our method to a larger class of problems , including regression and one-class classification ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["This paper gives a rigorous proof of the statistical convergence of kernel CCA and a related method ( NOCCO ) , which provides a theoretical justification for these methods .", "The result also gives a sufficient condition on the decay of the regularization coefficient in the methods to ensure convergence .", "While kernel canonical correlation analysis ( kernel CCA ) has been applied in many problems , the asymptotic convergence of the functions estimated from a finite sample to the true functions has not yet been established ."]}
{"orig_sents": ["0", "1", "2", "4", "3", "5", "6"], "shuf_sents": ["This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion ( border ownership ) and thinline objects .", "In natural scenes , thinline objects include sticks and wires , while in human graphical communication thinlines include connectors , dividers , and other abstract devices .", "Our analysis is directed at both natural and graphical domains .", "In a sparse heterogeneous Markov Random Field framework , we define a set of interpretation nodes and energy/potential functions among them .", "The basic problem is to formulate the logic of the interactions among local image events , specifically contrast edges , ridges , junctions , and alignment relations , such as to encode the natural constraints among these events in visual scenes .", "The minimum energy configuration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour figures such as the Kanizsa Triangle , as well as more difficult examples .", "In practical terms , the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost ."]}
{"orig_sents": ["6", "4", "1", "0", "3", "2", "7", "5"], "shuf_sents": ["Here we show how to successfully train such distance functions using rather limited amount of information .", "We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses : the distance between stimuli should be large when the responses they evoke are very different , and small when the responses they evoke are similar .", "For each neuron , a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar .", "The data consisted of the responses of neurons in primary auditory cortex ( A1 ) of anesthetized cats to 32 stimuli derived from natural sounds .", "One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive ( causing large gradients in the neural responses ) or alternatively dimensions in stimulus space to which the neuronal response are invariant ( defining iso-response manifolds ) .", "The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli .", "We present a novel approach to the characterization of complex sensory neurons .", "The distance function was trained to fit these constraints ."]}
{"orig_sents": ["4", "3", "0", "6", "1", "7", "2", "5", "8"], "shuf_sents": ["However , it is unclear whether the physiological self-motion of the retinal image serves a visual purpose during the brief periods of natural visual fixation .", "Fixational instability introduces fluctuations in the retinal input signals that , in the presence of natural images , lack spatial correlations .", "They decorrelate cell responses , even if the contrast sensitivity functions of simulated cells are not perfectly tuned to counter-balance the power-law spectrum of natural images .", "It is known that stimuli tend to fade when they are stabilized on the retina for several seconds .", "Under natural viewing conditions , small movements of the eye and body prevent the maintenance of a steady direction of gaze .", "A decorrelation of neural activity has been proposed to be beneficial for discarding statistical redundancies in the input signals .", "This study examines the impact of fixational instability on the statistics of visual input to the retina and on the structure of neural activity in the early visual system .", "These input fluctuations strongly influence neural activity in a model of the LGN .", "Fixational instability might , therefore , contribute to establishing efficient representations of natural stimuli ."]}
{"orig_sents": ["1", "5", "3", "0", "4", "6", "2"], "shuf_sents": ["In our experiments , we concentrate on modeling the diversity of HIV where the epitome emerges as a natural model for producing relatively small vaccines covering a large number of immune system targets known as epitopes .", "We introduce a new model of genetic diversity which summarizes a large input dataset into an epitome , a short sequence or a small set of short sequences of probability distributions capturing many overlapping subsequences from the dataset .", "In our experiments , we find that vaccine optimization is fairly robust to these uncertainties .", "The discrete sequence model we introduce in this paper targets applications in genetics , from multiple alignment to recombination and mutation inference .", "Our experiments show that the epitome includes more epitopes than other vaccine designs of similar length , including cocktails of consensus strains , phylogenetic tree centers , and observed strains .", "The epitome as a representation has already been used in modeling real-valued signals , such as images and audio .", "We also discuss epitome designs that take into account uncertainty about Tcell cross reactivity and epitope presentation ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["The scheme is demonstrated for collaborative filtering of users with movies rating as attributes .", "Moreover , we show that under mild technical conditions , clustering the objects on the basis of such a random subset performs almost as well as clustering with the full attribute set .", "We argue that when objects are characterized by many attributes , clustering them on the basis of a relatively small random subset of these attributes can capture information on the unobserved attributes as well .", "We prove a finite sample generalization theorems for this novel learning scheme that extends analogous results from the supervised learning setting ."]}
{"orig_sents": ["4", "6", "2", "0", "3", "1", "5"], "shuf_sents": ["A statistical model with an unknown function is called a semiparametric model , which is one of the unsolved problem in statistics and is generally very difficult to solve .", "We analytically obtained an optimal estimating function for the shape parameter independent of the functional form of the firing rate .", "Because the environment changes with time , observed data are generated from the time-dependent firing rate , which is an unknown function .", "We used a novel method of estimating functions in information geometry to estimate the shape parameter without estimating the unknown function .", "We considered a gamma distribution of interspike intervals as a statistical model for neuronal spike generation .", "This estimation is efficient without Fisher information loss and better than maximum likelihood estimation .", "The model parameters consist of a time-dependent firing rate and a shape parameter that characterizes spiking irregularities of individual neurons ."]}
{"orig_sents": ["2", "4", "3", "5", "1", "0"], "shuf_sents": ["In the cost-sensitive domains examined , superior accuracy is achieved .", "The message-passing algorithm that results is described and empirical results demonstrate large speedups without decrease in accuracy .", "Calculations that quantify the dependencies between variables are vital to many operations with graphical models , e.g. , active learning and sensitivity analysis .", "In this work , we show how to perform a similar computation with cost linear in network size .", "Previously , pairwise information gain calculation has involved a cost quadratic in network size .", "The loss function that allows this is of a form amenable to computation by dynamic programming ."]}
{"orig_sents": ["6", "7", "0", "4", "2", "3", "8", "1", "5"], "shuf_sents": ["All of these methods consider an n1 x n2 image as a high dimensional vector in Rn1 xn2 , while an image represented in the plane is intrinsically a matrix .", "We compare our proposed approach with PCA , LDA and LPP methods on two standard databases .", "TSA considers an image as the second order tensor in Rn1 Rn2 , where Rn1 and Rn2 are two vector spaces .", "The relationship between the column vectors of the image matrix and that between the row vectors can be naturally characterized by TSA .", "In this paper , we propose a new algorithm called Tensor Subspace Analysis ( TSA ) .", "Experimental results demonstrate that TSA achieves better recognition rate , while being much more efficient .", "Previous work has demonstrated that the image variations of many objects ( human faces in particular ) under variable lighting can be effectively modeled by low dimensional linear spaces .", "The typical linear subspace learning algorithms include Principal Component Analysis ( PCA ) , Linear Discriminant Analysis ( LDA ) , and Locality Preserving Projection ( LPP ) .", "TSA detects the intrinsic local geometrical structure of the tensor space by learning a lower dimensional tensor subspace ."]}
{"orig_sents": ["0", "3", "2", "1", "4", "5"], "shuf_sents": ["We discuss a method for obtaining a subject 's a priori beliefs from his/her behavior in a psychophysics context , under the assumption that the behavior is ( nearly ) optimal from a Bayesian perspective .", "In addition , we develop methods for analyzing the uncertainty of these estimates .", "Despite this increased generality , the method is relatively simple to implement , being based in the simplest case on a linear programming algorithm , and more generally on a straightforward maximum likelihood or maximum a posteriori formulation , which turns out to be a convex optimization problem ( with no non-global local maxima ) in many important cases .", "The method is nonparametric in the sense that we do not assume that the prior belongs to any fixed class of distributions ( e.g. , Gaussian ) .", "We demonstrate the accuracy of the method in a simple simulated coin-flipping setting ; in particular , the method is able to precisely track the evolution of the subject 's posterior distribution as more and more data are observed .", "We close by briefly discussing an interesting connection to recent models of neural population coding ."]}
{"orig_sents": ["1", "2", "3", "5", "4", "0", "6"], "shuf_sents": ["Unlike the the basis functions and filters learned by ICA or sparse coding , these functions individually more closely resemble simple cell receptive fields and collectively span a broad range of spatial scales .", "Linear implementations of the efficient coding hypothesis , such as independent component analysis ( ICA ) and sparse coding models , have provided functional explanations for properties of simple cells in V1 .", "These models , however , ignore the non-linear behavior of neurons and fail to match individual and population properties of neural receptive fields in subtle but important ways .", "Hierarchical models , including Gaussian Scale Mixtures and other generative statistical models , can capture higher-order regularities in natural images and explain nonlinear aspects of neural processing such as normalization and context effects .", "Here we examine the optimal lower-level representations derived in the context of a hierarchical model and find that the resulting representations are strikingly different from those based on linear models .", "Previously , it had been assumed that the lower level representation is independent of the hierarchy , and had been fixed when training these models .", "Our work unifies several related approaches and observations about natural image structure and suggests that hierarchical models might yield better representations of image structure throughout the hierarchy ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["An approximation algorithm is proposed to solve a relaxed version of the optimization problem as an eigenvalue problem .", "We present a novel spectral clustering method that enables users to incorporate prior knowledge of the size of clusters into the clustering process .", "The cost function , which is named size regularized cut ( SRcut ) , is defined as the sum of the inter-cluster similarity and a regularization term measuring the relative size of two clusters .", "Evaluations over different data sets demonstrate that the method is not sensitive to outliers and performs better than normalized cut .", "Finding a partition of the data set to minimize SRcut is proved to be NP-complete ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We explain theoretically and corroborate empirically that EP is superior to Laplace .", "We compare Laplace 's method and Expectation Propagation ( EP ) focusing on marginal likelihood estimates and predictive performance .", "Gaussian processes are attractive models for probabilistic classification but unfortunately exact inference is analytically intractable .", "We also compare to a sophisticated MCMC scheme and show that EP is surprisingly accurate ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["We present an improvement to the DP-SLAM algorithm for simultaneous localization and mapping ( SLAM ) that maintains multiple hypotheses about densely populated maps ( one full map per particle in a particle filter ) in time that is linear in all significant algorithm parameters and takes constant ( amortized ) time per iteration .", "We also present a hierarchical extension of DP-SLAM that uses a two level particle filter which models drift in the particle filtering process itself .", "This means that the asymptotic complexity of the algorithm is no greater than that of a pure localization algorithm using a single map and the same number of particles .", "The hierarchical approach enables recovery from the inevitable drift that results from using a finite number of particles in a particle filter and permits the use of DP-SLAM in more challenging domains , while maintaining linear time asymptotic complexity ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["In this paper , we provide a general theorem that establishes a correspondence between surrogate loss functions in classification and the family of f -divergences .", "These ideas have applications to classification problems that also involve a component of experiment design ; in particular , we leverage our results to prove consistency of a procedure for learning a classifier under decentralization requirements .", "Moreover , we provide constructive procedures for determining the f -divergence induced by a given surrogate loss , and conversely for finding all surrogate loss functions that realize a given f -divergence .", "Next we introduce the notion of universal equivalence among loss functions and corresponding f -divergences , and provide necessary and sufficient conditions for universal equivalence to hold ."]}
{"orig_sents": ["2", "3", "4", "5", "7", "6", "1", "0"], "shuf_sents": ["Furthermore , the CTM provides a natural way of visualizing and exploring this and other unstructured data sets .", "The CTM gives a better fit than LDA on a collection of OCRed articles from the journal Science .", "Topic models , such as latent Dirichlet allocation ( LDA ) , can be useful tools for the statistical analysis of document collections and other discrete data .", "The LDA model assumes that the words of each document arise from a mixture of topics , each of which is a distribution over the vocabulary .", "A limitation of LDA is the inability to model topic correlation even though , for example , a document about genetics is more likely to also be about disease than x-ray astronomy .", "This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions .", "We derive a mean-field variational inference algorithm for approximate posterior inference in this model , which is complicated by the fact that the logistic normal is not conjugate to the multinomial .", "In this paper we develop the correlated topic model ( CTM ) , where the topic proportions exhibit correlation via the logistic normal distribution ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["Experimental results based on real data demonstrate the advantage of the proposed algorithms and support our conclusions .", "Training data may also be actively selected to improve the network 's generalization to test data .", "We develop the algorithms for learning the network structure , in either a supervised or unsupervised manner .", "We extend radial basis function ( RBF ) networks to the scenario in which multiple correlated tasks are learned simultaneously , and present the corresponding learning algorithms ."]}
{"orig_sents": ["0", "1", "2", "4", "3"], "shuf_sents": ["We develop an approach for estimation with Gaussian Markov processes that imposes a smoothness prior while allowing for discontinuities .", "Instead of propagating information laterally between neighboring nodes in a graph , we study the posterior distribution of the hidden nodes as a whole -- how it is perturbed by invoking discontinuities , or weakening the edges , in the graph .", "We show that the resulting computation amounts to feed-forward fan-in operations reminiscent of V1 neurons .", "Simulation results illustrate the merits of this approach .", "Moreover , using suitable matrix preconditioners , the incurred matrix inverse and determinant can be approximated , without iteration , in the same computational style ."]}
{"orig_sents": ["1", "5", "8", "3", "2", "7", "6", "4", "0"], "shuf_sents": ["Experimental results demonstrate the effectiveness and efficiency of our algorithm .", "In supervised learning scenarios , feature selection has been studied widely in the literature .", "Our method can be performed in either supervised or unsupervised fashion .", "In this paper , we propose a `` filter '' method for feature selection which is independent of any learning algorithm .", "We compare our method with data variance ( unsupervised ) and Fisher score ( supervised ) on two data sets .", "Selecting features in unsupervised learning scenarios is a much harder problem , due to the absence of class labels that would guide the search for relevant information .", "The importance of a feature is evaluated by its power of locality preserving , or , Laplacian Score .", "The proposed method is based on the observation that , in many real world classification problems , data from the same class are often close to each other .", "And , almost all of previous unsupervised feature selection methods are `` wrapper '' techniques that require a learning algorithm to evaluate the candidate feature subsets ."]}
{"orig_sents": ["5", "1", "3", "2", "4", "0"], "shuf_sents": ["The result is a general probabilistic temporal planner , named the Factored Policy-Gradient Planner ( FPG-Planner ) , which can handle hundreds of tasks , optimising for probability of success , duration , and resource use .", "These domains are typically modelled as Markov decision problems and solved using dynamic programming methods .", "Our emphasis is large domains that are infeasible for dynamic programming .", "This paper demonstrates the application of reinforcement learning -- in the form of a policy-gradient method -- to these domains .", "Our approach is to construct simple policies , or agents , for each planning task .", "Probabilistic temporal planning attempts to find good policies for acting in domains with concurrent durative tasks , multiple uncertain outcomes , and limited resources ."]}
{"orig_sents": ["3", "4", "5", "0", "2", "1"], "shuf_sents": ["Our system uses relational Markov networks to represent the hierarchical activity model that encodes the complex relations among GPS readings , activities and significant places .", "We present experiments that show significant improvements over existing techniques .", "We apply FFT-based message passing to perform efficient summation over large numbers of nodes in the networks .", "Learning patterns of human behavior from sensor data is extremely important for high-level activity inference .", "We show how to extract and label a person 's activities and significant places from traces of GPS data .", "In contrast to existing techniques , our approach simultaneously detects and classifies the significant locations of a person and takes the highlevel context into account ."]}
{"orig_sents": ["3", "1", "2", "0", "4"], "shuf_sents": ["We show that this changes the likelihood function in such a way that the Bayesian estimator model can account for reported perceptual behavior .", "We first note that the perceptual effects of adaptation seems inconsistent with an adjustment of the internally represented prior distribution .", "Instead , we postulate that adaptation increases the signal-to-noise ratio of the measurements by adapting the operational range of the measurement stage to the input range .", "We extend a previously developed Bayesian framework for perception to account for sensory adaptation .", "In particular , we compare the model 's predictions to human motion discrimination data and demonstrate that the model accounts for the commonly observed perceptual adaptation effects of repulsion and enhanced discriminability ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["Consensus propagation can be viewed as a special case of belief propagation , and our results contribute to the belief propagation literature .", "We establish convergence , characterize the convergence rate for regular graphs , and demonstrate that the protocol exhibits better scaling properties than pairwise averaging , an alternative that has received much recent attention .", "In particular , beyond singly-connected graphs , there are very few classes of relevant problems for which belief propagation is known to converge .", "We propose consensus propagation , an asynchronous distributed protocol for averaging numbers across a network ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["To escape from the curse of dimensionality , we claim that one can learn non-local functions , in the sense that the value and shape of the learned function at x must be inferred using examples that may be far from x .", "With this objective , we present a non-local non-parametric density estimator .", "It builds upon previously proposed Gaussian mixture models with regularized covariance matrices to take into account the local shape of the manifold .", "It also builds upon recent work on non-local estimators of the tangent plane of a manifold , which are able to generalize in places with little training data , unlike traditional , local , non-parametric models ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["This problem is motivated by the task of efficiently linking faint asteroid detections , but is applicable to a range of spatial queries .", "To this end , we present a new type of multiple tree algorithm that uses a variable number of trees to exploit the advantages of both approaches .", "We survey current tree-based approaches , showing a trade-off exists between single tree and multiple tree algorithms .", "We empirically show that this algorithm performs well using both simulated and astronomical data .", "In this paper we consider the problem of finding sets of points that conform to a given underlying model from within a dense , noisy set of observations ."]}
{"orig_sents": ["6", "4", "0", "3", "1", "2", "5"], "shuf_sents": ["In this paper we introduce a new algorithm , KQBC , which is capable of actively learning large scale problems by using selective sampling .", "KQBC also enables the use of kernels , providing a simple way of extending QBC to the non-linear scenario .", "Sampling the low dimension space is done using the hit and run random walk .", "The algorithm overcomes the costly sampling step of the well known Query By Committee ( QBC ) algorithm by projecting onto a low dimensional space .", "A major goal of active learning is to reduce this cost .", "We demonstrate the success of this novel algorithm by applying it to both artificial and a real world problems .", "Training a learning algorithm is a costly task ."]}
{"orig_sents": ["4", "1", "6", "3", "2", "0", "5"], "shuf_sents": ["By using the variational framework we were able to overcome the highly ill posed fitting .", "Here we show a modification for DT-MRI that allows delineation of neuronal fibers which are infiltrated by edema .", "The variational framework was applied on data collected with conventional clinical parameters , containing only six diffusion directions .", "In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel , remove it , and then calculate the anisotropy of the remaining compartment .", "Diffusion Tensor Magnetic Resonance Imaging ( DT-MRI ) is a non invasive method for brain neuronal fibers delineation .", "The results show that we were able to find fibers that were not found by DT-MRI .", "We use the Muliple Tensor Variational ( MTV ) framework which replaces the diffusion model of DT-MRI with a multiple component model and fits it to the signal attenuation with a variational regularization mechanism ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["Individual level models actions of each player , and the group-level models actions of the team as a whole .", "Experiments on synthetic multi-player games and a multi-party meeting corpus show the effectiveness of the proposed model .", "The proposed model is a dynamic Bayesian network ( DBN ) with a two-level structure : individual-level and group-level .", "We present a model that learns the influence of interacting Markov chains within a team ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We show that we can use searches for the words in a dictionary to identify portions of the document whose transcriptions are unambiguous .", "We introduce a method to automatically improve character models for a handwritten script without the use of transcriptions and using a minimum of document specific training data .", "Using templates extracted from those regions , we retrain our character prediction model to drastically improve our search retrieval performance for words in the document ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We initiate the study of learning from multiple sources of limited data , each of which may be corrupted at a different rate .", "In both cases , efficient algorithms are provided for computing the optimal subset of data .", "We develop a complete theory of which data sources should be used for two fundamental problems : estimating the bias of a coin , and learning a classifier in the presence of label noise ."]}
{"orig_sents": ["1", "5", "4", "2", "6", "3", "0"], "shuf_sents": ["We show that , even on unstructured scenes , our algorithm is frequently able to recover fairly accurate depthmaps .", "We consider the task of depth estimation from a single monocular image .", "Then , we apply supervised learning to predict the depthmap as a function of the image .", "Our model uses a discriminatively-trained Markov Random Field ( MRF ) that incorporates multiscale local- and global-image features , and models both depths at individual points as well as the relation between depths at different points .", "and their corresponding ground-truth depthmaps .", "We take a supervised learning approach to this problem , in which we begin by collecting a training set of monocular images ( of unstructured outdoor environments which include forests , trees , buildings , etc . )", "Depth estimation is a challenging problem , since local features alone are insufficient to estimate depth at a point , and one needs to consider the global context of the image ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["This problem had not yet been explored in the framework of statistical learning theory .", "This work is a first step towards the construction of a topological model of a set of points grounded on statistics .", "Given a set of points and a set of prototypes representing them , how to create a graph of the prototypes whose topology accounts for that of the points ?", "In this work , we propose a generative model based on the Delaunay graph of the prototypes and the ExpectationMaximization algorithm to learn the parameters ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["The relation to the Bienenstock-Cooper-Munro rule as well as to some timing-based rules is discussed .", "Here we develop a mathematical framework that allows us to characterize timing based learning rules .", "Moreover , we identify a candidate learning rule with five variables ( and 5 free parameters ) that captures a variety of experimental data , including the dependence of potentiation and depression upon pre- and postsynaptic firing frequencies .", "While classical experiments on spike-timing dependent plasticity analyzed synaptic changes as a function of the timing of pairs of pre- and postsynaptic spikes , more recent experiments also point to the effect of spike triplets ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["We address the problem of robust , computationally-efficient design of biological experiments .", "Classical optimal experiment design methods have not been widely adopted in biological practice , in part because the resulting designs can be very brittle if the nominal parameter estimates for the model are poor , and in part because of computational constraints .", "We present a method for robust experiment design based on a semidefinite programming relaxation .", "We present an application of this method to the design of experiments for a complex calcium signal transduction pathway , where we have found that the parameter estimates obtained from the robust design are better than those obtained from an `` optimal '' design ."]}
{"orig_sents": ["2", "5", "3", "1", "4", "0"], "shuf_sents": ["1 Keywords : Markov random fields ; variational method ; message-passing algorithms ; sum-product ; belief propagation ; parameter estimation ; learning .", "En route to this result , we analyze the asymptotic properties of M-estimators based on convex variational relaxations , and establish a Lipschitz stability property that holds for a broad class of variational methods .", "Consider the problem of joint parameter estimation and prediction in a Markov random field : i.e. , the model parameters are estimated on the basis of an initial set of data , and then the fitted model is used to perform prediction ( e.g. , smoothing , denoising , interpolation ) on a new noisy observation .", "The key result of this paper is that in the computation-limited setting , using an inconsistent parameter estimator ( i.e. , an estimator that returns the `` wrong '' model even in the infinite data limit ) is provably beneficial , since the resulting errors can partially compensate for errors made by using an approximate prediction technique .", "We show that joint estimation/prediction based on the reweighted sum-product algorithm substantially outperforms a commonly used heuristic based on ordinary sum-product .", "Working in the computation-limited setting , we analyze a joint method in which the same convex variational relaxation is used to construct an M-estimator for fitting parameters , and to perform approximate marginalization for the prediction step ."]}
{"orig_sents": ["4", "2", "1", "5", "3", "0"], "shuf_sents": ["This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier .", "MILBoost uses cost functions from the Multiple Instance Learning literature combined with the AnyBoost framework .", "We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MILBoost .", "Experiments show that the detection rate is up to 1.6 times better using MILBoost .", "A good image object detection algorithm is accurate , fast , and does not require exact locations of objects in a training set .", "We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["This paper explores the statistical relationship between natural images and their underlying range ( depth ) images .", "Furthermore , we demonstrate that ideal linear shape-from-shading filters , when learned from natural scenes , may derive even more strength from shadow cues than from the traditional linear-Lambertian shading cues .", "We look at how this relationship changes over scale , and how this information can be used to enhance low resolution range data using a full resolution intensity image .", "Our extension is shown to provide a two-fold improvement over the current method .", "Based on our findings , we propose an extension to an existing technique known as shape recipes , and the success of the two methods are compared using images and laser scans of real scenes ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["In previous work we presented an efficient approach to computing kernel summations which arise in many machine learning methods such as kernel density estimation .", "In the process , we derive and demonstrate the first truly hierarchical fast Gauss transforms , effectively combining the best tools from discrete algorithms and continuous approximation theory .", "This approach , dual-tree recursion with finitedifference approximation , generalized existing methods for similar problems arising in computational physics in two ways appropriate for statistical problems : toward distribution sensitivity and general dimension , partly by avoiding series expansions .", "In this work , we explore the extent to which the dual-tree approach can be integrated with multipole-like Hermite expansions in order to achieve reasonable efficiency across all bandwidth scales , though only for low dimensionalities .", "While this proved to be the fastest practical method for multivariate kernel density estimation at the optimal bandwidth , it is much less efficient at larger-than-optimal bandwidths ."]}
{"orig_sents": ["3", "5", "0", "2", "4", "1"], "shuf_sents": ["The first one takes advantage of unbiased sufficient statistics which can be obtained from biased samples .", "We provide guarantees for the first two approaches and evaluate the performance of all three approaches in synthetic experiments and on real data from species habitat modeling , where maxent has been successfully applied and where sample selection bias is a significant problem .", "The second one estimates the biased distribution and then factors the bias out .", "We study the problem of maximum entropy density estimation in the presence of known sample selection bias .", "The third one approximates the second by only using samples from the sampling distribution .", "We propose three bias correction approaches ."]}
{"orig_sents": ["2", "1", "3", "4", "0"], "shuf_sents": ["has been experimentally demonstrated .", "It can perform 44-pixel kernel convolution for entire pixels only with 256 steps of simple analog processing .", "An analog focal-plane processor having a 128128 photodiode array has been developed for directional edge filtering .", "Newly developed cyclic line access and row-parallel processing scheme in conjunction with the `` only-nearest-neighbor interconnects '' architecture has enabled a very simple implementation .", "A proof-of-concept chip was fabricated in a 0.35- m 2-poly 3-metal CMOS technology and the edge filtering at a rate of 200 frames/sec ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["This provides a massively parallel model for intuitionistic modal reasoning , and sets the scene for integrated reasoning , knowledge representation , and learning of intuitionistic theories in neural networks , since the networks in the ensemble can be trained by examples using standard neural learning algorithms .", "We use ensembles of neural networks to represent intuitionistic modal theories , and show that for each intuitionistic modal program there exists a corresponding neural network ensemble that computes the program .", "We present a new connectionist model for constructive , intuitionistic modal reasoning ."]}
{"orig_sents": ["7", "2", "5", "4", "1", "3", "6", "0"], "shuf_sents": ["Tests on synthetic and real datasets show cases where there are significant improvements in performance over the existing approaches .", "Expectation Propagation is used for approximate inference and the mean of the posterior is used for classification .", "One problem is that of hyperparameter learning : performance depends greatly on the hyperparameters of the similarity graph , transformation of the graph Laplacian and the noise model .", "The hyperparameters are learned using EM for evidence maximization .", "Given some labeled data , which can contain inaccurate labels , we pose the semi-supervised classification as an inference problem over the unknown labels .", "We present a Bayesian framework for learning hyperparameters for graph-based semisupervised classification .", "We also show that the posterior mean can be written in terms of the kernel matrix , providing a Bayesian classifier to classify new points .", "There have been many graph-based approaches for semi-supervised classification ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["We establish a general equivalence among convex bounding methods , evidence based methods , and ensemble learning/Variational Bayes methods , which has previously been demonstrated only for particular cases .", "We consider criteria for variational representations of non-Gaussian latent variables , and derive variational EM algorithms in general form ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["The procedure does not require computations of eigenvalues of the Gram matrices , which makes it potentially attractive for clustering large data sets .", "The constraints are chosen such that patterns are likely to be clustered similarly if they lie close to specific unknown vectors in the feature space .", "We propose a simple information-theoretic approach to soft clustering based on maximizing the mutual information I ( x , y ) between the unknown cluster labels y and the training patterns x with respect to parameters of specifically constrained encoding distributions .", "The method may be conveniently applied to learning the optimal affinity matrix , which corresponds to learning parameters of the kernelized encoder ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["The stochastic complexity , which corresponds to the minimum free energy and a lower bound of the marginal likelihood , is a key quantity for model selection .", "In this paper , we discuss the Variational Bayesian learning of the mixture of exponential families and provide some additional theoretical support by deriving the asymptotic form of the stochastic complexity .", "It also enables us to discuss the effect of hyperparameters and the accuracy of the Variational Bayesian approach as an approximation of the true Bayesian learning .", "In various applications , it has provided computational tractability and good generalization performance .", "The Variational Bayesian framework has been widely used to approximate the Bayesian learning ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["Two essential tasks underlying such visual-motor cooperation are shown here to be simply expressed and directly solved as transformation-discovery inverse problems : ( a ) discriminating and determining the pose of a primed 3D object in a real-world scene , and ( b ) interpreting the 3D configuration of an articulated kinematic object in an image .", "The recently developed map-seeking method provides a mathematically tractable , cortically-plausible solution to these and a variety of other inverse problems which can be posed as the discovery of a composition of transformations between two patterns .", "If the common architecture and circuitry of the cortices is taken to imply a common computation across multiple perceptual and cognitive modalities , this visual-motor interaction might be expected to have a unified computational basis .", "Recent neurophysiological evidence suggests the ability to interpret biological motion is facilitated by a neuronal `` mirror system '' which maps visual inputs to the pre-motor cortex .", "The method relies on an ordering property of superpositions and on decomposition of the transformation spaces inherent in the generating processes of the problem ."]}
{"orig_sents": ["1", "3", "4", "0", "2"], "shuf_sents": ["By adding noise to the motor program inferred from an MNIST image we can generate a large set of very different images of the same class , thus enlarging the training set available to other methods .", "We describe a generative model for handwritten digits that uses two pairs of opposing springs whose stiffnesses are controlled by a motor program .", "We can also use the motor programs as additional , highly informative outputs which reduce overfitting when training a feed-forward classifier .", "We show how neural networks can be trained to infer the motor programs required to accurately reconstruct the MNIST digits .", "The inferred motor programs can be used directly for digit classification , but they can also be used in other ways ."]}
{"orig_sents": ["3", "4", "1", "5", "0", "2"], "shuf_sents": ["This kernel solves an extended regularization problem which requires a joint minimization over both the data and the set of graph kernels .", "For each of these graphs we associate a basic graph kernel .", "We present encouraging results on different OCR tasks where the optimal combined kernel is computed from graphs constructed with a variety of distances functions and the `k ' in nearest neighbors .", "A foundational problem in semi-supervised learning is the construction of a graph underlying the data .", "We propose to use a method which optimally combines a number of differently constructed graphs .", "We then compute an optimal combined kernel ."]}
{"orig_sents": ["0", "4", "3", "5", "1", "2"], "shuf_sents": ["Multiple visual cues are used by the visual system to analyze a scene ; achromatic cues include luminance , texture , contrast and motion .", "Our results relate cue-invariant response properties to natural image statistics , thereby showing how the statistical modeling approach can be used to model processing beyond the elemental response properties visual neurons .", "This work also demonstrates how to learn , from natural image data , more sophisticated feature detectors than those based on changes in mean luminance , thereby paving the way for new data-driven approaches to image processing and computer vision .", "This paper shows that cue-invariant response properties of simple- and complex-type cells can be learned from natural image data in an unsupervised manner .", "Singlecell recordings have shown that the mammalian visual cortex contains neurons that respond similarly to scene structure ( e.g. , orientation of a boundary ) , regardless of the cue type conveying this information .", "In order to do this , we also extend a previous conceptual model of cue invariance so that it can be applied to model simple- and complex-cell responses ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["We develop experiment selection methods based on entropy , misclassification rate , variance , and their combinations , and show how they perform on a number of data sets .", "We then show how these algorithms are used to determine simultaneously valid 1 - confidence intervals for seven cosmological parameters .", "Experimentation shows that the algorithm reduces the computation necessary for the parameter estimation problem by an order of magnitude .", "We present an efficient algorithm to actively select queries for learning the boundaries separating a function domain into regions where the function is above and below a given threshold ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We show that taking a particular stochastic process - the Pitman-Yor process - as an adaptor justifies the appearance of type frequencies in formal analyses of natural language , and improves the performance of a model for unsupervised learning of morphology .", "Standard statistical models of language fail to capture one of the most striking properties of natural languages : the power-law distribution in the frequencies of word tokens .", "We present a framework for developing statistical models that generically produce power-laws , augmenting standard generative models with an adaptor that produces the appropriate pattern of token frequencies ."]}
{"orig_sents": ["2", "1", "3", "4", "5", "0"], "shuf_sents": ["Keywords : Algorithms and architectures , learning theory .", "Given the pairwise adjacency matrix of all points , we define a diffusion distance between any two data points and show that the low dimensional representation of the data by the first few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion .", "This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian .", "Furthermore , assuming that data points are random samples from a density p ( x ) = e-U ( x ) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U ( x ) with reflecting boundary conditions .", "Finally , applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator , we provide a mathematical justification for the success of spectral clustering and dimensional reduction algorithms based on these first few eigenvectors .", "This analysis elucidates , in terms of the characteristics of diffusion processes , many empirical findings regarding spectral clustering algorithms ."]}
{"orig_sents": ["0"], "shuf_sents": ["We characterize the sample complexity of active learning problems in terms of a parameter which takes into account the distribution over the input space , the specific target hypothesis , and the desired accuracy ."]}
{"orig_sents": ["0", "3", "2", "7", "1", "6", "5", "4"], "shuf_sents": ["Active learning is the problem in supervised learning to design the locations of training input points so that the generalization error is minimized .", "However , it turns out that the weakened condition is still restrictive in practice .", "In many practical situations , however , this assumption may not be fulfilled .", "Existing active learning methods often assume that the model used for learning is correctly specified , i.e. , the learning target function can be expressed by the model at hand .", "Numerical studies show that the proposed active learning method is robust against the misspecification of models and is thus reliable .", "Thus , the proposed method has a broader range of applications than the existing method .", "To cope with this problem , we propose an alternative active learning method which can be theoretically justified for a wider class of misspecified models .", "In this paper , we first show that the existing active learning method can be theoretically justified under slightly weaker condition : the model does not have to be correctly specified , but slightly misspecified models are also allowed ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We introduce a technique for dimensionality estimation based on the notion of quantization dimension , which connects the asymptotic optimal quantization error for a probability distribution on a manifold to its intrinsic dimension .", "Using the formalism of high-rate vector quantization , we address issues of statistical consistency and analyze the behavior of our scheme in the presence of noise .", "The definition of quantization dimension yields a family of estimation algorithms , whose limiting case is equivalent to a recent method based on packing numbers ."]}
{"orig_sents": ["4", "3", "1", "2", "0"], "shuf_sents": ["Other individuals do not detect enough changes , and perform sub-optimally because they fail to notice short-term temporal trends .", "We assess individual differences between observers both empirically , and using two kinds of models : a Bayesian approach for change detection and a family of cognitively plausible fast and frugal models .", "Some individuals detect too many changes and hence perform sub-optimally due to excess variability .", "Accurate performance in this task requires the identification of changepoints .", "We measure the ability of human observers to predict the next datum in a sequence that is generated by a simple statistical process undergoing change at random points in time ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["We construct a convex optimization problem whose solution generates such a metric by trying to collapse all examples in the same class to a single point and push examples in other classes infinitely far away .", "We show that when the metric we learn is used in simple classifiers , it yields substantial improvements over standard alternatives on a variety of problems .", "Our method relies on the simple geometric intuition that a good metric is one under which points in the same class are simultaneously near each other and far from points in the other classes .", "We also discuss how the learned metric may be used to obtain a compact low dimensional feature representation of the original input space , allowing more efficient classification with very little reduction in performance .", "We present an algorithm for learning a quadratic Gaussian metric ( Mahalanobis distance ) for use in classification tasks ."]}
{"orig_sents": ["1", "4", "3", "0", "2"], "shuf_sents": ["A random walk analysis indicates that the algorithm exposes clustering structures in various resolutions , i.e. , a higher level statistically models a longer-term diffusion on graphs and thus discovers a more global clustering structure .", "We propose a simple clustering framework on graphs encoding pairwise data similarities .", "Finally we provide very encouraging experimental results .", "More importantly , a hierarchical clustering is naturally derived in this framework to gradually merge lower-level clusters into higher-level ones .", "Unlike usual similarity-based methods , the approach softly assigns data to clusters in a probabilistic way ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["We validated the model by comparing its behavior to the behavior of human observers performing the identical object class detection task ( looking for a teddy bear among visually complex nontarget objects ) .", "We present a computational model of human eye movements in an object class detection task .", "The model combines state-of-the-art computer vision object class detection methods ( SIFT features trained using AdaBoost ) with a biologically plausible model of human eye movement to produce a sequence of simulated fixations , culminating with the acquisition of a target .", "We found considerable agreement between the model and human data in multiple eye movement measures , including number of fixations , cumulative probability of fixating the target , and scanpath distance ."]}
{"orig_sents": ["8", "1", "3", "2", "0", "4", "5", "7", "6"], "shuf_sents": ["Exploration is mediated by the state of LC firing , with higher tonic and lower phasic activity producing greater response variability .", "The model is developed for a target detection task for which there is extant single neuron recording data available from locus coeruleus ( LC ) NE neurons .", "DA functions within the model to change synaptic weights according to a reinforcement learning algorithm .", "An exploration-exploitation trade-off is elicited by regularly switching which of the two stimuli are rewarded .", "The opposite state of LC function , with lower baseline firing rate and greater phasic responses , favors exploitative behavior .", "Changes in LC firing mode result from combined measures of response conflict and reward rate , where response conflict is monitored using models of anterior cingulate cortex ( ACC ) .", "This increases exploration , and facilitates discovery of the new target .", "Increased long-term response conflict and decreased reward rate , which occurs following reward contingency switch , favors the higher tonic state of LC function and NE release .", "We propose a model by which dopamine ( DA ) and norepinepherine ( NE ) combine to alternate behavior between relatively exploratory and exploitative modes ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["For settings of interest with a very large number of agents , this is impractical .", "This makes them applicable even in settings with a very large number of agents n .", "We consider the scaling of the number of examples necessary to achieve good performance in distributed , cooperative , multi-agent reinforcement learning , as a function of the the number of agents n. We prove a worstcase lower bound showing that algorithms that rely solely on a global reward signal to learn policies confront a fundamental limit : They require a number of real-world examples that scales roughly linearly in the number of agents .", "We demonstrate , however , that there is a class of algorithms that , by taking advantage of local reward signals in large distributed Markov Decision Processes , are able to ensure good performance with a number of samples that scales as O ( log n ) ."]}
{"orig_sents": ["2", "1", "4", "3", "0", "5", "6"], "shuf_sents": ["In this paper , we present a new spectral clustering algorithm , named `` Soft Cut '' .", "But , most spectral clustering algorithms can not handle multi-class clustering problems directly .", "Spectral clustering enjoys its success in both data clustering and semisupervised learning .", "Furthermore , most spectral clustering algorithms employ hard cluster membership , which is likely to be trapped by the local optimum .", "Additional strategies are needed to extend spectral clustering algorithms to multi-class clustering problems .", "It improves the normalized cut algorithm by introducing soft membership , and can be efficiently computed using a bound optimization algorithm .", "Our experiments with a variety of datasets have shown the promising performance of the proposed clustering algorithm ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["We present a family of approximation techniques for probabilistic graphical models , based on the use of graphical preconditioners developed in the scientific computing literature .", "Experiments are presented that compare the new approximation schemes to variational methods .", "As in mean field approaches , the approximations are built upon tractable subgraphs ; however , we recast the problem of optimizing the tractable distribution parameters and approximate inference in terms of the well-studied linear systems problem of obtaining a good matrix preconditioner .", "Our framework yields rigorous upper and lower bounds on event probabilities and the log partition function of undirected graphical models , using non-iterative procedures that have low time complexity ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["An efficient distributed algorithm is devised on the basis of insight gained from the analysis and is examined using numerical simulations , showing excellent performance and full agreement with the theoretical results .", "The problem of resource allocation in sparse graphs with real variables is studied using methods of statistical physics ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["Hybrid `` CMOL '' integrated circuits , combining CMOS subsystem with nanowire crossbars and simple two-terminal nanodevices , promise to extend the exponential Moore-Law development of microelectronics into the sub-10-nm range .", "In Conclusion , we discuss in brief possible short-term and long-term applications of the emerging technology .", "Preliminary estimates have shown that CMOL CrossNets may be extremely dense ( ~10 7 cells per cm2 ) and operate approximately a million times faster than biological neural networks , at manageable power consumption .", "We have shown how CrossNets may be trained to perform pattern recovery and classification despite the limitations imposed by the CMOL hardware .", "We are developing neuromorphic network ( `` CrossNet '' ) architectures for this future technology , in which neural cell bodies are implemented in CMOS , nanowires are used as axons and dendrites , while nanodevices ( bistable latching switches ) are used as elementary synapses ."]}
{"orig_sents": ["5", "6", "1", "0", "2", "4", "3"], "shuf_sents": ["We first describe algorithms for planning actions to achieve a goal state using probabilistic inference .", "In this paper , we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment .", "We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment .", "Using a simple maze navigation task , we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete .", "The resulting graphical model is then shown to be powerful enough to allow goal-based imitation .", "Humans are extremely adept at learning new skills by imitating the actions of others .", "A progression of imitative abilities has been observed in children , ranging from imitation of simple body movements to goalbased imitation based on inferring intent ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["By optimizing this criterion , we are then able to compute correspondence and morphs for novel heads .", "Establishing correspondence between distinct objects is an important and nontrivial task : correctness of the correspondence hinges on properties which are difficult to capture in an a priori criterion .", "While previous work has used a priori criteria which in some cases led to very good results , the present paper explores whether it is possible to learn a combination of features that , for a given training set of aligned human heads , characterizes the notion of correct correspondence ."]}
{"orig_sents": ["2", "5", "4", "6", "1", "3", "0", "7", "8"], "shuf_sents": ["Then , we used RL models to simulate their behavior .", "To study the effects of stress and genotype , we carried out 5-hole-box light conditioning and Morris water maze experiments with C57BL/6 and DBA/2 mouse strains .", "Stress and genetic background regulate different aspects of behavioral learning through the action of stress hormones and neuromodulators .", "The animals were exposed to different kinds of stress to evaluate its effects on immediate performance as well as on long-term memory .", "They are hypothesized to be related to neuromodulatory levels in the brain .", "In reinforcement learning ( RL ) models , meta-parameters such as learning rate , future reward discount factor , and exploitation-exploration factor , control learning dynamics and performance .", "We found that many aspects of animal learning and performance can be described by simple RL models using dynamic control of the meta-parameters .", "For each experimental session , we estimated a set of model meta-parameters that produced the best fit between the model and the animal performance .", "The dynamics of several estimated meta-parameters were qualitatively similar for the two simulated experiments , and with statistically significant differences between different genetic strains and stress conditions ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Moreover , we show that these bounds can be uniformly estimated on the training data for all possible posteriors Q .", "We propose new PAC-Bayes bounds for the risk of the weighted majority vote that depend on the mean and variance of the error of its associated Gibbs classifier .", "We show that these bounds can be smaller than the risk of the Gibbs classifier and can be arbitrarily close to zero even if the risk of the Gibbs classifier is close to 1/2 .", "Moreover , they can be improved by using a large sample of unlabelled data ."]}
{"orig_sents": ["0", "3", "2", "1", "6", "5", "4"], "shuf_sents": ["Graph matching is a fundamental problem in Computer Vision and Machine Learning .", "The second is a normalization procedure for existing graph matching scoring functions that can dramatically improve the matching accuracy .", "First , we give a new spectral relaxation technique for approximate solutions to matching problems , that naturally incorporates one-to-one or one-to-many constraints within the relaxation scheme .", "We present two contributions .", "Our normalization procedure can be used to improve the performance of many existing graph matching algorithms , including spectral matching , graduated assignment and semidefinite programming .", "We evaluate our two contributions on a comprehensive test set of random graph matching problems , as well as on image correspondence problem .", "It is based on a reinterpretation of the graph matching compatibility matrix as a bipartite graph on edges for which we seek a bistochastic normalization ."]}
{"orig_sents": ["1", "0", "4", "2", "3"], "shuf_sents": ["In this paper , we present an asymptotic analysis of active learning for generalized linear models .", "Active learning refers to algorithmic frameworks aimed at selecting training data points in order to reduce the number of required training data points and/or improve the generalization performance of a learning method .", "We derive unbiased estimators of generalization performance , as well as estimators of expected reduction in generalization error after adding a new training data point , that allow us to optimize its sampling distribution through a convex optimization problem .", "Our analysis naturally leads to an algorithm for sequential active learning which is applicable for all tasks supported by generalized linear models ( e.g. , binary classification , multi-class classification , regression ) and can be applied in non-linear settings through the use of Mercer kernels .", "Our analysis holds under the common practical situation of model misspecification , and is based on realistic assumptions regarding the nature of the sampling distributions , which are usually neither independent nor identical ."]}
{"orig_sents": ["3", "0", "4", "5", "1", "2"], "shuf_sents": ["The registration is treated as a Maximum Likelihood ( ML ) estimation problem with motion coherence constraint over the velocity field such that one point set moves coherently to align with the second set .", "The CPD method simultaneously finds both the non-rigid transformation and the correspondence between two point sets without making any prior assumption of the transformation model except that of motion coherence .", "This method can estimate complex non-linear non-rigid transformations , and is shown to be accurate on 2D and 3D examples and robust in the presence of outliers and missing points .", "We introduce Coherent Point Drift ( CPD ) , a novel probabilistic method for nonrigid registration of point sets .", "We formulate the motion coherence constraint and derive a solution of regularized ML estimation through the variational approach , which leads to an elegant kernel form .", "We also derive the EM algorithm for the penalized ML optimization with deterministic annealing ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["The risk , or probability of error , of the classifier produced by the AdaBoost algorithm is investigated .", "In particular , we consider the stopping strategy to be used in AdaBoost to achieve universal consistency .", "We show that provided AdaBoost is stopped after n iterations -- for sample size n and < 1 -- the sequence of risks of the classifiers it produces approaches the Bayes risk if Bayes risk L > 0 ."]}
{"orig_sents": ["1", "5", "2", "4", "0", "3"], "shuf_sents": ["Two observation schedules are proposed : the first treats scanlines as independent , the second uses an active learning criterion to select a sparse subset of points to measure .", "This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images .", "As such , we call our model a switched Gaussian process .", "We show that this probabilistic framework has comparable performance to the state-of-the-art .", "We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels .", "The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities ."]}
{"orig_sents": ["1", "0", "2", "3", "4"], "shuf_sents": ["The HMDP posits that a haplotype of genetic markers is generated by a sequence of recombination events that select an ancestor for each locus from an unbounded set of founders according to a 1st-order Markov transition process .", "We present a new statistical framework called hidden Markov Dirichlet process ( HMDP ) to jointly model the genetic recombinations among possibly infinite number of founders and the coalescence-with-mutation events in the resulting genealogies .", "Conjoining this process with a mutation model , our method accommodates both between-lineage recombination and within-lineage sequence variations , and leads to a compact and natural interpretation of the population structure and inheritance process underlying haplotype data .", "We have developed an efficient sampling algorithm for HMDP based on a two-level nested Polya urn scheme .", "On both simulated and real SNP haplotype data , our method performs competitively or significantly better than extant methods in uncovering the recombination hotspots along chromosomal loci ; and in addition it also infers the ancestral genetic patterns and offers a highly accurate map of ancestral compositions of modern populations ."]}
{"orig_sents": ["0", "3", "5", "7", "4", "1", "2", "8", "6"], "shuf_sents": ["Computational gene prediction using generative models has reached a plateau , with several groups converging to a generalized hidden Markov model ( GHMM ) incorporating phylogenetic models of nucleotide sequence evolution .", "We tested our model on the genome sequence of the fungal human pathogen Cryptococcus neoformans .", "Our baseline comparative model displays accuracy comparable to the the best available gene prediction tool for this organism .", "Further improvements in gene calling accuracy are likely to come through new methods that incorporate additional data , both comparative and species specific .", "We implement a model that encapsulates both a phylogenetic-GHMM ( our baseline comparative model ) and additional non-probabilistic features .", "Conditional Random Fields ( CRFs ) , which directly model the conditional probability P ( y|x ) of a vector of hidden states conditioned on a set of observations , provide a unified framework for combining probabilistic and non-probabilistic information and have been shown to outperform HMMs on sequence labeling tasks in natural language processing .", "Our software implementation , Conrad , is freely available with an open source license at http : //www.broad.mit.edu/annotation/conrad/ .", "We describe the use of CRFs for comparative gene prediction .", "Moreover , we show that discriminative training and the incorporation of non-probabilistic evidence significantly improve performance ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["A key challenge in designing analog-to-digital converters for cortically implanted prosthesis is to sense and process high-dimensional neural signals recorded by the micro-electrode arrays .", "In this paper , we describe a novel architecture for analog-to-digital ( A/D ) conversion that combines conversion with spatial de-correlation within a single module .", "The architecture called multiple-input multiple-output ( MIMO ) is based on a min-max gradient descent optimization of a regularized linear cost function that naturally lends to an A/D formulation .", "Using an online formulation , the architecture can adapt to slow variations in cross-channel correlations , observed due to relative motion of the microelectrodes with respect to the signal sources .", "Experimental results with real recorded multi-channel neural data demonstrate the effectiveness of the proposed algorithm in alleviating cross-channel redundancy across electrodes and performing data-compression directly at the A/D converter ."]}
{"orig_sents": ["4", "0", "3", "1", "7", "6", "2", "5"], "shuf_sents": ["However , in many real-world scenarios , planning can be simplified by decomposing the task into a hierarchy of smaller planning problems .", "In this paper , we investigate the problem of automatically discovering the hierarchy .", "Our method is flexible enough to allow any parts of the hierarchy to be specified based on prior knowledge while letting the optimization discover the unknown parts .", "Several approaches have been proposed to optimize a policy that decomposes according to a hierarchy specified a priori .", "Planning in partially observable domains is a notoriously difficult problem .", "It can also discover hierarchical policies , including recursive policies , that are more compact ( potentially infinitely fewer parameters ) and often easier to understand given the decomposition induced by the hierarchy .", "By encoding the hierarchical structure as variables of the optimization problem , we can automatically discover a hierarchy .", "More precisely , we frame the optimization of a hierarchical policy as a non-convex optimization problem that can be solved with general non-linear solvers , a mixed-integer non-linear approximation or a form of bounded hierarchical policy iteration ."]}
{"orig_sents": ["4", "3", "2", "5", "1", "0"], "shuf_sents": ["We discuss several variations on this model and show how some can be seen as exact generalizations of the PageRank algorithm .", "Several surprising results come with this shift : in addition to being computationally more tractable , the new model produces factors that more cleanly decompose the document collection .", "Many problems arise when trying to apply these joint models to corpus at the scale of the World Wide Web , however ; one of these is that the sheer overhead of representing a feature space on the order of billions of dimensions becomes impractical .", "Prior work demonstrated that when links exist between documents in the corpus ( as is the case with a collection of web pages or scientific papers ) , building a joint model of document contents and connections produces a better model than that built from contents or connections alone .", "Clustering , or factoring of a document collection attempts to `` explain '' each observed document in terms of one or a small number of inferred prototypes .", "We address this problem with a simple representational shift inspired by probabilistic relational models : instead of representing document linkage in terms of the identities of linking documents , we represent it by the explicit and inferred attributes of the linking documents ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["The upshot is that the method has strong expressive power even with rather few features , is clearly outperforming the ordinary kernel PLS , and therefore is an appealing method for feature extraction of labelled data .", "Our scheme is based on a novel kernel orthonormalized partial least squares ( PLS ) variant for feature extraction , imposing sparsity constrains in the solution to improve scalability .", "The algorithm is tested on a benchmark of UCI data sets , and on the analysis of integrated short-time music features for genre prediction .", "In this paper we are presenting a novel multivariate analysis method ."]}
{"orig_sents": ["3", "5", "7", "2", "4", "1", "6", "0"], "shuf_sents": ["Although this paper is directed towards ranking , the proposed method can be extended to any non-smooth and multivariate cost functions .", "We demonstrate significantly improved accuracy , over a state-of-the-art ranking algorithm , on several datasets .", "We describe LambdaRank using neural network models , although the idea applies to any differentiable function class .", "The quality measures used in information retrieval are particularly difficult to optimize directly , since they depend on the model scores only through the sorted order of the documents returned for a given query .", "We give necessary and sufficient conditions for the resulting implicit cost function to be convex , and we show that the general method has a simple mechanical interpretation .", "Thus , the derivatives of the cost with respect to the model parameters are either zero , or are undefined .", "We also show that LambdaRank provides a method for significantly speeding up the training phase of that ranking algorithm .", "In this paper , we propose a class of simple , flexible algorithms , called LambdaRank , which avoids these difficulties by working with implicit cost functions ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["Given distinct samples from multiple data sources and estimates of the dissimilarities between these sources , we provide a general theory of which samples should be used to learn models for each source .", "A key component of our approach is the development of approximate triangle inequalities for expected loss , which may be of independent interest .", "This theory is applicable in a broad decision-theoretic learning framework , and yields results for classification and regression generally , and for density estimation within the exponential family .", "We consider the problem of learning accurate models from multiple sources of `` nearby '' data ."]}
{"orig_sents": ["6", "5", "2", "3", "0", "4", "1"], "shuf_sents": [".", "Experiments on graphs from bioinformatics and other application domains show that our algorithms are often more than 1000 times faster than existing approaches .", "This includes kernels whose previous worst-case time complexity was O ( n6 ) , such as the geometric kernels of Gartner et al .", "and the marginal graph kernels of Kashima et al .", "Our algebra in RKHS allow us to exploit sparsity in directed and undirected graphs more effectively than previous methods , yielding sub-cubic computational complexity when combined with conjugate gradient solvers or fixed-point iterations .", "Reduction to a Sylvester equation allows us to compute many of these kernels in O ( n3 ) worst-case time .", "Using extensions of linear algebra concepts to Reproducing Kernel Hilbert Spaces ( RKHS ) , we define a unifying framework for random walk kernels on graphs ."]}
{"orig_sents": ["2", "3", "5", "4", "6", "1", "0"], "shuf_sents": ["We demonstrate that the system achieves its best performance when the model of temporal dynamics closely captures the grammatical constraints of the task .", "The estimated source signals are then recognized using a conventional speech recognition system .", "Human listeners have the extraordinary ability to hear and recognize speech even when more than one person is talking .", "Their machine counterparts have historically been unable to compete with this ability , until now .", "Remarkably , the system surpasses human recognition performance in many conditions .", "We present a modelbased system that performs on par with humans in the task of separating speech of two talkers from a single-channel recording .", "The models of speech use temporal dynamics to help infer the source speech signals , given mixed speech signals ."]}
{"orig_sents": ["5", "4", "1", "0", "3", "6", "2"], "shuf_sents": ["Variabilities in mixing proportions across groups are handled using hierarchical Dirichlet processes , also allowing for automatic determination of the number of components .", "Each group is assumed to be generated from a template mixture model with group level variability in both the mixing proportions and the component parameters .", "We present a Markov Chain Monte Carlo ( MCMC ) sampling algorithm to estimate model parameters and demonstrate the method by applying it to the problem of modeling spatial brain activation patterns across multiple images collected via functional magnetic resonance imaging ( fMRI ) .", "In addition , each group is allowed to have its own component parameters coming from a prior described by a template mixture model .", "In this paper we extend hierarchical Dirichlet processes to model such data .", "Data sets involving multiple groups with shared characteristics frequently arise in practice .", "This group-level variability in the component parameters is handled using a random effects model ."]}
{"orig_sents": ["4", "5", "1", "0", "3", "2", "6"], "shuf_sents": ["In our experience however , the success of many approaches often lie in the power of the features .", "Following a established line of research , pose estimation is framed as inference in a probabilistic model .", "We show quantitative results for human pose estimation on a database of over 300 images that suggest our algorithm is competitive with or surpasses the state-of-the-art .", "Our primary contribution is a novel casting of visual inference as an iterative parsing process , where one sequentially learns better and better features tuned to a particular image .", "We consider the machine vision task of pose estimation from static images , specifically for the case of articulated objects .", "This problem is hard because of the large number of degrees of freedom to be estimated .", "Since our procedure is quite general ( it does not rely on face or skin detection ) , we also use it to estimate the poses of horses in the Weizmann database ."]}
{"orig_sents": ["2", "0", "7", "4", "5", "3", "1", "6"], "shuf_sents": ["Starting from a given or random initial condition , we use normalized gradient descent to update the coefficients of a time varying polynomial whose degree is the number of hyperplanes and whose derivatives at a trajectory give an estimate of the vector normal to the hyperplane containing that trajectory .", "Our method not only segments the bird motion from the surrounding water motion , but also determines patterns of motion in the scene ( e.g. , periodic motion ) directly from the temporal evolution of the estimated polynomial coefficients .", "We propose a recursive algorithm for clustering trajectories lying in multiple moving hyperplanes .", "We test our algorithm on the segmentation of dynamic scenes containing rigid motions and dynamic textures , e.g. , a bird floating on water .", "The segmentation of the trajectories is then obtained by clustering their associated normal vectors .", "The final result is a simple recursive algorithm for segmenting a variable number of moving hyperplanes .", "Our experiments also show that our method can deal with appearing and disappearing motions in the scene .", "As time proceeds , the estimates of the hyperplane normals are shown to track their true values in a stable fashion ."]}
{"orig_sents": ["0", "7", "4", "5", "1", "3", "2", "6"], "shuf_sents": ["Starting with the work of Jaakkola and Haussler , a variety of approaches have been proposed for coupling domain-specific generative models with statistical learning methods .", "Specifically , the kernel quantifies the similarity of evolutionary escape from antiviral drug pressure between two viral sequence samples .", "The results show significant improvements in predictive performance across 17 anti-HIV drugs .", "We compare this novel kernel to a standard , evolution-agnostic amino acid encoding in the prediction of HIV drug resistance from genotype , using support vector regression .", "In computational biology , the full promise of this framework has rarely ever been exploited , as most kernels are derived from very generic models , such as sequence profiles or hidden Markov models .", "Here , we introduce the MTreeMix kernel , which is based on a generative model tailored to the underlying biological mechanism .", "Thus , in our study , the generative-discriminative paradigm is key to bridging the gap between population genetic modeling and clinical decision making .", "The link is established by a kernel function which provides a similarity measure based inherently on the underlying model ."]}
{"orig_sents": ["2", "3", "0", "1", "5", "4"], "shuf_sents": ["In this paper , we present efficient sparse coding algorithms that are based on iteratively solving two convex optimization problems : an L1 -regularized least squares problem and an L2 -constrained least squares problem .", "We propose novel algorithms to solve both of these optimization problems .", "Sparse coding provides a class of algorithms for finding succinct representations of stimuli ; given only unlabeled input data , it discovers basis functions that capture higher-level features in the data .", "However , finding sparse codes remains a very difficult computational problem .", "We apply these algorithms to natural images and demonstrate that the inferred sparse codes exhibit end-stopping and non-classical receptive field surround suppression and , therefore , may provide a partial explanation for these two phenomena in V1 neurons .", "Our algorithms result in a significant speedup for sparse coding , allowing us to learn larger sparse codes than possible with previously described algorithms ."]}
{"orig_sents": ["0", "3", "6", "5", "1", "2", "4"], "shuf_sents": ["We1 develop Conditional Random Sampling ( CRS ) , a technique particularly suitable for sparse data .", "For boolean ( 0/1 ) data , CRS is provably better than random projections .", "We show using real-world data that CRS often outperforms random projections .", "In large-scale applications , the data are often highly sparse .", "This technique can be applied in learning , data mining , information retrieval , and database query optimizations .", "This paper focuses on approximating pairwise l2 and l1 distances and comparing CRS with random projections .", "CRS combines sketching and sampling in that it converts sketches of the data into conditional random samples online in the estimation stage , with the sample size determined retrospectively ."]}
{"orig_sents": ["0", "4", "1", "5", "2", "3"], "shuf_sents": ["We describe a method to learn to make sequential stopping decisions , such as those made along a processing pipeline .", "Further processing costs time and resources , but may add value .", "We demonstrate how our framework encompasses problems from manufacturing to vision processing .", "We derive a quadratic ( in the number of decisions ) bound on testing performance and provide empirical results on object detection .", "We envision a scenario in which a series of decisions must be made as to whether to continue to process .", "Our goal is to create , based on historic data , a series of decision rules ( one at each stage in the pipeline ) that decide , based on information gathered up to that point , whether to continue processing the part ."]}
{"orig_sents": ["2", "8", "5", "7", "3", "4", "0", "6", "1", "9"], "shuf_sents": ["The proof uses a new form of VC-invariant shifting and a group-theoretic symmetrization .", "This bound on expected risk improves on known PAC-based results by a factor of O ( log n ) and is shown to be optimal up to a O ( log k ) factor .", "Under the prediction model of learning , a prediction strategy is presented with an i.i.d .", "The key data structure in their result is the natural subgraph of the hypercube -- the one-inclusion graph ; the key step is a d = VC ( F ) bound on one-inclusion graph density .", "The first main result of this n n-1 paper is a density bound of n d-1 / ( d ) < d , which positively resolves a conjecture of Kuzmin & Warmuth relating to their unlabeled Peeling compression scheme and also leads to an improved mistake bound for the randomized ( deterministic ) one-inclusion strategy for all d ( for d ( n ) ) .", "By exploiting the structure of F , Haussler et al .", "Our second main result is a k-class analogue of the d/n mistake bound , replacing the VC-dimension by the Pollard pseudo-dimension and the one-inclusion strategy by its natural hypergraph generalization .", "achieved a VC ( F ) /n bound for the natural one-inclusion prediction strategy , improving on bounds implied by PAC-type results by a O ( log n ) factor .", "sample of n - 1 points in X and corresponding labels from a concept f F , and aims to minimize the worst-case probability of erring on an nth point .", "The combinatorial technique of shifting takes a central role in understanding the one-inclusion ( hyper ) graph and is a running theme throughout ."]}
{"orig_sents": ["2", "3", "0", "5", "4", "6", "1"], "shuf_sents": ["Under what conditions can we adapt a classifier trained on the source domain for use in the target domain ?", "It also points toward a promising new model for domain adaptation : one which explicitly minimizes the difference between the source and target domains , while at the same time maximizing the margin of the training set .", "Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution .", "In many situations , though , we have labeled training data for a source domain , and we wish to learn a classifier which performs well on a target domain with a different distribution .", "We formalize this intuition theoretically with a generalization bound for domain adaption .", "Intuitively , a good feature representation is a crucial factor in the success of domain adaptation .", "Our theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model ."]}
{"orig_sents": ["3", "7", "0", "6", "4", "1", "2", "5"], "shuf_sents": ["These constraints are tied together through a single slack parameter .", "We derive concrete simultaneous projection schemes and analyze them in the mistake bound model .", "We demonstrate the power of the proposed algorithm in experiments with online multiclass text categorization .", "We describe and analyze an algorithmic framework for online classification where each online trial consists of multiple prediction tasks that are tied together .", "We show that this approach constitutes a feasible , albeit not necessarily optimal , solution for the original projection problem .", "Our experiments indicate that a combination of class-dependent features with the simultaneous projection method outperforms previously studied algorithms .", "We then introduce a general method for approximately solving the problem by projecting simultaneously and independently on each constraint which corresponds to a prediction sub-problem , and then averaging the individual solutions .", "We tackle the problem of updating the online hypothesis by defining a projection problem in which each prediction task corresponds to a single linear constraint ."]}
{"orig_sents": ["3", "4", "2", "0", "5", "1"], "shuf_sents": ["To achieve this goal we first define normalized CSP features and distances in-between .", "Finally , we construct a classifier based on these individualized prototypes and show that , indeed , classifiers can be successfully transferred to a new session for a number of subjects .", "We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions .", "Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min .", "From this data their ( movement ) intentions are so far infered .", "Second , we derive prototypical features across sessions : ( a ) by clustering or ( b ) by feature concatenation methods ."]}
{"orig_sents": ["1", "4", "0", "2", "3"], "shuf_sents": ["In the mean rate case the network amplifies the activity of neurons belonging to the selected stimulus and suppresses the activity of neurons receiving weaker stimuli .", "Cooperative competitive networks are believed to play a central role in cortical processing and have been shown to exhibit a wide set of useful computational properties .", "In the event correlation case , the recurrent network amplifies with a higher gain the correlation between neurons which receive highly correlated inputs while leaving the mean firing rate unaltered .", "We describe the network architecture and present experimental data demonstrating its context dependent computation capabilities .", "We propose a VLSI implementation of a spiking cooperative competitive network and show how it can perform context dependent computation both in the mean firing rate domain and in spike timing correlation space ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We consider single-class classification ( SCC ) as a two-person game between the learner and an adversary .", "We identify both `` hard '' and `` soft '' optimal classification strategies for different types of games and demonstrate that soft classification can provide a significant advantage .", "Our optimal strategies and bounds provide worst-case lower bounds for standard , finite-sample SCC and also motivate new approaches to solving SCC .", "In this game the target distribution is completely known to the learner and the learner 's goal is to construct a classifier capable of guaranteeing a given tolerance for the false-positive error while minimizing the false negative error ."]}
{"orig_sents": ["5", "4", "3", "0", "2", "1"], "shuf_sents": ["The independently obtained partial solutions can then be recombined in an efficient way , which allows us to solve label sequence learning problems with several thousands of labeled sequences .", "Results on a well-known model organism illustrate the great potential of SHM SVMs in computational biology .", "We have tested our algorithm for predicting gene structures , an important problem in computational biology .", "We propose a novel technique to partition the problem into sub-problems .", "This allows us to predict segmentations of sequences based on segment-based features measuring properties such as the length of the segment .", "We describe Hidden Semi-Markov Support Vector Machines ( SHM SVMs ) , an extension of HM SVMs to semi-Markov chains ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["In this paper we show convergence of eigenvectors of the point cloud Laplacian to the eigenfunctions of the Laplace-Beltrami operator on the underlying manifold , thus establishing the first convergence results for a spectral dimensionality reduction algorithm in the manifold setting .", "Geometrically based methods for various tasks of machine learning have attracted considerable attention over the last few years ."]}
{"orig_sents": ["2", "4", "3", "6", "1", "5", "0"], "shuf_sents": ["We show , via minimax inequalities , that this is essential : boundedness of pseudodimension or fat-shattering dimension alone is not sufficient .", "Previously , such results were derived by assuming boundedness of pseudodimension and Lipschitz continuity .", "We consider methods that try to find a good policy for a Markov decision process by choosing one from a given class .", "We are interested in conditions on the complexity of the policy class that ensure the success of such simulation based policy search methods .", "The policy is chosen based on its empirical performance in simulations .", "These assumptions and ours are both stronger than the usual combinatorial complexity measures .", "We show that under bounds on the amount of computation involved in computing policies , transition dynamics and rewards , uniform convergence of empirical estimates to true value functions occurs ."]}
{"orig_sents": ["4", "3", "2", "1", "0"], "shuf_sents": ["Experimental results for kernel PCA and spectral clustering of USPS digits as well as motion capture and image de-noising problems confirm that our methods converge substantially faster than conventional KHA .", "We then derive and apply Stochastic MetaDescent ( SMD ) to KHA/et ; this further speeds convergence by performing gain adaptation in RKHS .", "Our KHA/et algorithm accelerates KHA by incorporating the reciprocal of the current estimated eigenvalues as a gain vector .", "KHA has a scalar gain parameter which is either held constant or decreased as 1/t , leading to slow convergence .", "We introduce two methods to improve convergence of the Kernel Hebbian Algorithm ( KHA ) for iterative kernel PCA ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We consider the problem of training a conditional random field ( CRF ) to maximize per-label predictive accuracy on a training set , an approach motivated by the principle of empirical risk minimization .", "We give a gradient-based procedure for minimizing an arbitrarily accurate approximation of the empirical risk under a Hamming loss function .", "In experiments with both simulated and real data , our optimization procedure gives significantly better testing performance than several current approaches for CRF training , especially in situations of high label noise ."]}
{"orig_sents": ["0", "1", "2", "4", "5", "3"], "shuf_sents": ["Policy gradient methods are reinforcement learning algorithms that adapt a parameterized policy by following a performance gradient estimate .", "Conventional policy gradient methods use Monte-Carlo techniques to estimate this gradient .", "Since Monte Carlo methods tend to have high variance , a large number of samples is required , resulting in slow convergence .", "Moreover , estimates of the natural gradient as well as a measure of the uncertainty in the gradient estimates are provided at little extra cost .", "In this paper , we propose a Bayesian framework that models the policy gradient as a Gaussian process .", "This reduces the number of samples needed to obtain accurate gradient estimates ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["In this paper we propose a new probabilistic model that tempers this approach by representing each document as a combination of ( a ) a background distribution over common words , ( b ) a mixture distribution over general topics , and ( c ) a distribution over words that are treated as being specific to that document .", "These types of models and algorithms can be viewed as generating an abstraction from the words in a document to a lower-dimensional latent variable representation that captures what the document is generally about beyond the specific words it contains .", "Techniques such as probabilistic topic models and latent-semantic indexing have been shown to be broadly useful at automatically extracting the topical or semantic content of documents , or more generally for dimension-reduction of sparse count data .", "We illustrate how this model can be used for information retrieval by matching documents both at a general topic level and at a specific word level , providing an advantage over techniques that only match documents at a general level ( such as topic models or latent-sematic indexing ) or that only match documents at the specific word level ( such as TF-IDF ) ."]}
{"orig_sents": ["6", "3", "7", "2", "4", "1", "5", "0"], "shuf_sents": ["We find that the acquisition of directional information depends strongly on the time constant at which the intracellular response is filtered .", "Hence we provide a quantitative framework for addressing the question : how much could the cell know , and when could it know it ?", "Using Monte Carlo techniques ( MCell ) we construct a simulation in which a collection of individual ligand particles undergoing Brownian diffusion in a three-dimensional volume interact with receptors on the surface of a static amoeboid cell .", "Despite this suggestive terminology , there have been few attempts to analyze chemical signaling systems with the quantitative tools of information theory .", "Adapting a method for estimation of spike train entropies described by Victor ( originally due to Kozachenko and Leonenko ) , we estimate lower bounds on the mutual information between the transmitted signal ( direction of ligand source ) and the received signal ( spatiotemporal pattern of receptor binding/unbinding events ) .", "We show that the time course of the mutual information between the cell 's surface receptors and the ( unknown ) gradient direction is consistent with experimentally measured cellular response times .", "Chemical reaction networks by which individual cells gather and process information about their chemical environments have been dubbed `` signal transduction '' networks .", "Gradient sensing in the social amoeba Dictyostelium discoideum is a well characterized signal transduction system in which a cell estimates the direction of a source of diffusing chemoattractant molecules based on the spatiotemporal sequence of ligand-receptor binding events at the cell membrane ."]}
{"orig_sents": ["0", "3", "5", "1", "4", "2"], "shuf_sents": ["We present a robust distributed algorithm for approximate probabilistic inference in dynamical systems , such as sensor networks and teams of mobile robots .", "In addition , we identify a significant challenge for probabilistic inference in dynamical systems : message losses or network partitions can cause nodes to have inconsistent beliefs about the current state of the system .", "We present a suite of experimental results on real-world sensor data for two real sensor network deployments : one with 25 cameras and another with 54 temperature sensors .", "Using assumed density filtering , the network nodes maintain a tractable representation of the belief state in a distributed fashion .", "We address this problem by developing distributed algorithms that guarantee that nodes will reach an informative consistent distribution when communication is re-established .", "At each time step , the nodes coordinate to condition this distribution on the observations made throughout the network , and to advance this estimate to the next time step ."]}
{"orig_sents": ["0", "3", "1", "2", "4"], "shuf_sents": ["We consider the problem of denoising a noisily sampled submanifold M in Rd , where the submanifold M is a priori unknown and we are only given a noisy point sample .", "We analyze this diffusion process using recent results about the convergence of graph Laplacians .", "In the experiments we show that our method is capable of dealing with non-trivial high-dimensional noise .", "The presented denoising algorithm is based on a graph-based diffusion process of the point sample .", "Moreover using the denoising algorithm as pre-processing method we can improve the results of a semi-supervised learning algorithm ."]}
{"orig_sents": ["2", "5", "1", "3", "6", "4", "0", "7"], "shuf_sents": ["Very encouraging experimental results are achieved on a toy problem and a user-movie preference link prediction task .", "These models in fact define a set of nonparametric priors on infinite dimensional tensor matrices , where each element represents a relationship between a tuple of entities .", "We introduce a Gaussian process ( GP ) framework , stochastic relational models ( SRM ) , for learning social , physical , and other relational phenomena where interactions between entities are observed .", "By maximizing the marginalized likelihood , information is exchanged between the participating GPs through the entire relational network , so that the dependency structure of links is messaged to the dependency of entities , reflected by the adapted GP kernels .", "We discuss properties and variants of SRM and derive an efficient learning algorithm .", "The key idea is to model the stochastic structure of entity relationships ( i.e. , links ) via a tensor interaction of multiple GPs , each defined on one type of entities .", "The framework offers a discriminative approach to link prediction , namely , predicting the existences , strengths , or types of relationships based on the partially observed linkage network as well as the attributes of entities ( if given ) .", "In the end we discuss extensions of SRM to general relational learning tasks ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Its worst-case run-time is linear in the length of sequences and independent of the underlying embedding language , which can cover words , k-grams or all contained subsequences .", "We propose a generic algorithm for computation of similarity measures for sequential data .", "The algorithm uses generalized suffix trees for efficient calculation of various kernel , distance and non-metric similarity functions .", "Experiments with network intrusion detection , DNA analysis and text processing applications demonstrate the utility of distances and similarity coefficients for sequences as alternatives to classical kernel functions ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["In this paper we provide some formal analysis of that notion for a probability distribution .", "We show that sizes of the cuts of certain commonly used data adjacency graphs converge to this continuous weighted volume of the boundary .", "We introduce a notion of weighted boundary volume , which measures the length of the class/cluster boundary weighted by the density of the underlying probability distribution .", "keywords : Clustering , Semi-Supervised Learning", "One of the intuitions underlying many graph-based methods for clustering and semi-supervised learning , is that class or cluster boundaries pass through areas of low probability density ."]}
{"orig_sents": ["6", "3", "4", "8", "1", "2", "0", "7", "9", "5"], "shuf_sents": ["Shortest path problems are approximated to arbitrary precision with largest eigenvalue problems , yielding an O ( n ) algorithm .", "An exponential transformation of the optimal value function makes the minimized Bellman equation linear .", "Apart from their theoretical signi cance , the new MDPs enable ef cient approximations to traditional MDPs .", "They have discrete state spaces and continuous control spaces .", "The controls have the effect of rescaling the transition probabilities of an underlying Markov chain .", "This work was supported by NSF grant ECS-0524761 .", "We introduce a class of MPDs which greatly simplify Reinforcement Learning .", "Accurate approximations to generic MDPs are obtained via continuous embedding reminiscent of LP relaxation in integer programming .", "A control cost penalizing KL divergence between controlled and uncontrolled transition probabilities makes the minimization problem convex , and allows analytical computation of the optimal controls given the optimal value function .", "Offpolicy learning of the optimal value function is possible without need for stateaction values ; the new algorithm ( Z-learning ) outperforms Q-learning ."]}
{"orig_sents": ["4", "3", "2", "8", "9", "0", "5", "6", "7", "1"], "shuf_sents": ["A key issue in this setting is the ( unavoidable ) use of approximate inference , which can lead to errors in the gradient computation when the network structure is dense .", "We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone , demonstrating the existence of a feasible method for this important problem .", "In this paper , we provide a computationally efficient method for learning Markov network structure from data .", "In most current applications , even those that rely heavily on learned models , the structure of the Markov network is constructed by hand , due to the lack of effective algorithms for learning Markov network structure from data .", "Markov networks are commonly used in a wide variety of applications , ranging from computer vision , to natural language , to computational biology .", "Thus , we explore the use of different feature introduction schemes and compare their performance .", "We provide results for our method on synthetic data , and on two real world data sets : pixel values in the MNIST data , and genetic sequence variations in the human HapMap data .", "We show that our L1 -based method achieves considerably higher generalization performance than the more standard L2 -based method ( a Gaussian parameter prior ) or pure maximum-likelihood learning .", "Our method is based on the use of L1 regularization on the weights of the log-linear model , which has the effect of biasing the model towards solutions where many of the parameters are zero .", "This formulation converts the Markov network learning problem into a convex optimization problem in a continuous space , which can be solved using efficient gradient methods ."]}
{"orig_sents": ["2", "3", "4", "5", "6", "1", "0"], "shuf_sents": ["Simulations confirm the feasibility of the algorithm .", "After introducing this general model , we discuss joint block diagonalization with unknown block sizes , on which we base a simple extension of JADE to algorithmically perform the subspace analysis .", "The increasingly popular independent component analysis ( ICA ) may only be applied to data following the generative ICA model in order to guarantee algorithmindependent and theoretically valid results .", "Subspace ICA models generalize the assumption of component independence to independence between groups of components .", "They are attractive candidates for dimensionality reduction methods , however are currently limited by the assumption of equal group sizes or less general semi-parametric models .", "By introducing the concept of irreducible independent subspaces or components , we present a generalization to a parameter-free mixture model .", "Moreover , we relieve the condition of at-most-one-Gaussian by including previous results on non-Gaussian component analysis ."]}
{"orig_sents": ["6", "5", "4", "3", "1", "2", "0"], "shuf_sents": ["Experimental results show that it is much faster than the LapSVM , and can handle a million unlabeled examples on a standard PC ; while the LapSVM can only handle several thousand patterns .", "In this paper , we integrate manifold regularization with the core vector machine , which has been used for large-scale supervised and unsupervised learning .", "By using a sparsified manifold regularizer and formulating as a center-constrained minimum enclosing ball problem , the proposed method produces sparse solutions with low time and space complexities .", "Moreover , existing semi-supervised learning methods , including the LapSVM , can only handle a small number of unlabeled examples .", "However , the LapSVM solution typically involves kernel expansions of all the labeled and unlabeled examples , and is slow on testing .", "In particular , the manifold regularization framework , together with kernel methods , leads to the Laplacian SVM ( LapSVM ) that has demonstrated state-of-the-art performance .", "Semi-supervised learning is more powerful than supervised learning by using both labeled and unlabeled data ."]}
{"orig_sents": ["2", "0", "5", "1", "6", "3", "4"], "shuf_sents": ["Neurons subserving such detections are faced with the corresponding challenge to discern `` real '' changes in inputs as quickly as possible , while ignoring noisy fluctuations .", "In this paper , we utilize sophisticated tools developed in that community to formalize an instantiation of the problem faced by the nervous system , and characterize the Bayes-optimal decision policy under certain assumptions .", "Survival in a non-stationary , potentially adversarial environment requires animals to detect sensory changes rapidly yet accurately , two oft competing desiderata .", "This correspondence suggests that neurons are optimized for tracking input changes , and sheds new light on the computational import of intracellular properties such as resting membrane potential , voltage-dependent conductance , and post-spike reset voltage .", "We also explore the influence that factors such as timing , uncertainty , neuromodulation , and reward should and do have on neuronal dynamics and sensitivity , as the optimal decision strategy depends critically on these factors .", "Mathematically , this is an example of a change-detection problem that is actively researched in the controlled stochastic processes community .", "We will derive from this optimal strategy an information accumulation and decision process that remarkably resembles the dynamics of a leaky integrate-and-fire neuron ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We consider the well-studied problem of learning decision lists using few examples when many irrelevant features are present .", "We show that smooth boosting algorithms such as MadaBoost can efficiently learn decision lists of length k over n boolean variables using poly ( k , log n ) many examples provided that the marginal distribution over the relevant variables is `` not too concentrated '' in an L 2 -norm sense .", "Experimental results indicate that the use of a smooth boosting algorithm , which plays a crucial role in our analysis , has an impact on the actual performance of the algorithm .", "Using a recent result of Hastad , we extend the analysis to obtain a similar ( though quantitatively weaker ) result for learning arbitrary linear threshold functions with k nonzero coefficients ."]}
{"orig_sents": ["2", "4", "3", "0", "1"], "shuf_sents": ["We show that our approach is ideally suited for image segmentation : it avoids the combinatorial nature Markov random field priors , and opens the door to more sophisticated spatial priors ( e.g. , wavelet-based ) in a simple and computationally efficient way .", "Finally , we extend our formulation to work in unsupervised , semi-supervised , or discriminative modes .", "This paper proposes a new approach to model-based clustering under prior knowledge .", "To estimate the parameters of the proposed model , we derive a ( generalized ) EM algorithm with a closed-form E-step , in contrast with other recent approaches to semi-supervised probabilistic clustering which require Gibbs sampling or suboptimal shortcuts .", "The proposed formulation can be interpreted from two different angles : as penalized logistic regression , where the class labels are only indirectly observed ( via the probability density of each class ) ; as finite mixture learning under a grouping prior ."]}
{"orig_sents": ["1", "4", "0", "3", "2"], "shuf_sents": ["These conjunctive features appear to represent not only edges and bars , but also inherently two-dimensional stimuli , such as corners .", "In previous studies , quadratic modelling of natural images has resulted in cell models that react strongly to edges and bars .", "Our results indicate that the development of the V2 cells preferring angles and corners may be partly explainable by the principle of unsupervised sparse coding of natural images .", "In addition , we show that for many of the components , the underlying linear features have essentially V1 simple cell receptive field characteristics .", "Here we apply quadratic Independent Component Analysis to natural image patches , and show that up to a small approximation error , the estimated components are computing conjunctions of two linear features ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["Our algorithm is trained via supervised learning , using synthetic images for the training set .", "We consider the problem of grasping novel objects , specifically ones that are being seen for the first time through vision .", "We present a learning algorithm that neither requires , nor tries to build , a 3-d model of the object .", "We demonstrate on a robotic manipulation platform that this approach successfully grasps a wide variety of objects , such as wine glasses , duct tape , markers , a translucent box , jugs , knife-cutters , cellphones , keys , screwdrivers , staplers , toothbrushes , a thick coil of wire , a strangely shaped power horn , and others , none of which were seen in the training set .", "Instead it predicts , directly as a function of the images , a point at which to grasp the object ."]}
{"orig_sents": ["4", "3", "6", "1", "0", "5", "2"], "shuf_sents": ["Neurons coding the same depth experienced common inhibition early in their responses for stimuli presented at their nonpreferred disparities .", "We found that the interaction between pairs of neurons was a function of similarity in receptive fields , as well as of the input stimulus .", "These findings are consistent with a local competition mechanism that first removes gross mismatches , and a global cooperative mechanism that further refines depth estimates .", "Computational models on stereopsis suggest local competition and long-range cooperation are important for resolving ambiguity during stereo matching .", "Although there has been substantial progress in understanding the neurophysiological mechanisms of stereopsis , how neurons interact in a network during stereo computation remains unclear .", "They experienced mutual facilitation later in their responses for stimulation at their preferred disparity .", "To test these predictions , we simultaneously recorded from multiple neurons in V1 of awake , behaving macaques while presenting surfaces of different depths rendered in dynamic random dot stereograms ."]}
{"orig_sents": ["2", "4", "6", "7", "3", "0", "5", "1"], "shuf_sents": ["In this paper we study the tradeoff between exploration and exploitation , modeling advertisement placement as a multi-armed bandit problem .", "We measure empirical performance via extensive experiments over real-world data .", "We consider how a search engine should select advertisements to display with search results , in order to maximize its revenue .", "Budget constraints and finite advertisement lifetimes make it necessary to explore as well as exploit .", "Under the standard `` pay-per-click '' arrangement , revenue depends on how well the displayed advertisements appeal to users .", "We extend traditional bandit formulations to account for budget constraints that occur in search engine advertising markets , and derive theoretical bounds on the performance of a family of algorithms .", "The main difficulty stems from new advertisements whose degree of appeal has yet to be determined .", "Often the only reliable way of determining appeal is exploration via display to users , which detracts from exploitation of other advertisements known to have high appeal ."]}
{"orig_sents": ["7", "4", "6", "5", "1", "3", "2", "0"], "shuf_sents": ["Our experiments show that our technique achieves a significantly better sampling quality than the best alternative .", "Our approach exploits combinatorial properties of random parity ( XOR ) constraints to prune away solutions near-uniformly .", "The resulting sampling distribution is provably arbitrarily close to uniform .", "The final sample is identified amongst the remaining ones using a state-of-the-art SAT solver .", "We focus on problems specified as a Boolean formula , i.e. , on SAT instances .", "The best current approaches are based on Markov Chain Monte Carlo methods , which have some practical limitations .", "Sampling for SAT problems has been shown to have interesting connections with probabilistic reasoning , making practical sampling algorithms for SAT highly desirable .", "We propose a new technique for sampling the solutions of combinatorial problems in a near-uniform manner ."]}
{"orig_sents": ["4", "5", "2", "0", "3", "1"], "shuf_sents": ["After mapping predefined features and translates of a kernel simultaneously onto a hypothesis space by a specific way of constructing kernels , we proposed a new algorithm by utilizing a generalized regularizer which leaves part of the space unregularized .", "Empirical evaluations have confirmed the effectiveness of the algorithm for supervised learning tasks .", "This paper investigates a generalized form of representer theorem for kernel-based learning .", "Using a squared-loss function in calculating the empirical error , a simple convex solution is obtained which combines predefined features with translates of the kernel .", "Kernel-based regularized learning seeks a model in a hypothesis space by minimizing the empirical error and the model 's complexity .", "Based on the representer theorem , the solution consists of a linear combination of translates of a kernel ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["The study of point cloud data sampled from a stratification , a collection of manifolds with possible different dimensions , is pursued in this paper .", "We present a technique for simultaneously soft clustering and estimating the mixed dimensionality and density of such structures .", "The presentation of the approach is completed with artificial and real examples demonstrating the importance of extending manifold learning to stratification learning .", "The framework is based on a maximum likelihood estimation of a Poisson mixture model ."]}
{"orig_sents": ["4", "6", "2", "9", "0", "3", "10", "8", "7", "5", "1"], "shuf_sents": ["Second , these sets of extracted samples are formed into two `` bags of patches '' to model the foreground/background appearance , respectively .", "We also show that it is straightforward to apply our problem formulation on non-rigid object tracking with difficult surveillance videos .", "Our approach consists of three steps .", "We perform a novel bidirectional consistency check between new patches from incoming frames and current `` bags of patches '' to reject outliers , control model rigidity and make the model adaptive to new observations .", "In this paper , we propose a novel exemplar-based approach to extract dynamic foreground regions from a changing background within a collection of images or a video sequence .", "We evaluate and validate the proposed approach by extensive real examples of the object-level image mapping and tracking within a variety of challenging environments .", "By using image segmentation as a pre-processing step , we convert this traditional pixel-wise labeling problem into a lower-dimensional supervised , binary labeling procedure on image segments .", "The essence of the algorithm is conceptually simple and can be easily implemented within a few hundred lines of Matlab code .", "Finally , the foreground/background decision over segments in an image is formulated using an aggregation function defined on the similarity measurements of sampled patches relative to the foreground and background models .", "First , a set of random image patches are spatially and adaptively sampled within each segment .", "Within each bag , image patches are further partitioned and resampled to create an evolving appearance model ."]}
{"orig_sents": ["1", "2", "3", "4", "0"], "shuf_sents": ["We apply our model to compare and contrast solenoid valve current data , and also , liquid-chromatography-ultraviolet-diode array data from a study of the plant Arabidopsis thaliana .", "We present a hierarchical Bayesian model for sets of related , but different , classes of time series data .", "Our model performs alignment simultaneously across all classes , while detecting and characterizing class-specific differences .", "During inference the model produces , for each class , a distribution over a canonical representation of the class .", "These class-specific canonical representations are automatically aligned to one another -- preserving common sub-structures , and highlighting differences ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["However , as a fundamentally linear technique , there is always nonlinear residual redundancy that is not captured by ICA .", "Independent Component Analysis ( ICA ) is a popular method for extracting independent features from visual data .", "Hence there have been many attempts to try to create a hierarchical version of ICA , but so far none of the approaches have a natural way to apply them more than once .", "This results in a recursive ICA algorithm that may be applied any number of times in order to extract higher order structure from previous layers .", "Here we show that there is a relatively simple technique that transforms the absolute values of the outputs of a previous application of ICA into a normal distribution , to which ICA maybe applied again ."]}
{"orig_sents": ["0", "3", "2", "8", "6", "1", "5", "4", "7"], "shuf_sents": ["In supervised learning there is a typical presumption that the training and test points are taken from the same distribution .", "This paper tackles this issue for regression models .", "The situations where the training and test data are from different distributions is called covariate shift .", "In practice this assumption is commonly violated .", "Using this view , we obtain a general approach to regression under covariate shift , which reproduces previous work as a special case .", "Recent work on covariate shift can be understood in terms of mixture regression .", "As yet the literature lacks a Bayesian generative perspective on this problem .", "The main advantages of this new formulation over previous models for covariate shift are that we no longer need to presume the test and training densities are known , the regression and density estimation are combined into a single procedure , and previous methods are reproduced as special cases of this procedure , shedding light on the implicit assumptions the methods are making .", "Recent work has examined techniques for dealing with covariate shift in terms of minimisation of generalisation error ."]}
{"orig_sents": ["2", "0", "4", "3", "1"], "shuf_sents": ["Our framework incorporates recent graphical model constructs to account for existence uncertainty , value-specific independence , aggregation relationships , and local and global constraints , while still retaining a Bayesian network interpretation and efficient inference and learning techniques .", "We present results on MT word alignment in support of our claim that MDBNs are a promising framework for the rapid prototyping of new MT systems .", "We present a generalization of dynamic Bayesian networks to concisely describe complex probability distributions such as in problems with multiple interacting variable-length streams of random variables .", "Multi-dynamic Bayesian networks are motivated by our work on Statistical Machine Translation ( MT ) .", "We introduce one such general technique , which is an extension of Value Elimination , a backtracking search inference algorithm ."]}
{"orig_sents": ["2", "6", "4", "8", "5", "3", "7", "9", "0", "1"], "shuf_sents": ["The advantages of our approach is the speed of inference ( under one second ) , the parsing of the object , and increased accuracy of performance .", "Moreover , our approach is very general and can be applied to a large range of objects and structures .", "We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples .", "The individual objects can be recovered as different aspects of the grammar for the object class .", "We illustrate our approach using thirteen objects from the Caltech 101 database .", "This is illustrated by learning a hybrid class consisting of faces , motorbikes , and airplanes .", "Our approach is invariant to the scale and rotation of the objects .", "In all cases , we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets .", "In addition , we learn the model of a hybrid object class where we do not know the specific object or its position , scale or pose .", "We compare our method to alternative approaches ."]}
{"orig_sents": ["5", "0", "3", "4", "2", "1"], "shuf_sents": ["Most use of structural equation models in fMRI involves postulating a particular structure and comparing learnt parameters across different groups .", "We show that is is possible to learn sensible structural equation models that can provide modelling benefits , but that are not necessarily going to be the same as a true causal model , and suggest the combination of prior models and learning or the use of temporal information from dynamic models may provide more benefits than learning structural equations alone .", "We then show that for particular fMRI data the simple models usually assumed are not supported .", "In this paper it is argued that there are situations where priors about structure are not firm or exhaustive , and given sufficient data , it is worth investigating learning network structure as part of the approach to connectivity analysis .", "First we demonstrate structure learning on a toy problem .", "Structural equation models can be seen as an extension of Gaussian belief networks to cyclic graphs , and we show they can be understood generatively as the model for the joint distribution of long term average equilibrium activity of Gaussian dynamic belief networks ."]}
{"orig_sents": ["6", "2", "1", "0", "5", "4", "3"], "shuf_sents": ["We show how to convert the inference problem so that standard Kalman Filtering/Smoothing recursions from the literature may be applied .", "The most challenging aspect of implementing the method is in performing inference on the hidden state sequence of the model .", "The approximate Variational Bayesian method applied to these models is an attractive approach , used successfully in applications ranging from acoustics to bioinformatics .", "We demonstrate the elegance of the approach on Bayesian temporal ICA , with an application to finding independent dynamical processes underlying noisy EEG signals .", "Our framework both simplifies and unifies the inference problem , so that future applications may be more easily developed .", "This is in contrast to previously published approaches based on Belief Propagation .", "Linear Gaussian State-Space Models are widely used and a Bayesian treatment of parameters is therefore of considerable interest ."]}
{"orig_sents": ["5", "0", "3", "6", "1", "4", "2"], "shuf_sents": ["The common approach for handling missing features is to begin with a preprocessing phase that completes the missing features , and then use a standard classification procedure .", "By avoiding the pre-processing phase in which the data is completed , these approaches offer considerable computational savings .", "We demonstrate our results on two real-world problems : edge prediction in metabolic pathways , and automobile detection in natural images .", "In this paper we show how incomplete data can be classified directly without any completion of the missing features using a max-margin learning framework .", "More importantly , we show that by elegantly handling complex patterns of missing values , our approach is both competitive with other methods when the values are missing at random and outperforms them when the missing values have non-trivial structure .", "We consider the problem of learning classifiers for structurally incomplete data , where some objects have a subset of features inherently absent due to complex relationships between the features .", "We formulate this task using a geometrically-inspired objective function , and discuss two optimization approaches : The linearly separable case is written as a set of convex feasibility problems , and the non-separable case has a non-convex objective that we optimize iteratively ."]}
{"orig_sents": ["5", "3", "4", "2", "1", "0"], "shuf_sents": ["Experiments show that speedups relative to the standard variational algorithm can be significant .", "Our algorithm differs in the use of kd-trees and in the way we handle truncation : we only assume that the variational distributions are fixed at their priors after a certain level .", "The speedup is achieved by incorporating kd-trees into a variational Bayesian algorithm for DP mixtures in the stick-breaking representation , similar to that of Blei and Jordan ( 2005 ) .", "Due to computational considerations these models are unfortunately unsuitable for large scale data-mining applications .", "We propose a class of deterministic accelerated DP mixture models that can routinely handle millions of data-cases .", "Dirichlet Process ( DP ) mixture models are promising candidates for clustering applications where the number of clusters is unknown a priori ."]}
{"orig_sents": ["8", "3", "9", "7", "5", "6", "2", "4", "0", "1"], "shuf_sents": ["We show that this algorithm outperforms classical source separation algorithms for linear mixtures , and also a related method for mixtures with delays .", "In addition , applying the new algorithm to trajectories of human gaits , we demonstrate that it is suitable for the extraction of spatio-temporal components that are easier to interpret than components extracted with other classical algorithms .", "This case has only rarely been treated in the computational literature , and specifically for the case of dimension reduction almost no algorithms have been proposed .", "the extraction of unknown sources from a set of given signals , is relevant for many applications .", "We present a new algorithm for the solution of this problem , which is based on a timefrequency transformation ( Wigner-Ville distribution ) of the generative model .", "Most popular approaches for addressing this problem are based on purely linear mixing models .", "However , many applications like the modeling of acoustic signals , EMG signals , or movement trajectories , require temporal shift-invariance of the extracted components .", "Since in this case the signals outnumber the sources the problem is over-determined .", "Blind source separation , i.e .", "A special case of this problem is dimension reduction , where the goal is to approximate a given set of signals by superpositions of a minimal number of sources ."]}
{"orig_sents": ["2", "5", "0", "4", "1", "3"], "shuf_sents": ["The method improves on the standard Kim smoothing approach by dispensing with one of the key approximations , thus making fuller use of the available future information .", "Unlike the alternative unstable Expectation Propagation procedure , our method consists only of a single forward and backward pass and is reminiscent of the standard smoothing `correction ' recursions in the simpler linear dynamical system .", "We introduce a method for approximate smoothed inference in a class of switching linear dynamical systems , based on a novel form of Gaussian Sum smoother .", "The algorithm performs well on both toy experiments and in a large scale application to noise robust speech recognition .", "Whilst the only central assumption required is projection to a mixture of Gaussians , we show that an additional conditional independence assumption results in a simpler but stable and accurate alternative .", "This class includes the switching Kalman Filter and the more general case of switch transitions dependent on the continuous latent state ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["Selective attention is the strategy used by biological sensory systems to solve the problem of limited parallel processing capacity : salient subregions of the input stimuli are serially processed , while non-salient regions are suppressed .", "We describe the chip 's architecture and its behavior , when its is part of a multi-chip system with a spiking retina as input , and show how it can be used to implement in real-time flexible models of bottom-up attention .", "We present an mixed mode analog/digital Very Large Scale Integration implementation of a building block for a multi-chip neuromorphic hardware model of selective attention ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We then apply our semi-supervised approach to train DRFs to segment both synthetic and real data sets , and demonstrate significant improvements over supervised DRFs in each case .", "Although the training objective is no longer concave , we develop an efficient local optimization procedure that produces classifiers that are more accurate than ones based on standard supervised DRF training .", "We present a novel , semi-supervised approach to training discriminative random fields ( DRFs ) that efficiently exploits labeled and unlabeled training data to achieve improved accuracy in a variety of image processing tasks .", "We formulate DRF training as a form of MAP estimation that combines conditional loglikelihood on labeled data , given a data-dependent prior , with a conditional entropy regularizer defined on unlabeled data ."]}
{"orig_sents": ["0", "1", "3", "2", "4"], "shuf_sents": ["Pyramid intersection is an efficient method for computing an approximate partial matching between two sets of feature vectors .", "We introduce a novel pyramid embedding based on a hierarchy of non-uniformly shaped bins that takes advantage of the underlying structure of the feature space and remains accurate even for sets with high-dimensional feature vectors .", "Whereas previous matching approximation algorithms suffer from distortion factors that increase linearly with the feature dimension , we demonstrate that our approach can maintain constant accuracy even as the feature dimension increases .", "The matching similarity is computed in linear time and forms a Mercer kernel .", "When used as a kernel in a discriminative classifier , our approach achieves improved object recognition results over a state-of-the-art set kernel ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["It is found that the prediction is significantly improved by observing the state space of the membrane potential and its time derivative ( s ) in advance of a possible spike , in comparison to simply thresholding an instantaneous value of the estimated potential .", "It has been established that a neuron reproduces highly precise spike response to identical fluctuating input currents .", "We wish to accurately predict the firing times of a given neuron for any input current .", "For this purpose we adopt a model that mimics the dynamics of the membrane potential , and then take a cue from its dynamics for predicting the spike occurrence for a novel input current ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["We propose a non-parametric Bayesian framework for modeling collections of such data .", "This allows the model to learn in a data-driven fashion what `` factors '' are generating the observations on a particular day , including ( for example ) weekday versus weekend effects or day-specific effects corresponding to unique ( single-day ) occurrences of unusual behavior , sharing information where appropriate to obtain improved estimates of the behavior associated with each category .", "Data sets that characterize human activity over time through collections of timestamped events or counts are of increasing interest in application areas as humancomputer interaction , video surveillance , and Web data analysis .", "Applications to real-world data sets of count data involving both vehicles and people are used to illustrate the technique .", "In particular , we use a Dirichlet process framework for learning a set of intensity functions corresponding to different categories , which form a basis set for representing individual time-periods ( e.g. , several days ) depending on which categories the time-periods are assigned to ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We introduce binary matrix factorization , a novel model for unsupervised matrix decomposition .", "The decomposition is learned by fitting a non-parametric Bayesian probabilistic model with binary latent variables to a matrix of dyadic data .", "We provide simple learning and inference rules for this new model and show how to extend it to an infinite model in which the number of features is not a priori fixed but is allowed to grow with the size of the data .", "Unlike bi-clustering models , which assign each row or column to a single cluster based on a categorical hidden feature , our binary feature model reflects the prior belief that items and attributes can be associated with more than one latent cluster at a time ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["The contributions include a novel means of regularising multi-scale compactly supported basis functions that leads to the desirable properties previously only associated with fully supported bases , and show equivalence to a Gaussian process with modified covariance function .", "We consider the problem of constructing a function whose zero set is to represent a surface , given sample points with surface normal vectors .", "We also provide a regularisation framework for simpler and more direct treatment of surface normals , along with a corresponding generalisation of the representer theorem .", "We demonstrate the techniques on 3D problems of up to 14 million data points , as well as 4D time series data ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Important characteristics of LSML include the ability to recover the structure of the manifold in sparsely populated regions and beyond the support of the provided data .", "We present a new algorithm , Locally Smooth Manifold Learning ( LSML ) , that learns a warping function from a point on an manifold to its neighbors .", "Applications of our proposed technique include embedding with a natural out-of-sample extension and tasks such as tangent distance estimation , frame rate up-conversion , video compression and motion transfer ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["With the aid of the benchmark data , we show the Bayesian account has several advantages , including dealing naturally with the parameter variation needed to account for some key features of the data , and providing quantitative measures to guide decisions about model construction .", "We use this result to undertake Bayesian modeling of benchmark data , using posterior sampling to draw inferences about the interesting psychological parameters .", "We present a computational Bayesian approach for Wiener diffusion models , which are prominent accounts of response time distributions in decision-making .", "We first develop a general closed-form analytic approximation to the response time distributions for one-dimensional diffusion processes , and derive the required Wiener diffusion as a special case ."]}
{"orig_sents": ["0", "4", "1", "3", "2"], "shuf_sents": ["This paper develops a multi-frame image super-resolution approach from a Bayesian view-point by marginalizing over the unknown registration parameters relating the set of input low-resolution views .", "By integrating over the registration parameters rather than the high-resolution image , our method allows for more realistic prior distributions , and also reduces the dimension of the integral considerably , removing the main computational bottleneck of the other algorithm .", "We show results on real and synthetic datasets to illustrate the efficacy of this approach .", "In addition to the motion model used by Tipping and Bishop , illumination components are introduced into the generative model , allowing us to handle changes in lighting as well as motion .", "In Tipping and Bishop 's Bayesian image super-resolution approach , the marginalization was over the superresolution image , necessitating the use of an unfavorable image prior ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["We present two new algorithms for online learning in reproducing kernel Hilbert spaces .", "We then introduce a bounded memory version , SILK ( sparse ILK ) , that maintains a compact representation of the predictor without compromising solution quality , even in non-stationary environments .", "Experimental evidence shows that our proposed algorithms outperform current methods on synthetic and real data .", "Our first algorithm , ILK ( implicit online learning with kernels ) , employs a new , implicit update technique that can be applied to a wide variety of convex loss functions .", "We prove loss bounds and analyze the convergence rate of both ."]}
{"orig_sents": ["0", "1", "3", "2", "4"], "shuf_sents": ["We derive a cost functional for estimating the relationship between highdimensional observations and the low-dimensional process that generated them with no input-output examples .", "Limiting our search to invertible observation functions confers numerous benefits , including a compact representation and no suboptimal local minima .", "Our method can be viewed as a manifold learning algorithm that utilizes a prior on the low-dimensional manifold coordinates .", "Our approximation algorithms for optimizing this cost functional are fast and give diagnostic bounds on the quality of their solution .", "The benefits of taking advantage of such priors in manifold learning and searching for the inverse observation functions in system identification are demonstrated empirically by learning to track moving targets from raw measurements in a sensor network setting and in an RFID tracking experiment ."]}
{"orig_sents": ["3", "0", "8", "10", "5", "4", "6", "1", "2", "9", "7"], "shuf_sents": ["One regime , which we consider here , is the case of moving objects with contours but no visible texture .", "The grouping is done by constructing a graphical model and marginalizing it using importance sampling .", "We propose two equivalent representations in this graphical model , reversible switch variables attached to the ends of fragments and fragment chains , to capture both local and global statistics of boundaries .", "A reliable motion estimation algorithm must function under a wide range of conditions .", "Boundary fragment are chains of orientated edgelets , for which we derive motion estimates from local evidence .", "We propose a novel approach that avoids these points altogether , and derives global motion estimates by utilizing information from three levels of contour analysis : edgelets , boundary fragments and contours .", "The uncertainties of the local estimates are disambiguated after the boundary fragments are properly grouped into contours .", "The system produces good motion estimates along with properly grouped and completed contours .", "Tracking distinctive features such as corners can disambiguate the motion of contours , but spurious features such as T-junctions can be badly misleading .", "Our system is successfully applied to both synthetic and real video sequences containing high-contrast boundaries and textureless regions .", "It is difficult to determine the reliability of motion from local measurements , since a full rank covariance matrix can result from both real and spurious features ."]}
{"orig_sents": ["1", "4", "3", "6", "2", "5", "0", "7"], "shuf_sents": ["Similar to PX-EM and -DA , PX-VB expands a model with auxiliary variables to reduce the coupling between variables in the original model .", "Bayesian inference has become increasingly important in statistical machine learning .", "To address this problem , we propose Parameter-eXpanded Variational Bayesian ( PX-VB ) methods to speed up VB .", "A number of approximate Bayesian methods have been proposed to make such calculations practical , among them the variational Bayesian ( VB ) approach .", "Exact Bayesian calculations are often not feasible in practice , however .", "The new algorithm is inspired by parameter-expanded expectation maximization ( PX-EM ) and parameterexpanded data augmentation ( PX-DA ) .", "The VB approach , while useful , can nevertheless suffer from slow convergence to the approximate solution .", "We analyze the convergence rates of VB and PX-VB and demonstrate the superior convergence rates of PX-VB in variational probit regression and automatic relevance determination ."]}
{"orig_sents": ["0", "4", "1", "3", "2"], "shuf_sents": ["The local statistical properties of photographic images , when represented in a multi-scale basis , have been described using Gaussian scale mixtures ( GSMs ) .", "Specifically , we model subbands of wavelet coefficients as a product of an exponentiated homogeneous Gaussian Markov random field ( hGMRF ) and a second independent hGMRF .", "We develop an algorithm for image denoising based on the FoGSM model , and demonstrate substantial improvements over current state-ofthe-art denoising method based on the local GSM model .", "We show that parameter estimation for FoGSM is feasible , and that samples drawn from an estimated FoGSM model have marginal and joint statistics similar to wavelet coefficients of photographic images .", "Here , we use this local description to construct a global field of Gaussian scale mixtures ( FoGSM ) ."]}
{"orig_sents": ["1", "3", "4", "0", "5", "2"], "shuf_sents": ["We propose a graph learning method for the harmonic energy minimization method ; this is done by minimizing the leave-one-out prediction error on labeled data points .", "Semi-supervised learning algorithms have been successfully applied in many applications with scarce labeled data , by utilizing the unlabeled data .", "Experimental results show that the graph learning method is effective in improving the performance of the classification algorithm .", "One important category is graph based semi-supervised learning algorithms , for which the performance depends considerably on the quality of the graph , or its hyperparameters .", "In this paper , we deal with the less explored problem of learning the graphs .", "We use a gradient based method and designed an efficient algorithm which significantly accelerates the calculation of the gradient by applying the matrix inversion lemma and using careful pre-computation ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Kernel parameters are learned automatically by maximizing the cross-validation log likelihood , and predictive probabilities are estimated .", "We propose a highly efficient framework for kernel multi-class models with a large and structured set of classes .", "We demonstrate our approach on large scale text classification tasks with hierarchical class structure , achieving state-of-the-art results in an order of magnitude less time than previous work ."]}
{"orig_sents": ["2", "0", "3", "5", "4", "1", "6"], "shuf_sents": ["For example , muscle response can change because of fatigue , a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower .", "A system that adapts in this way predicts many properties observed in saccadic gain adaptation .", "Our motor system changes due to causes that span multiple timescales .", "Here we hypothesize that the nervous system adapts in a way that reflects the temporal properties of such potential disturbances .", "The adaptation schedule influences the behavior of the optimal learner , changing estimates at different timescales as well as the uncertainty .", "According to a Bayesian formulation of this idea , movement error results in a credit assignment problem : what timescale is responsible for this disturbance ?", "It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction ."]}
{"orig_sents": ["6", "2", "1", "3", "0", "4", "5"], "shuf_sents": ["We show how such tractable planar models can be used in a decomposition to derive upper bounds on the partition function of non-planar models .", "Here we base the approximation on a different tractable model , planar graphs with binary variables and pure interaction potentials ( no external field ) .", "Many recent approximate methods for graphs with cycles are based on tractable algorithms for tree structured graphs .", "The partition function for such models can be calculated exactly using an algorithm introduced by Fisher and Kasteleyn in the 1960s .", "The resulting algorithm also allows for the estimation of marginals .", "We compare our planar decomposition to the tree decomposition method of Wainwright et . al. , showing that it results in a much tighter bound on the partition function , improved pairwise marginals , and comparable singleton marginals .", "A number of exact and approximate methods are available for inference calculations in graphical models ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["Such a problem can occur in many real-world tasks , e.g .", "In this paper , we formalize multi-instance multi-label learning , where each training example is associated with not only multiple instances but also multiple class labels .", "an image usually contains multiple patches each of which can be described by a feature vector , and the image can belong to multiple categories since its semantics can be recognized in different ways .", "Then , we propose the M IML B OOST and M IML S VM algorithms which achieve good performance in an application to scene classification .", "We analyze the relationship between multi-instance multi-label learning and the learning frameworks of traditional supervised learning , multiinstance learning and multi-label learning ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["We then develop a scheme for finding the optimal , under Frobenius norm , doubly-stochastic approximation using Von-Neumann 's successive projections lemma .", "In this paper we focus on the issue of normalization of the affinity matrix in spectral clustering .", "The new normalization scheme is simple and efficient and provides superior clustering performance over many of the standardized tests .", "We show that the difference between N-cuts and Ratio-cuts is in the error measure being used ( relative-entropy versus L1 norm ) in finding the closest doubly-stochastic matrix to the input affinity matrix ."]}
{"orig_sents": ["0", "6", "2", "4", "3", "1", "8", "5", "7"], "shuf_sents": ["Neural motor prostheses ( NMPs ) require the accurate decoding of motor cortical population activity for the control of an artificial motor system .", "The nonlinear spring coefficients are estimated from the firing rates of neurons in the motor cortex .", "Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties .", "The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs .", "Here we show that the firing rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artificial physical system exhibiting realistic dynamics .", "We found that the decoded spring coefficients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics .", "Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics .", "Furthermore , using a physically-based system produced decoded movements that were more `` natural '' in that their frequency spectrum more closely matched that of natural hand movements .", "We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks ."]}
{"orig_sents": ["2", "4", "0", "6", "5", "3", "1"], "shuf_sents": ["Unlike earlier work on max-margin Markov networks , our approach is specifically geared to the modeling of real-valued observations ( such as acoustic feature vectors ) using Gaussian mixture models .", "We obtain competitive results for phonetic recognition on the TIMIT speech corpus .", "We study the problem of parameter estimation in continuous density hidden Markov models ( CD-HMMs ) for automatic speech recognition ( ASR ) .", "Its optimization can be performed efficiently with simple gradient-based methods that scale well to large problems .", "As in support vector machines , we propose a learning algorithm based on the goal of margin maximization .", "The objective function for large margin training of CD-HMMs is defined over a parameter space of positive semidefinite matrices .", "Unlike previous discriminative frameworks for ASR , such as maximum mutual information and minimum classification error , our framework leads to a convex optimization , without any spurious local minima ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Our interest lies in bounds for the algorithm 's online performance after some finite number of steps .", "In the spirit of similar methods already successfully applied for the exploration-exploitation tradeoff in multi-armed bandit problems , we use upper confidence bounds to show that our UCRL algorithm achieves logarithmic online regret in the number of steps taken with respect to an optimal policy .", "We present a learning algorithm for undiscounted reinforcement learning ."]}
{"orig_sents": ["2", "3", "1", "0", "4"], "shuf_sents": ["Based on parametric linear programming , we propose a method that computes the whole set of Pareto efficient policies in the performancerobustness plane when only the reward parameters are subject to uncertainty .", "In this paper we consider the tradeoff between nominal performance and the worst case performance over all possible models .", "Computation of a satisfactory control policy for a Markov decision process when the parameters of the model are not exactly known is a problem encountered in many practical applications .", "The traditional robust approach is based on a worstcase analysis and may lead to an overly conservative policy .", "In the more general case when the transition probabilities are also subject to error , we show that the strategy with the `` optimal '' tradeoff might be non-Markovian and hence is in general not tractable ."]}
{"orig_sents": ["3", "5", "0", "6", "1", "4", "2"], "shuf_sents": ["In the jigsaw model presented here , the shape , size and appearance of patches are learned automatically from the repeated structures in a set of training images .", "When applied to face images , for example , the learned jigsaw pieces are surprisingly strongly associated with face parts of different shapes and scales such as eyes , noses , eyebrows and cheeks , to name a few .", "This enables parts of similar appearance but different shapes to be distinguished ; for example , while foreheads and cheeks are both skin colored , they have markedly different shapes .", "Patch-based appearance models are used in a wide range of computer vision applications .", "We conclude that learning the shape of the patch not only improves the accuracy of appearance-based part detection but also allows for shape-based part detection .", "To learn such models it has previously been necessary to specify a suitable set of patch sizes and shapes by hand .", "By learning such irregularly shaped `jigsaw pieces ' , we are able to discover both the shape and the appearance of object parts without supervision ."]}
{"orig_sents": ["5", "2", "3", "0", "1", "4"], "shuf_sents": ["In particular , we propose that the brain explores a posterior distribution over image interpretations at a rapid time scale via a sampling-like process and updates its interpretation when a sampled interpretation is better than the discounted value of its current interpretation .", "We formalize the theory , explicitly derive switching rate distributions and discuss qualitative properties of the theory including the effect of changes in the posterior distribution on switching rates .", "Although switching behavior is increasingly well characterized , the origins remain elusive .", "We propose that perceptual switching naturally arises from the brain 's search for best interpretations while performing Bayesian inference .", "Finally , predictions of the theory are shown to be consistent with measured changes in human switching dynamics to Necker cube stimuli induced by context .", "Perceptual Bistability refers to the phenomenon of spontaneously switching between two or more interpretations of an image under continuous viewing ."]}
{"orig_sents": ["0", "2", "3", "4", "1"], "shuf_sents": ["We propose a family of kernels for structured objects which is based on the bag-ofcomponents paradigm .", "We propose experimental results on an image retrieval experiment which show that this mixture is an effective template procedure to be used with kernels on histograms .", "However , rather than decomposing each complex object into the single histogram of its components , we use for each object a family of nested histograms , where each histogram in this hierarchy describes the object seen from an increasingly granular perspective .", "We use this hierarchy of histograms to define elementary kernels which can detect coarse and fine similarities between the objects .", "We compute through an efficient averaging trick a mixture of such specific kernels , to propose a final kernel value which weights efficiently local and global matches ."]}
{"orig_sents": ["6", "3", "4", "0", "1", "5", "2"], "shuf_sents": ["However , physical principles underlying most networked systems suggest that not all feasible solutions are equally likely .", "Intuitively , nodes that co-occur more frequently are probably more closely connected .", "We derive a computationally efficient network inference algorithm and , via novel concentration inequalities for importance sampling estimators , prove that a polynomial complexity Monte Carlo version of the algorithm converges with high probability .", "This problem is motivated by network inference problems arising in computational biology and communication systems , in which it is difficult or impossible to obtain precise time ordering information .", "Without order information , every permutation of the activated nodes leads to a different feasible solution , resulting in combinatorial explosion of the feasible set .", "Building on this intuition , we model path co-occurrences as randomly shuffled samples of a random walk on the network .", "We consider the problem of inferring the structure of a network from cooccurrence data : observations that indicate which nodes occur in a signaling pathway but do not directly reveal node order within the pathway ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["In addition , it is shown that the use of this bound as a means to estimate the hyperparameters of the classifier compares favourably with cross validation in terms of accuracy of the model , while saving a lot of computational burden .", "This paper proposes a PAC-Bayes bound to measure the performance of Support Vector Machine ( SVM ) classifiers .", "The bound is based on learning a prior over the distribution of classifiers with a part of the training samples .", "Experimental work shows that this bound is tighter than the original PAC-Bayes , resulting in an enhancement of the predictive capabilities of the PAC-Bayes bound ."]}
{"orig_sents": ["1", "3", "0", "2", "4"], "shuf_sents": ["We show that for large-scale problems involving a wide choice of kernel-based models and validation functions , this computation can be very efficiently done ; often within just a fraction of the training time .", "We consider the task of tuning hyperparameters in SVM models based on minimizing a smooth performance validation function , e.g. , smoothed k-fold crossvalidation error , using non-linear optimization techniques .", "Empirical results show that a near-optimal set of hyperparameters can be identified by our approach with very few training rounds and gradient computations .", "The key computation in this approach is that of the gradient of the validation function with respect to hyperparameters .", "."]}
{"orig_sents": ["2", "3", "1", "5", "4", "8", "6", "7", "0"], "shuf_sents": ["We illustrate the approach on localization in large scale sensor networks , where optimizations involving tens of thousands of nodes can be solved in just a few minutes .", "In particular , many results have been obtained by constructing semidefinite programs ( SDPs ) with low rank solutions .", "In many areas of science and engineering , the problem arises how to discover low dimensional representations of high dimensional data .", "Recently , a number of researchers have converged on common solutions to this problem using methods from convex optimization .", "In this paper , we show how to solve very large problems of this type by a matrix factorization that leads to much smaller SDPs than those previously studied .", "While the rank of matrix variables in SDPs can not be directly constrained , it has been observed that low rank solutions emerge naturally by computing high variance or maximal trace solutions that respect local distance constraints .", "The smaller SDPs obtained from this matrix factorization yield very good approximations to solutions of the original problem .", "Moreover , these approximations can be further refined by conjugate gradient descent .", "The matrix factorization is derived by expanding the solution of the original problem in terms of the bottom eigenvectors of a graph Laplacian ."]}
{"orig_sents": ["4", "0", "1", "3", "2"], "shuf_sents": ["Our algorithm localizes multiple dipoles while suppressing noise sources with the computational complexity equivalent to a single dipole scan , and is therefore more efficient than traditional multidipole fitting procedures .", "In simulation , the algorithm can accurately localize and estimate the time course of several simultaneously-active dipoles , with rotating or fixed orientation , at noise levels typical for averaged MEG data .", "Success of this algorithm for localizing auditory cortex in a tumor patient and for localizing an epileptic spike source are also demonstrated .", "Furthermore , the algorithm is superior to beamforming techniques , which we show to be an approximation to our graphical model , in estimation of temporally correlated sources .", "We have developed a novel algorithm for integrating source localization and noise suppression based on a probabilistic graphical model of stimulus-evoked MEG/EEG data ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We present a Bayesian model of inductive reasoning that incorporates both kinds of knowledge , and show that it accounts well for human inferences about the properties of biological species .", "Everyday inductive reasoning draws on many kinds of knowledge , including knowledge about relationships between properties and knowledge about relationships between objects .", "Previous accounts of inductive reasoning generally focus on just one kind of knowledge : models of causal reasoning often focus on relationships between properties , and models of similarity-based reasoning often focus on similarity relationships between objects ."]}
{"orig_sents": ["3", "6", "0", "2", "5", "4", "1"], "shuf_sents": ["and , if so , 2 ) what is a low-dimensional representation of her pose ?", "We validate the model with extensive quantitative experiments and comparisons with other approaches on human detection and pose matching .", "We investigate models that can be learned in an unsupervised manner on unlabeled images of human poses , and provide information that can be used to match the pose of a new image to the ones present in the training set .", "We consider the problem of detecting humans and classifying their pose from a single image .", "We show how our model can efficiently describe the space of images of humans with their pose , by providing an effective representation of poses for tasks such as classification and matching , while performing remarkably well in human/non human decision problems , thus enabling its use for human detection .", "Starting from a set of descriptors recently proposed for human detection , we apply the Latent Dirichlet Allocation framework to model the statistics of these features , and use the resulting model to answer the above questions .", "Specifically , our goal is to devise a statistical model that simultaneously answers two questions : 1 ) is there a human in the image ?"]}
{"orig_sents": ["4", "3", "1", "0", "5", "2", "6"], "shuf_sents": ["By altering the relevance variable we eliminate the need in the sample of joint distribution of all input variables .", "The approach represents a consistent extension of the Information Bottleneck method that has previously relied on the availability of co-occurrence statistics .", "The approach is analyzed and shown to be on a par with the best known clustering algorithms for a wide range of domains .", "For example , in gene expression data , the expression level Z is a function of gene X and condition Y ; or in movie ratings data the rating Z is a function of viewer X and movie Y .", "We present a general model-independent approach to the analysis of data in cases when these data do not appear in the form of co-occurrence of two variables X , Y , but rather as a sample of values of an unknown ( stochastic ) function Z ( X , Y ) .", "This new formulation also enables simple MDL-like model complexity control and prediction of missing values of Z .", "For the prediction of missing values ( collaborative filtering ) it improves the currently best known results ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Approximate inference schemes employing Variational & Expectation Propagation based methods are developed and rigorously assessed .", "We demonstrate our approach to integrating multiple data sets on a large scale protein fold prediction problem where we infer the optimal combinations of covariance functions and achieve state-of-the-art performance without resorting to any ad hoc parameter tuning and classifier combination .", "By adopting Gaussian process priors a fully Bayesian solution to the problem of integrating possibly heterogeneous data sets within a classification setting is presented ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["We then show that for SVMs using Gaussian RBF kernels for classification this oracle inequality leads to learning rates that are faster than the ones established in .", "Finally , we use our oracle inequality to show that a simple parameter selection approach based on a validation set can yield the same fast learning rates without knowing the noise exponents which were required to be known a-priori in .", "We establish a general oracle inequality for clipped approximate minimizers of regularized empirical risks and apply this inequality to support vector machine ( SVM ) type algorithms ."]}
{"orig_sents": ["4", "0", "1", "2", "3"], "shuf_sents": ["Thus , kernels not only transform data sets such that good generalization can be achieved even by linear discriminant functions , but this transformation is also performed in a manner which makes economic use of feature space dimensions .", "In the best case , kernels provide efficient implicit representations of the data to perform classification .", "Practically , we propose an algorithm which enables us to recover the subspace and dimensionality relevant for good classification .", "Our algorithm can therefore be applied ( 1 ) to analyze the interplay of data set and kernel in a geometric fashion , ( 2 ) to help in model selection , and to ( 3 ) de-noise in feature space in order to yield better classification results .", "We show that the relevant information about a classification problem in feature space is contained up to negligible error in a finite number of leading kernel PCA components if the kernel matches the underlying learning problem ."]}
{"orig_sents": ["0", "1", "4", "3", "2"], "shuf_sents": ["Given a set of classifiers and a probability distribution over their domain , one can define a metric by taking the distance between a pair of classifiers to be the probability that they classify a random item differently .", "We prove bounds on the sample complexity of PAC learning in terms of the doubling dimension of this metric .", "We show that there is no bound on the doubling dimension in terms of the VC-dimension of ( in contrast with the metric dimension ) .", "We prove a bound that holds for any algorithm that outputs a classifier with zero error whenever this is possible ; this bound is in terms of the maximum of the doubling dimension and the VC-dimension of , and strengthens the best known bound in terms of the VC-dimension alone .", "These bounds imply known bounds on the sample complexity of learning halfspaces with respect to the uniform distribution that are optimal up to a constant factor ."]}
{"orig_sents": ["5", "1", "4", "9", "8", "2", "6", "0", "7", "3"], "shuf_sents": ["We present both synthetic examples and real image segmentation problems where various spectral clustering algorithms fail .", "Spectral clustering algorithms typically start from local information encoded in a weighted graph on the data and cluster according to the global eigenvectors of the corresponding ( normalized ) similarity matrix .", "Based on these findings , a second contribution of this paper is a novel diffusion based measure to evaluate the coherence of individual clusters .", "Keywords : Clustering , kernels , learning theory .", "One contribution of this paper is to present fundamental limitations of this general local to global approach .", "Spectral clustering methods are common graph-based approaches to clustering of data .", "Our measure can be used in conjunction with any bottom-up graph-based clustering method , it is scale-free and can determine coherent clusters at all scales .", "In contrast , using this coherence measure finds the expected clusters at all scales .", "Further , even with a suitable similarity measure , we show that the first few eigenvectors of such adjacency matrices can not successfully cluster datasets that contain structures at different scales of size and density .", "We show that based only on local information , the normalized cut functional is not a suitable measure for the quality of clustering ."]}
{"orig_sents": ["4", "3", "1", "6", "2", "5", "0"], "shuf_sents": ["The new learning rule that achieves this is derived from abstract information optimization principles .", "Another powerful processing strategy is to extract preferentially those components from high-dimensional input streams that are related to other information sources , such as internal predictions or proprioceptive feedback .", "However , concrete learning rules that implement these general unsupervised learning principles for spiking neurons are still missing .", "Such independent component analysis ( or blind source separation ) could provide a less redundant representation of information about the external world .", "The extraction of statistically independent components from high-dimensional multi-sensory input streams is assumed to be an essential component of sensory processing in the brain .", "We show how both information bottleneck optimization and the extraction of independent components can in principle be implemented with stochastically spiking neurons with refractoriness .", "This strategy allows the optimization of internal representation according to the information bottleneck method ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["In this model , players may purchase edges at distance d at a cost of d , and wish to minimize the sum of their edge purchases and their average distance to other players .", "We contrast our results with those of Kleinberg in a stochastic model , and empirically investigate the `` navigability '' of equilibrium networks .", "We introduce a game-theoretic model for network formation inspired by earlier stochastic models that mix localized and long-distance connectivity .", "Our theoretical results all generalize to higher dimensions .", "In this model , we show there is a striking `` small world '' threshold phenomenon : in two dimensions , if < 2 then every Nash equilibrium results in a network of constant diameter ( independent of network size ) , and if > 2 then every Nash equilibrium results in a network whose diameter grows as a root of the network size , and thus is unbounded ."]}
{"orig_sents": ["10", "3", "2", "6", "8", "7", "11", "0", "1", "5", "4", "9"], "shuf_sents": ["The new framework generalizes the maximum margin clustering algorithm by allowing any clustering boundaries including those not passing through the origins .", "It significantly improves the computational efficiency by reducing the number of parameters .", "Despite its good performance , there are three major problems with maximum margin clustering that question its efficiency for real-world applications .", "It extends the theory of support vector machine to unsupervised learning .", "Finally , we show a formal connection between maximum margin clustering and spectral clustering .", "Furthermore , the new framework is able to automatically determine the appropriate kernel matrix without any labeled data .", "First , it is computationally expensive and difficult to scale to large-scale datasets because the number of parameters in maximum margin clustering is quadratic in the number of examples .", "Third , it is sensitive to the choice of kernel functions , and requires external procedure to determine the appropriate values for the parameters of kernel functions .", "Second , it requires data preprocessing to ensure that any clustering boundary will pass through the origins , which makes it unsuitable for clustering unbalanced dataset .", "We demonstrate the efficiency of the generalized maximum margin clustering algorithm using both synthetic datasets and real datasets from the UCI repository .", "Maximum margin clustering was proposed lately and has shown promising performance in recent studies .", "In this paper , we propose `` generalized maximum margin clustering '' framework that addresses the above three problems simultaneously ."]}
{"orig_sents": ["1", "3", "0", "2", "5", "4"], "shuf_sents": ["The basic idea is to group the original mixture components into compact clusters , and then minimize an upper bound on the approximation error between the original and simplified models .", "Finite mixture model is a powerful tool in many statistical learning problems .", "By adopting the L2 norm as the distance measure between mixture models , we can derive closed-form solutions that are more robust and reliable than using the KL-based distance measure .", "In this paper , we propose a general , structure-preserving approach to reduce its model complexity , which can bring significant computational benefits in many applications .", "Experiments on density estimation and clustering-based image segmentation demonstrate its outstanding performance in terms of both speed and accuracy .", "Moreover , the complexity of our algorithm is only linear in the sample size and dimensionality ."]}
{"orig_sents": ["4", "2", "0", "3", "5", "7", "1", "6"], "shuf_sents": ["This paper presents a study of regression problems in that setting .", "Our study also includes the results of experiments with several publicly available regression data sets with up to 20,000 unlabeled examples .", "A common instance of this problem is the transductive setting where the unlabeled test points are known to the learning algorithm .", "It presents explicit VC-dimension error bounds for transductive regression that hold for all bounded loss functions and coincide with the tight classification bounds of Vapnik when applied to classification .", "In many modern large-scale learning applications , the amount of unlabeled data far exceeds that of labeled data .", "It also presents a new transductive regression algorithm inspired by our bound that admits a primal and kernelized closedform solution and deals efficiently with large amounts of unlabeled data .", "The comparison with other transductive regression algorithms shows that it performs well and that it can scale to large data sets .", "The algorithm exploits the position of unlabeled points to locally estimate their labels and then uses a global optimization to ensure robust predictions ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["Most algorithms for this setting try to first recover sampling distributions and then make appropriate corrections based on the distribution estimate .", "Experimental results demonstrate that our method works well in practice .", "Our method works by matching distributions between training and testing sets in feature space .", "We consider the scenario where training and test data are drawn from different distributions , commonly referred to as sample selection bias .", "We present a nonparametric method which directly produces resampling weights without distribution estimation ."]}
{"orig_sents": ["8", "2", "7", "10", "1", "5", "9", "6", "0", "3", "4"], "shuf_sents": ["Therefore we trade off fidelity and complexity of the aligned ensemble rather than minimizing the complexity alone .", "While IC is simple and general , it may introduce degenerate solutions when the transformations allow minimizing the complexity of the data by collapsing them to a constant .", "The method attempts to undo the deformations by minimizing a measure of complexity of the image ensemble , such as the averaged per-pixel entropy .", "This eliminates the need for an explicit regularization of the transformations , and has a number of other useful properties such as noise suppression .", "We show the modeling and computational benefits of the approach to the some of the problems on which IC has been demonstrated .", "Such solutions need to be explicitly removed by regularization .", "We make the simple observation that alignment should simplify the data while preserving the useful information carried by them .", "This enables alignment without an explicit model of the aligned dataset as required by other methods ( e.g .", "Image Congealing ( IC ) is a non-parametric method for the joint alignment of a collection of images affected by systematic and unwanted deformations .", "In this paper we propose an alternative formulation which solves this regularization issue on a more principled ground .", "transformed component analysis ) ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["Given a collection of features and relations defined over a set of objects , an annotated hierarchy includes a specification of the categories that are most useful for describing each individual feature and relation .", "We define a generative model for annotated hierarchies and the features and relations that they describe , and develop a Markov chain Monte Carlo scheme for learning annotated hierarchies .", "The objects in many real-world domains can be organized into hierarchies , where each internal node picks out a category of objects .", "We show that our model discovers interpretable structure in several real-world data sets ."]}
{"orig_sents": ["4", "5", "2", "3", "1", "0"], "shuf_sents": ["Website : http : //www.cs.toronto.edu/gwtaylor/publications/nips2006mhmublv/", "We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture .", "Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure .", "After training , the model finds a single set of parameters that simultaneously capture several different kinds of motion .", "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued `` visible '' variables that represent joint angles .", "The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps ."]}
{"orig_sents": ["0", "3", "2", "4", "1"], "shuf_sents": ["We present a novel algorithm called PG-means which is able to learn the number of clusters in a classical Gaussian mixture model .", "Further , our new method provides a much more stable estimate of the number of clusters than existing methods .", "In so doing , we are applying a statistical test for the entire model at once , not just on a per-cluster basis .", "Our method is robust and efficient ; it uses statistical hypothesis tests on one-dimensional projections of the data and model to determine if the examples are well represented by the model .", "We show that our method works well in difficult cases such as non-Gaussian data , overlapping clusters , eccentric clusters , high dimension , and many true clusters ."]}
{"orig_sents": ["3", "6", "5", "4", "1", "2", "0", "7"], "shuf_sents": ["The second machine learning technique is active learning that allows Alice to construct an online classifier , based on a small number of calls to Bob 's face detector .", "Unfortunately , these methods are slow to compute and we introduce a couple of machine learning techniques that allow the parties to solve the problem while leaking a controlled amount of information .", "The first method is an information-bottleneck variant of AdaBoost that lets Bob find a subset of features that are enough for classifying an image patch , but not enough to actually reconstruct it .", "Bob offers a face-detection web service where clients can submit their images for analysis .", "Secure MultiParty computations use cryptographic tools to solve this problem without leaking any information .", "Bob , for his part , is reluctant to release his face detector , as he spent a lot of time , energy and money constructing it .", "Alice would very much like to use the service , but is reluctant to reveal the content of her images to Bob .", "She can then use her online classifier as a fast rejector before using a cryptographically secure classifier on the remaining image patches ."]}
{"orig_sents": ["7", "6", "5", "1", "8", "3", "2", "0", "4"], "shuf_sents": ["These Lagrangian Hedging algorithms are based on a general class of potential functions , and are a direct generalization of known learning rules like weighted majority and external-regret matching .", "But , compared to algorithms for special cases of OCP such as learning from expert advice , these algorithms are not very numerous or flexible .", "In this paper we derive a new class of no-regret learning algorithms for OCP .", "Until now , there has been no such recipe for the more general OCP problem , and therefore no ability to tune OCP algorithms to take advantage of properties of the problem or data .", "In addition to proving regret bounds , we demonstrate our algorithms learning to play one-card poker .", "Several researchers have designed no-regret algorithms for OCP .", "For example , OCP can be used for learning a linear classifier , dynamically rebalancing a binary search tree , finding the shortest path in a graph with unknown edge lengths , solving a structured classification problem , or finding a good strategy in an extensive-form game .", "Online convex programming has recently emerged as a powerful primitive for designing machine learning algorithms .", "In learning from expert advice , one tool which has proved particularly valuable is the correspondence between no-regret algorithms and convex potential functions : by reasoning about these potential functions , researchers have designed algorithms with a wide variety of useful guarantees such as good performance when the target hypothesis is sparse ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["Some of the most effective recent methods for content-based image classification work by extracting dense or sparse local image descriptors , quantizing them according to a coding rule such as k-means vector quantization , accumulating histograms of the resulting `` visual word '' codes over the image , and classifying these with a conventional classifier such as an SVM .", "Large numbers of descriptors and large codebooks are needed for good results and this becomes slow using k-means .", "We introduce Extremely Randomized Clustering Forests - ensembles of randomly created clustering trees - and show that these provide more accurate results , much faster training and testing and good resistance to background clutter in several state-of-the-art image classification tasks ."]}
{"orig_sents": ["4", "2", "5", "0", "3", "1"], "shuf_sents": ["Like boosting , each weak learner ( i.e. , each weak tree ) contributes a small amount to the overall model .", "This model-based approach enables a full and accurate assessment of uncertainty in model predictions , while remaining highly competitive in terms of predictive accuracy .", "Fitting and inference are accomplished via an iterative backfitting MCMC algorithm .", "However , our procedure is defined by a statistical model : a prior and a likelihood , while boosting is defined by an algorithm .", "We develop a Bayesian `` sum-of-trees '' model , named BART , where each tree is constrained by a prior to be a weak learner .", "This model is motivated by ensemble methods in general , and boosting algorithms in particular ."]}
{"orig_sents": ["6", "3", "4", "8", "5", "0", "2", "7", "9", "1"], "shuf_sents": ["Our approach relies on the observation that the statistics of derivative filters in images are significantly changed by blur .", "The approach produces convincing deconvolution results on real world images with rich texture .", "Assuming the blur results from a constant velocity motion , we can limit the search to one dimensional box filter blurs .", "In such situations only part of the image may be blurred , and the scene consists of layers blurred in different degrees .", "Most of of existing blind deconvolution research concentrates at recovering a single blurring kernel for the entire image .", "Thus , the task of deblurring needs to involve segmentation of the image into regions with different blurs .", "We address the problem of blind motion deblurring from a single image , caused by a few moving objects .", "This enables us to model the expected derivatives distributions as a function of the width of the blur kernel .", "However , in the case of different motions , the blur can not be modeled with a single kernel , and trying to deconvolve the entire image with the same kernel will cause serious artifacts .", "Those distributions are surprisingly powerful in discriminating regions with different blurs ."]}
{"orig_sents": ["0", "2", "1", "4", "3"], "shuf_sents": ["The standard Support Vector Machine formulation does not provide its user with the ability to explicitly control the number of support vectors used to define the generated classifier .", "This idea can be used to derive sparse versions of both L1-SVM and L2-SVM .", "We present a modified version of SVM that allows the user to set a budget parameter B and focuses on minimizing the loss attained by the B worst-classified examples while ignoring the remaining examples .", "We also adapt the SMO optimization algorithm to our setting and report on some preliminary experimental results .", "Technically , we obtain these new SVM variants by replacing the 1-norm in the standard SVM formulation with various interpolation-norms ."]}
{"orig_sents": ["0", "3", "2", "4", "5", "1"], "shuf_sents": ["Current road-traffic optimisation practice around the world is a combination of hand tuned policies with a small degree of automatic adaption .", "Along the way we extend natural-actor critic approaches to work for distributed and online infinite-horizon problems .", "We use a policy-gradient reinforcement learning approach to directly optimise the traffic signals , mapping currently deployed sensor observations to control signals .", "Even state-ofthe-art research controllers need good models of the road traffic , which can not be obtained directly from existing sensors .", "Our trained controllers are ( theoretically ) compatible with the traffic system used in Sydney and many other cities around the world .", "We apply two policy-gradient methods : ( 1 ) the recent natural actor-critic algorithm , and ( 2 ) a vanilla policy-gradient algorithm for comparison ."]}
{"orig_sents": ["5", "7", "0", "6", "3", "4", "1", "2"], "shuf_sents": ["In such cases , previous work has relied on a two-step solution : first apply dimensionality reduction methods to the data , and then learn a metric in the resulting low-dimensional subspace .", "Theory and results are presented for both a linear as well as a kernelized version of the algorithm .", "Overall , we achieve classification rates similar , and in several cases superior , to those of support vector machines .", "We propose a method that solves for the low-dimensional projection of the inputs , which minimizes a metric objective aimed at separating points in different classes by a large margin .", "This projection is defined by a significantly smaller number of parameters than metrics learned in input space , and thus our optimization reduces the risks of overfitting .", "Metric learning has been shown to significantly improve the accuracy of k-nearest neighbor ( kNN ) classification .", "In this paper we show that better classification performance can be achieved by unifying the objectives of dimensionality reduction and metric learning .", "In problems involving thousands of features , distance learning algorithms can not be used due to overfitting and high computational complexity ."]}
{"orig_sents": ["4", "2", "3", "1", "0"], "shuf_sents": ["We also derive theoretical properties of this methodology related to convergence , local minima , and localization bias and explore connections with established algorithms .", "While seemingly quite different in many respects , we apply a unifying framework based on automatic relevance determination ( ARD ) that elucidates various attributes of these methods and suggests directions for improvement .", "Bayesian methods are useful in this capacity because they allow these assumptions to be explicitly quantified .", "Recently , a number of empirical Bayesian approaches have been proposed that attempt a form of model selection by using the data to guide the search for an appropriate prior .", "The ill-posed nature of the MEG/EEG source localization problem requires the incorporation of prior assumptions when choosing an appropriate solution out of an infinite set of candidates ."]}
{"orig_sents": ["0", "6", "5", "2", "3", "4", "1"], "shuf_sents": ["Attempting to model human categorization and similarity judgements is both a very interesting but also an exceedingly difficult challenge .", "Thus there may not be a strict dichotomy between either a metric or a non-metric internal space but rather degrees to which potentially large subsets of stimuli are represented metrically with a small subset causing a global violation of metricity .", "Here we show how a single stimulus , carefully constructed in a psychophysical experiment , introduces l2 violations in what used to be an internal similarity space that could be adequately modelled as Euclidean .", "We term this one influential data point a conflictual judgement .", "We present an algorithm of how to analyse such data and how to identify the crucial point .", "Intuitively , this has a strong appeal as it would allow ( dis ) similarity to be represented geometrically as distance in some internal space .", "Some of the difficulty arises because of conflicting evidence whether human categorization and similarity judgements should or should not be modelled as to operate on a mental representation that is essentially metric ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We develop and analyze game-theoretic algorithms for predicting coordinate binding of multiple DNA binding regulators .", "We also briefly demonstrate the approach in the context of the -phage switch .", "The allocation of proteins to local neighborhoods and to sites is carried out with resource constraints while explicating competing and coordinate binding relations among proteins with affinity to the site or region .", "The focus of this paper is on mathematical foundations of the approach ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["In this paper , we generalize the previous iLSTD algorithm and present three new results : ( 1 ) the first convergence proof for an iLSTD algorithm ; ( 2 ) an extension to incorporate eligibility traces without changing the asymptotic computational complexity ; and ( 3 ) the first empirical results with an iLSTD algorithm for a problem ( mountain car ) with feature vectors large enough ( n = 10 , 000 ) to show substantial computational advantages over LSTD .", "iLSTD is an incremental method for achieving results similar to LSTD , the dataefficient , least-squares version of temporal difference learning , without incurring the full cost of the LSTD computation .", "We present new theoretical and empirical results with the iLSTD algorithm for policy evaluation in reinforcement learning with linear function approximation .", "LSTD is O ( n2 ) , where n is the number of parameters in the linear function approximator , while iLSTD is O ( n ) ."]}
{"orig_sents": ["6", "1", "2", "0", "3", "4", "5"], "shuf_sents": ["This algorithm requires only low-rank matrix manipulations and a one-dimensional linesearch to choose the stimulus and is therefore efficient even for high-dimensional stimulus and parameter spaces ; for example , we require just 15 milliseconds on a desktop computer to optimize a 100-dimensional stimulus .", "However , the potential for these methods has been limited to date by severe computational challenges : choosing the stimulus which will provide the most information about the ( typically high-dimensional ) model parameters requires evaluating a high-dimensional integration and optimization in near-real time .", "Here we present a fast algorithm for choosing the optimal ( most informative ) stimulus based on a Fisher approximation of the Shannon information and specialized numerical linear algebra techniques .", "Our algorithm therefore makes real-time adaptive experimental design feasible .", "Simulation results show that model parameters can be estimated much more efficiently using these adaptive techniques than by using random ( nonadaptive ) stimuli .", "Finally , we generalize the algorithm to efficiently handle both fast adaptation due to spike-history effects and slow , non-systematic drifts in the model parameters .", "Adaptively optimizing experiments can significantly reduce the number of trials needed to characterize neural responses using parametric statistical models ."]}
{"orig_sents": ["1", "7", "3", "2", "4", "8", "0", "9", "6", "5"], "shuf_sents": ["The aggregation of these probabilities provides an effective strategic evaluation function that is an estimate of the expected area at the end ( or at other stages ) of the game .", "Go is an ancient board game that poses unique opportunities and challenges for AI and machine learning .", "The system we propose is capable of automatically learning the propensity of local patterns from a library of games .", "Scalability is essential at multiple levels , from the library of local tactical patterns , to the integration of patterns across the board , to the size of the board itself .", "Propensity and other local tactical information are fed into a recursive neural network , derived from a Bayesian network architecture .", "Possible directions for further improvements are briefly discussed .", "A system trained using only 9 x 9 amateur game data performs surprisingly well on a test set derived from 19 x 19 professional game data .", "Here we develop a machine learning approach to Go , and related board games , focusing primarily on the problem of learning a good evaluation function in a scalable way .", "The network integrates local information across the board and produces local outputs that represent local territory ownership probabilities .", "Local area targets for training can be derived from datasets of human games ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["A new bottom-up visual saliency model , Graph-Based Visual Saliency ( GBVS ) , is proposed .", "This model powerfully predicts human xations on 749 variations of 108 natural images , achieving 98 % of the ROC area of a human-based control , whereas the classical algorithms of Itti & Koch ( , , ) achieve only 84 % .", "The model is simple , and biologically plausible insofar as it is naturally parallelized .", "It consists of two steps : rst forming activation maps on certain feature channels , and then normalizing them in a way which highlights conspicuity and admits combination with other maps ."]}
{"orig_sents": ["4", "3", "0", "2", "1"], "shuf_sents": ["In a fast sequence of stimulus presentation , information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted .", "The important implications of these properties for the nonlinear brain theory are discussed .", "These results suggest nonlinear properties of cortical representations .", "We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed .", "We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli ."]}
{"orig_sents": ["3", "7", "8", "0", "2", "4", "1", "5", "6"], "shuf_sents": ["Our key contribution is a nonparametric learning method which generalizes to systems with very different dynamics .", "We provide experimental results for two systems : a biomechanical model of the human arm and a 25-degrees-of-freedom humanoid robot .", "Rather than relying on a known forward model of the dynamics , our approach learns a nonparametric forward model via exploration .", "Learning by imitation represents an important mechanism for rapid acquisition of new behaviors in humans and robots .", "Leveraging advances in approximate inference in graphical models , we show how the learned forward model can be directly used to plan an imitating sequence .", "We demonstrate that the proposed method can be used to learn appropriate motor inputs to the model arm which imitates the desired movements .", "A second set of results demonstrates dynamically stable full-body imitation of a human teacher by the humanoid robot .", "A critical requirement for learning by imitation is the ability to handle uncertainty arising from the observation process as well as the imitator 's own dynamics and interactions with the environment .", "In this paper , we present a new probabilistic method for inferring imitative actions that takes into account both the observations of the teacher as well as the imitator 's dynamics ."]}
{"orig_sents": ["7", "1", "6", "5", "2", "3", "4", "0"], "shuf_sents": ["We demonstrate our algorithm and protocol on two simple robotic planning problems.1", "Often these agents ' goals are neither completely aligned with our own nor directly opposed to them .", "Research in multi-agent planning has often avoided the problem of making sure that all agents have an incentive to follow a proposed joint plan .", "On the other hand , while game theoretic algorithms handle incentives correctly , they often do n't scale to large planning problems .", "In this paper we attempt to bridge the gap between these two lines of research : we present an efficient game-theoretic approximate planning algorithm , along with a negotiation protocol which encourages agents to compute and agree on joint plans that are fair and optimal in a sense defined below .", "But , in order to cooperate , the agents must negotiate a mutually acceptable plan from among the many possible ones , and each agent must trust that the others will follow their parts of the deal .", "Instead there are opportunities for cooperation : by joining forces , the agents can all achieve higher utility than they could separately .", "In real-world planning problems , we must reason not only about our own goals , but about the goals of other agents with which we may interact ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We discuss how kernel learning can be used not just for improving the performance of classification and regression methods , but also as a stand-alone algorithm for dimensionality reduction and relational or metric learning .", "The former is especially attractive in that it has an interpretable regularization scheme reminiscent of that of the Gaussian RBF kernel .", "These we call the Gaussian and Wishart hyperkernels .", "We propose a new method for constructing hyperkenels and define two promising special cases that can be computed in closed form ."]}
{"orig_sents": ["6", "7", "4", "5", "3", "2", "8", "1", "0"], "shuf_sents": ["The impossibility of such bounds for the graph geodesic nearest neighbors algorithm will be demonstrated .", "We derive an upper bound that depends only on natural properties of the graph - the graph diameter and the cut size of a partitioning of the graph - which are only indirectly dependent on the size of the graph .", "Often the norm of a concept can vary dramatically with only small perturbations in a labeling .", "These bounds depend crucially on the norm of the learned concept .", "Graph learning is framed as an instance of prediction on a finite set .", "To treat label noise we show that the hinge loss bounds derived by Gentile for online perceptron learning can be transformed to relative mistake bounds with an optimal leading constant when applied to prediction on a finite set .", "We study the problem of online prediction of a noisy labeling of a graph with the perceptron .", "We address both label noise and concept noise .", "We analyze a simple transformation that stabilizes the norm under perturbations ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["This paper introduces adaptor grammars , a class of probabilistic models of language that generalize probabilistic context-free grammars ( PCFGs ) .", "Adaptor grammars augment the probabilistic rules of PCFGs with `` adaptors '' that can induce dependencies among successive uses .", "With a particular choice of adaptor , based on the Pitman-Yor process , nonparametric Bayesian models of language using Dirichlet processes and hierarchical Dirichlet processes can be written as simple grammars .", "We present a general-purpose inference algorithm for adaptor grammars , making it easy to define and use such models , and illustrate how several existing nonparametric Bayesian models can be expressed within this framework ."]}
{"orig_sents": ["4", "5", "2", "1", "0", "3"], "shuf_sents": ["We apply this theory to memory in a model of oscillatory associative recall in hippocampal area CA3 .", "Here , we observe that , since neurons in an oscillatory network need not only fire once in each cycle ( or even at all ) , uncertainty about the analog quantities each neuron represents by its firing phase might naturally be reported through the degree of concentration of the spikes that it fires .", "However , it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture , and the substantial recent work on neural codes for uncertainty has omitted any analysis of oscillatory systems .", "Although it is not well treated in the literature , representing and manipulating uncertainty is fundamental to competent memory ; our theory enables us to view CA3 as an effective uncertainty-aware , retrieval system .", "Many neural areas , notably , the hippocampus , show structured , dynamical , population behavior such as coordinated oscillations .", "It has long been observed that such oscillations provide a substrate for representing analog information in the firing phases of neurons relative to the underlying population rhythm ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["The simulation result shows that our algorithm can express dynamics with a high degree of accuracy .", "In this paper , we present a subspace method for learning nonlinear dynamical systems based on stochastic realization , in which state vectors are chosen using kernel canonical correlation analysis , and then state-space systems are identified through regression with the state vectors .", "We construct the theoretical underpinning and derive a concrete algorithm for nonlinear identification .", "The obtained algorithm needs no iterative optimization procedure and can be implemented on the basis of fast and reliable numerical schemes ."]}
{"orig_sents": ["1", "0", "2", "3", "4"], "shuf_sents": ["The goal is to create a low dimensional representation from a collection of points which on the one hand maximizes the variance of the projected points and on the other uses only parts of the original coordinates , and thereby creating a sparse representation .", "We describe a nonnegative variant of the `` Sparse PCA '' problem .", "What distinguishes our problem from other Sparse PCA formulations is that the projection involves only nonnegative weights of the original coordinates -- a desired quality in various fields , including economics , bioinformatics and computer vision .", "Adding nonnegativity contributes to sparseness , where it enforces a partitioning of the original coordinates among the new axes .", "We describe a simple yet efficient iterative coordinate-descent type of scheme which converges to a local optimum of our optimization criteria , giving good results on large real world datasets ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We present a probabilistic model applied to the fMRI video rating prediction task of the Pittsburgh Brain Activity Interpretation Competition ( PBAIC ) .", "We also employed non-traditional methods for feature selection and regularization that exploit the spatial structure of voxel activity in the brain .", "Our goal is to predict a time series of subjective , semantic ratings of a movie given functional MRI data acquired during viewing by three subjects .", "Our method uses conditionally trained Gaussian Markov random fields , which model both the relationships between the subjects ' fMRI voxel measurements and the ratings , as well as the dependencies of the ratings across time steps and between subjects .", "The model displayed good performance in predicting the scored ratings for the three subjects in test data sets , and a variant of this model was the third place entrant to the 2006 PBAIC ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["In this paper we describe such a hVLSI neural network that performs an interesting task of selective attentional processing that was previously described for a simulated 'pointer-map ' rate model by Hahnloser and colleagues .", "However , for simplicity of simulation , most models of processing by cortical neural networks have assumed that the activations of their neurons can be approximated by event rates rather than taking account of individual spikes .", "We found that most of the computational features of their rate model can be reproduced in the spiking implementation ; but , that spike-based processing requires a modification of the original network architecture in order to memorize a previously attended target .", "The obstacle to exploring the more detailed spike processing of these networks has been reduced considerably in recent years by the development of hybrid analog-digital Very-Large Scale Integrated ( hVLSI ) neural networks composed of spiking neurons that are able to operate in real-time .", "The neurons of the neocortex communicate by asynchronous events called action potentials ( or 'spikes ' ) ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["We show that various online learning and boosting algorithms can be all derived as special cases of our algorithmic framework .", "This unified view explains the properties of existing algorithms and also enables us to derive several new interesting algorithms .", "We describe an algorithmic framework for an abstract game which we term a convex repeated game .", "Our algorithmic framework stems from a connection that we build between the notions of regret in game theory and weak duality in convex optimization ."]}
{"orig_sents": ["4", "3", "5", "1", "2", "0"], "shuf_sents": ["Experimental results on several real world data sets verify the usefulness of this algorithm .", "This approach provides a novel non-parametric Bayesian framework with a data-dependent covariance function for supervised learning tasks .", "We also apply this framework to semi-supervised learning .", "Relational knowledge can further reveal additional pairwise correlations between variables of interest .", "Correlation between instances is often modelled via a kernel function using input attributes of the instances .", "In this paper , we develop a class of models which incorporates both reciprocal relational information and input attributes using Gaussian process techniques ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We cast the task of learning to synthesize desired movement styles as a regression problem : sequences generated via space-time interpolation of motion capture data are used to learn a nonlinear mapping between animation parameters and movement styles in perceptual space .", "We demonstrate that the learned model can apply a variety of motion styles to pre-recorded motion sequences and it can extrapolate styles not originally included in the training data .", "We use a theory of movement observation ( Laban Movement Analysis ) to describe movement styles as points in a multi-dimensional perceptual space .", "This paper presents an algorithm for synthesis of human motion in specified styles ."]}
{"orig_sents": ["3", "2", "5", "1", "0", "4"], "shuf_sents": ["We apply our approach to a variety of problems , including attribute matching for databases using the Hungarian marriage method , where our test performs strongly .", "The test statistic can be computed in O ( m2 ) time .", "Our test statistic is in both cases the distance between the means of the two samples mapped into a reproducing kernel Hilbert space ( RKHS ) .", "We propose two statistical tests to determine if two samples are from different distributions .", "We also demonstrate excellent performance when comparing distributions over graphs , for which no alternative tests currently exist .", "The first test is based on a large deviation bound for the test statistic , while the second is based on the asymptotic distribution of this statistic ."]}
{"orig_sents": ["4", "0", "1", "3", "2", "5"], "shuf_sents": ["Numerous facial features that describe facial geometry , color and texture , combined with an average human attractiveness score for each facial image , are used to train various predictors .", "Facial attractiveness ratings produced by the final predictor are found to be highly correlated with human ratings , markedly improving previous machine learning achievements .", "These experiments shed new light on existing theories of facial attractiveness such as the averageness , smoothness and symmetry hypotheses .", "Simulated psychophysical experiments with virtually manipulated images reveal preferences in the machine 's judgments which are remarkably similar to those of humans .", "This work presents a method for estimating human facial attractiveness , based on supervised learning techniques .", "It is intriguing to find that a machine trained explicitly to capture an operational performance criteria such as attractiveness rating , implicitly captures basic human psychophysical biases characterizing the perception of facial attractiveness in general ."]}
{"orig_sents": ["6", "5", "2", "1", "3", "0", "7", "4"], "shuf_sents": ["Inference and learning are very fast , requiring no preprocessing , and no expensive sampling .", "Learning proceeds in a two-phase EM-like fashion : ( 1 ) compute the minimum-energy code vector , ( 2 ) adjust the parameters of the encoder and decoder so as to decrease the energy .", "Given an input , the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output .", "The model produces `` stroke detectors '' when trained on handwritten numerals , and Gabor-like filters when trained on natural image patches .", "Finally , an extension of the method is described to learn topographical filter maps .", "The model uses a linear encoder , and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector .", "We describe a novel unsupervised method for learning sparse , overcomplete features .", "Using the proposed unsupervised method to initialize the first layer of a convolutional network , we achieved an error rate slightly lower than the best reported result on the MNIST dataset ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Due to the large scale nature of these applications , current inference procedures like variational Bayes and Gibbs sampling have been found lacking .", "In this paper we propose the collapsed variational Bayesian inference algorithm for LDA , and show that it is computationally efficient , easy to implement and significantly more accurate than standard variational Bayesian inference for LDA .", "Latent Dirichlet allocation ( LDA ) is a Bayesian network that has recently gained much popularity in applications ranging from document modeling to computer vision ."]}
{"orig_sents": ["1", "3", "4", "5", "0", "7", "6", "10", "9", "8", "2"], "shuf_sents": ["However , the image sampled by retinal photoreceptors is degraded both by the optics of the eye and by the photoreceptor noise .", "Efficient coding models predict that the optimal code for natural images is a population of oriented Gabor receptive fields .", "The proposed model provides a unified account of retinal coding , and more generally , it may be viewed as an extension of the Wiener filter with an arbitrary number of noisy units .", "These results match response properties of neurons in primary visual cortex , but not those in the retina .", "Does the retina use an optimal code , and if so , what is it optimized for ?", "Previous theories of retinal coding have assumed that the goal is to encode the maximal amount of information about the sensory signal .", "Furthermore , the ideal retinal code should be robust to neural noise and make optimal use of all available neurons .", "Therefore , de-blurring and de-noising of the retinal signal should be important aspects of retinal coding .", "Importantly , the characteristics of receptive fields vary with retinal eccentricities where the optical blur and the number of RGCs are significantly different .", "When optimized for natural images , the model yields filters that show strong similarities to retinal ganglion cell ( RGC ) receptive fields .", "Here we present a theoretical framework to derive codes that simultaneously satisfy all of these desiderata ."]}
{"orig_sents": ["3", "2", "1", "5", "0", "4"], "shuf_sents": ["We also briefly investigate the parameter selection issue and provide a simple parameter selection method for the proposed algorithm .", "An optimization problem is formulated such that its solution has the above property .", "The basic idea is that a good clustering result should have the property that the cluster label of each data point can be well predicted based on its neighboring data and their cluster labels , using current supervised learning methods .", "We present a local learning approach for clustering .", "Experimental results are provided to validate the effectiveness of the proposed approach .", "Relaxation and eigen-decomposition are applied to solve this optimization problem ."]}
{"orig_sents": ["0", "2", "3", "5", "1", "4"], "shuf_sents": ["We phrase K-means clustering as an empirical risk minimization procedure over a class HK and explicitly calculate the covering number for this class .", "We conclude by proving that stability of the functions in HK implies stability of the actual centers of the clusters .", "Next , we show that stability of K-means clustering is characterized by the geometry of HK with respect to the underlying distribution .", "We prove that in the case of a unique global minimizer , the clustering solution is stable with respect to complete changes of the data , while for the case of multiple minimizers , the change of ( n1/2 ) samples defines the transition between stability and instability .", "Since stability is often used for selecting the number of clusters in practice , we hope that our analysis serves as a starting point for finding theoretically grounded recipes for the choice of K .", "While for a finite number of minimizers this result follows from multinomial distribution estimates , the case of infinite minimizers requires more refined tools ."]}
{"orig_sents": ["4", "0", "2", "1", "6", "5", "3", "7"], "shuf_sents": ["However , in certain subclasses of MRF , an optimal or close-to-optimal assignment can be found very efficiently using combinatorial optimization algorithms : certain MRFs with mutual exclusion constraints can be solved using bipartite matching , and MRFs with regular potentials can be solved using minimum cut methods .", "In this paper , we present a new method , called C OMPOSE , for exploiting combinatorial optimization for sub-networks within the context of a max-product belief propagation algorithm .", "However , these solutions do not apply to the many MRFs that contain such tractable components as sub-networks , but also other non-complying potentials .", "We present results on both synthetic and real networks encoding correspondence problems between images , which involve both matching constraints and pairwise geometric constraints .", "In general , the problem of computing a maximum a posteriori ( MAP ) assignment in a Markov random field ( MRF ) is computationally intractable .", "We describe highly efficient methods for computing max-marginals for subnetworks corresponding both to bipartite matchings and to regular networks .", "C OMPOSE uses combinatorial optimization for computing exact maxmarginals for an entire sub-network ; these can then be used for inference in the context of the network as a whole .", "We compare to a range of current methods , showing that the ability of C OMPOSE to transmit information globally across the network leads to improved convergence , decreased running time , and higher-scoring assignments ."]}
{"orig_sents": ["4", "1", "3", "2", "0"], "shuf_sents": ["Moreover , experiments on a well-studied problem -- inferring the stable configurations of the Ising spin glass -- show that the solutions can be significantly better than those obtained using sum-product-based methods .", "Mean field approximations have been applied to a broader set of problems , but the solutions are often poor .", "While not usable on their own , combined with sequential Monte Carlo they produce guaranteed improvements over conventional mean field .", "We propose a new class of conditionally-specified variational approximations based on mean field theory .", "Despite all the attention paid to variational methods based on sum-product message passing ( loopy belief propagation , tree-reweighted sum-product ) , these methods are still bound to inference on a small set of probabilistic models ."]}
{"orig_sents": ["4", "0", "1", "3", "2"], "shuf_sents": ["While some of them are relatively easy to measure , such as mRNA decay rates and mRNA abundance levels , it is still very hard to measure the active concentration levels of the transcription factor proteins that drive the process and the sensitivity of target genes to these concentrations .", "In this paper we show how these quantities for a given transcription factor can be inferred from gene expression levels of a set of known target genes .", "We apply this procedure to a human leukemia dataset , focusing on the tumour repressor p53 and obtaining results in good accordance with recent biological studies .", "We treat the protein concentration as a latent function with a Gaussian process prior , and include the sensitivities , mRNA decay rates and baseline expression levels as hyperparameters .", "Modelling the dynamics of transcriptional processes in the cell requires the knowledge of a number of key biological quantities ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We provide a PAC-Bayesian bound for the expected loss of convex combinations of classifiers under a wide class of loss functions ( which includes the exponential loss and the logistic loss ) .", "Our numerical experiments with Adaboost indicate that the proposed upper bound , computed on the training set , behaves very similarly as the true loss estimated on the testing set ."]}
{"orig_sents": ["1", "2", "5", "3", "0", "4"], "shuf_sents": ["An enhanced spectral clustering algorithm is proposed , by replacing kernel PCA by kernel MaxEnt as an intermediate step .", "We propose a new kernel-based data transformation technique .", "It is founded on the principle of maximum entropy ( MaxEnt ) preservation , hence named kernel MaxEnt .", "We show that kernel MaxEnt is based on eigenvectors , and is in that sense similar to kernel PCA , but may produce strikingly different transformed data sets .", "This has a major impact on performance .", "The key measure is Renyi 's entropy estimated via Parzen windowing ."]}
{"orig_sents": ["5", "3", "4", "2", "7", "6", "0", "1"], "shuf_sents": ["Experimental results show that -- despite the lack of any biological prior knowledge -- our model performs comparably to existing approaches , and in fact learns image features that resemble findings from several previous studies .", "In particular , its maximally excitatory stimuli have center-surround structure , similar to receptive fields in the early human visual system .", "As a result , these parameters have to be chosen in a more or less ad hoc way .", "Most existing computational models use a set of biologically plausible linear filters , e.g. , Gabor or Difference-of-Gaussians filters as a front-end , the outputs of which are nonlinearly combined into a real number that indicates visual saliency .", "Unfortunately , this requires many design parameters such as the number , type , and size of the front-end filters , as well as the choice of nonlinearities , weighting and normalization schemes etc. , for which biological plausibility can not always be justified .", "This paper addresses the bottom-up influence of local image information on human eye movements .", "The model is rather simplistic and essentially parameter-free , and therefore contrasts recent developments in the field that usually aim at higher prediction rates at the cost of additional parameters and increasing model complexity .", "Here , we propose to learn a visual saliency model directly from human eye movement data ."]}
{"orig_sents": ["1", "2", "3", "4", "0"], "shuf_sents": ["We demonstrate how to train an auto-encoder neural network using this rule .", "In biological neurons , the timing of a spike depends on the timing of synaptic currents , in a way that is classically described by the Phase Response Curve .", "This has implications for temporal coding : an action potential that arrives on a synapse has an implicit meaning , that depends on the position of the postsynaptic neuron on the firing cycle .", "Here we show that this implicit code can be used to perform computations .", "Using theta neurons , we derive a spike-timing dependent learning rule from an error criterion ."]}
{"orig_sents": ["4", "5", "6", "3", "1", "0", "2"], "shuf_sents": ["Experimental studies on two different CAD applications further demonstrate that the proposed algorithm significantly improves diagnostic accuracy when compared to both MIL and traditional classifiers .", "Our CH framework applies to any standard hyperplane-based learning algorithm , and for some algorithms , is guaranteed to find the global optimal solution .", "Although not designed for standard MIL problems ( which have both positive and negative bags and relatively balanced datasets ) , comparisons against other MIL methods on benchmark problems also indicate that the proposed method is competitive with the state-of-the-art .", "We describe CH , a framework for learning a Convex Hull representation of multiple instances that is significantly faster than existing MIL algorithms .", "Many computer aided diagnosis ( CAD ) problems can be best modelled as a multiple-instance learning ( MIL ) problem with unbalanced data : i.e .", ", the training data typically consists of a few positive bags , and a very large number of negative instances .", "Existing MIL algorithms are much too computationally expensive for these datasets ."]}
{"orig_sents": ["1", "0", "2", "5", "3", "4"], "shuf_sents": ["The framework consists of three steps : extracting extended examples from the original examples , learning a binary classifier on the extended examples with any binary classification algorithm , and constructing a ranking rule from the binary classifier .", "We present a reduction framework from ordinal regression to binary classification based on extended examples .", "A weighted 0/1 loss of the binary classifier would then bound the mislabeling cost of the ranking rule .", "In addition , our framework unifies many existing ordinal regression algorithms , such as perceptron ranking and support vector ordinal regression .", "When compared empirically on benchmark data sets , some of our newly designed algorithms enjoy advantages in terms of both training speed and generalization performance over existing algorithms , which demonstrates the usefulness of our framework .", "Our framework allows not only to design good ordinal regression algorithms based on well-tuned binary classification approaches , but also to derive new generalization bounds for ordinal regression from known bounds for binary classification ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We learn a distance function for each training image as a combination of elementary distances between patch-based visual features .", "In this paper we introduce and experiment with a framework for learning local perceptual distance functions for visual recognition .", "On the Caltech 101 object recognition benchmark , we achieve 60.3 % mean recognition across classes using 15 training images per class , which is better than the best published performance by Zhang , et al .", "We apply these combined local distance functions to the tasks of image retrieval and classification of novel images ."]}
{"orig_sents": ["9", "8", "2", "1", "3", "4", "6", "7", "5", "0"], "shuf_sents": ["We show a few such examples .", "Therefore , the larger those pieces are , the more similar S1 is to S2 .", "Obviously , if we use small enough pieces , then any signal can be composed of any other .", "This induces a local similarity score at every point in the signal , based on the size of its supported surrounding region .", "These local scores can in turn be accumulated in a principled information-theoretic way into a global similarity score of the entire S1 to S2 .", ") , and can be applied to a wide range of signal types ( images , video , audio , biological data , etc . )", "`` Similarity by Composition '' can be applied between pairs of signals , between groups of signals , and also between different portions of the same signal .", "It can therefore be employed in a wide variety of machine learning problems ( clustering , classification , retrieval , segmentation , attention , saliency , labelling , etc .", "We say that a signal S1 is `` similar '' to a signal S2 if it is `` easy '' to compose S1 from few large contiguous chunks of S2 .", "We propose a new approach for measuring similarity between two signals , which is applicable to many machine learning tasks , and to many signal types ."]}
{"orig_sents": ["1", "2", "5", "0", "3", "4"], "shuf_sents": ["Therefore we consider using hypergraphs instead to completely represent complex relationships among the objects of our interest , and thus the problem of learning with hypergraphs arises .", "We usually endow the investigated objects with pairwise relationships , which can be illustrated as graphs .", "In many real-world problems , however , relationships among the objects of our interest are more complex than pairwise .", "Our main contribution in this paper is to generalize the powerful methodology of spectral clustering which originally operates on undirected graphs to hypergraphs , and further develop algorithms for hypergraph embedding and transductive classification on the basis of the spectral hypergraph clustering approach .", "Our experiments on a number of benchmarks showed the advantages of hypergraphs over usual graphs .", "Naively squeezing the complex relationships into pairwise ones will inevitably lead to loss of information which can be expected valuable for our learning tasks however ."]}
{"orig_sents": ["1", "0", "2", "5", "4", "3"], "shuf_sents": ["In particular , information-theoretic and psycholinguistic considerations suggest that this may include maximizing the uniformity of information density in an utterance .", "If language users are rational , they might choose to structure their utterances so as to optimize communicative properties .", "We investigate this possibility in the context of syntactic reduction , where the speaker has the option of either marking a higher-order unit ( a phrase ) with an extra word , or leaving it unmarked .", "We demonstrate that the trend toward predictability-sensitive syntactic reduction ( Jaeger , 2006 ) is robust in the face of a wide variety of control variables , and present evidence that speakers use both surface and structural cues for predictability estimation .", "In a second step , we combine a stochastic model of structured utterance production with a logistic-regression model of syntactic reduction to study which types of cues speakers employ when estimating the predictability of upcoming elements .", "We demonstrate that speakers are more likely to reduce less information-dense phrases ."]}
{"orig_sents": ["5", "6", "2", "8", "0", "1", "7", "4", "3"], "shuf_sents": ["However , discriminative methods are usually sensitive to corruption in signals due to lacking crucial properties for signal reconstruction .", "In this paper , we present a theoretical framework for signal classification with sparse representation .", "This objective function works well in applications where signals need to be reconstructed , like coding and denoising .", "The theoretical results are demonstrated with signal classification tasks , showing that the proposed approach outperforms the standard discriminative methods and the standard sparse representation in the case of corrupted signals .", "The proposed approach is therefore capable of robust classification with a sparse representation of signals .", "In this paper , application of sparse representation ( factorization ) of signals over an overcomplete basis ( dictionary ) for signal classification is discussed .", "Searching for the sparse representation of a signal over an overcomplete dictionary is achieved by optimizing an objective function that includes two terms : one that measures the signal reconstruction error and another that measures the sparsity .", "The approach combines the discrimination power of the discriminative methods with the reconstruction property and the sparsity of the sparse representation that enables one to deal with signal corruptions : noise , missing data and outliers .", "On the other hand , discriminative methods , such as linear discriminative analysis ( LDA ) , are better suited for classification tasks ."]}
{"orig_sents": ["0", "4", "6", "3", "5", "1", "2"], "shuf_sents": ["We address the problem of sub-ordinate class recognition , like the distinction between different types of motorcycles .", "We describe extensive experimental results with several subclasses .", "The proposed algorithm typically gives better results than a competing one-step algorithm , or a two stage algorithm where classification is based on a model of the sub-ordinate class .", "The model is then used to build a class-specific vector representation for images , where each entry corresponds to a model 's part .", "Our approach is motivated by observations from cognitive psychology , which identify parts as the defining component of basic level categories ( like motorcycles ) , while sub-ordinate categories are more often defined by part properties ( like 'jagged wheels ' ) .", "In the second stage we train a standard discriminative classifier to classify subclass instances ( e.g. , cross motorcycles ) based on the class-specific vector representation .", "Accordingly , we suggest a two-stage algorithm : First , a relational part based object model is learnt using unsegmented object images from the inclusive class ( e.g. , motorcycles in general ) ."]}
{"orig_sents": ["4", "5", "2", "3", "1", "0"], "shuf_sents": ["Numerical examples are given that show the improvement and efficiency of MLLE .", "MLLE is also compared with the local tangent space alignment ( LTSA ) .", "The modified locally linear embedding ( MLLE ) proposed in this paper is much stable .", "It can retrieve the ideal embedding if MLLE is applied on data points sampled from an isometric manifold .", "The locally linear embedding ( LLE ) is improved by introducing multiple linearly independent local weight vectors for each neighborhood .", "We characterize the reconstruction weights and show the existence of the linearly independent weight vectors at each neighborhood ."]}
{"orig_sents": ["4", "2", "0", "5", "1", "3", "6"], "shuf_sents": ["The CSP-algorithm however suffers from a lack of robustness , requiring training data without artifacts for good performance .", "More specifically , we design an adaptive spatial filter that maximizes the ratio of the variance of the electric field originating in a predefined region of interest ( ROI ) and the overall variance of the measured EEG .", "For BCIs employing imaginary movements of different limbs , the method of Common Spatial Patterns ( CSP ) has been shown to achieve excellent classification results .", "Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex , we design two adaptive spatial filters with the ROIs centered in the hand areas of the left and right motor cortex .", "The performance of EEG-based Brain-Computer-Interfaces ( BCIs ) critically depends on the extraction of features from the EEG carrying information relevant for the classification of different mental states .", "To overcome this lack of robustness , we propose an adaptive spatial filter that replaces the training data in the CSP approach by a-priori information .", "We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects , and show that the adaptive spatial filters outperform the CSP-algorithm , enabling classification rates of up to 94.7 % without artifact rejection ."]}
{"orig_sents": ["6", "4", "3", "0", "2", "1", "5"], "shuf_sents": ["In the first case , the problem is convex and the logistic regression is optimal under a generative model .", "The regression coefficients can also be topographically mapped onto the scalp similarly to CSP projections , which allows neuro-physiological interpretation .", "The latter case is shown to be related to the Common Spatial Pattern ( CSP ) algorithm , which is a popular technique in Brain Computer Interfacing .", "We present two variations of parameterizing the regression function : ( a ) with a full rank symmetric matrix coefficient and ( b ) as a difference of two rank=1 matrices .", "Framed in this robust statistical framework no prior feature extraction or outlier removal is required .", "Simulations on 162 BCI datasets demonstrate that classification accuracy and robustness compares favorably against conventional CSP based classifiers .", "We propose a novel framework for the classification of single trial ElectroEncephaloGraphy ( EEG ) , based on regularized logistic regression ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["The associated optimization problem is non-convex .", "Semi-supervised SVMs ( S3 VM ) attempt to learn low-density separators by maximizing the margin over labeled and unlabeled examples .", "To examine the full potential of S3 VMs modulo local minima problems in current implementations , we apply branch and bound techniques for obtaining exact , globally optimal solutions .", "While our current implementation is only applicable to small datasets , we discuss variants that can potentially lead to practically useful algorithms .", "Empirical evidence suggests that the globally optimal solution can return excellent generalization performance in situations where other implementations fail completely ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["The additive clustering model is widely used to infer the features of a set of stimuli from their similarities , on the assumption that similarity is a weighted linear function of common features .", "We use this to explore several approaches to parameter estimation , showing that the nonparametric Bayesian approach provides a straightforward way to obtain estimates of both the number of features used in producing similarity judgments and their importance .", "This paper develops a fully Bayesian formulation of the additive clustering model , using methods from nonparametric Bayesian statistics to allow the number of features to vary ."]}
{"orig_sents": ["5", "3", "4", "6", "1", "2", "0"], "shuf_sents": ["We evaluate our method across several domains , including synthetic data , sensor network data , and a statistical debugging application .", "In this paper , we consider the problem of clustering such input objects , each represented as a multivariate Gaussian .", "We formulate the problem using an information theoretic approach and draw several interesting theoretical connections to Bregman divergences and also Bregman matrix divergences .", "However , in many real-life settings , each input object is best described by multiple samples drawn from a multivariate Gaussian .", "Such data can arise , for example , in a movie review database where each movie is rated by several users , or in time-series domains such as sensor networks .", "Gaussian data is pervasive and many learning algorithms ( e.g. , k-means ) model their inputs as a single sample drawn from a multivariate Gaussian .", "Here , each input can be naturally described by both a mean vector and covariance matrix which parameterize the Gaussian distribution ."]}
{"orig_sents": ["2", "4", "0", "1", "3"], "shuf_sents": ["Our framework applies to the high-dimensional setting , in which both the number of nodes p and maximum neighborhood sizes d are allowed to grow as a function of the number of observations n. Our main result is to establish sufficient conditions on the triple ( n , p , d ) for the method to succeed in consistently estimating the neighborhood of every node in the graph simultaneously .", "Under certain mutual incoherence conditions analogous to those imposed in previous work on linear regression , we prove that consistent neighborhood selection can be obtained as long as the number of observations n grows more quickly than 6d6 log d + 2d5 log p , thereby establishing that logarithmic growth in the number of samples n relative to graph size p is sufficient to achieve neighborhood consistency .", "We focus on the problem of estimating the graph structure associated with a discrete Markov random field .", "Keywords : Graphical models ; Markov random fields ; structure learning ; 1 -regularization ; model selection ; convex risk minimization ; high-dimensional asymptotics ; concentration .", "We describe a method based on 1 regularized logistic regression , in which the neighborhood of any given node is estimated by performing logistic regression subject to an 1 -constraint ."]}
{"orig_sents": ["3", "0", "7", "2", "1", "4", "5", "6"], "shuf_sents": ["For machine learning approaches to these predictions , the diversity and high dimensionality of the structures involved mandate very large training sets .", "To our knowledge , it is the first purely discriminative learning algorithm for translation with treestructured models .", "Its accuracy was at least as good as other comparable methods on a standard parsing task .", "Parsing and translating natural languages can be viewed as problems of predicting tree structures .", "Unlike other popular methods , this method does not require a great deal of feature engineering a priori , because it performs feature selection over a compound feature space as it learns .", "Experiments demonstrate the method 's versatility , accuracy , and efficiency .", "Relevant software is freely available at http : //nlp.cs.nyu.edu/parser and http : //nlp.cs.nyu.edu/GenPar .", "This paper presents a purely discriminative learning method that scales up well to problems of this size ."]}
{"orig_sents": ["1", "5", "4", "3", "0", "6", "2"], "shuf_sents": ["It is notable that the optimal bin size diverges if only a small number of experimental trials are available from a moderately fluctuating rate process .", "The time-histogram method is a handy tool for capturing the instantaneous rate of spike occurrence .", "Given a paucity of data , our method can also suggest how many more trials are needed until the set of data can be analyzed with the required resolution .", "The resolution of the histogram increases , or the optimal bin size decreases , with the number of spike sequences sampled .", "We propose an objective method for selecting the bin size of a time-histogram from the spike data , so that the time-histogram best approximates the unknown underlying rate .", "In most of the neurophysiological literature , the bin size that critically determines the goodness of the fit of the time-histogram to the underlying rate has been selected by individual researchers in an unsystematic manner .", "In this case , any attempt to characterize the underlying spike rate will lead to spurious results ."]}
{"orig_sents": ["3", "4", "8", "6", "1", "5", "0", "7", "2"], "shuf_sents": ["Here we model this situation as a Bayesian estimation problem .", "( 2 ) They can have distinct causes , in which case information should be processed independently .", "Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed , because they need to infer the causal structure that is underlying their sensory experience .", "Many recent studies analyze how data from different modalities can be combined .", "Often this is modeled as a system that optimally combines several sources of information about the same variable .", "In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues .", "Two cues that are perceived by different modalities can have different causal relationships : ( 1 ) They can both have the same cause , in this case we should fully integrate both cues into a joint estimate .", "We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration .", "However , it has long been realized that this information combining depends on the interpretation of the data ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["A central question in game theory and artificial intelligence is how a rational agent should behave in a complex environment , given that it can not perform unbounded computations .", "Both zero-sum and potential games with strategy costs maintain a very appealing property : simple learning dynamics converge to equilibrium .", "We then show that potential games with strategy costs remain potential games .", "We study strategic aspects of this question by formulating a simple model of a game with additional costs ( computational or otherwise ) for each strategy .", "First we connect this to zero-sum games , proving a counter-intuitive generalization of the classic min-max theorem to zero-sum games with the addition of strategy costs ."]}
{"orig_sents": ["3", "2", "0", "1", "4", "5"], "shuf_sents": ["We show that this problem is equivalent to a convex optimization problem and develop an iterative algorithm for solving it .", "The algorithm has a simple interpretation : it alternately performs a supervised and an unsupervised step , where in the latter step we learn commonacross-tasks representations and in the former step we learn task-specific functions using these representations .", "The method builds upon the wellknown 1-norm regularization problem using a new regularizer which controls the number of learned features common for all the tasks .", "We present a method for learning a low-dimensional representation which is shared across a set of multiple related tasks .", "We report experiments on a simulated and a real data set which demonstrate that the proposed method dramatically improves the performance relative to learning each task independently .", "Our algorithm can also be used , as a special case , to simply select - not learn - a few common features across the tasks ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["In each trial the current instance is projected onto a probabilistically chosen low dimensional subspace .", "The total expected quadratic approximation error equals the total quadratic approximation error of the best subspace chosen in hindsight plus some additional term that grows linearly in dimension of the subspace but logarithmically in the dimension of the instances .", "We design an on-line algorithm for Principal Component Analysis ."]}
{"orig_sents": ["1", "2", "3", "0", "5", "4"], "shuf_sents": ["A method for implementing this non-parametric anomaly detector is proposed that approximates this minimum entropy set by the influence region of a K-point entropic graph built on the training data .", "We introduce a novel adaptive non-parametric anomaly detection approach , called GEM , that is based on the minimal covering properties of K-point entropic graphs when constructed on N training samples from a nominal probability distribution .", "Such graphs have the property that as N their span recovers the entropy minimizing set that supports at least = K/N ( 100 ) % of the mass of the Lebesgue part of the distribution .", "When a test sample falls outside of the entropy minimizing set an anomaly can be declared at a statistical level of significance = 1 - .", "We illustrate GEM for several simulated and real data sets in high dimensional feature spaces .", "By implementing an incremental leave-one-out k-nearest neighbor graph on resampled subsets of the training data GEM can efficiently detect outliers at a given level of significance and compute their empirical p-values ."]}
{"orig_sents": ["4", "0", "3", "2", "1", "5"], "shuf_sents": ["We present a probabilistic approach that matches shapes using independent part transformations , where the parts themselves are learnt during matching .", "Thus , unlike many shape matching techniques , our approach can be applied to shapes extracted from real images .", "Shapes are represented by unlabeled point sets of arbitrary size and a background component is used to handle occlusion , local dissimilarity and clutter .", "Ideas from semi-supervised learning are used to bias the algorithm towards finding `perceptually valid ' part structures .", "Correspondence algorithms typically struggle with shapes that display part-based variation .", "Model parameters are estimated using an EM algorithm that alternates between finding a soft correspondence and computing the optimal part transformations using Procrustes analysis ."]}
{"orig_sents": ["0", "3", "2", "4", "5", "1"], "shuf_sents": ["Many unsupervised learning problems can be expressed as a form of matrix factorization , reconstructing an observed data matrix as the product of two matrices of latent variables .", "We illustrate this approach with two matrix factorization models and show favorable performance relative to Gibbs sampling .", "Nonparametric Bayesian matrix factorization is one way of dealing with this challenge , yielding a posterior distribution over possible factorizations of unbounded dimensionality .", "A standard challenge in solving these problems is determining the dimensionality of the latent matrices .", "A drawback to this approach is that posterior estimation is typically done using Gibbs sampling , which can be slow for large problems and when conjugate priors can not be used .", "As an alternative , we present a particle filter for posterior estimation in nonparametric Bayesian matrix factorization models ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We use this analysis to obtain a better understanding of the role of normalization of the graph Laplacian matrix as well as the effect of dimension reduction .", "We consider a general form of transductive learning on graphs with Laplacian regularization , and derive margin-based generalization bounds using appropriate geometric properties of the graph .", "We propose a remedy from our analysis and demonstrate empirically that the remedy leads to improved classification performance .", "The results suggest a limitation of the standard degree-based normalization ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["The main reason is the presence of the partition function which is intractable to evaluate , let alone integrate over .", "We propose to approximate the marginal likelihood by employing two levels of approximation : we assume normality of the posterior ( the Laplace approximation ) and approximate all remaining intractable quantities using belief propagation and the linear response approximation .", "Scoring structures of undirected graphical models by means of evaluating the marginal likelihood is very hard .", "This results in a fast procedure for model scoring .", "Empirically , we find that our procedure has about two orders of magnitude better accuracy than standard BIC methods for small datasets , but deteriorates when the size of the dataset grows ."]}
{"orig_sents": ["3", "6", "5", "2", "4", "1", "0"], "shuf_sents": ["Our experimental results show basically linear speedup with an increasing number of processors .", "We adapt Google 's map-reduce paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression ( LWLR ) , k-means , logistic regression ( LR ) , naive Bayes ( NB ) , SVM , ICA , PCA , gaussian discriminant analysis ( GDA ) , EM , and backpropagation ( NN ) .", "Our work is in distinct contrast to the tradition in machine learning of designing ( often ingenious ) ways to speed up a single algorithm at a time .", "We are at the beginning of the multicore era .", "Specifically , we show that algorithms that fit the Statistical Query model can be written in a certain `` summation form , '' which allows them to be easily parallelized on multicore computers .", "In this paper , we develop a broadly applicable parallel programming method , one that is easily applied to many different learning algorithms .", "Computers will have increasingly many cores ( processors ) , but there is still no good programming framework for these architectures , and thus no simple and unified way for machine learning to take advantage of the potential speed up ."]}
{"orig_sents": ["0", "3", "5", "4", "1", "2"], "shuf_sents": ["Autonomous helicopter flight is widely regarded to be a highly challenging control problem .", "Then we used a reinforcement learning ( optimal control ) algorithm to find a controller that is optimized for the resulting model and reward function .", "More specifically , we used differential dynamic programming ( DDP ) , an extension of the linear quadratic regulator ( LQR ) .", "This paper presents the first successful autonomous completion on a real RC helicopter of the following four aerobatic maneuvers : forward flip and sideways roll at low speed , tail-in funnel , and nose-in funnel .", "We used the following approach : First we had a pilot fly the helicopter to help us find a helicopter dynamics model and a reward ( cost ) function .", "Our experimental results significantly extend the state of the art in autonomous helicopter flight ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["We examine the problem of predicting local sentiment flow in documents , and its application to several areas of text analysis .", "Using the Mobius transform , we express the model as a simple convex optimization problem .", "Formally , the problem is stated as predicting an ordinal sequence based on a sequence of word sets .", "Experiments demonstrate the model and its applications to sentiment prediction , style analysis , and text summarization .", "In the spirit of isotonic regression , we develop a variant of conditional random fields that is wellsuited to handle this problem ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We rigorously establish a close relationship between message passing algorithms and models of neurodynamics by showing that the equations of a continuous Hopfield network can be derived from the equations of belief propagation on a binary Markov random field .", "Our results lead to a better understanding of the role of message passing algorithms in real biological neural networks .", "As Hopfield networks are equipped with a Lyapunov function , convergence is guaranteed .", "As a consequence , in the limit of many weak connections per neuron , Hopfield networks exactly implement a continuous-time variant of belief propagation starting from message initialisations that prevent from running into convergence problems ."]}
{"orig_sents": ["5", "4", "2", "3", "1", "0"], "shuf_sents": ["( Taskar et al. , 2005 ) Our technique is applied to navigation and planning problems for outdoor mobile robots and robotic legged locomotion .", "This approach uses simple binary classification or regression to improve performance of MMP imitation learning , and naturally extends to the class of structured maximum margin prediction problems .", "These mappings are chosen so that example policies ( or trajectories ) given by a teacher appear to be lower cost ( with a lossscaled margin ) than any other policy for a given planning domain .", "We provide a novel approach , M MP B OOST , based on the functional gradient descent view of boosting ( Mason et al. , 1999 ; Friedman , 1999a ) that extends MMP by `` boosting '' in new features .", "The learned policy is the result of minimum-cost planning using these cost functions .", "The Maximum Margin Planning ( MMP ) ( Ratliff et al. , 2006 ) algorithm solves imitation learning problems by learning linear mappings from features to cost functions in a planning domain ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["In this paper , we propose a sparse multinomial logistic regression method , in which the sparsity arises from the use of a Laplace prior , but where the usual regularisation parameter is integrated out analytically .", "Multinomial logistic regression provides the standard penalised maximumlikelihood solution to multi-class pattern recognition problems .", "Evaluation over a range of benchmark datasets reveals this approach results in similar generalisation performance to that obtained using cross-validation , but at greatly reduced computational expense .", "More recently , the development of sparse multinomial logistic regression models has found application in text processing and microarray classification , where explicit identification of the most informative features is of value ."]}
{"orig_sents": ["2", "5", "0", "4", "3", "1"], "shuf_sents": ["This method was shown to work well empirically in highly aggregated networks , that is , those with a limited number of large nodes and at coarse time scales .", "Our method is based on a stochastic matrix perturbation analysis that characterizes the tradeoff between the accuracy of anomaly detection and the amount of data communicated over the network .", "We consider the problem of network anomaly detection in large distributed systems .", "To overcome these limitations , we develop a PCA-based anomaly detector in which adaptive local data filters send to a coordinator just enough data to enable accurate global detection .", "This approach , however , has scalability limitations .", "In this setting , Principal Component Analysis ( PCA ) has been proposed as a method for discovering anomalies by continuously tracking the projection of the data onto a residual subspace ."]}
{"orig_sents": ["2", "3", "4", "1", "0", "5"], "shuf_sents": ["The effectiveness of this procedure is verified by its successful application in the 3rd BCI competition .", "In order to incorporate decisions from prior time-points we suggest an appropriate weighting scheme , that emphasizes time instances , providing a higher discriminatory power between the instantaneous class distributions of each feature , where the discriminatory power is quantified in terms of the Bayes error of misclassification .", "We present a method for binary on-line classification of triggered but temporally blurred events that are embedded in noisy time series in the context of on-line discrimination between left and right imaginary hand-movement .", "In particular the goal of the binary classification problem is to obtain the decision , as fast and as reliably as possible from the recorded EEG single trials .", "To provide a probabilistic decision at every time-point t the presented method gathers information from two distinct sequences of features across time .", "Disclosure of the data after the competition revealed this approach to be superior with single trial error rates as low as 10.7 , 11.5 and 16.7 % for the three different subjects under study ."]}
{"orig_sents": ["6", "3", "5", "1", "4", "0", "2"], "shuf_sents": ["A nonparametric hierarchical Bayesian model furthermore generalizes across users by learning a common prior which is imposed on new email accounts .", "Labeled messages from publicly available sources can be utilized , but they are governed by a distinct distribution , not adequately representing most inboxes .", "Empirically , we observe that bias-corrected learning outperforms naive reliance on the assumption of independent and identically distributed data ; Dirichlet-enhanced generalization across users outperforms a single ( `` one size fits all '' ) filter as well as independent filters for all users .", "Each user receives messages according to an individual , unknown distribution , reflected only in the unlabeled inbox .", "We devise a method that minimizes a loss function with respect to a user 's personal distribution based on the available biased sample .", "The spam filter for a user is required to perform well with respect to this distribution .", "We study a setting that is motivated by the problem of filtering spam messages for many users ."]}
{"orig_sents": ["2", "4", "3", "1", "0"], "shuf_sents": ["Our method outperforms the others in anechoic conditions and performs as well as the better of the two in the presence of reverberation .", "We evaluate this method against two comparable algorithms on simulations of simultaneous speech from two or three sources .", "We present a method for localizing and separating sound sources in stereo recordings that is robust to reverberation and does not make any assumptions about the source statistics .", "These parameters include distributions over delays and assignments of time-frequency regions to sources .", "The method consists of a probabilistic model of binaural multisource recordings and an expectation maximization algorithm for finding the maximum likelihood parameters of that model ."]}
{"orig_sents": ["2", "8", "0", "4", "3", "5", "7", "1", "6"], "shuf_sents": ["Specifically , when experimental subjects are shown an exemplar of some target category , the category prototype appears to be pulled toward the exemplar , and the prototypes of all nontarget categories appear to be pushed away .", "We find that the distributed maximum-likelihood model can explain the key experimental phenomena .", "Categorization is a central activity of human cognition .", "We propose and evaluate four principled probabilistic ( Bayesian ) accounts of context effects in categorization .", "These push and pull effects diminish with experience , and likely reflect long-term learning of category boundaries .", "In all four accounts , the probability of an exemplar given a category is encoded as a Gaussian density in feature space , and categorization involves computing category posteriors given an exemplar .", "Further , the model predicts other phenomena that were confirmed via reanalysis of the experimental data .", "The models differ in how the uncertainty distribution of category prototypes is represented ( localist or distributed ) , and how it is updated following each experience ( using a maximum likelihood gradient ascent , or a Kalman filter update ) .", "When an individual is asked to categorize a sequence of items , context effects arise : categorization of one item influences category decisions for subsequent items ."]}
{"orig_sents": ["2", "0", "1", "4", "3"], "shuf_sents": ["The network of integrate-and-fire neurons is connected by bistable synapses that can change their weight using a local spike-based plasticity mechanism .", "Learning is supervised by a teacher which provides an extra input to the output neurons during training .", "We propose a compact , low power VLSI network of spiking neurons which can learn to classify complex patterns of mean firing rates on-line and in real-time .", "We present experimental results that demonstrate how this VLSI network is able to robustly classify uncorrelated linearly separable spatial patterns of mean firing rates .", "The synaptic weights are updated only if the current generated by the plastic synapses does not match the output desired by the teacher ( as in the perceptron learning rule ) ."]}
{"orig_sents": ["3", "4", "2", "6", "5", "7", "1", "0"], "shuf_sents": ["We argue that without understanding combinations of inference and learning , such as these , that are appropriately compatible , learning performance under approximate inference can not be guaranteed .", "In contrast , we give two positive results in the form of learning bounds for the use of LP-relaxed inference in structured perceptron and empirical risk minimization settings .", "We show in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees .", "In many structured prediction problems , the highest-scoring labeling is hard to compute exactly , leading to the use of approximate inference methods .", "However , when inference is used in a learning algorithm , a good approximation of the score may not be sufficient .", "First , approximate methods can effectively reduce the expressivity of an underlying model by making it impossible to choose parameters that reliably give good predictions .", "There are two reasons for this .", "Second , approximations can respond to parameter changes in such a way that standard learning algorithms are misled ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We show that , for competitive POSGs , the complexity of determining whether one team has a positive-expected-reward strategy is complete for NEXPNP .", "It is known that determinining whether a DEC-POMDP , namely , a cooperative partially observable stochastic game ( POSG ) , has a cooperative strategy with positive expected reward is complete for NEXP .", "It was not known until now how cooperation affected that complexity ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["For a constant treewidth , our algorithm has polynomial time and sample complexity .", "One of our key new theoretical insights is a method for bounding the conditional mutual information of arbitrarily large sets of variables with only polynomially many mutual information computations on fixed-size subsets of variables , if the underlying distribution can be approximated by a bounded-treewidth junction tree .", "We also present a lazy extension of our approach that leads to very significant speed ups in practice , and demonstrate the viability of our method empirically , on several real world datasets .", "We present the first truly polynomial algorithm for PAC-learning the structure of bounded-treewidth junction trees - an attractive subclass of probabilistic graphical models that permits both the compact representation of probability distributions and efficient exact inference .", "If a junction tree with sufficiently strong intraclique dependencies exists , we provide strong theoretical guarantees in terms of KL divergence of the result from the true distribution ."]}
{"orig_sents": ["1", "2", "0", "5", "3", "4"], "shuf_sents": ["Another way is to use the social context of an utterance to infer the intended referent of a word .", "For infants , early word learning is a chicken-and-egg problem .", "One way to learn a word is to observe that it co-occurs with a particular referent across different situations .", "We test our model on a small corpus of mother-infant interaction and find it performs better than competing models .", "Finally , we show that our model accounts for experimental phenomena including mutual exclusivity , fast-mapping , and generalization from social cues .", "Here we present a Bayesian model of cross-situational word learning , and an extension of this model that also learns which social cues are relevant to determining reference ."]}
{"orig_sents": ["5", "0", "6", "4", "2", "1", "3"], "shuf_sents": ["Kernel estimators and other methods are burdened by these expensive computations .", "This method differs from many previous scalability techniques ( such as standard multi-tree methods ) in that its error is stochastic , but we derive conditions for error control and demonstrate that they work .", "The essential idea is fast approximation by sampling in trees .", "Further , we give a theoretical sample complexity for the method that is independent of dataset size , and show that this appears to hold in experiments , where speedups reach as high as 1014 , many orders of magnitude beyond the previous state of the art .", "We present a multi-stage stratified Monte Carlo method for approximating such summations with probabilistic relative error control .", "Machine learning contains many computational bottlenecks in the form of nested summations over datasets .", "Exact evaluation is typically O ( n2 ) or higher , which severely limits application to large datasets ."]}
{"orig_sents": ["6", "5", "1", "2", "3", "4", "0"], "shuf_sents": ["We discuss relevant issues and relate our regularizer to previous work .", "To our knowledge , however , none of them takes local smoothness constraints among data into account during ensemble learning .", "In this paper , we introduce a local smoothness regularizer to semi-supervised boosting algorithms based on the universal optimization framework of margin cost functionals .", "Our regularizer is applicable to existing semi-supervised boosting algorithms to improve their generalization and speed up their training .", "Comparative results on synthetic , benchmark and real world tasks demonstrate the effectiveness of our local smoothness regularizer .", "Several boosting algorithms have been extended to semi-supervised learning with various strategies .", "Semi-supervised inductive learning concerns how to learn a decision rule from a data set containing both labeled and unlabeled data ."]}
{"orig_sents": ["5", "4", "0", "3", "2", "6", "1"], "shuf_sents": ["Furthermore , the transparency of this new learning rule makes a theoretical analysis of its convergence properties feasible .", "In a biological interpretation , this target signal YT ( also called relevance variable ) could represent proprioceptive feedback , input from other sensory modalities , or top-down signals .", "By applying this rule to an ensemble of neurons , different principal components of the input can be extracted .", "A variation of this learning rule ( with sign changes ) provides a theoretically founded method for performing Principal Component Analysis ( PCA ) with spiking neurons .", "This rule performs on common benchmark tasks as well as a rather complex rule that has previously been proposed .", "We show that under suitable assumptions ( primarily linearization ) a simple and perspicuous online learning rule for Information Bottleneck optimization with spiking neurons can be derived .", "In addition , it is possible to preferentially extract those principal components from incoming signals X that are related or are not related to some additional target signal YT ."]}
{"orig_sents": ["5", "1", "0", "4", "3", "2"], "shuf_sents": ["Although the important role of high level stimulus properties ( e.g. , semantic information ) in search stands undisputed , most models are based on low-level image properties .", "Many computational models try to predict such voluntary eye and attentional shifts .", "Remarkably , our model 's predictive performance in images that do not contain faces is not impaired , and is even improved in some cases by spurious face detector responses .", "Observers , even when not instructed to look for anything particular , fixate on a face with a probability of over 80 % within their first two fixations ; furthermore , they exhibit more similar scanpaths when faces are present .", "We here demonstrate that a combined model of face detection and low-level saliency significantly outperforms a low-level model in predicting locations humans fixate on , based on eye-movement recordings of humans observing photographs of natural scenes , most of which contained at least one person .", "Under natural viewing conditions , human observers shift their gaze to allocate processing resources to subsets of the visual input ."]}
{"orig_sents": ["3", "1", "5", "4", "0", "2"], "shuf_sents": ["Our method can be used to learn tractable graphical models that satisfy additional , otherwise intractable constraints .", "Very often , however , our aim is primarily to find a model that assigns values to the latent variables that have intended meaning for our data and maximizing expected likelihood only sometimes accomplishes this .", "Focusing on clustering and the alignment problem for statistical machine translation , we show that simple , intuitive posterior constraints can greatly improve the performance over standard baselines and be competitive with more complex , intractable models .", "The expectation maximization ( EM ) algorithm is a widely used maximum likelihood estimation procedure for statistical models when the values of some of the variables in the model are not observed .", "In this paper , we present an efficient , principled way to inject rich constraints on the posteriors of latent variables into the EM algorithm .", "Unfortunately , it is typically difficult to add even simple a-priori information about latent variables in graphical models without making the models overly complex or intractable ."]}
{"orig_sents": ["7", "2", "1", "5", "0", "6", "4", "3", "8"], "shuf_sents": ["Simple statistical analyses of the data first reveal robust power-law behavior for package , SLOC , and lexical containment distributions .", "Sourcerer allows us to gather Internet-scale source code .", "Here we first develop Sourcerer , an infrastructure for the automated crawling , parsing , and database storage of open source software .", "Finally , by combining software textual content with structural information captured by our CodeRank approach , we are able to significantly improve software retrieval performance , increasing the AUC metric to 0.84- roughly 10-30 % better than previous approaches based on text alone .", "In addition to serving as a convenient summary for program function and developer activities , these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing developer similarity and competence , topic scattering , and document tangling , with direct applications to software engineering .", "For instance , in one experiment , we gather 4,632 java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers .", "We then develop and apply unsupervised author-topic , probabilistic models to automatically discover the topics embedded in the code and extract topic-word and author-topic distributions .", "Large repositories of source code create new challenges and opportunities for statistical machine learning .", "Supplementary material may be found at : http : //sourcerer.ics.uci.edu/nips2007/nips07.html ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["We adapt a particle filter and smoother to the task , and discuss some of the practical approaches used to tackle the difficulties , including use of sparse matrices and parallelisation .", "The model poses a difficult parameter estimation problem , both theoretically due to the nonlinearity and divergence of the differential system , and computationally due to its time and space complexity .", "Results demonstrate the tractability of the approach in its application to an effective connectivity study .", "We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent ( BOLD ) signal in Functional Magnetic Resonance Imaging ( fMRI ) ."]}
{"orig_sents": ["4", "1", "2", "0", "6", "3", "5"], "shuf_sents": ["From an initial round of Rosetta sampling , we learn properties of the energy landscape that guide a subsequent round of sampling toward lower-energy structures .", "It is a Monte Carlo energy minimization method requiring many random restarts to find structures with low energy .", "In this paper we present a resampling technique for structure prediction of small alpha/beta proteins using Rosetta .", "We then enrich these structural features in the second sampling round .", "Rosetta is one of the leading algorithms for protein structure prediction today .", "Results are presented across a benchmark set of nine small alpha/beta proteins demonstrating that our methods seldom impair , and frequently improve , Rosetta 's performance .", "Rather than attempt to fit the full energy landscape , we use feature selection methods -- both L1-regularized linear regression and decision trees -- to identify structural features that give rise to low energy ."]}
{"orig_sents": ["1", "5", "4", "3", "0", "2"], "shuf_sents": ["We present an online learning rule that exploits delayed correlations in the input .", "Independent component analysis ( ICA ) is a powerful method to decouple signals .", "This rule performs ICA by detecting joint variations in the firing rates of pre- and postsynaptic neurons , similar to a local rate-based Hebbian learning rule .", "In this paper , we are interested in understanding the neural mechanism responsible for solving ICA .", "Moreover , they require some preprocessing of the data ( whitening ) so as to remove second order correlations .", "Most of the algorithms performing ICA do not consider the temporal correlations of the signal , but only higher moments of its amplitude distribution ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We explore the use of non-parametric models for partially ranked data and derive efficient procedures for their use for large n. The derivations are largely possible through combinatorial and algebraic manipulations based on the lattice of partial rankings .", "Statistical models on full and partial rankings of n items are often of limited practical use for large n due to computational consideration .", "In particular , we demonstrate for the first time a non-parametric coherent and consistent model capable of efficiently aggregating partially ranked data of different types ."]}
{"orig_sents": ["2", "0", "1", "5", "4", "9", "8", "7", "6", "3"], "shuf_sents": ["Empirical results have shown its favorable performance in comparison with several other popular clustering algorithms .", "However , the inherent relationship between subspace selection and clustering in this framework is not well understood , due to the iterative nature of the algorithm .", "We present a theoretical study on the discriminative clustering framework , recently proposed for simultaneous subspace selection via linear discriminant analysis ( LDA ) and clustering .", "The presented theories and algorithms are evaluated through experiments on a collection of benchmark data sets .", "This provides significant and new insights into the nature of this subspace selection procedure .", "We show in this paper that this iterative subspace selection and clustering is equivalent to kernel K-means with a specific kernel Gram matrix .", "The connection between DisKmeans and several other clustering algorithms is also analyzed .", "We show that the learning of the kernel matrix over a convex set of pre-specified kernel matrices can be incorporated into the clustering formulation .", "We also present the nonlinear extension of DisKmeans using kernels .", "Based on this equivalence relationship , we propose the Discriminative K-means ( DisKmeans ) algorithm for simultaneous LDA subspace selection and clustering , as well as an automatic parameter estimation procedure ."]}
{"orig_sents": ["0", "5", "4", "2", "3", "1"], "shuf_sents": ["In order to represent state in controlled , partially observable , stochastic dynamical systems , some sort of sufficient statistic for history is necessary .", "We evaluate the quality of our model with reinforcement learning by directly evaluating the control performance of the model .", "This choice of state representation explicitly connects PSRs to state-of-the-art probabilistic modeling , which allows us to take advantage of current efforts in high-dimensional density estimation , and in particular , graphical models and maximum entropy models .", "We present a parameter learning algorithm based on maximum likelihood , and we show how a variety of current approximate inference methods apply .", "We introduce a new model of such systems called the `` Exponential family PSR , '' which defines as state the time-varying parameters of an exponential family distribution which models n sequential observations in the future .", "Predictive representations of state ( PSRs ) capture state as statistics of the future ."]}
{"orig_sents": ["1", "4", "6", "3", "0", "7", "5", "2"], "shuf_sents": ["The regret incurred by Epoch-Greedy is controlled by a sample complexity bound for a hypothesis class .", "We present Epoch-Greedy , an algorithm for contextual multi-armed bandits ( also known as bandits with side information ) .", "Here S is the complexity term in a sample complexity bound for standard supervised learning .", "2 .", "Epoch-Greedy has the following properties : 1 .", "The regret scales as O ( T 2/3 S 1/3 ) or better ( sometimes , much better ) .", "No knowledge of a time horizon T is necessary .", "3 ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["Recently , we have introduced a novel approach to dynamic programming and reinforcement learning that is based on maintaining explicit representations of stationary distributions instead of value functions .", "In this paper , we investigate the convergence properties of these dual algorithms both theoretically and empirically , and show how they can be scaled up by incorporating function approximation ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["This result is then used to derive an oracle inequality for an SVM based on the pinball loss .", "For the pinball loss a condition on the data-generating distribution P is given that ensures that the conditional quantiles are approximated with respect to * 1 .", "Moreover , we show that SVMs based on the -insensitive loss estimate the conditional median only under certain conditions on P .", "We investigate quantile regression based on the pinball loss and the -insensitive loss ."]}
{"orig_sents": ["7", "0", "6", "2", "4", "1", "3", "8", "5"], "shuf_sents": ["The EM algorithm widely used to solve the resulting optimization problem is inherently a gradient-descent method and is sensitive to initialization .", "We introduce an exemplar-based likelihood function that approximates the exact likelihood .", "This sensitivity to initialization presents a significant challenge in clustering large data sets into many clusters .", "This formulation leads to a convex minimization problem and an efficient algorithm with guaranteed convergence to the globally optimal solution .", "In this paper , we present a different approach to approximate mixture fitting for clustering .", "We present experimental results illustrating the performance of our algorithm and its comparison with the conventional approach to mixture model clustering .", "The resulting solution is a local optimum in the neighborhood of the initial guess .", "Clustering is often formulated as the maximum likelihood estimation of a mixture model that explains the data .", "The resulting clustering can be thought of as a probabilistic mapping of the data points to the set of exemplars that minimizes the average distance and the information-theoretic cost of mapping ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We explore two sets of random features , provide convergence bounds on their ability to approximate various radial basis kernels , and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines .", "To accelerate the training of kernel machines , we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods .", "The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shiftinvariant kernel ."]}
{"orig_sents": ["5", "0", "6", "1", "4", "3", "2", "7"], "shuf_sents": ["Representing uncertainty over permutations is challenging , since there are n !", "In this paper , we use the `` low-frequency '' terms of a Fourier decomposition to represent such distributions compactly .", "To address this problem , we present an efficient quadratic program defined directly in the Fourier domain to project the approximation onto a relaxed form of the marginal polytope .", "Low order Fourier-based approximations can lead to functions that do not correspond to valid distributions .", "We present Kronecker conditioning , a general and efficient approach for maintaining these distributions directly in the Fourier domain .", "Permutations are ubiquitous in many real world problems , such as voting , rankings and data association .", "possibilities , and typical compact representations such as graphical models can not efficiently capture the mutual exclusivity constraints associated with permutations .", "We demonstrate the effectiveness of our approach on a real camera-based multi-people tracking setting ."]}
{"orig_sents": ["4", "0", "3", "1", "5", "6", "2", "7"], "shuf_sents": ["For example vigilance fluctuations in the individual , variable task involvement , workload etc .", "In the present work we aim to define features based on a variant of the common spatial patterns ( CSP ) algorithm that are constructed invariant with respect to such nonstationarities .", "As a proof of concept we present a BCI classifier that is robust to changes in the level of parietal -activity .", "alter the characteristics of EEG signals and thus challenge a stable BCI operation .", "Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions .", "We enforce invariance properties by adding terms to the denominator of a Rayleigh coefficient representation of CSP such as disturbance covariance matrices from fluctuations in visual processing .", "In this manner physiological prior knowledge can be used to shape the classification engine for BCI .", "In other words , the EEG decoding still works when there are lapses in vigilance ."]}
{"orig_sents": ["3", "0", "4", "1", "2"], "shuf_sents": ["The model is based on a construction of treestructured copulas - multivariate distributions with uniform on marginals .", "We propose an EM algorithm to estimate the parameters for these tree-averaged models for both the real-valued and the categorical case .", "Based on the tree-averaged framework , we propose a new model for joint precipitation amounts data on networks of rain stations .", "We utilize the ensemble of trees framework , a tractable mixture over superexponential number of tree-structured distributions , to develop a new model for multivariate density estimation .", "By averaging over all possible tree structures , the new model can approximate distributions with complex variable dependencies ."]}
{"orig_sents": ["1", "3", "0", "2", "4"], "shuf_sents": ["The running time of the algorithm is ( n ) ( n is the number of nodes in G ) , with constant dependent on accuracy , degree of graph and size of the graph that is excluded as a minor ( constant for Planar graphs ) .", "We present a new local approximation algorithm for computing MAP and logpartition function for arbitrary exponential family distribution represented by a finite-valued pair-wise Markov random field ( MRF ) , say G. Our algorithm is based on decomposing G into appropriately chosen small components ; computing estimates locally in each of these components and then producing a good global solution .", "Our algorithm for minor-excluded graphs uses the decomposition scheme of Klein , Plotkin and Rao ( 1993 ) .", "We prove that the algorithm can provide approximate solution within arbitrary accuracy when G excludes some finite sized graph as its minor and G has bounded degree : all Planar graphs with bounded degree are examples of such graphs .", "In general , our algorithm works with any decomposition scheme and provides quantifiable approximation guarantee that depends on the decomposition scheme ."]}
{"orig_sents": ["4", "0", "6", "3", "1", "5", "2"], "shuf_sents": ["Knowledge of this structure may lead to better generalization performance on the tasks and may also facilitate learning new tasks .", "In addition , we provide a necessary and sufficient condition for convexity of the regularizer .", "Experiments on two real data sets indicate that the algorithm scales well with the number of tasks and improves on state of the art statistical performance .", "This class of regularization problems exhibits appealing computational properties and can be optimized efficiently by an alternating minimization algorithm .", "Learning the common structure shared by a set of supervised tasks is an important practical and theoretical problem .", "We analyze concrete examples of the framework , which are equivalent to regularization with Lp matrix norms .", "We propose a framework for solving this problem , which is based on regularization with spectral functions of matrices ."]}
{"orig_sents": ["4", "1", "2", "3", "0"], "shuf_sents": ["Then , we explain how to implement this method in practice by combining the LAR algorithm and a reduced version of the dynamic programming algorithm and we apply it to synthetic and real data .", "Our approach consists in reframing this task in a variable selection context .", "We use a penalized least-squares criterion with a 1 -type penalty for this purpose .", "We prove some theoretical results on the estimated change-points and on the underlying piecewise constant estimated function .", "We propose a new approach for dealing with the estimation of the location of change-points in one-dimensional piecewise constant signals observed in white noise ."]}
{"orig_sents": ["2", "1", "3", "0", "4", "5"], "shuf_sents": ["We show that under the assumption of noise-free observations and a block design , predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs .", "We propose a model that learns a shared covariance function on input-dependent features and a `` free-form '' covariance matrix over tasks .", "In this paper we investigate multi-task learning in the context of Gaussian Processes ( GP ) .", "This allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training .", "We evaluate the benefits of our model on two practical applications : a compiler performance prediction problem and an exam score prediction task .", "Additionally , we make use of GP approximations and properties of our model in order to provide scalability to large data sets ."]}
{"orig_sents": ["3", "0", "4", "1", "7", "6", "5", "2"], "shuf_sents": ["This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not .", "These predictions can be used to evaluate the performance of a search engine , using our novel formalization of the confidence of the standard evaluation metric discounted cumulative gain ( DCG ) , so comparisons can be made across time and datasets .", "Furthermore , we give an algorithm to guide the selection of additional documents to judge to improve confidence .", "We propose a model that leverages the millions of clicks received by web search engines to predict document relevance .", "After an initial training phase using a set of relevance judgments paired with click data , we show that our model can predict the relevance score of documents that have not been judged .", "While our experiments are on sponsored search results , which is the financial backbone of web search , our method is general enough to be applicable to algorithmic web search results as well .", "When no relevance judgments are available , we can identify the better of two ranked lists up to 82 % of the time , and with only two relevance judgments for each query , we can identify the better ranking up to 94 % of the time .", "This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query ."]}
{"orig_sents": ["0", "3", "1", "2", "5", "4"], "shuf_sents": ["We propose a novel method for linear dimensionality reduction of manifold modeled data .", "Second , we rigorously prove that using only this set of random projections , we can estimate the structure of the underlying manifold .", "In both cases , the number of random projections required is linear in K and logarithmic in N , meaning that K < M N .", "First , we show that with a small number M of random projections of sample points in RN belonging to an unknown K-dimensional Euclidean manifold , the intrinsic dimension ( ID ) of the sample set can be estimated to high accuracy .", "Our method is particularly relevant in distributed sensing systems and leads to significant potential savings in data acquisition , storage and transmission costs .", "To handle practical situations , we develop a greedy algorithm to estimate the smallest size of the projection space required to perform manifold learning ."]}
{"orig_sents": ["7", "3", "9", "6", "5", "4", "1", "8", "0", "2"], "shuf_sents": ["The results show that for most domains ACT produces trees of significantly lower costs .", "Due to its stochastic nature ACT is expected to be able to escape local minima , into which greedy methods may be trapped .", "ACT is also shown to exhibit good anytime behavior with diminishing returns .", "As the complexity of these applications grows , the management of resources during the learning and classification processes becomes a challenging task .", "Using sampling techniques ACT approximates for each candidate split the cost of the subtree under it and favors the one with a minimal cost .", "It builds a tree top-down and exploits additional time resources to obtain better estimations for the utility of the different candidate splits .", "ACT is an anytime algorithm that allows trading computation time for lower classification costs .", "Machine learning techniques are increasingly being used to produce a wide-range of classifiers for complex real-world applications that involve nonuniform testing costs and misclassification costs .", "Experiments with a variety of datasets were conducted to compare the performance of ACT to that of the state of the art cost-sensitive tree learners .", "In this work we introduce ACT ( Anytime Cost-sensitive Trees ) , a novel framework for operating in such environments ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We develop and analyze an algorithm for nonparametric estimation of divergence functionals and the density ratio of two probability distributions .", "Our simulation results demonstrate the convergence behavior of the method , which compares favorably with existing methods in the literature .", "Our method is based on a variational characterization of f -divergences , which turns the estimation into a penalized convex risk minimization problem .", "We present a derivation of our kernel-based estimation algorithm and an analysis of convergence rates for the estimator ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["A statistical analysis of the properties of SpAM is given together with empirical results on synthetic and real data , showing that SpAM can be effective in fitting sparse nonparametric models in high dimensional data .", "We derive a method for fitting the models that is effective even when the number of covariates is larger than the sample size .", "We present a new class of models for high-dimensional nonparametric regression and classification called sparse additive models ( SpAM ) .", "Our methods combine ideas from sparse linear modeling and additive nonparametric regression ."]}
{"orig_sents": ["0"], "shuf_sents": ["We present a simple variant of the k-d tree which automatically adapts to intrinsic low dimensional structure in data ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["We use this framework to explore the consequences of two different schemes for defining probabilistic models of phonological change , evaluating these schemes by reconstructing ancient word forms of Romance languages .", "We present a probabilistic approach to language change in which word forms are represented by phoneme sequences that undergo stochastic edits along the branches of a phylogenetic tree .", "The result is an efficient inference procedure for automatically inferring ancient word forms from modern languages , which can be generalized to support inferences about linguistic phylogenies .", "This framework combines the advantages of the classical comparative method with the robustness of corpus-based probabilistic models ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["This result builds on Kearns and Singh 's work that provides a provably efficient algorithm for finite state MDPs .", "Specifically , we take a model-based approach and show that a special type of online linear regression allows us to learn MDPs with ( possibly kernalized ) linearly parameterized dynamics .", "Our approach is not restricted to the linear setting , and is applicable to other classes of continuous MDPs .", "We provide a provably efficient algorithm for learning Markov Decision Processes ( MDPs ) with continuous state and action spaces in the online setting ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["A semi-supervised multitask learning ( MTL ) framework is presented , in which M parameterized semi-supervised classifiers , each associated with one of M partially labeled data manifolds , are learned jointly under the constraint of a softsharing prior imposed over the parameters of the classifiers .", "Experimental results on real data sets demonstrate that semi-supervised MTL yields significant improvements in generalization performance over either semi-supervised single-task learning ( STL ) or supervised MTL .", "The unlabeled data are utilized by basing classifier learning on neighborhoods , induced by a Markov random walk over a graph representation of each manifold ."]}
{"orig_sents": ["5", "7", "0", "1", "3", "4", "2", "6"], "shuf_sents": ["We compare three sector scanning strategies .", "The sit-and-spin strategy always scans 360 .", "We show that the main benefits of using a lookahead strategy are when there are multiple meteorological phenomena in the environment , and when the maximum radius of any phenomenon is sufficiently smaller than the radius of the radars .", "The limited lookahead strategy additionally uses the expected environmental state K decision epochs in the future , as predicted from Kalman filters , in its decision-making .", "The full lookahead strategy uses all expected future states by casting the problem as a Markov decision process and using reinforcement learning to estimate the optimal scan strategy .", "We address the problem of adaptive sensor control in dynamic resourceconstrained sensor networks .", "We also show that there is a trade-off between the average quality with which a phenomenon is scanned and the number of decision epochs before which a phenomenon is rescanned .", "We focus on a meteorological sensing network comprising radars that can perform sector scanning rather than always scanning 360 ."]}
{"orig_sents": ["1", "3", "0", "4", "2"], "shuf_sents": ["The algorithm is derived via block coordinate descent in a dual of the LP relaxation of MAP , but does not require any tunable parameters such as step size or tree weights .", "We present a novel message passing algorithm for approximating the MAP problem in graphical models .", "The new method is tested on synthetic and real-world problems , and compares favorably with previous approaches .", "The algorithm is similar in structure to max-product but unlike max-product it always converges , and can be proven to find the exact MAP solution in various settings .", "We also describe a generalization of the method to cluster based potentials ."]}
{"orig_sents": ["0", "2", "1", "3", "4"], "shuf_sents": ["Although kernel measures of independence have been widely applied in machine learning ( notably in kernel ICA ) , there is as yet no method to determine whether they have detected statistically significant dependence .", "The resulting test costs O ( m2 ) , where m is the sample size .", "We provide a novel test of the independence hypothesis for one particular kernel independence measure , the Hilbert-Schmidt independence criterion ( HSIC ) .", "We demonstrate that this test outperforms established contingency table and functional correlation-based tests , and that this advantage is greater for multivariate data .", "Finally , we show the HSIC test also applies to text ( and to structured data more generally ) , for which no other independence test presently exists ."]}
{"orig_sents": ["4", "2", "3", "5", "1", "0"], "shuf_sents": ["PSVM Open Source is available for download at http : //code.google.com/p/psvm/ .", "Empirical study shows PSVM to be effective .", "To improve scalability , we have developed a parallel SVM algorithm ( PSVM ) , which reduces memory use through performing a row-based , approximate matrix factorization , and which loads only essential data to each machine to perform parallel computation .", "Let n denote the number of training instances , p the reduced matrix dimension after factorization ( p is significantly smaller than n ) , and m the number of machines .", "Support Vector Machines ( SVMs ) suffer from a widely recognized scalability problem in both memory use and computational time .", "PSVM reduces the memory requirement from O ( n2 ) to O ( np/m ) , and improves computation time to O ( np2 /m ) ."]}
{"orig_sents": ["5", "0", "2", "4", "3", "1"], "shuf_sents": ["We assume that the entire matrix is a single sample drawn from a matrix-variate t distribution and suggest a matrixvariate t model ( MVTM ) to predict those missing elements .", "The experiments on a toy data and EachMovie dataset show a good predictive accuracy of the model .", "We show that MVTM generalizes a range of known probabilistic models , and automatically performs model selection to encourage sparse predictive models .", "We suggest an optimization method that sequentially minimizes a convex upper-bound of the log-likelihood , which is very efficient and scalable .", "Due to the non-conjugacy of its prior , it is difficult to make predictions by computing the mode or mean of the posterior distribution .", "It is becoming increasingly important to learn from a partially-observed random matrix and predict its missing elements ."]}
{"orig_sents": ["1", "2", "0", "3", "6", "5", "7", "4"], "shuf_sents": ["We analyse handwriting data to gain a better understanding of primitives and their timings in biological movements .", "Biological movement is built up of sub-blocks or motion primitives .", "Such primitives provide a compact representation of movement which is also desirable in robotic control applications .", "Inference of the shape and the timing of primitives can be done using a factorial HMM based model , allowing the handwriting to be represented in primitive timing space .", "The timing code provides a compact representation of the movement while generating a movement without an explicit timing model produces a scribbling style of output .", "We show how the coupling of the low level primitive model , and the higher level timing model during inference can produce good reconstructions of handwriting , with shared primitives for all characters modelled .", "This representation provides a distribution of spikes corresponding to the primitive activations , which can also be modelled using HMM architectures .", "This coupled model also captures the variance profile of the dataset which is accounted for by spike timing jitter ."]}
{"orig_sents": ["0", "2", "1", "4", "3"], "shuf_sents": ["Although theorists have interpreted classical conditioning as a laboratory model of Bayesian belief updating , a recent reanalysis showed that the key features that theoretical models capture about learning are artifacts of averaging over subjects .", "We suggest that abrupt and unstable learning can be modeled by assuming subjects are conducting inference using sequential Monte Carlo sampling with a small number of samples -- one , in our simulations .", "Rather than learning smoothly to asymptote ( reflecting , according to Bayesian models , the gradual tradeoff from prior to posterior as data accumulate ) , subjects learn suddenly and their predictions fluctuate perpetually .", "Further , the model is capable of exhibiting sophisticated behaviors like retrospective revaluation at the ensemble level , even given minimally sophisticated individuals that do not track uncertainty in their beliefs over trials .", "Ensemble behavior resembles exact Bayesian models since , as in particle filters , it averages over many samples ."]}
{"orig_sents": ["4", "2", "5", "3", "0", "1"], "shuf_sents": ["This is achieved using a manifold learning algorithm applied to pixels associated with a measure of distributional similarity between pixel intensities .", "We compare different topologyextraction approaches and show how having the two-dimensional topology can be exploited .", "If someone gave us a learning task involving images for which the two-dimensional topology of pixels was not known , could we discover it automatically and exploit it ?", "The surprising result presented here is that not only the answer is yes , but that about as few as a thousand images are enough to approximately recover the relative locations of about a thousand pixels .", "We study the following question : is the two-dimensional structure of images a very strong prior or is it something that can be learned with a few examples of natural images ?", "For example suppose that the pixels had been permuted in a fixed but unknown way , could we recover the relative two-dimensional location of pixels on images ?"]}
{"orig_sents": ["1", "5", "3", "2", "0", "4", "7", "6"], "shuf_sents": ["We first compare these models on a formal level .", "Bayesian models of multisensory perception traditionally address the problem of estimating an underlying variable that is assumed to be the cause of the two sensory signals .", "One of these has the strength that it formalizes the causal structure of sensory signals .", "In the last couple of years , a few models have been proposed to solve this problem in a Bayesian fashion .", "Furthermore , we conduct a psychophysics experiment to test human performance in an auditory-visual spatial localization task in which integration is not mandatory .", "The brain , however , has to solve a more general problem : it also has to establish which signals come from the same source and should be integrated , and which ones do not and should be segregated .", "Keywords : causal inference , Bayesian methods , visual perception .", "We find that the causal Bayesian inference model accounts for the data better than other models ."]}
{"orig_sents": ["5", "2", "4", "0", "1", "3"], "shuf_sents": ["Finally , we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences .", "The resulting model is able to generalize considerably better for users with very few ratings .", "In this paper we present the Probabilistic Matrix Factorization ( PMF ) model which scales linearly with the number of observations and , more importantly , performs well on the large , sparse , and very imbalanced Netflix dataset .", "When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models , we achieve an error rate of 0.8861 , that is nearly 7 % better than the score of Netflix 's own system .", "We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically .", "Many existing approaches to collaborative filtering can neither handle very large datasets nor easily deal with users who have very few ratings ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["Our learning procedure seems to generalize quite well , and converges faster than the corresponding multiplicative baseline algorithms .", "An initial theoretical analysis is provided suggesting that our algorithm might be viewed as a standard Perceptron algorithm operating on a transformed sequence of examples with improved margin properties .", "A new algorithm for on-line learning linear-threshold functions is proposed which efficiently combines second-order statistics about the data with the `` logarithmic behavior '' of multiplicative/dual-norm algorithms .", "We also report on experiments carried out on datasets from diverse domains , with the goal of comparing to known Perceptron algorithms ( first-order , second-order , additive , multiplicative ) ."]}
{"orig_sents": ["6", "3", "0", "2", "4", "5", "1"], "shuf_sents": ["This is undesirable .", "We show , using the INRIA Person dataset , that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder .", "However , the human configuration can itself be estimated discriminatively using structure learning .", "In fact , these pedestrian finders make most errors on pedestrians in configurations that are uncommon in the training data , for example , mounting a bicycle .", "We demonstrate a pedestrian finder which first finds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset .", "We then present features ( local histogram of oriented gradient and local PCA of gradient ) based on that configuration to an SVM classifier .", "Fair discriminative pedestrian finders are now available ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["Performance at both regression and classification can then be further improved by using backpropagation through the DBN to discriminatively fine-tune the covariance kernel .", "We first learn a deep generative model of the unlabeled data using the fast , greedy algorithm introduced by .", "We show how to use unlabeled data and a deep belief net ( DBN ) to learn a good covariance kernel for a Gaussian process .", "If the data is high-dimensional and highly-structured , a Gaussian kernel applied to the top layer of features in the DBN works much better than a similar kernel applied to the raw input ."]}
{"orig_sents": ["3", "1", "2", "4", "0"], "shuf_sents": ["Our theory also gives results when we have multiple source domains , each of which may have a different number of instances , and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization .", "In the real world , though , we often wish to adapt a classifier from a source domain with a large amount of training data to different target domain with very little training data .", "In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk .", "Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain .", "The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set ."]}
{"orig_sents": ["5", "1", "3", "2", "4", "0", "6"], "shuf_sents": ["The system consists of an advanced recurrent neural network with an output layer designed for sequence labelling , combined with a probabilistic language model .", "Although the trajectory provides a compact and complete representation of the written output , it is hard to transcribe directly , because each letter is spread over many pen locations .", "However these techniques require considerable human effort , and are specific to particular languages and alphabets .", "Most recognition systems therefore employ sophisticated preprocessing techniques to put the inputs into a more localised form .", "This paper describes a system capable of directly transcribing raw online handwriting data .", "In online handwriting recognition the trajectory of the pen is recorded during writing .", "In experiments on an unconstrained online database , we record excellent results using either raw or preprocessed data , well outperforming a state-of-the-art HMM based system in both cases ."]}
{"orig_sents": ["4", "2", "3", "1", "5", "0", "6"], "shuf_sents": ["The task is constructed so that these decisions follow an MCMC acceptance rule , defining a Markov chain for which the stationary distribution is the category distribution .", "Using a correspondence between a model of human choice and Markov chain Monte Carlo ( MCMC ) , we describe a method for sampling from the distributions over objects that people associate with different categories .", "Most applications of these models determine these distributions indirectly .", "We propose a method for directly determining the assumptions of human learners by sampling from subjective probability distributions .", "Many formal models of cognition implicitly use subjective probability distributions to capture the assumptions of human learners .", "In our task , subjects choose whether to accept or reject a proposed change to an object .", "We test this procedure for both artificial categories acquired in the laboratory , and natural categories acquired from experience ."]}
{"orig_sents": ["11", "3", "9", "6", "5", "8", "1", "4", "10", "7", "2", "0"], "shuf_sents": ["with the Gaussian kernel , even though the Gaussian involves a second parameter ( the length scale ) .", "representer theorem .", "For the thinplate kernel this leads to a classifier with only one parameter ( the amount of regularisation ) , which we demonstrate to be as effective as an s.v.m .", "We show that no non-trivial positive definite ( p.d . )", "On the practical side , we give a support vector machine ( s.v.m . )", "Accordingly , we discuss the c.p.d .", "ones .", "kernels .", "case and provide some novel analysis , including an elementary derivation of a c.p.d .", "kernels exist which are radial and dilation invariant , only conditionally positive definite ( c.p.d . )", "algorithm for arbitrary c.p.d .", "This paper considers kernels invariant to translation , rotation and dilation ."]}
{"orig_sents": ["1", "4", "0", "2", "3"], "shuf_sents": ["Selection of a bin width or a kernel size is often done in an relatively arbitrary fashion , even though there have been recent attempts to remedy this situation .", "The peristimulus time histogram ( PSTH ) and its more continuous cousin , the spike density function ( SDF ) are staples in the analytic toolkit of neurophysiologists .", "We develop an exact Bayesian , generative model approach to estimating PSTHs and demonstate its superiority to competing methods .", "Further advantages of our scheme include automatic complexity control and error bars on its predictions .", "The former is usually obtained by binning spike trains , whereas the standard method for the latter is smoothing with a Gaussian kernel ."]}
{"orig_sents": ["3", "5", "0", "4", "2", "1", "7", "6"], "shuf_sents": ["The model sees attributes as patterns of image segments , repeatedly sharing some characteristic properties .", "To enable learning from unsegmented training images , the model is learnt discriminatively , by optimizing a likelihood ratio .", "Moreover , attributes with general appearance are taken into account , such as the pattern of alternation of any two colors which is characteristic for stripes .", "We present a probabilistic generative model of visual attributes , together with an efficient learning algorithm .", "These can be any combination of appearance , shape , or the layout of segments within the pattern .", "Attributes are visual qualities of objects , such as `red ' , `striped ' , or `spotted ' .", "We show that attributes can be learnt starting from a text query to Google image search , and can then be used to recognize the attribute and determine its spatial extent in novel real-world images .", "As demonstrated in the experimental evaluation , our model can learn in a weakly supervised setting and encompasses a broad range of attributes ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Incorporating invariances into a learning algorithm is a common problem in machine learning .", "The advantage of our setting is that it relies on column generation instead of modifying the underlying optimization problem directly .", "We provide a convex formulation which can deal with arbitrary loss functions and arbitrary losses .", "In addition , it is a drop-in replacement for most optimization algorithms for kernels , including solvers of the SVMStruct family ."]}
{"orig_sents": ["6", "3", "5", "4", "0", "1", "2"], "shuf_sents": ["We demonstrate the effectiveness of the new algorithm compared to related active learning methods .", "We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials .", "The tool finds the best parameters while minimizing the number of queries .", "The algorithm automatically decides what items are best presented to an individual in order to find the item that they value highly in as few trials as possible , and exploits quirks of human psychology to minimize time and cognitive burden .", "The problem is particularly difficult because the space of choices is infinite .", "To do this , our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface , which would be needlessly expensive .", "We propose an active learning algorithm that learns a continuous valuation model from discrete preferences ."]}
{"orig_sents": ["5", "8", "3", "6", "10", "7", "9", "0", "2", "1", "4"], "shuf_sents": ["The resulting population receptive fields span the subspace of stimuli that is most informative about the population response .", "We show how the model can be extended to capture nonlinear stimulus-response relationships using kernel canonical correlation analysis , which makes it possible to test different coding mechanisms .", "We evaluate our approach using both neuronal models and multi-electrode recordings from rabbit retinal ganglion cells .", "This approach treats each spike as an independent message but does not take into account that information might be conveyed through patterns of neural activity that are distributed across space or time .", "Our technique can also be used to calculate receptive fields from multi-dimensional neural measurements such as those obtained from dynamic imaging methods .", "S timulus selectivity of sensory neurons is often characterized by estimating their receptive field properties such as orientation selectivity .", "Can we find a concise description for the processing of a whole population of neurons analogous to the receptive field for single neurons ?", "More precisely , we seek to identify those stimulus features and the corresponding patterns of neural activity that are most reliably coupled .", "Receptive fields are usually derived from the mean ( or covariance ) of the spike-triggered stimulus ensemble .", "We use an extension of reverse-correlation methods based on canonical correlation analysis .", "Here , we present a generalization of the linear receptive field which is not bound to be triggered on individual spikes but can be meaningfully linked to distributed response patterns ."]}
{"orig_sents": ["0", "1", "3", "2", "4"], "shuf_sents": ["We extend position and phase-shift tuning , concepts already well established in the disparity energy neuron literature , to motion energy neurons .", "We show that Reichardt-like detectors can be considered examples of position tuning , and that motion energy filters whose complex valued spatio-temporal receptive fields are space-time separable can be considered examples of phase tuning .", "Similar to recently described neurons in the primary visual cortex , these new motion energy neurons exhibit tuning that is between purely spacetime separable and purely speed tuned .", "By combining these two types of detectors , we obtain an architecture for constructing motion energy neurons whose center frequencies can be adjusted by both phase and position shifts .", "We propose a functional role for this intermediate level of tuning by demonstrating that comparisons between pairs of these motion energy neurons can reliably discriminate between inputs whose velocities lie above or below a given reference velocity ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["We study various algorithms that implement our HCA concept extracting sparse heterogeneous structure by obtaining common components for the blocks and specific components within each block .", "We propose a new machine learning tool , heterogeneous component analysis ( HCA ) , for feature extraction in order to better understand the factors that underlie such complex structured heterogeneous data .", "HCA is a linear block-wise sparse Bayesian PCA based not only on a probabilistic model with block-wise residual variance terms but also on a Bayesian treatment of a block-wise sparse factor-loading matrix .", "Simulations on toy and bioinformatics data underline the usefulness of the proposed structured matrix factorization concept .", "In bioinformatics it is often desirable to combine data from various measurement sources and thus structured feature vectors are to be analyzed that possess different intrinsic blocking characteristics ( e.g. , different patterns of missing values , observation noise levels , effective intrinsic dimensionalities ) ."]}
{"orig_sents": ["7", "1", "6", "5", "9", "3", "4", "0", "8", "2"], "shuf_sents": ["We present search methods that use these features , pairwise and not , to find a factorization , and we compare their results on several datasets .", "Despite their structure , exact inference in DBNs is generally intractable .", "Moreover , tests on real DBNs show that automatic factorization can achieve significantly lower error in some cases .", "An empirical comparison shows that the most useful of these is a heuristic that estimates the mutual information introduced between factors by one step of belief propagation .", "In addition to features computed over entire factors , for efficiency we explored scores computed over pairs of variables .", "In this paper we present several techniques for decomposing a dynamic Bayesian network automatically to enable factored inference .", "One approach to approximate inference involves grouping the variables in the process into smaller factors and keeping independent beliefs over these factors .", "Dynamic Bayesian networks are structured representations of stochastic processes .", "Automatic factorization extends the applicability of factored inference to large , complex models that are undesirable to factor by hand .", "We examine a number of features of a DBN that capture different types of dependencies that will cause error in factored inference ."]}
{"orig_sents": ["1", "3", "5", "4", "2", "0"], "shuf_sents": ["Here , we investigate the statistical properties of an estimator of elapsed time which is based on a simple family of stochastic process .", "Many perceptual processes and neural computations , such as speech recognition , motor control and learning , depend on the ability to measure and mark the passage of time .", "Such processes need not be specific to the sense of time ; typical neural and sensory processes contain at least some statistical structure across a range of time scales .", "However , the processes that make such temporal judgements possible are unknown .", "Alternatively , judgements of elapsed time might be based on observations of temporally structured , but stochastic processes .", "A number of different hypothetical mechanisms have been advanced , all of which depend on the known , temporally predictable evolution of a neural or psychological state , possibly through oscillations or the gradual decay of a memory trace ."]}
{"orig_sents": ["4", "1", "3", "5", "2", "0"], "shuf_sents": ["This new result will be useful when applying stable random projections to distancebased clustering , classifications , kernels , massive data streams etc .", "For dimension reductions in the l norm ( 0 < 2 ) , the method of stable random projections can efficiently compute the l distances in massive datasets ( e.g. , the Web or massive data streams ) in one pass of the data .", "In fact , it achieves the Cramer-Rao bound when = 2 and = 0+ .", "The estimation task for stable random projections has been an interesting topic .", "Many tasks ( e.g. , clustering ) in machine learning only require the l distances instead of the original data .", "We propose a simple estimator based on the fractional power of the samples ( projected data ) , which is surprisingly near-optimal in terms of the asymptotic variance ."]}
{"orig_sents": ["3", "2", "4", "1", "0"], "shuf_sents": ["We analyze the performance of a LELVM-based probabilistic sigma point mixture tracker in several real and synthetic human motion sequences and demonstrate that LELVM not only provides sufficient constraints for robust operation in the presence of missing , noisy and ambiguous image measurements , but also compares favorably with alternative trackers based on PCA or GPLVM priors .", "LELVM is computationally efficient , simple to learn from sparse training data , and compatible with standard probabilistic trackers such as particle filters .", "We construct priors for people tracking using the Laplacian Eigenmaps Latent Variable Model ( LELVM ) .", "Reliably recovering 3D human pose from monocular video requires models that bias the estimates towards typical human poses and motions .", "LELVM is a recently introduced probabilistic dimensionality reduction model that combines the advantages of latent variable models -- a multimodal probability density for latent and observed variables , and globally differentiable nonlinear mappings for reconstruction and dimensionality reduction -- with those of spectral manifold learning methods -- no local optima , ability to unfold highly nonlinear manifolds , and good practical scaling to latent spaces of high dimension ."]}
{"orig_sents": ["6", "8", "0", "4", "5", "2", "3", "7", "1"], "shuf_sents": ["This led to the conclusion that stability is lacking as a theoretical and practical tool .", "We conclude that stability remains a meaningful cluster validation criterion over finite samples .", "In such cases , the model chosen governs the convergence rate of generalization bounds .", "By arguing that these rates are more important than the sample size , we are led to the prediction that stability-based cluster validation algorithms should not degrade with increasing sample size , despite the asymptotic universal stability .", "The discrepancy between this conclusion and the success of stability in practice has remained an open question , which we attempt to address .", "Our theoretical approach is that stability , as used by cluster validation algorithms , is similar in certain respects to measures of generalization in a model-selection framework .", "Over the past few years , the notion of stability in data clustering has received growing attention as a cluster validation criterion in a sample-based framework .", "This prediction is substantiated by a theoretical analysis as well as some empirical results .", "However , recent work has shown that as the sample size increases , any clustering model will usually become asymptotically stable ."]}
{"orig_sents": ["2", "3", "7", "1", "4", "6", "0", "5"], "shuf_sents": ["The theory also suggests that , in a very formal and precise sense , no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method , and that sequential transfer is always justified .", "This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it .", "In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems .", "Transfer learning has been successful in practice , and extensive PAC analysis of these methods has been developed .", "In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks .", "We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository .", "We show how existing theory neatly solves the problem of measuring relatedness and transferring the `right ' amount of information in sequential transfer learning in a Bayesian setting .", "However it is not yet clear how to define relatedness between tasks ."]}
{"orig_sents": ["4", "1", "3", "2", "0"], "shuf_sents": ["We test the performance of the method on simulated data and experimentally gathered neural spike trains , and we demonstrate improvements over conventional estimators .", "Many studies of neuroscientific and neural prosthetic importance rely on a smoothed , denoised estimate of the spike train 's underlying firing rate .", "We present a new method , based on a Gaussian Process prior , for inferring probabilistically optimal estimates of firing rate functions underlying single or multiple neural spike trains .", "Current techniques to find time-varying firing rates require ad hoc choices of parameters , offer no confidence intervals on their estimates , and can obscure potentially important single trial variability .", "Neural spike trains present challenges to analytical efforts due to their noisy , spiking nature ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["In addition to the unified framework we present tight convergence bounds , which show that our algorithm converges in O ( 1/ ) steps to precision for general convex problems and in O ( log ( 1/ ) ) steps for continuously differentiable problems .", "We present a globally convergent method for regularized risk minimization problems .", "Our method applies to Support Vector estimation , regression , Gaussian Processes , and any other regularized risk minimization setting which leads to a convex optimization problem .", "SVMPerf can be shown to be a special case of our approach .", "We demonstrate in experiments the performance of our approach ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We also provide experimental results .", "We assay the behavior of the algorithm by establishing links with Fisher discriminant analysis and oriented PCA , as well as with an SVM in a projected subspace ( or , equivalently , with a data-dependent reduced kernel ) .", "It builds on a new inductive principle which assumes that in addition to positive and negative data , a third class of data is available , termed the Universum .", "We study a pattern classification algorithm which has recently been proposed by Vapnik and coworkers ."]}
{"orig_sents": ["7", "4", "1", "2", "3", "0", "5", "6"], "shuf_sents": ["We demonstrate this effect for global semantic structures shaped topologically as a ring , and as a two-dimensional sheet .", "Recent mathematical modeling of episodic memory argues that episodic recall relies on retrieval of a gradually-changing representation of temporal context .", "We show that retrieved context enables the development of a global memory space that reflects relationships between all items that have been previously learned .", "When newly-learned information is integrated into this structure , it is placed in some relationship to all other items , even if that relationship has not been explicitly learned .", "A successful semantic memory depends on inferring relationships between items that are not explicitly taught .", "We also examined the utility of this learning algorithm for learning a more realistic semantic space by training it on a large pool of synonym pairs .", "Retrieved context enabled the model to `` infer '' relationships between synonym pairs that had not yet been presented .", "Semantic memory refers to our knowledge of facts and relationships between concepts ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We provide a rigorous analysis of this algorithm , proving what we believe is the first finite-time bound for value-function based algorithms for continuous state and action problems .", "We consider continuous state , continuous action batch reinforcement learning where the goal is to learn a good policy from a sufficiently rich trajectory generated by some policy .", "We study a variant of fitted Q-iteration , where the greedy action selection is replaced by searching for a policy in a restricted set of candidate policies by maximizing the average action values ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Guided by the goal of obtaining an optimization algorithm that is both fast and yields good generalization , we study the descent direction maximizing the decrease in generalization error or the probability of not increasing generalization error .", "We report experimental results showing much faster convergence in computation time and in number of iterations with TONGA ( Topmoumoute Online natural Gradient Algorithm ) than with stochastic gradient descent , even on very large datasets .", "The surprising result is that from both the Bayesian and frequentist perspectives this can yield the natural gradient direction .", "Although that direction can be very expensive to compute we develop an efficient , general , online approximation to the natural gradient descent which is suited to large scale problems ."]}
{"orig_sents": ["5", "0", "1", "3", "4", "6", "2"], "shuf_sents": ["Methods like Probabilistic Latent Semantic Analysis ( PLSA ) and Latent Dirichlet Allocation ( LDA ) have been proposed for this purpose .", "However , they are limited in the number of components they can extract and lack an explicit provision to control the `` expressiveness '' of the extracted components .", "We present experimental evidence of the utility of such representations .", "In this paper , we present a learning formulation to address these limitations by employing the notion of sparsity .", "We start with the PLSA framework and use an entropic prior in a maximum a posteriori formulation to enforce sparsity .", "An important problem in many fields is the analysis of counts data to extract meaningful latent components .", "We show that this allows the extraction of overcomplete sets of latent components which better characterize the data ."]}
{"orig_sents": ["4", "1", "3", "0", "5", "2"], "shuf_sents": ["The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology .", "event related potentials ; and second order methods , in which the feature of interest is the power of the signal , e.g .", "The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classification algorithms for brain computer interfaces .", "event related ( de ) synchronization .", "Traditional analysis methods for single-trial classification of electroencephalography ( EEG ) focus on two types of paradigms : phase locked methods , in which the amplitude of the signal is used as the feature for classification , e.g .", "Here we propose a principled method , based on a bilinear model , in which the algorithm simultaneously learns the best first and second order spatial and temporal features for classification of EEG ."]}
{"orig_sents": ["2", "4", "1", "0", "3"], "shuf_sents": ["When adapted to the statistics of natural images , the coupling terms learn a combination of facilitatory and inhibitory interactions among neighboring basis functions .", "Here , we propose a model that attempts to capture the dependencies among the basis function coefficients by including a pairwise coupling term in the prior over the coefficient activity states .", "It has been shown that adapting a dictionary of basis functions to the statistics of natural images so as to maximize sparsity in the coefficients results in a set of dictionary elements whose spatial properties resemble those of V1 ( primary visual cortex ) receptive fields .", "These learned interactions may offer an explanation for the function of horizontal connections in V1 in terms of a prior over natural images .", "However , the resulting sparse coefficients still exhibit pronounced statistical dependencies , thus violating the independence assumption of the sparse coding model ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["We next exhibit a random source of examples for which a `` picky '' variant of AdaBoost that skips poor base classifiers can outperform the standard AdaBoost algorithm , which uses every base classifier , by an exponential factor .", "This paper studies boosting algorithms that make a single pass over a set of base classifiers .", "We first analyze a one-pass algorithm in the setting of boosting with diverse base classifiers .", "Experiments with Reuters and synthetic data show that one-pass boosting can substantially improve on the accuracy of Naive Bayes , and that picky boosting can sometimes lead to a further improvement in accuracy .", "Our guarantee is the same as the best proved for any boosting algorithm , but our one-pass algorithm is much faster than previous approaches ."]}
{"orig_sents": ["9", "8", "0", "1", "3", "6", "2", "4", "5", "7"], "shuf_sents": ["But , as in much of learning theory , existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed ( i.i.d . ) .", "In many machine learning applications , however , this assumption does not hold .", "It proves novel stability-based generalization bounds that hold even with this more general setting .", "The observations received by the learning algorithm often have some inherent temporal dependence , which is clear in system diagnosis or time series prediction problems .", "These bounds strictly generalize the bounds given in the i.i.d .", "case .", "This paper studies the scenario where the observations are drawn from a stationary mixing sequence , which implies a dependence between observations that weaken over time .", "It also illustrates their application in the case of several general classes of learning algorithms , including Support Vector Regression and Kernel Ridge Regression .", "A key advantage of these bounds is that they are designed for specific learning algorithms , exploiting their particular properties .", "The notion of algorithmic stability has been used effectively in the past to derive tight generalization bounds ."]}
{"orig_sents": ["3", "2", "8", "6", "4", "5", "7", "0", "1"], "shuf_sents": ["Finally , we show that any problem of MAP estimation for probability distributions over finite domains can be reduced to an MWIS problem .", "We believe this reduction will yield new insights and algorithms for MAP estimation .", "First , we study the performance of loopy max-product belief propagation .", "We investigate the use of message-passing algorithms for the problem of finding the max-weight independent set ( MWIS ) in a graph .", "We then develop a modification of max-product - one that converges to an optimal solution of the dual of the MWIS problem .", "We also develop a simple iterative algorithm for estimating the max-weight independent set from this dual solution .", "We use this relationship to obtain sufficient conditions for correctness of the estimate .", "We show that the MWIS estimate obtained using these two algorithms in conjunction is correct when the graph is bipartite and the MWIS is unique .", "We show that , if it converges , the quality of the estimate is closely related to the tightness of an LP relaxation of the MWIS problem ."]}
{"orig_sents": ["4", "1", "0", "3", "2"], "shuf_sents": ["Manifold Sculpting is a new algorithm that iteratively reduces dimensionality by simulating surface tension in local neighborhoods .", "Unfortunately , existing algorithms often lose significant precision in this transformation .", "Manifold Sculpting is also able to benefit from both prior dimensionality reduction efforts .", "We present several experiments that show Manifold Sculpting yields more accurate results than existing algorithms with both generated and natural data-sets .", "Many algorithms have been recently developed for reducing dimensionality by projecting data onto an intrinsic non-linear manifold ."]}
{"orig_sents": ["5", "3", "6", "8", "4", "9", "7", "0", "10", "1", "2"], "shuf_sents": ["We numerically test how these optimization schemes perform in the regime of low signal-to-noise ratio ( small number of spikes and increasing neural noise ) for model visual neurons .", "Information maximization provides slightly , but significantly , better reconstructions than least square fitting .", "This makes the problem of finding relevant dimensions , together with the problem of lossy compression , one of examples where informationtheoretic measures are no more data limited than those derived from least squares .", "In this model , the neural firing rate is a nonlinear function of a small number of relevant stimulus components .", "Next , we derive reconstruction errors in relevant dimensions found by maximizing Renyi divergences of arbitrary order in the asymptotic limit of large spike numbers .", "This paper compares a family of methods for characterizing neural feature selectivity with natural stimuli in the framework of the linear-nonlinear model .", "The relevant stimulus dimensions can be found by maximizing one of the family of objective functions , Renyi divergences of different orders .", "This corresponds to finding relevant dimensions by maximizing mutual information .", "We show that maximizing one of them , Renyi divergence of order 2 , is equivalent to least-square fitting of the linear-nonlinear model to neural data .", "We find that the smallest errors are obtained with Renyi divergence of order 1 , also known as Kullback-Leibler divergence .", "We find that optimization schemes based on either least square fitting or information maximization perform well even when number of spikes is small ."]}
{"orig_sents": ["3", "1", "4", "2", "0"], "shuf_sents": ["The power of the MAM principle is illustrated further by application to ordinal regression tasks , resulting in an O ( n ) algorithm able to process large datasets in reasonable time .", "It is shown that the application of this risk minimization principle results in a class of ( computationally ) simple learning machines similar to the classical Parzen window classifier .", "This analysis is related to Support Vector Machines by means of a margin transformation .", "This paper1 explores the use of a Maximal Average Margin ( MAM ) optimality principle for the design of learning algorithms .", "A direct relation with the Rademacher complexities is established , as such facilitating analysis and providing a notion of certainty of prediction ."]}
{"orig_sents": ["2", "5", "4", "3", "0", "6", "1", "7"], "shuf_sents": ["Second , I consider a maximum a posteriori estimator to test whether a Bayesian model with a prior that emphasizes directions near the center of gaze can reproduce the owl 's localization behavior .", "This result suggests that the standard cue matching model will not be sufficient to explain sound localization behavior in the barn owl .", "Sound localization by barn owls is commonly modeled as a matching procedure where localization cues derived from auditory inputs are compared to stored templates .", "First , I consider a maximum likelihood estimator in order to further evaluate the cue matching model .", "Here , I examine two models for the barn owl 's sound localization behavior .", "While the matching models can explain properties of neural responses , no model explains how the owl resolves spatial ambiguity in the localization cues to produce accurate localization for sources near the center of gaze .", "I show that the maximum likelihood estimator can not reproduce the owl 's behavior , while the maximum a posteriori estimator is able to match the behavior .", "The Bayesian model provides a new framework for analyzing sound localization in the barn owl and leads to predictions about the owl 's localization behavior ."]}
{"orig_sents": ["8", "0", "5", "1", "4", "3", "7", "6", "2"], "shuf_sents": ["In many domains such as document classification , image histogram classification and gene microarray experiments , fixed monotonic transformations can be useful as a preprocessing step .", "The proposed method learns monotonic transformations automatically while training a large-margin classifier without any prior knowledge of the domain .", "The effectiveness of these learned transformations on synthetic problems , text data and image data is demonstrated .", "Two algorithmic implementations of the method are formalized .", "A monotonic piecewise linear function is learned which transforms data for subsequent processing by a linear hyperplane classifier .", "However , most classifiers only explore these transformations through manual trial and error or via prior domain knowledge .", "An improved algorithm is then derived using a convex semidefinite relaxation that overcomes initialization issues in the greedy optimization problem .", "The first solves a convergent alternating sequence of quadratic and linear programs until it obtains a locally optimal solution .", "A discriminative method is proposed for learning monotonic transformations of the training data while jointly estimating a large-margin classifier ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["In contrast to traditional approaches based on approximate inference in a single intractable model , our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables .", "The learning of probabilistic models with many hidden variables and nondecomposable dependencies is an important and challenging problem .", "This allows us to capture non-decomposable aspects of the data while still maintaining tractability .", "We propose an objective function for our approach , derive EM-style algorithms for parameter estimation , and demonstrate their effectiveness on three challenging real-world learning tasks ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["We further show that this boosting can be performed even in the presence of independent misclassification noise , given access to a noise-tolerant weak ranker .", "We show that any weak ranker that can achieve an area under the ROC curve slightly better than 1/2 ( which can be achieved by random guessing ) can be efficiently boosted to achieve an area under the ROC curve arbitrarily close to 1 ."]}
{"orig_sents": ["7", "6", "0", "5", "4", "2", "3", "1"], "shuf_sents": ["Therefore , accurately estimating the density ratio , called the importance , is one of the key issues in covariate shift adaptation .", "Simulations illustrate the usefulness of our approach .", "In this paper , we propose a direct importance estimation method that does not involve density estimation .", "Our method is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized .", "However , this naive approach tends to perform poorly since density estimation is a hard task particularly in high dimensional cases .", "A naive approach to this task is to first estimate training and test input densities separately and then estimate the importance by taking the ratio of the estimated densities .", "Under covariate shift , standard learning methods such as maximum likelihood estimation are no longer consistent -- weighted variants according to the ratio of test and training input densities are consistent .", "A situation where training and test samples follow different input distributions is called covariate shift ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["Rational players are modeled by players using no regret algorithms , which guarantee that their payoff in the long run is close to the maximum they could hope to achieve by consistently deviating from the algorithm 's suggested action .", "Further , we show that if all players use a no regret algorithm , then the empirical distribution of their plays converges to an equilibrium .", "We study the relation between notions of game-theoretic equilibria which are based on stability under a set of deviations , and empirical equilibria which are reached by rational players .", "We show that for a given set of deviations over the strategy set of a player , it is possible to efficiently approximate fixed points of a given deviation if and only if there exist efficient no regret algorithms resistant to the deviations ."]}
{"orig_sents": ["7", "2", "0", "6", "4", "1", "3", "5"], "shuf_sents": ["Thus it seems natural to try to unify offline and online techniques , preserving the theoretical properties of the former , and exploiting the scalability of the latter .", "We provide a general theorem showing that these search heuristics are admissible , and lead to complete and -optimal algorithms .", "A few online methods have also been proposed recently , and proven to be remarkably scalable , but without the theoretical guarantees of their offline counterparts .", "This is , to the best of our knowledge , the strongest theoretical result available for online POMDP solution methods .", "The algorithm uses search heuristics based on an error analysis of lookahead search , to guide the online search towards reachable beliefs with the most potential to reduce error .", "We also provide empirical evidence showing that our approach is also practical , and can find ( provably ) near-optimal solutions in reasonable time .", "In this paper , we provide theoretical guarantees on an anytime algorithm for POMDPs which aims to reduce the error made by approximate offline value iteration algorithms through the use of an efficient online searching procedure .", "Planning in partially observable environments remains a challenging problem , despite significant recent advances in offline approximation techniques ."]}
{"orig_sents": ["4", "5", "6", "2", "3", "1", "0"], "shuf_sents": ["We describe innovative practical solutions to these challenges , and demonstrate clear performance improvements over both hand-designed policies as well as obvious `` cookbook '' RL implementations .", "Our testbed scenario posed a number of challenges to successful use of RL , including multiple disparate reward functions , limited decision sampling rates , and pathologies arising when using multiple sensor readings as state variables .", "We apply RL in a realistic laboratory testbed using a Blade cluster and dynamically varying HTTP workload running on a commercial web applications middleware platform .", "We embed a CPU frequency controller in the Blade servers ' firmware , and we train policies for this controller using a multi-criteria reward signal depending on both application performance and CPU power consumption .", "Electrical power management in large-scale IT systems such as commercial datacenters is an application area of rapidly growing interest from both an economic and ecological perspective , with billions of dollars and millions of metric tons of CO2 emissions at stake annually .", "Businesses want to save power without sacrificing performance .", "This paper presents a reinforcement learning approach to simultaneous online management of both performance and power consumption ."]}
{"orig_sents": ["2", "4", "5", "0", "3", "6", "1"], "shuf_sents": ["We consider the particular case in which an MI learner is allowed to selectively query unlabeled instances from positive bags .", "Our experiments show that learning from instance labels can significantly improve performance of a basic MI learning algorithm in two multiple-instance domains : content-based image retrieval and text classification .", "We present a framework for active learning in the multiple-instance ( MI ) setting .", "This approach is well motivated in domains in which it is inexpensive to acquire bag labels and possible , but expensive , to acquire instance labels .", "In an MI learning problem , instances are naturally organized into bags and it is the bags , instead of individual instances , that are labeled for training .", "MI learners assume that every instance in a bag labeled negative is actually negative , whereas at least one instance in a bag labeled positive is actually positive .", "We describe a method for learning from labels at mixed levels of granularity , and introduce two active query selection strategies motivated by the MI setting ."]}
{"orig_sents": ["4", "7", "2", "1", "3", "5", "6", "0"], "shuf_sents": ["In particular , in this paper we apply the hierarchical apprenticeship learning algorithm to the task of quadruped locomotion over extreme terrain , and achieve , to the best of our knowledge , results superior to any previously published work .", "For example , consider the task of teaching a quadruped robot to navigate over extreme terrain ; demonstrating an optimal policy ( i.e. , an optimal set of foot locations over the entire terrain ) is a highly non-trivial task , even for an expert .", "However , in many problems even an expert has difficulty controlling the system , which makes this approach infeasible .", "In this paper we propose a method for hierarchical apprenticeship learning , which allows the algorithm to accept isolated advice at different hierarchical levels of the control task .", "We consider apprenticeship learning -- learning from expert demonstrations -- in the setting of large , complex domains .", "This type of advice is often feasible for experts to give , even if the expert is unable to demonstrate complete trajectories .", "This allows us to extend the apprenticeship learning paradigm to much larger , more challenging domains .", "Past work in apprenticeship learning requires that the expert demonstrate complete trajectories through the domain ."]}
{"orig_sents": ["2", "4", "1", "5", "3", "0"], "shuf_sents": ["We demonstrate the effectiveness of this approach and study algorithm component contributions using held-out test sets from the LabelMe database .", "We achieve this through a simple approach : by matching the input image , in an appropriate representation , to images in a large training set of labeled images .", "Current object recognition systems can only recognize a limited number of object categories ; scaling up to many categories is the next challenge .", "We build a probabilistic model to transfer the labels from the retrieval set to the input image .", "We seek to build a system to recognize and localize many different object categories in complex scenes .", "Due to regularities in object identities across similar scenes , the retrieved matches provide hypotheses for object identities and locations ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We give an implementation of our algorithm and provide experiments that show that the algorithm can yield up to two orders of magnitude speedups on answering queries and responding to dynamic changes over the sum-product algorithm .", "Motivated by stochastic systems in which observed evidence and conditional dependencies between states of the network change over time , and certain quantities of interest ( marginal distributions , likelihood estimates etc . )", "must be updated , we study the problem of adaptive inference in tree-structured Bayesian networks .", "We describe an algorithm for adaptive inference that handles a broad range of changes to the network and is able to maintain marginal distributions , MAP estimates , and data likelihoods in all expected logarithmic time ."]}
{"orig_sents": ["4", "5", "0", "3", "2", "1"], "shuf_sents": ["Here we introduce a new twist on the point-process modeling approach : we include unobserved as well as observed spiking neurons in a joint encoding model .", "We formulate the estimation procedure using variational EM and the wake-sleep algorithm , and illustrate the model 's performance using a simulated example network consisting of two coupled neurons .", "More importantly , it allows us to estimate connectivity patterns among neurons ( both observed and unobserved ) , and may provide insight into how networks process sensory input .", "The resulting model exhibits richer dynamics and more highly nonlinear response properties , making it more powerful and more flexible for fitting neural data .", "Point process encoding models provide powerful statistical methods for understanding the responses of neurons to sensory stimuli .", "Although these models have been successfully applied to neurons in the early sensory pathway , they have fared less well capturing the response properties of neurons in deeper brain areas , owing in part to the fact that they do not take into account multiple stages of processing ."]}
{"orig_sents": ["1", "4", "0", "3", "2", "5"], "shuf_sents": ["Although this appears to be a strong negative outcome , we then demonstrate how the problem can be bypassed by using equivalence relations instead of value assignments over hidden variables .", "We investigate a new , convex relaxation of an expectation-maximization ( EM ) variant that approximates a standard objective while eliminating local minima .", "This reformulation leads to an exact expression for EM variants in a wide range of problems .", "In particular , we develop new algorithms for estimating exponential conditional models that only require equivalence relation information over the variable values .", "First , a cautionary result is presented , showing that any convex relaxation of EM over hidden variables must give trivial results if any dependence on the missing values is retained .", "We then develop a semidefinite relaxation that yields global training by eliminating local minima ."]}
{"orig_sents": ["0", "1", "5", "2", "3", "4"], "shuf_sents": ["We present four new reinforcement learning algorithms based on actor-critic and natural-gradient ideas , and provide their convergence proofs .", "Actor-critic reinforcement learning methods are online approximations to policy iteration in which the value-function parameters are estimated using temporal difference learning and the policy parameters are updated by stochastic gradient descent .", "The use of temporal difference learning in this way is of interest because in many applications it dramatically reduces the variance of the gradient estimates .", "The use of the natural gradient is of interest because it can produce better conditioned parameterizations and has been shown to further reduce variance in some cases .", "Our results extend prior two-timescale convergence results for actor-critic methods by Konda and Tsitsiklis by using temporal difference learning in the actor and by incorporating natural gradients , and they extend prior empirical studies of natural actor-critic methods by Peters , Vijayakumar and Schaal by providing the first convergence proofs and the first fully incremental algorithms .", "Methods based on policy gradients in this way are of special interest because of their compatibility with function approximation methods , which are needed to handle large or infinite state spaces ."]}
{"orig_sents": ["3", "0", "2", "5", "4", "1"], "shuf_sents": ["The distribution is represented in terms of noisy-or 's and noisy-and-not 's of causal features which are conjunctions of the binary inputs .", "We speculate on the use of the noisy-logical distribution for causal reasoning and artificial intelligence .", "The standard noisy-or and noisy-andnot models , used in causal reasoning and artificial intelligence , are special cases of the noisy-logical distribution .", "We describe a novel noisy-logical distribution for representing the distribution of a binary output variable conditioned on multiple binary input variables .", "We illustrate the noisy-logical distribution by showing that it can account for new experimental findings on how humans perform causal reasoning in complex contexts .", "We prove that the noisy-logical distribution is complete in the sense that it can represent all conditional distributions provided a sufficient number of causal factors are used ."]}
{"orig_sents": ["3", "4", "1", "5", "2", "0"], "shuf_sents": ["Experiments on toy data and real world data sets illustrate the benefits of this approach .", "Building upon new insights from this model , we propose an improved method for co-training , which is a novel co-training kernel for Gaussian process classifiers .", "Furthermore , it can automatically estimate how much each view should be trusted , and thus accommodate noisy or unreliable views .", "We propose a Bayesian undirected graphical model for co-training , or more generally for semi-supervised multi-view learning .", "This makes explicit the previously unstated assumptions of a large class of co-training type algorithms , and also clarifies the circumstances under which these assumptions fail .", "The resulting approach is convex and avoids local-maxima problems , unlike some previous multi-view learning methods ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["We describe an analog-VLSI neural network for face recognition based on subspace methods .", "The system uses on-chip compensation techniques to reduce the effects of device mismatch .", "A second network with userprogrammed coefficients performs classification with Manhattan distances .", "The system uses a dimensionality-reduction network whose coefficients can be either programmed or learned on-chip to perform PCA , or programmed to perform LDA .", "Using the ORL database with 12x12-pixel images , our circuit achieves up to 85 % classification performance ( 98 % of an equivalent software implementation ) ."]}
{"orig_sents": ["3", "1", "8", "6", "7", "2", "0", "5", "4"], "shuf_sents": ["The sparseness of solutions is controlled by l1 -norm regularization parameters .", "The most challenging step in speech dereverberation is blind channel identification ( BCI ) .", "Under this model , we show how to formulate the BCI of a single-input multiple-output ( SIMO ) system into a l1 norm regularized least squares ( LS ) problem , which is convex and can be solved efficiently with guaranteed global convergence .", "Speech dereverberation remains an open problem after more than three decades of research .", "Our results show that the proposed approach is effective and robust , and it yields source estimates in real acoustic environments with high fidelity to anechoic chamber measurements .", "We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework .", "The main difficulty in BCI lies in finding an appropriate acoustic model , which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source , but also robustly models real acoustic environments .", "This paper proposes a sparse acoustic room impulse response ( RIR ) model for BCI , that is , an acoustic RIR can be modeled by a sparse FIR filter .", "Although many BCI approaches have been developed , their performance is still far from satisfactory for practical applications ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["Our analysis makes use of the Neyman-Pearson lemma as a theoretical basis to analyze combinations of classifiers .", "We give a method for finding the optimal decision rule for a combination of classifiers and prove that it has the optimal ROC curve .", "We show how our method generalizes and improves previous work on combining classifiers and generating ROC curves .", "We present a new analysis for the combination of binary classifiers ."]}
{"orig_sents": ["0", "4", "2", "5", "6", "1", "3"], "shuf_sents": ["The classical hypothesis , that bottom-up saliency is a center-surround process , is combined with a more recent hypothesis that all saliency decisions are optimal in a decision-theoretic sense .", "Optimal solutions , under this hypothesis , are derived for a number of the former ( including static natural images , dense motion fields , and even dynamic textures ) , and applied to a number of the latter ( the prediction of human eye fixations , motion-based saliency in the presence of ego-motion , and motion-based saliency in the presence of highly dynamic backgrounds ) .", "This architecture equates the saliency of each image location to the discriminant power of a set of features with respect to the classification problem that opposes stimuli at center and surround , at that location .", "In result , discriminant saliency is shown to predict eye fixations better than previous models , and produces background subtraction algorithms that outperform the state-of-the-art in computer vision .", "The combined hypothesis is denoted as discriminant center-surround saliency , and the corresponding optimal saliency architecture is derived .", "It is shown that the resulting saliency detector makes accurate quantitative predictions for various aspects of the psychophysics of human saliency , including non-linear properties beyond the reach of previous saliency models .", "Furthermore , it is shown that discriminant center-surround saliency can be easily generalized to various stimulus modalities ( such as color , orientation and motion ) , and provides optimal solutions for many other saliency problems of interest for computer vision ."]}
{"orig_sents": ["3", "0", "7", "1", "5", "4", "8", "2", "6"], "shuf_sents": ["Driven by this success , cascade learning has been an area of active research in recent years .", "In particular , determining the optimal target detection rate for each stage of the cascade remains an unsolved issue .", "The MIP process is fully automatic and requires no assumptions of probability distributions , statistical independence , or ad hoc intermediate rejection targets .", "Cascade detectors have been shown to operate extremely rapidly , with high accuracy , and have important applications such as face detection .", "This algorithm computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset .", "In this paper , we propose the multiple instance pruning ( MIP ) algorithm for soft cascades .", "Experimental results on the MIT+CMU dataset demonstrate significant performance advantages .", "Nevertheless , there are still challenging technical problems during the training process of cascade detectors .", "The algorithm is based on two key insights : i ) examples that are destined to be rejected by the complete classifier can be safely pruned early ; ii ) face detection is a multiple instance learning problem ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We introduce a new Bayesian model for hierarchical clustering based on a prior over trees called Kingman 's coalescent .", "We develop novel greedy and sequential Monte Carlo inferences which operate in a bottom-up agglomerative fashion .", "We show experimentally the superiority of our algorithms over the state-of-the-art , and demonstrate our approach in document clustering and phylolinguistics ."]}
{"orig_sents": ["2", "1", "3", "4", "5", "0"], "shuf_sents": ["Experiments on a collected data have demonstrated the merits of our approach .", "In this paper , we motivate both feature selection and model order identification as two key issues for a successful CBIS .", "Content-based image suggestion ( CBIS ) targets the recommendation of products based on user preferences on the visual content of images .", "We propose a generative model in which the visual features and users are clustered into separate classes .", "We identify the number of both user and image classes with the simultaneous selection of relevant visual features using the message length approach .", "The goal is to ensure an accurate prediction of ratings for multidimensional non-Gaussian and continuous image descriptors ."]}
{"orig_sents": ["7", "3", "1", "5", "4", "2", "6", "0"], "shuf_sents": ["The resulting segmentations are compared to the state-of-the-art on three different image datasets .", "We introduce a CRF based scene labeling model that incorporates both local features and features aggregated over the whole image or large sections of it .", "Loopy Belief Propagation is used to approximate the marginals needed for the gradient and log-likelihood calculations and the Bethe free-energy approximation to the log-likelihood is monitored to control the step size .", "For accurate labeling it is important to capture the global context of the image as well as local information .", "We introduce a method for learning CRFs from datasets with many unlabeled nodes by marginalizing out the unknown labels so that the log-likelihood of the known ones can be maximized by gradient ascent .", "Secondly , traditional CRF learning requires fully labeled datasets which can be costly and troublesome to produce .", "Our experimental results show that effective models can be learned from fragmentary labelings and that incorporating top-down aggregate features significantly improves the segmentations .", "Conditional Random Fields ( CRFs ) are an effective tool for a variety of different data segmentation and labeling tasks including visual scene interpretation , which seeks to partition images into their constituent semantic-level regions and assign appropriate class labels to each region ."]}
{"orig_sents": ["0", "2", "5", "4", "3", "1"], "shuf_sents": ["We present a novel linear clustering framework ( D IFFRAC ) which relies on a linear discriminative cost function and a convex relaxation of a combinatorial optimization problem .", "We present empirical evaluations of our algorithms on synthetic and real medium-scale datasets .", "The large convex optimization problem is solved through a sequence of lower dimensional singular value decompositions .", "( 3 ) Prior information on the partition is easily incorporated , leading to state-of-the-art performance for semi-supervised learning , for clustering or classification .", "( 2 ) It can be readily extended to non linear clustering if the discriminative cost function is based on positive definite kernels , and can then be seen as an alternative to spectral clustering .", "This framework has several attractive properties : ( 1 ) although apparently similar to K-means , it exhibits superior clustering performance than K-means , in particular in terms of robustness to noise ."]}
{"orig_sents": ["5", "2", "1", "0", "3", "6", "4"], "shuf_sents": ["We propose using the Expected Relevance to convert class probabilities into ranking scores .", "Our approach is motivated by the fact that perfect classifications result in perfect DCG scores and the DCG errors are bounded by classification errors .", "We consider the DCG criterion ( discounted cumulative gain ) , a standard quality measure in information retrieval .", "The class probabilities are learned using a gradient boosting tree algorithm .", "An efficient implementation of the boosting tree algorithm is also presented .", "We cast the ranking problem as ( 1 ) multiple classification ( `` Mc '' ) ( 2 ) multiple ordinal classification , which lead to computationally tractable learning algorithms for relevance ranking in Web search .", "Evaluations on large-scale datasets show that our approach can improve LambdaRank and the regressions-based ranker , in terms of the ( normalized ) DCG scores ."]}
{"orig_sents": ["3", "7", "6", "10", "2", "5", "4", "9", "0", "1", "8"], "shuf_sents": ["Experimental results show that our method is capable of robustly recovering articulated pose , shape and biometric measurements ( e.g .", "height , weight , etc . )", "Specifically , we represent the body using a parameterized triangulated mesh model that is learned from a database of human range scans .", "Estimation of three-dimensional articulated human pose and motion from images is a central problem in computer vision .", "This predicted pose and shape are used to initialize a generative model for more detailed pose and shape estimation .", "We demonstrate a discriminative method to directly recover the model parameters from monocular images using a conditional mixture of kernel regressors .", "Automatic initialization of such models has proved difficult and most approaches assume that the size and shape of the body parts are known a priori .", "Much of the previous work has been limited by the use of crude generative models of humans represented as articulated collections of simple parts such as cylinders .", "in both calibrated and uncalibrated camera environments .", "The resulting approach allows fully automatic pose and shape recovery from monocular and multi-camera imagery .", "In this paper we propose a method for automatically recovering a detailed parametric model of non-rigid body shape and pose from monocular imagery ."]}
{"orig_sents": ["1", "3", "7", "4", "0", "8", "2", "6", "5"], "shuf_sents": ["In this case , an automatic method of building up keywords from short context units such as phones is desirable .", "Many tasks in speech processing involve classification of long term characteristics of a speech segment such as language , speaker , dialect , or topic .", "We cast the problem of keyword selection as a feature selection problem for n-grams of phones .", "A natural technique for determining these characteristics is to first convert the input speech into a sequence of tokens such as words , phones , etc .", "In many applications , a set of distinctive keywords may not be known a priori .", "Application of this method to language recognition and topic recognition tasks shows that the technique produces interesting and significant qualitative and quantitative results .", "We propose an alternating filter-wrapper method that builds successively longer keywords .", "From these tokens , we can then look for distinctive sequences , keywords , that characterize the speech .", "We propose a method for the construction of keywords based upon Support Vector Machines ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["A simple extension to our model can accomplish circular-shift dynamic routing with only O ( N ) connections , compared to O ( N 2 ) connections required by traditional models .", "We describe a neurobiologically plausible model to implement dynamic routing using the concept of neuronal communication through neuronal coherence .", "The correct mapping between input and output tiers is realized by an appropriate alignment of the phases of their respective background oscillations by the routing control units .", "We present an example architecture , implemented on a neuromorphic chip , that is able to achieve circular-shift invariance .", "The model has a three-tier architecture : a raw input tier , a routing control tier , and an invariant output tier ."]}
{"orig_sents": ["5", "1", "0", "2", "4", "3"], "shuf_sents": ["Valid constraints on the marginal polytope are derived through a series of projections onto the cut polytope .", "When combined with a concave upper bound on the entropy , this gives a new variational inference algorithm for probabilistic inference in discrete Markov Random Fields ( MRFs ) .", "As a result , we obtain tighter upper bounds on the log-partition function .", "Finally , we demonstrate the advantage of the new constraints for finding the MAP assignment in protein structure prediction .", "We also show empirically that the approximations of the marginals are significantly more accurate when using the tighter outer bounds .", "We give a new class of outer bounds on the marginal polytope , and propose a cutting-plane algorithm for efficiently optimizing over these constraints ."]}
{"orig_sents": ["3", "1", "4", "2", "0", "5"], "shuf_sents": ["Based on walk-sum calculations , we develop adaptive methods that optimize the choice of subgraphs used at each iteration with a view to achieving maximum reduction in error .", "We analyze the Embedded Trees algorithm , which solves a sequence of problems on tractable subgraphs thereby leading to the solution of the estimation problem on an intractable graph .", "We show that non-stationary iterations of the Embedded Trees algorithm using any sequence of subgraphs converge in walk-summable models .", "We consider the estimation problem in Gaussian graphical models with arbitrary structure .", "Our analysis is based on the recently developed walk-sum interpretation of Gaussian estimation .", "These adaptive procedures provide a significant speedup in convergence over stationary iterative methods , and also appear to converge in a larger class of models ."]}
{"orig_sents": ["0", "2", "1", "7", "4", "5", "6", "3"], "shuf_sents": ["When predicting class labels for objects within a relational database , it is often helpful to consider a model for relationships : this allows for information between class labels to be shared and to improve prediction performance .", "One traditional way corresponds to a Markov network structure : each existing relation is represented by an undirected edge .", "However , there are different ways by which objects can be related within a relational database .", "A Bayesian nonparametric classification model is built upon this graphical representation and evaluated with several empirical studies .", "However , there is no reason why Markov networks should be the only representation of choice for symmetric dependence structures .", "Here we discuss the case when relationships are postulated to exist due to hidden common causes .", "We discuss how the resulting graphical model differs from Markov networks , and how it describes different types of real-world relational processes .", "This encodes that , conditioned on input features , each object label is independent of other object labels given its neighbors in the graph ."]}
{"orig_sents": ["2", "5", "3", "0", "4", "1"], "shuf_sents": ["Based on this analysis we define the switch-distribution , a modification of the Bayesian model averaging distribution .", "The method is practical ; we give an efficient algorithm .", "Bayesian model averaging , model selection and their approximations such as BIC are generally statistically consistent , but sometimes achieve slower rates of convergence than other methods such as AIC and leave-one-out cross-validation .", "We identify the catch-up phenomenon as a novel explanation for the slow convergence of Bayesian methods .", "We prove that in many situations model selection and prediction based on the switch-distribution is both consistent and achieves optimal convergence rates , thereby resolving the AIC-BIC dilemma .", "On the other hand , these other methods can be inconsistent ."]}
{"orig_sents": ["2", "0", "1", "6", "3", "5", "7", "4"], "shuf_sents": ["However , many of these applications have difficulty with modeling the spatial and temporal structure among visual words , since LDA assumes that a document is a `` bag-of-words '' .", "It is also critical to properly design `` words '' and `` documents '' when using a language model to solve vision problems .", "In recent years , the language model Latent Dirichlet Allocation ( LDA ) , which clusters co-occurring words into topics , has been widely applied in the computer vision field .", "The spatial information is not encoded in the values of visual words but in the design of documents .", "We use SLDA to discover objects from a collection of images , and show it achieves better performance than LDA .", "Instead of knowing the partition of words into documents a priori , the word-document assignment becomes a random hidden variable in SLDA .", "In this paper , we propose a topic model Spatial Latent Dirichlet Allocation ( SLDA ) , which better encodes spatial structures among visual words that are essential for solving many vision problems .", "There is a generative procedure , where knowledge of spatial structure can be flexibly added as a prior , grouping visual words which are close in space into the same document ."]}
{"orig_sents": ["1", "2", "3", "4", "0"], "shuf_sents": ["We show that this type of model is good at capturing the statistics of patches of natural images .", "We describe an efficient learning procedure for multilayer generative models that combine the best aspects of Markov random fields and deep , directed belief nets .", "The generative models can be learned one layer at a time and when learning is complete they have a very fast inference procedure for computing a good approximation to the posterior distribution in all of the hidden layers .", "Each hidden layer has its own MRF whose energy function is modulated by the top-down directed connections from the layer above .", "To generate from the model , each layer in turn must settle to equilibrium given its top-down input ."]}
{"orig_sents": ["0", "1", "5", "4", "3", "2"], "shuf_sents": ["Recent research has studied the role of sparsity in high dimensional regression and signal reconstruction , establishing theoretical limits for recovering sparse models from sparse data .", "In this paper we study a variant of this problem where the original n input variables are compressed by a random linear transformation to m n examples in p dimensions , and establish conditions under which a sparse linear model can be successfully recovered from the compressed data .", "Finally , we characterize the privacy properties of the compression procedure in information-theoretic terms , establishing upper bounds on the rate of information communicated between the compressed and uncompressed data that decay to zero .", "In addition , we show that 1 -regularized compressed regression asymptotically predicts as well as an oracle linear model , a property called `` persistence . ''", "We characterize the number of random projections that are required for 1 -regularized compressed regression to identify the nonzero coefficients in the true model with probability approaching one , a property called `` sparsistence . ''", "A primary motivation for this compression procedure is to anonymize the data and preserve privacy by revealing little information about the original data ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We present a nonparametric Bayesian method of estimating variable order Markov processes up to a theoretically infinite order .", "By extending a stick-breaking prior , which is usually defined on a unit interval , `` vertically '' to the trees of infinite depth associated with a hierarchical Chinese restaurant process , our model directly infers the hidden orders of Markov dependencies from which each symbol originated .", "We expect that this basic model will also extend to the variable order hierarchical clustering of general data .", "Experiments on character and word sequences in natural language showed that the model has a comparative performance with an exponentially large full-order model , while computationally much efficient in both time and space ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["Diffusion processes are a family of continuous-time continuous-state stochastic processes that are in general only partially observed .", "We propose a variational treatment of diffusion processes , which allows us to compute type II maximum likelihood estimates of the parameters by simple gradient techniques and which is computationally less demanding than most MCMC approaches .", "We also show how a cheap estimate of the posterior over the parameters can be constructed based on the variational free energy .", "The joint estimation of the forcing parameters and the system noise ( volatility ) in these dynamical systems is a crucial , but non-trivial task , especially when the system is nonlinear and multimodal ."]}
{"orig_sents": ["4", "0", "2", "1", "3", "6", "5"], "shuf_sents": ["We obtain several new results for this problem .", "Using this generalization , we first derive a nonlinear optimization model to maximize the new agreement measure .", "First , we note that the notion of agreement under such circumstances can be better captured using an agreement measure based on a 2D string encoding rather than voting strategy based methods proposed in literature .", "We then show that our optimization problem can be transformed into a strict 0-1 Semidefinite Program ( SDP ) via novel convexification techniques which can subsequently be relaxed to a polynomial time solvable SDP .", "We consider the ensemble clustering problem where the task is to `aggregate ' multiple clustering solutions into a single consolidated clustering that maximizes the shared information among given clustering solutions .", "We discuss evaluations on clustering and image segmentation databases .", "Our experiments indicate improvements not only in terms of the proposed agreement measure but also the existing agreement measures based on voting strategies ."]}
{"orig_sents": ["2", "4", "1", "3", "5", "0"], "shuf_sents": ["The experimental results on several real-world data sets verify superior learning capacity .", "The inter-dependencies of edges can be effectively modeled by adapting the GP hyper-parameters .", "This paper aims to model relational data on edges of networks .", "The framework suggests an intimate connection between link prediction and transfer learning , which were traditionally two separate research topics .", "We describe appropriate Gaussian Processes ( GPs ) for directed , undirected , and bipartite networks .", "We develop an efficient learning algorithm that can handle a large number of observations ."]}
{"orig_sents": ["1", "2", "0", "3", "4"], "shuf_sents": ["We show that max-product converges to the correct answer if the linear programming ( LP ) relaxation of the weighted matching problem is tight and does not converge if the LP relaxation is loose .", "Loopy belief propagation has been employed in a wide variety of applications with great empirical success , but it comes with few theoretical guarantees .", "In this paper we investigate the use of the max-product form of belief propagation for weighted matching problems on general graphs .", "This provides an exact characterization of max-product performance and reveals connections to the widely used optimization technique of LP relaxation .", "In addition , we demonstrate that max-product is effective in solving practical weighted matching problems in a distributed fashion by applying it to the problem of self-organization in sensor networks ."]}
{"orig_sents": ["2", "3", "1", "0", "4"], "shuf_sents": ["Using an implicit differentiation trick , we derive an efficient gradient-based method for learning Gaussian regularization priors with multiple hyperparameters .", "In this paper , we consider the problem of choosing regularization hyperparameters for log-linear models , a class of structured prediction probabilistic models which includes conditional random fields ( CRFs ) .", "In problems where input features have varying amounts of noise , using distinct regularization hyperparameters for different features provides an effective means of managing model complexity .", "While regularizers for neural networks and support vector machines often rely on multiple hyperparameters , regularizers for structured prediction models ( used in tasks such as sequence labeling or parsing ) typically rely only on a single shared hyperparameter for all features .", "In both simulations and the real-world task of computational RNA secondary structure prediction , we find that multiple hyperparameter learning can provide a significant boost in accuracy compared to using only a single regularization hyperparameter ."]}
{"orig_sents": ["3", "1", "0", "2", "4"], "shuf_sents": ["We propose a sequential model and evaluate its suitability for the generation of the facial animation from a sequence of phonemes , which we obtain from speech .", "The face and sound are modelled separately , with phonemes being the link between both .", "We evaluate the results both by computing the error between generated sequences and real video , as well as with a rigorous double-blind test with human subjects .", "The present work aims to model the correspondence between facial motion and speech .", "Experiments show that our model compares favourably to other existing methods and that the sequences generated are comparable to real video sequences ."]}
{"orig_sents": ["3", "0", "5", "4", "2", "1", "6"], "shuf_sents": ["This is accomplished by making sampling assumptions on a dataset that smoothly interpolate between the extreme of independently distributed ( or id ) sample data ( as in nonparametric kernel density estimators ) to the extreme of independent identically distributed ( or iid ) sample data .", "The proposed isd scheme is an alternative for handling nonstationarity in data without making drastic hidden variable assumptions which often make estimation difficult and laden with local optima .", "Surprisingly , the isd method maintains certain consistency and unimodality properties akin to maximum likelihood estimation .", "A method is proposed for semiparametric estimation where parametric and nonparametric criteria are exploited in density estimation and unsupervised learning .", "The parameter controls a Bhattacharyya affinity penalty between pairs of distributions on samples .", "This article makes independent similarly distributed ( or isd ) sampling assumptions and interpolates between these two using a scalar parameter .", "Experiments in density estimation on a variety of datasets confirm the value of isd over iid estimation , id estimation and mixture modeling ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["This paper describes a new model for human visual classification that enables the recovery of image features that explain human subjects ' performance on different visual classification tasks .", "Unlike previous methods , this algorithm does not model their performance with a single linear classifier operating on raw image pixels .", "Instead , it represents classification as the combination of multiple feature detectors .", "This approach extracts more information about human visual classification than previous methods and provides a foundation for further exploration ."]}
{"orig_sents": ["2", "0", "6", "3", "4", "5", "1"], "shuf_sents": ["Specifically , we start with the variational principle and then bootstrap to produce an updating rule for discounted state value estimates .", "To do this we combine our update equation with both Watkins ' Q ( ) and Sarsa ( ) and find that it again offers superior performance without a learning rate parameter .", "We derive an equation for temporal difference learning from statistical principles .", "In the place of this free parameter there is now an equation for the learning rate that is specific to each state transition .", "We experimentally test this new learning rule against TD ( ) and find that it offers superior performance in various settings .", "Finally , we make some preliminary investigations into how to extend our new temporal difference algorithm to reinforcement learning .", "The resulting equation is similar to the standard equation for temporal difference learning with eligibility traces , so called TD ( ) , however it lacks the parameter that specifies the learning rate ."]}
{"orig_sents": ["3", "4", "1", "0", "2", "5"], "shuf_sents": ["We also show that under the weaker condition of having a small covering number for an optimal reachable space , which is the subset of the belief space reachable under an optimal policy , computing an approximately optimal solution is NP-hard .", "We show that an approximately optimal POMDP solution can be computed in time polynomial in the covering number of a reachable belief space , which is the subset of the belief space reachable from a given belief point .", "However , given a suitable set of points that `` cover '' an optimal reachable space well , an approximate solution can be computed in polynomial time .", "Point-based algorithms have been surprisingly successful in computing approximately optimal solutions for partially observable Markov decision processes ( POMDPs ) in high dimensional belief spaces .", "In this work , we seek to understand the belief-space properties that allow some POMDP problems to be approximated efficiently and thus help to explain the point-based algorithms ' success often observed in the experiments .", "The covering number highlights several interesting properties that reduce the complexity of POMDP planning in practice , e.g. , fully observed state variables , beliefs with sparse support , smooth beliefs , and circulant state-transition matrices ."]}
{"orig_sents": ["2", "3", "5", "6", "0", "1", "4"], "shuf_sents": ["Inference can be done at this speed by combining a mean-field variational approximation and the use of stochastic gradient descent to optimize a variational cost function .", "We use this fast inference to diagnose a time series of anomalous HTTP requests taken from a real web service .", "Web servers on the Internet need to maintain high reliability , but the cause of intermittent failures of web transactions is non-obvious .", "We use approximate Bayesian inference to diagnose problems with web services .", "The inference is fast enough to analyze network logs with billions of entries in a matter of hours .", "This diagnosis problem is far larger than any previously attempted : it requires inference of 104 possible faults from 105 observations .", "Further , such inference must be performed in less than a second ."]}
{"orig_sents": ["0", "4", "2", "1", "3", "6", "5"], "shuf_sents": ["We study the problem of an apprentice learning to behave in an environment with an unknown reward function by observing the behavior of an expert .", "However , unlike their algorithm , we show that ours may produce a policy that is substantially better than the expert 's .", "We give a new algorithm that , like theirs , is guaranteed to learn a policy that is nearly as good as the expert 's , given enough examples .", "Moreover , our algorithm is computationally faster , is easier to implement , and can be applied even in the absence of an expert .", "We follow on the work of Abbeel and Ng who considered a framework in which the true reward function is assumed to be a linear combination of a set of known and observable features .", "In addition to our formal presentation and analysis of the new algorithm , we sketch how the method can be applied when the transition function itself is unknown , and we provide an experimental demonstration of the algorithm on a toy video-game environment .", "The method is based on a game-theoretic view of the problem , which leads naturally to a direct application of the multiplicative-weights algorithm of Freund and Schapire for playing repeated matrix games ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["This article discusses a latent variable model for inference and prediction of symmetric relational data .", "The model , based on the idea of the eigenvalue decomposition , represents the relationship between two nodes as the weighted inner-product of node-specific vectors of latent characteristics .", "The practical implications of this are examined in the context of three real datasets , for which the eigenmodel has as good or better out-of-sample predictive performance than the other two models .", "This `` eigenmodel '' generalizes other popular latent variable models , such as latent class and distance models : It is shown mathematically that any latent class or distance model has a representation as an eigenmodel , but not vice-versa ."]}
{"orig_sents": ["6", "3", "1", "4", "0", "5", "2"], "shuf_sents": ["The optimization is formulated to maximize the discriminative classification performance of the target classifier , while also taking the unlabeled data into account .", "Recently a few batch mode active learning approaches have been proposed that select a set of most informative unlabeled instances in each iteration under the guidance of heuristic scores .", "Our empirical studies on UCI datasets show that the proposed active learning is more effective than current state-of-the art batch mode active learning algorithms .", "Most previous studies in active learning have focused on selecting one unlabeled instance to label at a time while retraining in each iteration .", "In this paper , we propose a discriminative batch mode active learning approach that formulates the instance selection task as a continuous optimization problem over auxiliary instance selection variables .", "Although the objective is not convex , we can manipulate a quasi-Newton method to obtain a good local solution .", "Active learning sequentially selects unlabeled instances to label with the goal of reducing the effort needed to learn a good classifier ."]}
{"orig_sents": ["2", "0", "3", "4", "1"], "shuf_sents": ["However , realistic systems are analytically intractable and they have traditionally been analysed using simulation based techniques , which do not provide a framework for statistical inference .", "We illustrate our approach on two biologically motivated systems .", "Markov jump processes play an important role in a large number of application domains .", "We propose a mean field approximation to perform posterior inference and parameter estimation .", "The approximation allows a practical solution to the inference problem , while still retaining a good degree of accuracy ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["The control of high-dimensional , continuous , non-linear dynamical systems is a key problem in reinforcement learning and control .", "Local , trajectory-based methods , using techniques such as Differential Dynamic Programming ( DDP ) , are not directly subject to the curse of dimensionality , but generate only local controllers .", "In this paper , we introduce Receding Horizon DDP ( RH-DDP ) , an extension to the classic DDP algorithm , which allows us to construct stable and robust controllers based on a library of local-control trajectories .", "We demonstrate the effectiveness of our approach on a series of high-dimensional problems using a simulated multi-link swimming robot .", "These experiments show that our approach effectively circumvents dimensionality issues , and is capable of dealing with problems of ( at least ) 24 state and 9 action dimensions ."]}
{"orig_sents": ["1", "3", "0", "4", "2"], "shuf_sents": ["We introduce a new general formulation of simulated annealing which allows one to guarantee finite-time performance in the optimization of functions of continuous variables .", "Simulated annealing is a popular method for approaching the solution of a global optimization problem .", "This work is inspired by the concept of finite-time learning with known accuracy and confidence developed in statistical learning theory .", "Existing results on its performance apply to discrete combinatorial optimization where the optimization variables can assume only a finite set of possible values .", "The results hold universally for any optimization problem on a bounded domain and establish a connection between simulated annealing and up-to-date theory of convergence of Markov chain Monte Carlo methods on continuous domains ."]}
{"orig_sents": ["0", "1", "5", "4", "2", "3", "6"], "shuf_sents": ["It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state , integrate information from multiple sensory modalities , form predictions and choose actions .", "What is less clear is how these putative computations are implemented by cortical neural networks .", "Much of this work , however , uses various approximations , which severely restrict the domain of applicability of these implementations .", "Here we make use of rigorous mathematical results from the theory of continuous time point process filtering , and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks .", "A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible `` world states '' .", "An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents , rather than directly .", "We demonstrate the applicability of the approach with several examples , and relate the required network properties to the statistical nature of the environment , thereby quantifying the compatibility of a given network with its environment ."]}
{"orig_sents": ["3", "2", "0", "6", "1", "10", "8", "9", "4", "5", "7"], "shuf_sents": ["Using the expectation propagation algorithm , we are able to approximate the full posterior distribution over all weights .", "Therefore , stimulus features that do not critically influence neural activity will be assigned zero weights and thus be effectively excluded by the model .", "Here we present a Bayesian treatment of such models .", "Generalized linear models are the most commonly used tools to describe the stimulus selectivity of sensory neurons .", "In such a situation , both regularization by a sparsity prior and uncertainty estimates for the model parameters are essential .", "We apply our method to multi-electrode recordings of retinal ganglion cells and use our uncertainty estimate to test the statistical significance of functional couplings between neurons .", "In addition , we use a Laplacian prior to favor sparse solutions .", "Furthermore we used the sparsity of the Laplace prior to select those filters from a spike-triggered covariance analysis that are most informative about the neural response .", "The posterior distribution can be used to obtain confidence intervals which makes it possible to assess the statistical significance of the solution .", "In neural data analysis , the available amount of experimental measurements is often limited whereas the parameter space is large .", "This feature selection mechanism facilitates both the interpretation of the neuron model as well as its predictive abilities ."]}
{"orig_sents": ["3", "7", "1", "8", "4", "5", "2", "6", "0", "9"], "shuf_sents": ["Control is thus cast as probabilistic inference , not optimization .", "To prioritize search , GS assigns saliency to locations in the visual field .", "We propose a principled probabilistic formulation of GS , called Experience-Guided Search ( EGS ) , based on a generative model of the environment that makes three claims : ( 1 ) Feature detectors produce Poisson spike trains whose rates are conditioned on feature type and whether the feature belongs to a target or distractor ; ( 2 ) the environment and/or task is nonstationary and can change over a sequence of trials ; and ( 3 ) a prior specifies that features are more likely to be present for target than for distractors .", "People perform a remarkable range of tasks that require search of the visual environment for a target item among distractors .", "GS includes heuristics for setting the gain coefficient associated with each map .", "Variants of GS have formalized the notion of optimization as a principle of attentional control ( e.g. , Baldwin & Mozer , 2006 ; Cave , 1999 ; Navalpakkam & Itti , 2006 ; Rao et al. , 2002 ) , but every GS-like model must be 'dumbed down ' to match human data , e.g. , by corrupting the saliency map with noise and by imposing arbitrary restrictions on gain modulation .", "Through experience , EGS infers latent environment variables that determine the gains for guiding search .", "The Guided Search model ( Wolfe , 1994 , 2007 ) , or GS , is perhaps the best developed psychological account of human visual search .", "Saliency is a linear combination of activations from retinotopic maps representing primitive visual features .", "We show that EGS can replicate a range of human data from visual search , including data that GS does not address ."]}
{"orig_sents": ["0"], "shuf_sents": ["We provide provably privacy-preserving versions of belief propagation , Gibbs sampling , and other local algorithms -- distributed multiparty protocols in which each party or vertex learns only its final local value , and absolutely nothing else ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["This work shows that , surprisingly , for appropriate reference sets G , thedeviation convergence rate of the progressive mixture rule is no better than Cst / n : it fails to achieve the expected Cst /n .", "If R ( g ) denotes the generalization error of a prediction function g , under reasonable assumptions on the loss function ( typically satisfied by the least square loss when the output is bounded ) , it is known that the progressive mixture rule g satisfies ( 1 ) ER ( g ) mingG R ( g ) + Cst log |G| , n where n denotes the size of the training set , and E denotes the expectation w.r.t . the training set distribution.", "We also provide an algorithm which does not suffer from this drawback , and which is optimal in both deviation and expectation convergence rates .", "We consider the learning task consisting in predicting as well as the best function in a finite reference set G up to the smallest possible additive term ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["Two novel kernels on neighborhoods are proposed , one evaluating the attribute similarity and the other evaluating shape similarity .", "Shape similarity function is motivated from spectral graph matching techniques .", "The embedding gives the notion of neighborhood , which is used to define positive semidefinite kernels on pointsets .", "This paper introduces kernels on attributed pointsets , which are sets of vectors embedded in an euclidean space .", "The kernels are tested on three real life applications : face recognition , photo album tagging , and shot annotation in video sequences , with encouraging results ."]}
{"orig_sents": ["3", "0", "2", "4", "1"], "shuf_sents": ["Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm .", "We present experimental results for Web search using data from a commercial search engine that show signicant improvements of our proposed methods over some existing methods .", "More importantly , this general framework enables us to use a standard regression base learner such as single regression tree for tting any loss function .", "We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems .", "We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training ."]}
{"orig_sents": ["0", "1", "4", "2", "3", "5"], "shuf_sents": ["Extensive games are a powerful model of multiagent decision-making scenarios with incomplete information .", "Finding a Nash equilibrium for very large instances of these games has received a great deal of recent attention .", "In particular , we introduce the notion of counterfactual regret , which exploits the degree of incomplete information in an extensive game .", "We show how minimizing counterfactual regret minimizes overall regret , and therefore in self-play can be used to compute a Nash equilibrium .", "In this paper , we describe a new technique for solving large games based on regret minimization .", "We demonstrate this technique in the domain of poker , showing we can solve abstractions of limit Texas Hold'em with as many as 1012 states , two orders of magnitude larger than previous methods ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["Maximum variance unfolding ( MVU ) is an effective heuristic for dimensionality reduction .", "We show that MVU also optimizes a statistical dependence measure which aims to retain the identity of individual observations under the distancepreserving constraints .", "subject to class labels or other side information .", "It produces a low-dimensional representation of the data by maximizing the variance of their embeddings while preserving the local distances of the original data .", "This general view allows us to design `` colored '' variants of MVU , which produce low-dimensional representations for a given task , e.g ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["We compare its performance with state-of-the-art algorithms including the max-product belief propagation , its sequential tree-reweighted variant , residual ( sum-product ) belief propagation , and tree-structured expectation propagation .", "We show that it outperforms all approaches for Ising models with mixed couplings , as well as on a web person disambiguation task formulated as a supervised clustering problem .", "We describe a new algorithm , Relaxed Survey Propagation ( RSP ) , for finding MAP configurations in Markov random fields ."]}
{"orig_sents": ["0", "1", "2", "3", "5", "4"], "shuf_sents": ["We present a probability distribution over non-negative integer valued matrices with possibly an infinite number of columns .", "We also derive a stochastic process that reproduces this distribution over equivalence classes .", "This model can play the role of the prior in nonparametric Bayesian learning scenarios where multiple latent features are associated with the observed data and each feature can have multiple appearances or occurrences within each data point .", "Such data arise naturally when learning visual object recognition systems from unlabelled images .", "Inference with this model is carried out using a Markov chain Monte Carlo algorithm .", "Together with the nonparametric prior we consider a likelihood model that explains the visual appearance and location of local image patches ."]}
{"orig_sents": ["2", "1", "0", "4", "5", "3"], "shuf_sents": ["words in documents or features in images ) .", "This class of infinite state Bayes nets ( ISBN ) can be viewed as directed networks of `hierarchical Dirichlet processes ' ( HDPs ) where the domain of the variables can be structured ( e.g .", "A general modeling framework is proposed that unifies nonparametric-Bayesian models , topic-models and Bayesian networks .", "Two experiments have been performed to illustrate these ideas .", "We show that collapsed Gibbs sampling can be done efficiently in these models by leveraging the structure of the Bayes net and using the forward-filtering-backward-sampling algorithm for junction trees .", "Existing models , such as nested-DP , Pachinko allocation , mixed membership stochastic block models as well as a number of new models are described as ISBNs ."]}
{"orig_sents": ["2", "4", "3", "0", "1", "5"], "shuf_sents": ["We argue here for the normative appropriateness of an additional , but so far marginalized control system , associated with episodic memory , and involving the hippocampus and medial temporal cortices .", "We analyze in depth a class of simple environments to show that episodic control should be useful in a range of cases characterized by complexity and inferential noise , and most particularly at the very early stages of learning , long before habitization has set in .", "Recent experimental studies have focused on the specialization of different neural structures for different types of instrumental behavior .", "Two particlar controllers have been identified , one associated with a forward model and the prefrontal cortex and a second associated with computationally simpler , habitual , actor-critic methods and part of the striatum .", "Recent theoretical work has provided normative accounts for why there should be more than one control system , and how the output of different controllers can be integrated .", "We interpret data on the transfer of control from the hippocampus to the striatum in the light of this hypothesis ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["Despite this currency , the question of how sparse or how over-complete a sparse representation should be , has gone without principled answer .", "Computational models of visual cortex , and in particular those based on sparse coding , have enjoyed much recent attention .", "Having validated our methods on toy data , we find that natural images are indeed best modelled by extremely sparse distributions ; although for the Student-t prior , the associated optimal basis size is only modestly over-complete .", "Here , we use Bayesian model-selection methods to address these questions for a sparse-coding model based on a Student-t prior ."]}
{"orig_sents": ["3", "6", "8", "2", "7", "9", "5", "4", "0", "1"], "shuf_sents": ["More interestingly , in a quantitative comparison , the encoding of these more complex `` corner '' features matches well with the results from the Ito & Komatsu 's study of biological V2 responses .", "This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features .", "Specifically , we develop a sparse variant of the deep belief networks of Hinton et al .", "Motivated in part by the hierarchical organization of the cortex , a number of algorithms have recently been proposed that try to learn hierarchical , or `` deep , '' structure from unlabeled data .", "Specifically , it picks up both colinear ( `` contour '' ) features as well as corners and junctions .", "Further , the second layer in our model encodes correlations of the first layer responses in the data .", "While several authors have formally or informally compared their algorithms to computations performed in visual area V1 ( and the cochlea ) , little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hierarchy .", "( 2006 ) .", "This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2 .", "We learn two layers of nodes in the network , and demonstrate that the first layer , similar to prior work on sparse coding and ICA , results in localized , oriented , edge filters , similar to the Gabor functions known to model V1 cell receptive fields ."]}
{"orig_sents": ["6", "1", "5", "4", "3", "2", "0"], "shuf_sents": ["This simple classification criterion and its kernel and local versions perform competitively against existing classifiers on both synthetic examples and real imagery data such as handwritten digits and human faces , without requiring domain-specific information .", "The criterion assigns a test sample to the class that uses the minimum number of additional bits to code the test sample , subject to an allowable distortion .", "Compression also provides a uniform means of handling classes of varying dimension .", "Minimizing the lossy coding length induces a regularization effect which stabilizes the ( implicit ) density estimate in a small-sample setting .", "Theoretical results provide new insights into relationships among popular classifiers such as MAP and RDA , as well as unsupervised clustering methods based on lossy compression .", "We prove asymptotic optimality of this criterion for Gaussian data and analyze its relationships to classical classifiers .", "We present a simple new criterion for classification , based on principles from lossy data compression ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["Our algorithms are analogous to the classical Viterbi algorithm for Hidden Markov Models , which finds the single most probable sample path given a sequence of observations .", "We investigate a family of inference problems on Markov models , where many sample paths are drawn from a Markov chain and partial information is revealed to an observer who attempts to reconstruct the sample paths .", "Our work is motivated by an important application in ecology : inferring bird migration paths from a large database of observations .", "We present algorithms and hardness results for several variants of this problem which arise by revealing different information to the observer and imposing different requirements for the reconstruction of sample paths ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We summarize the implementation of an analog VLSI chip hosting a network of 32 integrate-and-fire ( IF ) neurons with spike-frequency adaptation and 2,048 Hebbian plastic bistable spike-driven stochastic synapses endowed with a selfregulating mechanism which stops unnecessary synaptic changes .", "The synaptic matrix can be flexibly configured and provides both recurrent and AER-based connectivity with external , AER compliant devices .", "We demonstrate the ability of the network to efficiently classify overlapping patterns , thanks to the self-regulating mechanism ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We present a novel Bayesian model for semi-supervised part-of-speech tagging .", "Our model extends the Latent Dirichlet Allocation model and incorporates the intuition that words ' distributions over tags , p ( t|w ) , are sparse .", "Our model outperforms the best previously proposed model for this task on a standard dataset .", "In addition we introduce a model for determining the set of possible tags of a word which captures important dependencies in the ambiguity classes of words ."]}
{"orig_sents": ["1", "3", "4", "0", "2"], "shuf_sents": ["The importance sampling step is performed on the basis of the values learned by the critic , while the resampling step modifies the actor 's policy .", "Learning in real-world domains often requires to deal with continuous state and action spaces .", "The proposed approach has been empirically compared to other learning algorithms into several domains ; in this paper , we report results obtained in a control problem consisting of steering a boat across a river .", "Although many solutions have been proposed to apply Reinforcement Learning algorithms to continuous state problems , the same techniques can be hardly extended to continuous action spaces , where , besides the computation of a good approximation of the value function , a fast method for the identification of the highest-valued action is needed .", "In this paper , we propose a novel actor-critic approach in which the policy of the actor is estimated through sequential Monte Carlo methods ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["Furthermore , we show strong optimality of the algorithm .", "We study the rates of growth of the regret in online convex optimization .", "First , we show that a simple extension of the algorithm of Hazan et al eliminates the need for a priori knowledge of the lower bound on the second derivatives of the observed functions .", "We then provide an algorithm , Adaptive Online Gradient Descent , which interpolates between the results of Zinkevich for linear functions and of Hazan et al for strongly convex functions , achieving intermediate rates between T and log T .", "Finally , we provide an extension of our results to general norms ."]}
{"orig_sents": ["7", "6", "2", "1", "9", "0", "4", "3", "5", "8"], "shuf_sents": ["In particular , we build effective models based on the decorrelated components of cognitive activity in the classically-defined Brodmann areas .", "We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction .", "Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction .", "Direct sensory experience resulted in the most robust predictions , with the highest correlation ( c 0.8 ) between the predicted and experienced time series of verbal instructions .", "For some of the stimuli , the top predictive areas were surprisingly transparent , including Wernicke 's area for verbal instructions , visual cortex for facial and body features , and visual-temporal regions for velocity .", "Techniques based on non-linear dimensionality reduction ( Laplacian eigenmaps ) performed similarly .", "One approach towards illuminating the connection between fMRI and cognitive function is through decoding ; how do the time series of voxel activities combine to provide information about internal and external experience ?", "Functional Magnetic Resonance Imaging ( fMRI ) provides dynamical access into the complex functioning of the human brain , detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points .", "The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic , natural experience .", "We find that the prediction of complex stimuli is remarkably low-dimensional , saturating with less than 100 features ."]}
{"orig_sents": ["3", "5", "4", "0", "2", "1"], "shuf_sents": ["is a strong PAC learner , albeit within the filtering setting .", "Empirically , our algorithm proves more robust to noise and overfitting than batch boosters in conditional probability estimation and proves competitive in classification .", "Our proofs demonstrate the algorithm 's strong theoretical properties for both classification and conditional probability estimation , and we validate these results through extensive experiments .", "We study boosting in the filtering setting , where the booster draws examples from an oracle instead of using a fixed training set and so may train efficiently on very large datasets .", "Moreover , we give the first proof that the algorithm of Collins et al .", "Our algorithm , which is based on a logistic regression technique proposed by Collins , Schapire , & Singer , requires fewer assumptions to achieve bounds equivalent to or better than previous work ."]}
{"orig_sents": ["5", "1", "4", "0", "6", "3", "2"], "shuf_sents": ["Those parameters quantify the synchrony of oscillatory events , and hence , they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony .", "SES may be applied to generic one-dimensional and multi-dimensional point processes , however , the paper mainly focusses on point processes in time-frequency domain .", "The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment ( MCI ) patients ; the results indicate that SES significantly improves the sensitivity of EEG in detecting MCI .", "The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori ( MAP ) estimation .", "The average event similarity is in that case described by two parameters : the average frequency offset between events in the time-frequency plane , and the variance of the frequency offset ( `` frequency jitter '' ) ; SES then consists of five parameters in total .", "A novel approach to measure the interdependence of two time series is proposed , referred to as `` stochastic event synchrony '' ( SES ) ; it quantifies the alignment of two point processes by means of the following parameters : time delay , variance of the timing jitter , fraction of `` spurious '' events , and average similarity of events .", "The pairwise alignment of point processes is cast as a statistical inference problem , which is solved by applying the maxproduct algorithm on a graphical model ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways .", "Small-scale learning problems are subject to the usual approximation-estimation tradeoff .", "The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems .", "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["The approach delivers impressive out-of-sample risk-adjusted returns after transaction costs on a portfolio of 30 spreads .", "By virtue of using Gaussian processes , a complete covariance matrix between forecasts at several time-steps is available .", "This information is put to use in an application to actively trade price spreads between commodity futures contracts .", "We introduce a functional representation of time series which allows forecasts to be performed over an unspecified horizon with progressively-revealed information sets ."]}
{"orig_sents": ["2", "1", "0", "4", "3", "5"], "shuf_sents": ["Our algorithm extends the simple scheme of Cohn , Atlas , and Ladner to the agnostic setting , using reductions to supervised learning that harness generalization bounds in a simple but subtle manner .", "Most previous work on active learning either makes strong distributional assumptions , or else is computationally prohibitive .", "We present an agnostic active learning algorithm for any hypothesis class of bounded VC dimension under arbitrary data distributions .", "Our analysis yields asymptotic label complexity improvements for certain hypothesis classes and distributions .", "We provide a fall-back guarantee that bounds the algorithm 's label complexity by the agnostic PAC sample complexity .", "We also demonstrate improvements experimentally ."]}
{"orig_sents": ["1", "4", "0", "2", "5", "3"], "shuf_sents": ["The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic .", "We propose a method for reconstruction of human brain states directly from functional neuroimaging data .", "Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function first .", "Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus .", "The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements , facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging .", "Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data ."]}
{"orig_sents": ["1", "0", "6", "4", "3", "5", "2"], "shuf_sents": ["The representation makes use of the summarization principle so that lower level nodes in the graph only pass on summary statistics to the higher level nodes .", "In this paper we formulate a novel AND/OR graph representation capable of describing the different configurations of deformable articulated objects such as horses .", "We demonstrate that the algorithm is fast and comparable with the state of the art approaches .", "The strategy of surround suppression is applied to ensure that the inference time is polynomial in the size of input data .", "We develop a novel inference algorithm that combined a bottom-up process for proposing configurations for horses together with a top-down process for refining and validating these proposals .", "The algorithm was applied to the tasks of detecting , segmenting and parsing horses .", "The probability distributions are invariant to position , orientation , and scale ."]}
{"orig_sents": ["3", "5", "2", "1", "0", "4"], "shuf_sents": ["We test sLDA on two real-world problems : movie ratings predicted from reviews , and web page popularity predicted from text descriptions .", "Prediction problems motivate this research : we use the fitted model to predict response values for new documents .", "We derive a maximum-likelihood procedure for parameter estimation , which relies on variational approximations to handle intractable posterior expectations .", "We introduce supervised latent Dirichlet allocation ( sLDA ) , a statistical model of labelled documents .", "We illustrate the benefits of sLDA versus modern regularized regression , as well as versus an unsupervised LDA analysis followed by a separate regression .", "The model accommodates a variety of response types ."]}
{"orig_sents": ["3", "5", "1", "6", "0", "2", "4"], "shuf_sents": ["OLP is closely related to an algorithm proposed by Burnetas and Katehakis with four key differences : OLP is simpler , it does not require knowledge of the supports of transition probabilities , the proof of the regret bound is simpler , but our regret bound is a constant factor larger than the regret of their algorithm .", "It chooses actions by optimistically maximizing estimated future rewards over a set of next-state transition probabilities that are close to the estimates , a computation that corresponds to solving linear programs .", "OLP is also similar in flavor to an algorithm recently proposed by Auer and Ortner .", "We present an algorithm called Optimistic Linear Programming ( OLP ) for learning to optimize average reward in an irreducible but otherwise unknown Markov decision process ( MDP ) .", "But OLP is simpler and its regret bound has a better dependence on the size of the MDP .", "OLP uses its experience so far to estimate the MDP .", "We show that the total expected reward obtained by OLP up to time T is within C ( P ) log T of the reward obtained by the optimal policy , where C ( P ) is an explicit , MDP-dependent constant ."]}
{"orig_sents": ["5", "1", "3", "2", "0", "4"], "shuf_sents": ["Using five real-world text corpora we show that distributed learning works very well for LDA models , i.e. , perplexity and precision-recall scores for distributed learning are indistinguishable from those obtained with single-processor learning .", "We propose two distributed inference schemes that are motivated from different perspectives .", "The second scheme relies on a hierarchical Bayesian extension of the standard LDA model to directly account for the fact that data are distributed across processors -- it has a theoretical guarantee of convergence but is more complex to implement than the approximate method .", "The first scheme uses local Gibbs sampling on each processor with periodic updates -- it is simple to implement and can be viewed as an approximation to a single processor implementation of Gibbs sampling .", "Our extensive experimental results include large-scale distributed computation on 1000 virtual processors ; and speedup experiments of learning topics in a 100-million word corpus using 16 processors .", "We investigate the problem of learning a widely-used latent-variable model - the Latent Dirichlet Allocation ( LDA ) or `` topic '' model - using distributed computation , where each of processors only sees of the total data set ."]}
{"orig_sents": ["1", "4", "5", "7", "6", "3", "2", "0"], "shuf_sents": ["Our results indicate that a ) the overall playing strength has increased over the past 150 years , and b ) that modelling a player 's ability to force a draw provides significantly better predictive power .", "We extend the Bayesian skill rating system TrueSkill to infer entire time series of skills of players by smoothing through time instead of filtering .", "Results include plots of players ' lifetime skill development as well as the ability to compare the skills of different players across time .", "Based on these models we present an analysis of the skill curves of important players in the history of chess over the past 150 years .", "The skill of each participating player , say , every year is represented by a latent skill variable which is affected by the relevant game outcomes that year , and coupled with the skill variables of the previous and subsequent year .", "Inference in the resulting factor graph is carried out by approximate message passing ( EP ) along the time series of skills .", "We extend the system to estimate player-specific draw margins .", "As before the system tracks the uncertainty about player skills , explicitly models draws , can deal with any number of competing entities and can infer individual skills from team results ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We describe two experiments that test our approach , and show that it provides a better account of human learning and reasoning than an approach developed by Goodman .", "Much of human knowledge is organized into sophisticated systems that are often called intuitive theories .", "We propose that intuitive theories are mentally represented in a logical language , and that the subjective complexity of a theory is determined by the length of its representation in this language .", "This complexity measure helps to explain how theories are learned from relational data , and how they support inductive inferences about unobserved relations ."]}
{"orig_sents": ["5", "3", "0", "6", "7", "2", "4", "1"], "shuf_sents": ["Our goal is to extend these ideas to the more general Partially Observable MDP ( POMDP ) framework , where the state is a hidden variable .", "Empirical results on two domains show that the model estimate and agent 's return improve over time , as the agent learns better model estimates .", "We show how the model can be finitely approximated while preserving the value function .", "However most investigations of Bayesian reinforcement learning to date focus on the standard Markov Decision Processes ( MDPs ) .", "We describe approximations for belief tracking and planning in this model .", "Bayesian Reinforcement Learning has generated substantial interest recently , as it provides an elegant solution to the exploration-exploitation trade-off in reinforcement learning .", "To address this problem , we introduce a new mathematical model , the Bayes-Adaptive POMDP .", "This new model allows us to ( 1 ) improve knowledge of the POMDP domain through interaction with the environment , and ( 2 ) plan optimal sequences of actions which can tradeoff between improving the model , identifying the state , and gathering reward ."]}
{"orig_sents": ["3", "2", "4", "6", "0", "1", "5"], "shuf_sents": ["Based upon this confidence measure , we propose an algorithm for disparity estimation that uses many populations of high-resolution phase-tuned neurons that are biased to different disparity ranges via position shifts between the left and right eye receptive fields .", "The population with the highest confidence is used to estimate the stimulus disparity .", "Unfortunately , the disparity range covered by a phasetuned population is limited by phase wraparound .", "The peak location in a population of phase-tuned neurons has been shown to be a more reliable estimator for disparity than the peak location in a population of position-tuned neurons .", "Thus , a single population can not cover the large range of disparities encountered in natural scenes unless the scale of the receptive fields is chosen to be very large , which results in very low resolution depth estimates .", "We show that this algorithm outperforms a previously proposed coarse-to-fine algorithm for disparity estimation , which uses disparity estimates from coarse scales to select the populations used at finer scales and can effectively detect occlusions .", "Here we describe a biologically plausible measure of the confidence that the stimulus disparity is inside the range covered by a population of phase-tuned neurons ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Asymptotic null distributions under null hypothesis are derived , and consistency against fixed alternatives is assessed .", "Finally , experimental evidence of the performance of the proposed approach on both artificial and real datasets is provided .", "We propose to investigate test statistics for testing homogeneity based on kernel Fisher discriminant analysis ."]}
{"orig_sents": ["4", "3", "0", "5", "6", "2", "1"], "shuf_sents": ["In sensory coding , however , high-dimensional data is ubiquitous .", "Our results indicate that the statistics of such higher-dimensional measurements exhibit additional structure that are not predicted by pairwise correlations , despite the fact that pairwise correlations explain the lower-dimensional marginal statistics surprisingly well up to the limit of dimensionality where estimation of the full joint distribution is feasible .", "We demonstrate its usefulness by studying natural images with dichotomized pixel intensities .", "Unfortunately , these approaches suffer from their poor scalability to high dimensions .", "Maximum entropy analysis of binary variables provides an elegant way for studying the role of pairwise correlations in neural populations .", "Here , we introduce a new approach using a near-maximum entropy model , that makes this type of analysis feasible for very high-dimensional data -- the model parameters can be derived in closed form and sampling is easy .", "Therefore , our NearMaxEnt approach can serve as a tool for testing predictions from a pairwise maximum entropy model not only for low-dimensional marginals , but also for high dimensional measurements of more than thousand units ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["We compare L1 and L2 regularization and show that L1 regularization is superior , requiring fewer iterations to converge , and yielding sparser solutions .", "We demonstrate that log-linear grammars with latent variables can be practically trained using discriminative methods .", "Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient-based procedure .", "On full-scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non-latent baselines ."]}
{"orig_sents": ["5", "2", "4", "3", "1", "0"], "shuf_sents": ["Supervised learning : regression , kernel methods , sparsity and feature selection .", "Keywords - Optimization : constrained and convex optimization .", "The penalizer is a convex functional that performs soft selection at the group level , and shrinks variables within each group .", "The framework , originally derived for taking prior knowledge into account , is shown to be useful in linear regression , when several parameters are used to model the influence of one feature , or in kernel regression , for learning multiple kernels .", "This favors solutions with few leading terms in the final combination .", "Hierarchical penalization is a generic framework for incorporating prior information in the fitting of statistical models , when the explicative variables are organized in a hierarchical structure ."]}
{"orig_sents": ["3", "0", "2", "4", "1"], "shuf_sents": ["Instead of directly minimizing or stabilizing a nonconvex loss function , our method simultaneously finds the support vectors and a proxy kernel matrix used in computing the loss .", "We compare the performance of our technique with other methods on several data sets .", "This can be interpreted as a robust classification problem where the indefinite kernel matrix is treated as a noisy observation of the true positive semidefinite kernel .", "In this paper , we propose a method for support vector machine classification using indefinite kernels .", "Our formulation keeps the problem convex and relatively large problems can be solved efficiently using the analytic center cutting plane method ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We propose a new measure of conditional dependence of random variables , based on normalized cross-covariance operators on reproducing kernel Hilbert spaces .", "We discuss the theoretical properties of the measure , and demonstrate its application in experiments .", "Unlike previous kernel dependence measures , the proposed criterion does not depend on the choice of kernel in the limit of infinite data , for a wide class of kernels .", "At the same time , it has a straightforward empirical estimate with good convergence behaviour ."]}
{"orig_sents": ["4", "0", "3", "1", "7", "6", "5", "2"], "shuf_sents": ["Often , we want to select observations which perform well when evaluated with an objective function chosen by an adversary .", "In this paper , we present the Submodular Saturation algorithm , a simple and efficient algorithm with strong theoretical approximation guarantees for the case where the possible objective functions exhibit submodularity , an intuitive diminishing returns property .", "For robust experimental design , our algorithm performs favorably compared to SDP-based algorithms .", "Examples include minimizing the maximum posterior variance in Gaussian Process regression , robust experimental design , and sensor placement for outbreak detection .", "In many applications , one has to actively select among a set of expensive observations before making an informed decision .", "For Gaussian Process regression , our algorithm compares favorably with state-of-the-art heuristics described in the geostatistics literature , while being simpler , faster and providing theoretical guarantees .", "We evaluate our algorithm on several real-world problems .", "Moreover , we prove that better approximation algorithms do not exist unless NP-complete problems admit efficient algorithms ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["While Gibbs sampling remains an important method of inference in such models , variational techniques have certain advantages such as easy assessment of convergence , easy optimization without the need to maintain detailed balance , a bound on the marginal likelihood , and side-stepping of issues with topic-identifiability .", "A wide variety of Dirichlet-multinomial `topic ' models have found interesting applications in recent years .", "The most accurate variational technique thus far , namely collapsed variational latent Dirichlet allocation , did not deal with model selection nor did it include inference for hyperparameters .", "Experiments show a significant improvement in accuracy .", "We address both issues by generalizing the technique , obtaining the first variational algorithm to deal with the hierarchical Dirichlet process and to deal with hyperparameters of Dirichlet variables ."]}
{"orig_sents": ["0", "2", "1", "5", "4", "3"], "shuf_sents": ["A recently proposed formulation of the stochastic planning and control problem as one of parameter estimation for suitable artificial statistical models has led to the adoption of inference algorithms for this notoriously hard problem .", "In this paper , we begin by making the crucial observation that the stochastic control problem can be reinterpreted as one of trans-dimensional inference .", "At the algorithmic level , the focus has been on developing Expectation-Maximization ( EM ) algorithms .", "The new approach involves sampling directly from a distribution that is proportional to the reward and , consequently , performs better than classic simulations methods in situations where the reward is a rare event .", "Moreover , it enables us to implement full Bayesian policy search , without the need for gradients and with one single Markov chain .", "With this new interpretation , we are able to propose a novel reversible jump Markov chain Monte Carlo ( MCMC ) algorithm that is more efficient than its EM counterparts ."]}
{"orig_sents": ["1", "4", "0", "3", "2"], "shuf_sents": ["This paper develops a new method for detecting an instance of each minority class via an unsupervised local-density-differential sampling strategy .", "Rare category detection is an open challenge for active learning , especially in the de-novo case ( no labeled examples ) , but of significant practical importance for data mining - e.g .", "Results on both synthetic and real data sets are very positive , detecting each minority class with only a fraction of the actively sampled points required by random sampling and by Pelleg 's Interleave method , the prior best technique in the sparse literature on this topic .", "Essentially a variable-scale nearest neighbor process is used to optimize the probability of sampling tightly-grouped minority classes , subject to a local smoothness assumption of the majority class .", "detecting new financial transaction fraud patterns , where normal legitimate transactions dominate ."]}
{"orig_sents": ["9", "10", "3", "5", "11", "8", "0", "1", "7", "4", "6", "2"], "shuf_sents": ["However , in most realistic situations , one would not expect that the data comes from a parametric mixture distribution with identifiable components .", "There have been recent efforts to analyze the non-parametric situation , for example , `` cluster '' and `` manifold '' assumptions have been suggested as a basis for analysis .", "the contribution of this paper is an analysis of the role of labeled and unlabeled data depending on the amount of imperfection in the model .", "Still our understanding of the theoretical foundations of the usefulness of unlabeled data remains somewhat limited .", "In this paper we investigate an intermediate situation , when the data comes from a probability distribution , which can be modeled , but not perfectly , by an identifiable mixture distribution .", "The simplest and the best understood situation is when the data is described by an identifiable mixture model , and where each class comes from a pure component .", "This seems applicable to many situation , when , for example , a mixture of Gaussians is used to model the data .", "Still , a satisfactory and fairly complete theoretical understanding of the nonparametric problem , similar to that in has not yet been developed .", "One important result was that in certain regimes , labeled data becomes exponentially more valuable than unlabeled data .", "Semi-supervised learning , i.e .", "learning from both labeled and unlabeled data has received significant attention in the machine learning literature in recent years .", "This natural setup and its implications ware analyzed in ."]}
{"orig_sents": ["2", "6", "0", "1", "5", "3", "7", "4"], "shuf_sents": ["The value of this restriction is in its tractable expectation propagation updates , which allow for faster inference and model selection , and better convergence than the standard mixture .", "An additional benefit over the latter method lies in our ability to incorporate knowledge of the noise domain to influence predictions , and to recover with the predictive distribution information about the outlier distribution via the gating process .", "We propose a Gaussian process ( GP ) framework for robust inference in which a GP prior on the mixing weights of a two-component noise model augments the standard process over latent function values .", "We show further how our approach can be used without adjustment for more smoothly heteroscedastic data , and suggest how it could be extended to more general noise models .", ".", "The model has asymptotic complexity equal to that of conventional robust methods , but yields more confident predictions on benchmark problems than classical heavy-tailed models and exhibits improved stability for data with clustered corruptions , for which they fail altogether .", "This approach is a generalization of the mixture likelihood used in traditional robust GP regression , and a specialization of the GP mixture models suggested by Tresp and Rasmussen and Ghahramani .", "We also address similarities with the work of Goldberg et al ."]}
{"orig_sents": ["7", "0", "2", "4", "8", "5", "6", "3", "1"], "shuf_sents": ["In the Bayesian paradigm , one must find a good counterstrategy to the inferred posterior of the other agents ' behavior .", "We also compose the generated strategies in an experts algorithm showing a dramatic improvement in performance over using simple best responses .", "In the experts paradigm , one may want to choose experts that are good counter-strategies to the other agents ' expected behavior .", "We show that the computed poker strategies are substantially more robust than best response counter-strategies , while still exploiting a suspected tendency .", "In this paper we introduce a technique for computing robust counter-strategies for adaptation in multiagent scenarios under a variety of paradigms .", "The technique involves solving a modified game , and therefore can make use of recently developed algorithms for solving very large extensive games .", "We demonstrate the effectiveness of the technique in two-player Texas Hold'em .", "Adaptation to other initially unknown agents often requires computing an effective counter-strategy .", "The strategies can take advantage of a suspected tendency in the decisions of the other agents , while bounding the worst-case performance when the tendency is not observed ."]}
{"orig_sents": ["5", "6", "0", "3", "1", "2", "4"], "shuf_sents": ["Furthermore , the ability to automatically select a small subset of discriminatory features from a large pool can be advantageous in terms of computational speed as well as accuracy .", "The objective function of sVEB combines the unlabeled conditional entropy with labeled conditional pseudo-likelihood .", "It reduces the overall system cost as well as the human labeling cost required during training , which are both important considerations in building real-world inference systems .", "In this paper , we introduce the semi-supervised virtual evidence boosting ( sVEB ) algorithm for training CRFs - a semi-supervised extension to the recently developed virtual evidence boosting ( VEB ) method for feature selection and parameter learning .", "Experiments on synthetic data and real activity traces collected from wearable sensors , illustrate that sVEB benefits from both the use of unlabeled data and automatic feature selection , and outperforms other semi-supervised approaches .", "We present a new and efficient semi-supervised training method for parameter estimation and feature selection in conditional random fields ( CRFs ) .", "In real-world applications such as activity recognition , unlabeled sensor traces are relatively easy to obtain whereas labeled examples are expensive and tedious to collect ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["However the potential and limitations of this learning rule could so far only be tested through computer simulations .", "This article provides tools for an analytic treatment of reward-modulated STDP , which allow us to predict under which conditions reward-modulated STDP will be able to achieve a desired learning effect .", "In particular , we can produce in this way a theoretical explanation and a computer model for a fundamental experimental finding on biofeedback in monkeys ( reported in ) .", "Reward-modulated spike-timing-dependent plasticity ( STDP ) has recently emerged as a candidate for a learning rule that could explain how local learning rules at single synapses support behaviorally relevant adaptive changes in complex networks of spiking neurons ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We combine three threads of research on approximate dynamic programming : sparse random sampling of states , value function and policy approximation using local models , and using local trajectory optimizers to globally optimize a policy and associated value function .", "In this paper we show that we can now solve problems we could n't solve previously .", "Our focus is on finding steady state policies for deterministic time invariant discrete time control problems with continuous states and actions often found in robotics ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["By taking advantage of the SPGP prior covariance structure , we derive a numerically stable algorithm with O ( N M 2 ) training complexity -- asymptotically the same as related sparse methods such as the informative vector machine , but which more faithfully represents the posterior .", "We present an efficient generalization of the sparse pseudo-input Gaussian process ( SPGP ) model developed by Snelson and Ghahramani , applying it to binary classification problems .", "Following , we locate pseudo-inputs by gradient ascent on the marginal likelihood , but exhibit occasions when this is likely to fail , for which we suggest alternative solutions .", "We present experimental results for several benchmark problems showing that in many cases this allows an exceptional degree of sparsity without compromising accuracy ."]}
{"orig_sents": ["3", "5", "1", "4", "2", "0"], "shuf_sents": ["It is to be noted that the algorithm presented here nicely complements existing large scale SVM learning approaches as it can be used to scale up any SVM solver .", "The second contribution is a sampling based algorithm , motivated from randomized algorithms , which solves a SVM problem by considering subsets of the dataset which are greater in size than the number of support vectors for the problem .", "Experiments done on synthetic and real life datasets show that the algorithm does scale up state of the art SVM solvers in terms of memory required and execution time without loss in accuracy .", "This paper investigates the application of randomized algorithms for large scale SVM learning .", "These two ideas are combined to obtain an algorithm for SVM classification problems which performs the learning by considering only O ( log n ) points at a time .", "The key contribution of the paper is to show that , by using ideas random projections , the minimal number of support vectors required to solve almost separable classification problems , such that the solution obtained is near optimal with a very high probability , is given by O ( log n ) ; if on removal of properly chosen O ( log n ) points the data becomes linearly separable then it is called almost separable ."]}
{"orig_sents": ["5", "4", "7", "3", "1", "6", "0", "2"], "shuf_sents": ["Using tools from statistical learning theory we prove that nearest neighbor clustering is statistically consistent .", "As an alternative , we suggest the paradigm of `` nearest neighbor clustering '' .", "Moreover , its worst case complexity is polynomial by construction , and it can be implemented with small average case complexity using branch and bound .", "We argue that the discrete optimization approach usually does not achieve this goal .", "The objective is to find , among all partitions of the data set , the best one according to some quality measure .", "Clustering is often formulated as a discrete optimization problem .", "Instead of selecting the best out of all partitions of the sample , it only considers partitions in some restricted function class .", "However , in the statistical setting where we assume that the finite data set has been sampled from some underlying space , the goal is not to find the best partition of the given sample , but to approximate the true partition of the underlying space ."]}
{"orig_sents": ["1", "4", "2", "0", "5", "3"], "shuf_sents": ["We prove that for a class of attractive binary models , the so-called Bethe approximation associated with any fixed point of loopy BP always lower bounds the true likelihood .", "Variational methods are frequently used to approximate or bound the partition or likelihood function of a Markov random field .", "In general , loopy belief propagation ( BP ) provides often accurate approximations , but not bounds .", "We establish these lower bounds using a loop series expansion due to Chertkov and Chernyak , which we show can be derived as a consequence of the tree reparameterization characterization of BP fixed points .", "Methods based on mean field theory are guaranteed to provide lower bounds , whereas certain types of convex relaxations provide upper bounds .", "Empirically , this bound is much tighter than the naive mean field bound , and requires no further work than running BP ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["Most models of decision-making in neuroscience assume an infinite horizon , which yields an optimal solution that integrates evidence up to a fixed decision threshold ; however , under most experimental as well as naturalistic behavioral settings , the decision has to be made before some finite deadline , which is often experienced as a stochastic quantity , either due to variable external constraints or internal timing uncertainty .", "We use numerical simulations to illustrate the optimal policy in the special cases of a fixed deadline and one that is drawn from a gamma distribution .", "We use dynamic programming tools to show that , for a large class of deadline distributions , the Bayes-optimal solution requires integrating evidence up to a threshold that declines monotonically over time .", "In this work , we formulate this problem as sequential hypothesis testing under a stochastic horizon ."]}
{"orig_sents": ["1", "2", "0", "3", "4"], "shuf_sents": ["To address this problem , we propose solving Transductive SVM via a convex relaxation , which converts the NP-hard problem to a semi-definite programming .", "We consider the problem of Support Vector Machine transduction , which involves a combinatorial problem with exponential computational complexity in the number of unlabeled examples .", "Although several studies are devoted to Transductive SVM , they suffer either from the high computation complexity or from the solutions of local optimum .", "Compared with the other SDP relaxation for Transductive SVM , the proposed algorithm is computationally more efficient with the number of free parameters reduced from O ( n2 ) to O ( n ) where n is the number of examples .", "Empirical study with several benchmark data sets shows the promising performance of the proposed algorithm in comparison with other state-of-the-art implementations of Transductive SVM ."]}
{"orig_sents": ["4", "2", "3", "0", "1"], "shuf_sents": ["We derive a generalization theory for these data structure classes and present simple learning algorithms for both .", "Experimental results reveal that learning often improves on the already strong performance of these data structures .", "We present a general learning framework for the NN problem in which sample queries are used to learn the parameters of a data structure that minimize the retrieval time and/or the miss rate .", "We explore the potential of this novel framework through two popular NN data structures : KD-trees and the rectilinear structures employed by locality sensitive hashing .", "Can we leverage learning techniques to build a fast nearest-neighbor ( ANN ) retrieval data structure ?"]}
{"orig_sents": ["3", "4", "5", "2", "1", "0"], "shuf_sents": ["We compare our method to those of Lacy and Bernstein , with positive results in terms of accuracy , quality of simulated sequences , and efficiency .", "The constraint generation approach leads to noticeable improvement in the quality of simulated sequences .", "We apply our algorithm to the task of learning dynamic textures from image sequences as well as to modeling biosurveillance drug-sales data .", "Stability is a desirable characteristic for linear dynamical systems , but it is often ignored by algorithms that learn these systems from data .", "We propose a novel method for learning stable linear dynamical systems : we formulate an approximation of the problem as a convex program , start with a solution to a relaxed version of the program , and incrementally add constraints to improve stability .", "Rather than continuing to generate constraints until we reach a feasible solution , we test stability at each step ; because the convex program is only an approximation of the desired problem , this early stopping rule can yield a higher-quality solution ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["We employ structured output prediction to optimize directly for ranking scores .", "In this paper , we consider collaborative filtering as a ranking problem .", "We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating .", "Experimental results show that our method gives very good ranking scores and scales well on collaborative filtering tasks ."]}
{"orig_sents": ["4", "5", "0", "1", "6", "2", "3"], "shuf_sents": ["Here , we develop a hybrid computational/behavioral framework , combining simple models for bottom-up salience and top-down relevance , and looking for changes in the predictive power of these components at different critical event times during 4.7 hours ( 500,000 video frames ) of observers playing car racing and flight combat video games .", "This approach is motivated by our observation that the predictive strengths of the salience and relevance models exhibit reliable temporal signatures during critical event windows in the task sequence -- for example , when the game player directly engages an enemy plane in a flight combat game , the predictive strength of the salience model increases significantly , while that of the relevance model decreases significantly .", "Critically , we find that an event detector based on fused behavioral and stimulus information ( in the form of the model 's predictive strength ) is much stronger than detectors based on behavioral information alone ( eye position ) or image information alone ( model prediction maps ) .", "This approach to event detection , based on eye tracking combined with computational models applied to the visual input , may have useful applications as a less-invasive alternative to other event detection approaches based on neural signatures derived from EEG or fMRI recordings .", "Current computational models of bottom-up and top-down components of attention are predictive of eye movements across a range of stimuli and of simple , fixed visual tasks ( such as visual search for a target among distractors ) .", "However , to date there exists no computational framework which can reliably mimic human gaze behavior in more complex environments and tasks , such as driving a vehicle through traffic .", "Our new framework combines these temporal signatures to implement several event detectors ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["This paper proposes constraint propagation relaxation ( CPR ) , a probabilistic approach to classical constraint propagation that provides another view on the whole parametric family of survey propagation algorithms SP ( ) .", "More importantly , the approach elucidates the implicit , but fundamental assumptions underlying SP ( ) , thus shedding some light on its effectiveness and leading to applications beyond k-SAT ."]}
{"orig_sents": ["0", "3", "1", "2", "4"], "shuf_sents": ["We introduce a hierarchical Bayesian model for the discovery of putative regulators from gene expression data only .", "This is implemented through a so-called spike-and-slab prior , a mixture of Gaussians with different widths , with mixing weights from a hierarchical Bernoulli model .", "For efficient inference we implemented expectation propagation .", "The hierarchy incorporates the knowledge that there are just a few regulators that by themselves only regulate a handful of genes .", "Running the model on a malaria parasite data set , we found four genes with significant homology to transcription factors in an amoebe , one RNA regulator and three genes of unknown function ( out of the top ten genes considered ) ."]}
{"orig_sents": ["0", "6", "5", "2", "3", "4", "1", "7"], "shuf_sents": ["Unsupervised learning algorithms aim to discover the structure hidden in the data , and to learn representations that are more suitable as input to a supervised machine than the raw input .", "We demonstrate this method by extracting features from a dataset of handwritten numerals , and from a dataset of natural image patches .", "Others are based on approximating density by stochastically reconstructing the input from the representation .", "We describe a novel and efficient algorithm to learn sparse representations , and compare it theoretically and experimentally with a similar machine trained probabilistically , namely a Restricted Boltzmann Machine .", "We propose a simple criterion to compare and select different unsupervised machines based on the trade-off between the reconstruction error and the information content of the representation .", "low dimension , sparsity , etc ) .", "Many unsupervised methods are based on reconstructing the input from the representation , while constraining the representation to have certain desirable properties ( e.g .", "We show that by stacking multiple levels of such machines and by training sequentially , high-order dependencies between the input observed variables can be captured ."]}
{"orig_sents": ["2", "3", "1", "0", "4"], "shuf_sents": ["This specific type of network is believed to play a major role in shaping cortical responses and selecting the relevant signal among distractors and noise .", "Specifically , we apply this theory to a special class of recurrent networks , often called Cooperative Competitive Networks ( CCNs ) , which are an abstract representation of the cooperative-competitive connectivity observed in cortex .", "A non-linear dynamic system is called contracting if initial conditions are forgotten exponentially fast , so that all trajectories converge to a single trajectory .", "We use contraction theory to derive an upper bound for the strength of recurrent connections that guarantees contraction for complex neural networks .", "In this paper , we analyze contraction of combined CCNs of linear threshold units and verify the results of our analysis in a hybrid analog/digital VLSI CCN comprising spiking neurons and dynamic synapses ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["In this paradigm , parallel sentence-pairs from a parallel document-pair are coupled via a certain semantic-flow , to ensure coherence of topical context in the alignment of mapping words between languages , likelihood-based training of topic-dependent translational lexicons , as well as in the inference of topic representations in each language .", "We present a novel paradigm for statistical machine translation ( SMT ) , based on a joint modeling of word alignment and the topical aspects underlying bilingual document-pairs , via a hidden Markov Bilingual Topic AdMixture ( HM-BiTAM ) .", "Our method integrates the conventional model of HMM -- a key component for most of the state-of-the-art SMT systems , with the recently proposed BiTAM model ; we report an extensive empirical analysis ( in many ways complementary to the description-oriented ) of our method in three aspects : bilingual topic representation , word alignment , and translation .", "The learned HM-BiTAM can not only display topic patterns like methods such as LDA , but now for bilingual corpora ; it also offers a principled way of inferring optimal translation using document context ."]}
{"orig_sents": ["4", "3", "0", "1", "9", "6", "8", "5", "2", "7"], "shuf_sents": ["The auditory system uses information from each of these time-scales to solve complicated tasks such as auditory scene analysis .", "One route toward understanding how auditory processing accomplishes this analysis is to build neuroscienceinspired algorithms which solve similar tasks and to compare the properties of these algorithms with properties of auditory processing .", "The contribution of this work is to develop a new statistical model for natural sounds that captures structure across a wide range of time-scales , and to provide efficient learning and inference algorithms .", "A typical segment of speech , for example , contains features that span four orders of magnitude : Sentences ( 1 s ) ; phonemes ( 10-1 s ) ; glottal pulses ( 10-2 s ) ; and formants ( 10-3 s ) .", "Natural sounds are structured on many time-scales .", "Secondly , it is computationally demanding to simultaneously process data both at high resolution ( to extract short temporal information ) and for long duration ( to extract long temporal information ) .", "The reason for this is two-fold .", "We demonstrate the success of this approach on a missing data task .", "Firstly , it is a difficult technical problem to construct an algorithm that utilises both sorts of information .", "There is however a discord : Current machine-audition algorithms largely concentrate on the shorter time-scale structures in sounds , and the longer structures are ignored ."]}
{"orig_sents": ["4", "1", "2", "5", "3", "0"], "shuf_sents": ["This fundamental insight opens new directions in the assessment of feature similarity , with projected improvements in object and scene recognition algorithms .", "We argue that knowledge on the distribution of distances generated by similarity functions is crucial in deciding whether features are similar or not .", "Intuitively one would expect that similarities between features could arise from any distribution .", "Besides these assumptions being realistic for images , we experimentally show them to hold for various popular feature extraction algorithms , for a diverse range of images .", "Assessing similarity between features is a key step in object recognition and scene categorization tasks .", "In this paper , we will derive the contrary , and report the theoretical result that Lp -norms -a class of commonly applied distance metrics- from one feature vector to other vectors are Weibull-distributed if the feature values are correlated and non-identically distributed ."]}
{"orig_sents": ["7", "8", "4", "6", "3", "5", "0", "9", "1", "2"], "shuf_sents": ["This allows us to deal with intricate relation structures in a systematic way .", "We apply the above idea to support vector machines ( SVMs ) and show that the optimization problem can be cast as a second order cone program , which is convex and can be solved efficiently .", "The usefulness of our approach is demonstrated through simulations with protein super-family classification and ordinal regression problems .", "In this paper , we propose a novel MTL algorithm that can overcome these problems .", "Existing approaches to MTL often treat all the tasks as uniformly related to each other and the relatedness of the tasks is controlled globally .", "Our method makes use of a task network , which describes the relation structure among tasks .", "For this reason , the existing methods can lead to undesired solutions when some tasks are not highly related to each other , and some pairs of related tasks can have significantly different solutions .", "When we have several related tasks , solving them simultaneously is shown to be more effective than solving them individually .", "This approach is called multi-task learning ( MTL ) and has been studied extensively .", "Furthermore , we control the relatedness of the tasks locally , so all pairs of related tasks are guaranteed to have similar solutions ."]}
{"orig_sents": ["3", "1", "5", "0", "6", "2", "4"], "shuf_sents": ["Using a set of boosted classifiers , we map audio features onto social tags collected from the Web .", "In the case of music , social tags have become an important component of `` Web2.0 '' recommender systems , allowing users to generate playlists based on use-dependent terms such as chill or jogging that have been applied to particular songs .", "This avoids the `` cold-start problem '' common in such systems .", "Social tags are user-generated keywords associated with some resource on the Web .", "Autotags can also be used to smooth the tag space from which similarities and recommendations are made by providing a set of comparable baseline tags for all tracks in a recommender system .", "In this paper , we propose a method for predicting these social tags directly from MP3 files .", "The resulting automatic tags ( or autotags ) furnish information about music that is otherwise untagged or poorly tagged , allowing for insertion of previously unheard music into a social recommender ."]}
{"orig_sents": ["8", "7", "3", "2", "5", "1", "4", "6", "0"], "shuf_sents": ["The bandit algorithm we present can be implemented efficiently in special cases of particular interest , such as path planning and Markov Decision Problems .", "It is striking that the convergence rate for the bandit setting is only a factor of n worse than in the full information case -- in stark contrast to the setting , where the gap in the dependence on K is K-arm bandit exponential ( T Kvs .", "For the full information case , the upper bound on the regret is O ( nT ) , where n is the ambient dimension and T is the time horizon .", "In particular , this paper is concerned with the price of bandit information , by which we mean the ratio of the best achievable regret in the bandit setting to that in the full-information setting .", "T log K ) .", "For the bandit case , we present an algorithm which achieves O ( n3/2 T ) regret -- all previous ( nontrivial ) bounds here were O ( poly ( n ) T 2/3 ) or worse .", "We also present lower bounds showing that this gap is at least n , which we conjecture to be the correct order .", "We present sharp rates of convergence ( with respect to additive regret ) for both the full information setting ( where the cost function is revealed at the end of each round ) and the bandit setting ( where only the scalar cost incurred is revealed ) .", "In the online linear optimization problem , a learner must choose , in each round , a decision from a set D Rn in order to minimize an ( unknown and changing ) linear cost function ."]}
{"orig_sents": ["7", "3", "0", "6", "1", "5", "2", "8", "4", "9"], "shuf_sents": ["Moreover , it remains unclear exactly how ARD relates to more traditional MAP estimation-based methods for learning sparse representations ( e.g. , the Lasso ) .", "First , the proposed reformulation of ARD can naturally be optimized by solving a series of re-weighted 1 problems .", "Secondly , the analysis reveals that ARD is exactly equivalent to performing standard MAP estimation in weight space using a particular feature- and noise-dependent , non-factorial weight prior .", "However , popular update rules used for ARD are either difficult to extend to more general problems of interest or are characterized by non-ideal convergence properties .", "Overall these results suggest alternative cost functions and update procedures for selecting features and promoting sparse solutions in a variety of general situations .", "The result is an efficient , extensible algorithm that can be implemented using standard convex programming toolboxes and is guaranteed to converge to a local minimum ( or saddle point ) .", "This paper furnishes an alternative means of expressing the ARD cost function using auxiliary functions that naturally addresses both of these issues .", "Automatic relevance determination ( ARD ) and the closely-related sparse Bayesian learning ( SBL ) framework are effective tools for pruning large numbers of irrelevant features leading to a sparse explanatory subset .", "We then demonstrate that this implicit prior maintains several desirable advantages over conventional priors with respect to feature selection .", "In particular , the methodology readily extends to handle problems such as non-negative sparse coding and covariance component estimation ."]}
{"orig_sents": ["1", "5", "4", "0", "7", "2", "6", "3"], "shuf_sents": ["In this paper , we present an analysis of three such algorithms based on convex relaxations : ( i ) LP - S : the linear programming ( LP ) relaxation proposed by Schlesinger for a special case and independently in for the general case ; ( ii ) QP - RL : the quadratic programming ( QP ) relaxation by Ravikumar and Lafferty ; and ( iii ) SOCP - MS : the second order cone programming ( SOCP ) relaxation first proposed by Muramatsu and Suzuki for two label problems and later extended in for a general label set .", "The problem of obtaining the maximum a posteriori estimate of a general discrete random field ( i.e .", "Furthermore , we prove that despite the flexibility in the form of the constraints/objective function offered by QP and SOCP , the LP - S relaxation strictly dominates ( i.e .", "Based on these results we propose some novel SOCP relaxations which strictly dominate the previous approaches .", "However , due to its central importance in many applications , several approximate algorithms have been proposed in the literature .", "a random field defined using a finite and discrete set of labels ) is known to be NP-hard .", "provides a better approximation than ) QP - RL and SOCP - MS. We generalize these results by defining a large class of SOCP ( and equivalent QP ) relaxations which is dominated by the LP - S relaxation .", "We show that the SOCP - MS and the QP - RL relaxations are equivalent ."]}
{"orig_sents": ["5", "6", "9", "4", "0", "8", "3", "7", "2", "1"], "shuf_sents": ["Our algorithm produces a convex combination of hypotheses whose soft margin is within of its maximum .", "In a benchmark comparison we illustrate the competitiveness of our approach .", "In simulation studies we show that our algorithm converges about as fast as LPBoost , faster than BrownBoost , and much faster than SmoothBoost .", "We compare our algorithm with other approaches including LPBoost , BrownBoost , and SmoothBoost .", "The capping constraints imply a soft margin in the dual optimization problem .", "We present a novel boosting algorithm , called SoftBoost , designed for sets of binary labeled examples that are not necessarily separable by convex combinations of base hypotheses .", "Our algorithm achieves robustness by capping the distributions on the examples .", "We show that there exist cases where the number of iterations required by LPBoost grows linearly in N instead of the logarithmic growth for SoftBoost .", "We employ relative entropy projection methods to prove an O ( ln2N ) iteration bound for our algorithm , where N is number of examples .", "Our update of the distribution is motivated by minimizing a relative entropy subject to the capping constraints and constraints on the edges of the obtained base hypotheses ."]}
{"orig_sents": ["4", "5", "0", "2", "3", "1"], "shuf_sents": ["In contrast , the standard approach to learning the popular proportional hazard ( PH ) model is based on Cox 's partial likelihood .", "We also explain why a method designed to maximize the Cox 's partial likelihood also ends up ( approximately ) maximizing the CI .", "We devise two bounds on CI-one of which emerges directly from the properties of PH models-and optimize them directly .", "Our experimental results suggest that all three methods perform about equally well , with our new approach giving slightly better results .", "In this paper , we show that classical survival analysis involving censored data can naturally be cast as a ranking problem .", "The concordance index ( CI ) , which quantifies the quality of rankings , is the standard performance measure for model assessment in survival analysis ."]}
{"orig_sents": ["6", "1", "4", "0", "3", "5", "2"], "shuf_sents": ["Our first result shows that some common methods based on regularization using graph Laplacians do not lead to faster minimax rates of convergence .", "While existing semi-supervised methods have shown some promising empirical performance , their development has been based largely based on heuristics .", "The statistical tools of minimax analysis are thus used to offer some new perspective on the problem of semi-supervised learning .", "Thus , the estimators that use the unlabeled data do not have smaller risk than the estimators that use only labeled data .", "In this paper we study semi-supervised learning from the viewpoint of minimax theory .", "We then develop several new approaches that provably lead to improved performance .", "Semi-supervised methods use unlabeled data in addition to labeled data to construct predictors ."]}
{"orig_sents": ["7", "2", "1", "6", "5", "4", "8", "9", "0", "3"], "shuf_sents": ["These results show that it 's possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction .", "Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination .", "An elegant approach to improve the accuracy of BCIs consists in a verification procedure directly based on the presence of error-related potentials ( ErrP ) in the EEG recorded right after the occurrence of an error .", "Finally , using a well-known inverse model ( sLORETA ) , we show that the main focus of activity at the occurrence of the ErrP are , as expected , in the pre-supplementary motor area and in the anterior cingulate cortex .", "But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classifier embedded in the BCI .", "These `` Interaction ErrP '' exhibit a first sharp negative peak followed by a positive peak and a second broader negative peak ( 290 , 350 and 470 ms after the feedback , respectively ) .", "This experiment confirms the previously reported presence of a new kind of ErrP .", "Brain-computer interfaces ( BCIs ) , as any other interaction modality based on physiological signals and body channels ( e.g. , muscular activity , speech and gestures ) , are prone to errors in the recognition of subject 's intent .", "We have achieved an average recognition rate of correct and erroneous single trials of 81.8 % and 76.2 % , respectively .", "Furthermore , we have achieved an average recognition rate of the subject 's intent while trying to mentally drive the cursor of 73.1 % ."]}
{"orig_sents": ["2", "0", "6", "5", "4", "3", "1"], "shuf_sents": ["The model consists of two hidden layers : the first layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables .", "In addition , the model demonstrates how feedback from higher levels can influence representations at lower levels as a by-product of inference in a graphical model .", "We describe a hierarchical , probabilistic model that learns to extract complex motion from movies of the natural environment .", "The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT .", "We show that the top layer units encode transformational invariants : they are selective for the speed and direction of a moving pattern , but are invariant to its spatial structure ( orientation/spatial-frequency ) .", "After training on natural movies , the top layer units discover the structure of phase-shifts within the first layer .", "The second layer learns the higher-order structure among the time-varying phase variables ."]}
{"orig_sents": ["5", "1", "0", "4", "3", "2"], "shuf_sents": ["However , message passing in mixture models is not well captured by factor graphs unless the entire mixture is represented by one factor , because the message equations have a containment structure .", "Factor graphs provide a natural representation for message-passing algorithms , such as expectation propagation .", "We present general equations for expectation propagation and variational message passing in the presence of gates .", "Different variational approximations for mixture models can be understood as different ways of drawing the gates in a model .", "Gates capture this containment structure graphically , allowing both the independences and the message-passing equations for a model to be readily visualized .", "Gates are a new notation for representing mixture models and context-sensitive independence in factor graphs ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We present a generative model for performing sparse probabilistic projections , which includes sparse principal component analysis and sparse canonical correlation analysis as special cases .", "We derive a variational Expectation-Maximisation algorithm for the estimation of the hyperparameters and show that our novel probabilistic approach compares favourably to existing techniques .", "We illustrate how the proposed method can be applied in the context of cryptoanalysis as a preprocessing tool for the construction of template attacks .", "Sparsity is enforced by means of automatic relevance determination or by imposing appropriate prior distributions , such as generalised hyperbolic distributions ."]}
{"orig_sents": ["3", "4", "0", "1", "2", "5"], "shuf_sents": ["The paper proves that when an MF is given , PAC learning is possible with no hand-labeled data under certain assumptions .", "We argue that MFs arise naturally in a broad range of textual classification applications .", "On the classic `` 20 Newsgroups '' data set , a learner given an MF and unlabeled data achieves classification accuracy equal to that of a state-of-the-art semi-supervised learner relying on 160 hand-labeled examples .", "Is accurate classification possible in the absence of hand-labeled data ?", "This paper introduces the Monotonic Feature ( MF ) abstraction -- where the probability of class membership increases monotonically with the MF 's value .", "Even when MFs are not given as input , their presence or absence can be determined from a small amount of hand-labeled data , which yields a new semi-supervised learning method that reduces error by 15 % on the 20 Newsgroups data ."]}
{"orig_sents": ["4", "1", "0", "3", "5", "2"], "shuf_sents": ["We propose that infant object perception is guided in part by probabilistic principles like persistence : things tend to remain the same , and when they change they do so gradually .", "Developmental psychologists have provided verbal accounts of the knowledge that supports these inferences , but often these accounts focus on categorical rather than probabilistic principles .", "We support these arguments by modeling several experiments from the developmental literature .", "To illustrate this idea we develop an ideal observer model that incorporates probabilistic principles of rigidity and inertia .", "Before the age of 4 months , infants make inductive inferences about the motions of physical objects .", "Like previous researchers , we suggest that rigid motions are expected from an early age , but we challenge the previous claim that the inertia principle is relatively slow to develop ."]}
{"orig_sents": ["0", "5", "4", "1", "3", "2"], "shuf_sents": ["Semantic hashing seeks compact binary codes of data-points so that the Hamming distance between codewords correlates with semantic similarity .", "By utilizing recent results on convergence of graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of manifolds , we show how to efficiently calculate the code of a novel datapoint .", "Our experiments show that our codes outperform the state-of-the art .", "Taken together , both learning the code and applying it to a novel point are extremely simple .", "By relaxing the original problem , we obtain a spectral method whose solutions are simply a subset of thresholded eigenvectors of the graph Laplacian .", "In this paper , we show that the problem of finding a best code for a given dataset is closely related to the problem of graph partitioning and can be shown to be NP hard ."]}
{"orig_sents": ["5", "1", "4", "3", "2", "0"], "shuf_sents": ["We anticipate that the model will be invaluable in the study of gene expression patterns in other diverse organisms as well , such as worms and insects .", "Recent studies have demonstrated the success of probabilistic models in studying the evolution of gene expression in simple eukaryotic organisms such as yeast , for which measurements are typically scalar and independent .", "We demonstrate the efficacy of our method on a microarray dataset profiling diverse tissues from multiple vertebrate species .", "We present Brownian Factor Phylogenetic Analysis , a statistical model that makes a number of significant extensions to previous models to enable characterization of changes in expression among highly complex organisms .", "Models capable of studying expression evolution in much more complex organisms such as vertebrates are particularly important given the medical and scientific interest in species such as human and mouse .", "We address the challenge of assessing conservation of gene expression in complex , non-homogeneous datasets ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory ; it is beneficial to be able to learn this function for adaptive control .", "A robotic manipulator will often need to be controlled while holding different loads in its end effector , giving rise to a multi-task learning problem .", "Experiments demonstrate that this multi-task formulation is effective in sharing information among the various loads , and generally improves performance over either learning only on single tasks or pooling the data over all tasks .", "By placing independent Gaussian process priors over the latent functions of the inverse dynamics , we obtain a multi-task Gaussian process prior for handling multiple loads , where the inter-task similarity depends on the underlying inertial parameters ."]}
{"orig_sents": ["1", "9", "7", "2", "3", "5", "6", "10", "4", "0", "11", "8"], "shuf_sents": ["The modified LMA performed better than the standard LMA on these problems .", "Many popular optimization algorithms , like the Levenberg-Marquardt algorithm ( LMA ) , use heuristic-based `` controllers '' that modulate the behavior of the optimizer during the optimization process .", "Improving the performance of off-the-shelf optimizers is particularly important for time-constrained optimization problems .", "For example the LMA algorithm has become popular for many real-time computer vision problems , including object tracking from video , where only a small amount of time can be allocated to the optimizer on each incoming video frame .", "This controller was trained on a collection of classic , relatively small , non-linear regression problems .", "Here we show that a popular modern reinforcement learning technique using a very simple state space can dramatically improve the performance of general purpose optimizers , like the LMA .", "Surprisingly the controllers learned for a particular domain also work well in very different optimization domains .", "Reinforcement learning ( RL ) is a machine learning approach to learn optimal controllers from examples and thus is an obvious candidate to improve the heuristic-based controllers implicit in the most popular and heavily used optimization algorithms .", "Thus the controller appeared to have extracted control rules that were not just domain specific but generalized across a range of optimization domains .", "For example , in the LMA a damping parameter is dynamically modified based on a set of rules that were developed using heuristic arguments .", "For example we used RL methods to train a new controller for the damping parameter of the LMA .", "This controller also dramatically outperformed the standard LMA on a difficult computer vision problem for which it had not been trained ."]}
{"orig_sents": ["6", "1", "0", "2", "4", "5", "3"], "shuf_sents": ["The importance values can be used for various succeeding tasks such as non-stationarity adaptation or outlier detection .", "the importance ) .", "In this paper , we propose a new importance estimation method that has a closed-form solution ; the leave-one-out cross-validation score can also be computed analytically .", "Numerical experiments show that the proposed method is comparable to the best existing method in accuracy , while it is computationally more efficient than competing approaches .", "Therefore , the proposed method is computationally very efficient and numerically stable .", "We also elucidate theoretical properties of the proposed method such as the convergence rate and approximation error bound .", "We address the problem of estimating the ratio of two probability density functions ( a.k.a ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["We derive risk bounds for the randomized classifiers in Sample Compression setting where the classifier-specification utilizes two sources of information viz .", "By extending the recently proposed Occam 's Hammer principle to the data-dependent settings , we derive point-wise versions of the bounds on the stochastic sample compressed classifiers and also recover the corresponding classical PAC-Bayes bound .", "the compression set and the message string .", "We further show how these compare favorably to the existing results ."]}
{"orig_sents": ["3", "1", "4", "2", "0", "8", "6", "7", "5"], "shuf_sents": ["The definitions are used to learn a distribution in the latent space that best represents a sense .", "Existing unsupervised approaches do not take word sense into consideration .", "The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary definitions .", "Polysemy is a problem for methods that exploit image search engines to build object category models .", "We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data .", "Category classification experiments show that our dictionarybased approach outperforms baseline methods .", "An object classifier is trained on the resulting sense-specific images .", "We evaluate our method on a dataset obtained by searching the web for polysemous words .", "The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["Maximum-margin parameter estimation for a boundary detection task shows our approach to be efficient and effective .", "A C++ implementation is available from http : //nic.schraudolph.org/isinf/ .", "Our approach provides an interesting alternative to the well-known graph cut paradigm in that it does not impose any submodularity constraints ; instead we require planarity to establish a correspondence with perfect matchings in an expanded dual graph .", "We give polynomial-time algorithms for the exact computation of lowest-energy states , worst margin violators , partition functions , and marginals in certain binary undirected graphical models ."]}
{"orig_sents": ["3", "0", "5", "4", "1", "2"], "shuf_sents": ["Mathematical models for Bayesian decision making typically require datastructures that are hard to implement in neural networks .", "Modulated by reward-signals , this Hebbian plasticity rule also provides a new perspective for understanding how Bayesian inference could support fast reinforcement learning in the brain .", "In particular we show that recent experimental results by Yang and Shadlen on reinforcement learning of probabilistic inference in primates can be modeled in this way .", "Uncertainty is omnipresent when we perceive or interact with our environment , and the Bayesian framework provides computational methods for dealing with it .", "We present a concrete Hebbian learning rule operating on log-probability ratios .", "This article shows that even the simplest and experimentally best supported type of synaptic plasticity , Hebbian learning , in combination with a sparse , redundant neural code , can in principle learn to infer optimal Bayesian decisions ."]}
{"orig_sents": ["1", "6", "0", "3", "5", "2", "7", "8", "4"], "shuf_sents": ["We analyze the high-dimensional scaling of 1 / -regularized quadratic programming , considering both consistency rates in -norm , and also how the minimal sample size n required for performing variable selection grows as a function of the model dimension , sparsity , and overlap between the supports .", "Given a collection of r 2 linear regression problems in p dimensions , suppose that the regression coefficients share partially common supports .", "Our second set of results applies to design matrices drawn from standard Gaussian ensembles , for which we provide a sharp set of necessary and sufficient conditions : the 1 / -regularized method undergoes a phase transition characterized by the rescaled sample size 1 , ( n , p , s , ) = n/ { ( 4 - 3 ) s log ( p - ( 2 - ) s ) } .", "We begin by establishing bounds on the error as well sufficient conditions for exact variable selection for fixed design matrices , as well as designs drawn randomly from general Gaussian matrices .", "We illustrate the close agreement between these theoretical predictions , and the actual behavior in simulations .", "These results show that the high-dimensional scaling of 1 / -regularization is qualitatively similar to that of ordinary 1 -regularization .", "This set-up suggests the use of 1 / -regularized regression for joint estimation of the p x r matrix of regression coefficients .", "More precisely , for any > 0 , the probability of successfully recovering both supports converges to 1 for scalings such that 1 , 1 + , and converges to 0 for scalings for which 1 , 1 - .", "An implication of this threshold is that use of 1 , -regularization yields improved statistical efficiency if the overlap parameter is large enough ( > 2/3 ) , but performs worse than a naive Lasso-based approach for moderate to small overlap ( < 2/3 ) ."]}
{"orig_sents": ["1", "3", "6", "4", "2", "0", "5"], "shuf_sents": ["Our methods are particularly useful for learning control , where reliable estimation of local tangent planes is essential for adaptive controllers and reinforcement learning .", "In kernel-based regression learning , optimizing each kernel individually is useful when the data density , curvature of regression surfaces ( or decision boundaries ) or magnitude of output noise varies spatially .", "It can be used for nonparametric regression with local polynomials or as a novel method to achieve nonstationary regression with Gaussian processes .", "Previous work has suggested gradient descent techniques or complex statistical hypothesis methods for local kernel shaping , typically requiring some amount of manual tuning of meta parameters .", "The algorithm is computationally efficient , requires no sampling , automatically rejects outliers and has only one prior to be specified .", "We evaluate our methods on several synthetic data sets and on an actual robot which learns a task-level control law .", "We introduce a Bayesian formulation of nonparametric regression that , with the help of variational approximations , results in an EM-like algorithm for simultaneous estimation of regression and kernel parameters ."]}
{"orig_sents": ["2", "4", "0", "3", "1"], "shuf_sents": ["In this work we show how a network of spiking neurons is able to self-organize towards a critical state for which the range of possible inter-spike-intervals ( dynamic range ) is maximized .", "The resulting plasticity rule is defined locally so that global homeostasis near the critical state is achieved by local regulation of individual synapses .", "Large networks of spiking neurons show abrupt changes in their collective dynamics resembling phase transitions studied in statistical physics .", "Self-organization occurs via synaptic dynamics that we analytically derive .", "An example of this phenomenon is the transition from irregular , noise-driven dynamics to regular , self-sustained behavior observed in networks of integrate-and-fire neurons as the interaction strength between the neurons increases ."]}
{"orig_sents": ["7", "0", "3", "1", "5", "4", "6", "2"], "shuf_sents": ["Previous inference algorithms for these models are mostly based on Gibbs sampling , which can be very slow , particularly for large-scale data sets .", "Each expert is still a Gaussian process but is reformulated by a linear model .", "A variety of tests show the advantages of our method .", "We present a new generative mixture of experts model .", "Our gating network is more flexible than previous generative approaches as inputs for each expert are modeled by a Gaussian mixture model .", "This breaks the dependency among training outputs and enables us to use a much faster variational Bayesian algorithm for training .", "The number of experts and number of Gaussian components for an expert are inferred automatically .", "Mixture of Gaussian processes models extended a single Gaussian process with ability of modeling multi-modal data and reduction of training complexity ."]}
{"orig_sents": ["2", "0", "1", "4", "3"], "shuf_sents": ["For sufficiently rich ( characteristic ) RKHSs , each probability distribution has a unique embedding , allowing all statistical properties of the distribution to be taken into consideration .", "Necessary and sufficient conditions for an RKHS to be characteristic exist for Rn .", "Embeddings of random variables in reproducing kernel Hilbert spaces ( RKHSs ) may be used to conduct statistical inference based on higher order moments .", "Illustrative examples are provided , including characteristic kernels on periodic domains , rotation matrices , and Rn+ .", "In the present work , conditions are established for an RKHS to be characteristic on groups and semigroups ."]}
{"orig_sents": ["5", "4", "0", "3", "2", "1"], "shuf_sents": ["We consider a policy gradient approach for parameterized policy optimization .", "We propose a more sophisticated FD method which overcomes this problem and establish its consistency .", "We show that the naive FD is subject to variance explosion because of the non-smoothness of the resampling procedure .", "For that purpose , we investigate sensitivity analysis of the performance measure with respect to the parameters of the policy , focusing on Finite Difference ( FD ) techniques .", "Decisions are based on a Particle Filter for estimating the belief state given past observations .", "Our setting is a Partially Observable Markov Decision Process with continuous state , observation and action spaces ."]}
{"orig_sents": ["0", "4", "3", "1", "2"], "shuf_sents": ["We develop the syntactic topic model ( STM ) , a nonparametric Bayesian model of parsed documents .", "Words are assumed to be generated in an order that respects the parse tree .", "We derive an approximate posterior inference method based on variational methods for hierarchical Dirichlet processes , and we report qualitative and quantitative results on both synthetic data and hand-parsed documents .", "Each word of a sentence is generated by a distribution that combines document-specific topic weights and parse-tree-specific syntactic transitions .", "The STM generates words that are both thematically and syntactically constrained , which combines the semantic insights of topic models with the syntactic information available from parse trees ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["While likelihood-based methods have been extensively explored , to our knowledge , learning structured prediction models with latent variables based on the max-margin principle remains largely an open problem .", "Learning graphical models with hidden variables can offer semantic insights to complex data and lead to salient structured predictors without relying on expensive , sometime unattainable fully annotated training data .", "In this paper , we present a partially observed Maximum Entropy Discrimination Markov Network ( PoMEN ) model that attempts to combine the advantages of Bayesian and margin based paradigms for learning Markov networks from partially labeled data .", "We demonstrate competent performance of PoMEN over existing methods on a real-world web data extraction task .", "PoMEN leads to an averaging prediction rule that resembles a Bayes predictor that is more robust to overfitting , but is also built on the desirable discriminative laws resemble those of the M3 N. We develop an EM-style algorithm utilizing existing convex optimization algorithms for M3 N as a subroutine ."]}
{"orig_sents": ["1", "2", "4", "0", "3", "5"], "shuf_sents": ["Thus , we obtain a rate of 1/n on the convergence of the SVM objective ( with fixed regularization parameter ) to its infinite data limit .", "We study convergence properties of empirical minimization of a stochastic strongly convex objective , where the stochastic component is linear .", "We show that the value attained by the empirical minimizer converges to the optimal value with rate 1/n .", "We demonstrate how this is essential for obtaining certain type of oracle inequalities for SVMs .", "The result applies , in particular , to the SVM objective .", "The results extend also to approximate minimization as well as to strong convexity with respect to an arbitrary norm , and so also to objectives regularized using other p norms ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We also present a corresponding lower bound of ( DSAT ) on the total regret of any learning algorithm .", "We present a rein AT ) after T steps for any forcement learning algorithm with total regret O ( DS unknown MDP with S states , A actions per state , and diameter D. This bound holds with high probability .", "In order to describe the transition structure of an MDP we propose a new parameter : An MDP has diameter D if for any pair of states s , s there is a policy which moves from s to s in at most D steps ( on average ) .", "For undiscounted reinforcement learning in Markov decision processes ( MDPs ) we consider the total regret of a learning algorithm with respect to an optimal policy ."]}
{"orig_sents": ["4", "3", "6", "7", "5", "0", "1", "2"], "shuf_sents": ["The Continuous CRF model is defined as a conditional probability distribution over ranking scores of objects conditioned on the objects .", "It can naturally represent the content information of objects as well as the relation information between objects , necessary for global ranking .", "Taking two specific information retrieval tasks as examples , the paper shows how the Continuous CRF method can perform global ranking better than baselines .", "Conventional learning to rank methods are usually designed for `local ranking ' , in the sense that the ranking model is defined on a single object , for example , a document in information retrieval .", "This paper studies global ranking problem by learning to rank methods .", "This paper refers to the problem as global ranking and proposes employing a Continuous Conditional Random Fields ( CRF ) for conducting the learning task .", "For many applications , this is a very loose approximation .", "Relations always exist between objects and it is better to define the ranking model as a function on all the objects to be ranked ( i.e. , the relations are also included ) ."]}
{"orig_sents": ["2", "4", "0", "6", "3", "1", "5"], "shuf_sents": ["The training data is partitioned in local regions , for each an individual GP model is trained .", "The proposed method achieves online learning and prediction in real-time .", "Learning in real-time applications , e.g. , online approximation of the inverse dynamics model for model-based robot control , requires fast online regression techniques .", "Unlike other GP approximations , such as mixtures of experts , we use a distance based measure for partitioning of the data and weighted prediction .", "Inspired by local learning , we propose a method to speed up standard Gaussian process regression ( GPR ) with local GP models ( LGP ) .", "Comparisons with other non-parametric regression methods show that LGP has higher accuracy than LWPR and close to the performance of standard GPR and -SVR .", "The prediction for a query point is performed by weighted estimation using nearby local models ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["This paper is devoted to thoroughly investigating how to bootstrap the ROC curve , a widely used visual tool for evaluating the accuracy of test/scoring statistics in the bipartite setup .", "Theoretical arguments and simulation results are presented to show that the `` smoothed bootstrap '' is preferable to a `` naive '' bootstrap in order to construct accurate confidence bands .", "The issue of confidence bands for the ROC curve is considered and a resampling procedure based on a smooth version of the empirical distribution called the `` smoothed bootstrap '' is introduced ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["Inspired by the hierarchical hidden Markov models ( HHMM ) , we present the hierarchical semi-Markov conditional random field ( HSCRF ) , a generalisation of embedded undirected Markov chains to model complex hierarchical , nested Markov processes .", "It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference .", "Importantly , we develop efficient algorithms for learning and constrained inference in a partially-supervised setting , which is important issue in practice where labels can only be obtained sparsely .", "We demonstrate the HSCRF in two applications : ( i ) recognising human activities of daily living ( ADLs ) from indoor surveillance cameras , and ( ii ) noun-phrase chunking .", "We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We evaluate our method in two problem domains -- multiple sequence alignment and reconstruction of ancestral sequences -- and show substantial improvement over the current state of the art .", "While classical treatments have made unrealistic site independence assumptions , ignoring insertions and deletions , realistic approaches require tracking insertions and deletions along the phylogenetic tree -- a challenging and unsolved computational problem .", "We propose a new ancestry resampling procedure for inference in evolutionary trees .", "Accurate and efficient inference in evolutionary trees is a central problem in computational biology ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We study the problem of domain transfer for a supervised classification task in mRNA splicing .", "We find that in cases where the organisms are not closely related , the use of domain adaptation methods can help improve classification performance .", "We consider a number of recent domain transfer methods from machine learning , including some that are novel , and evaluate them on genomic sequence data from model organisms of varying evolutionary distance ."]}
{"orig_sents": ["1", "4", "2", "7", "3", "0", "6", "5", "8"], "shuf_sents": ["The resulting method can be thought of as an adaptive template matching procedure .", "How does one extract unknown but stereotypical events that are linearly superimposed within a signal with variable latencies and variable amplitudes ?", "However , traditional matching approaches require that the templates be known a priori .", "The algorithm estimates templates directly from the data along with their non-negative amplitudes .", "One could think of using template matching or matching pursuit to find the arbitrarily shifted linear components .", "On these data the algorithm essentially performs spike detection and unsupervised spike clustering .", "We demonstrate the procedure on the task of extracting spikes from single channel extracellular recordings .", "To overcome this restriction we use instead semi Non-Negative Matrix Factorization ( semiNMF ) that we extend to allow for time shifts when matching the templates to the signal .", "Results on simulated data and extracellular recordings indicate that the method performs well for signalto-noise ratios of 6dB or higher and that spike templates are recovered accurately provided they are sufficiently different ."]}
{"orig_sents": ["4", "0", "2", "5", "3", "1", "6"], "shuf_sents": ["In this paper , we propose a maximum likelihood ( ML ) approach to covariance estimation , which employs a novel sparsity constraint .", "The resulting estimator is positive definite and well-conditioned even when the sample size is limited .", "More specifically , the covariance is constrained to have an eigen decomposition which can be represented as a sparse matrix transform ( SMT ) .", "Using this framework , the covariance can be efficiently estimated using greedy minimization of the log likelihood function , and the number of Givens rotations can be efficiently computed using a cross-validation procedure .", "Covariance estimation for high dimensional vectors is a classically difficult problem in statistical analysis and machine learning .", "The SMT is formed by a product of pairwise coordinate rotations known as Givens rotations .", "Experiments on standard hyperspectral data sets show that the SMT covariance estimate is consistently more accurate than both traditional shrinkage estimates and recently proposed graphical lasso estimates for a variety of different classes and sample sizes ."]}
{"orig_sents": ["2", "4", "1", "3", "0"], "shuf_sents": ["We compare this density modeling technique to several existing techniques on a toy problem and a skullreconstruction task .", "Our formulation allows us to infer an unknown density from data using Markov chain Monte Carlo , which gives samples from the posterior distribution over density functions and from the predictive distribution on data space .", "We present the Gaussian Process Density Sampler ( GPDS ) , an exchangeable generative model for use in nonparametric Bayesian density estimation .", "We can also infer the hyperparameters of the Gaussian process .", "Samples drawn from the GPDS are consistent with exact , independent samples from a fixed density function that is a transformation of a function drawn from a Gaussian process prior ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["It captures and generalizes ( at least intuitively ) the bottleneck concept , which has inspired many of the existing skill-discovery algorithms .", "More importantly , it serves as a useful guide for developing incremental skill-discovery algorithms that do not rely on knowing or representing the interaction graph in its entirety .", "Our characterization uses betweenness , a measure of centrality on graphs .", "Our characterization may be used directly to form a set of skills suitable for a given task .", "We present a characterization of a useful class of skills based on a graphical representation of an agent 's interaction with its environment ."]}
{"orig_sents": ["7", "4", "0", "2", "5", "1", "6", "8", "3"], "shuf_sents": ["To this end , we develop an algorithm named Zeta l-links ( Zell ) which consists of two parts : Zeta merging with a similarity graph and an initial set of small clusters derived from local l-links of samples .", "The popularity character of a cluster is conceptualized as the global fusion of variations of such a structural descriptor by means of the leave-one-out strategy in the cluster .", "More specifically , we propose to structurize a cluster using cycles in the associated subgraph .", "The 98.1 % accuracy , in the sense of the normalized mutual information ( NMI ) , is obtained on the FRGC face data of 16028 samples and 466 facial clusters .", "In this paper , we tackle the problem of clustering complex data of multiple distributions and multiple scales .", "A new mathematical tool , Zeta function of a graph , is introduced for the integration of all cycles , leading to a structural descriptor of a cluster in determinantal form .", "Zeta merging proceeds , in the hierarchical agglomerative fashion , according to the maximum incremental popularity among all pairwise clusters .", "Detecting underlying clusters from large-scale data plays a central role in machine learning research .", "Experiments on toy data clustering , imagery pattern clustering , and image segmentation show the competitive performance of Zell ."]}
{"orig_sents": ["4", "0", "3", "5", "2", "1"], "shuf_sents": ["Current algorithms for automatic query expansion can often improve retrieval accuracy on average , but are not robust : that is , they are highly unstable and have poor worst-case performance for individual queries .", "Our approach does not assume a particular retrieval model , making it applicable to a broad class of existing expansion algorithms .", "Results across multiple standard test collections show consistent and significant reductions in the number and magnitude of expansion failures , while retaining the strong positive gains of the baseline algorithm .", "To address this problem , we introduce a novel formulation of query expansion as a convex optimization problem over a word graph .", "Query expansion is a long-studied approach for improving retrieval effectiveness by enhancing the user 's original query with additional related words .", "The model combines initial weights from a baseline feedback algorithm with edge weights based on word similarity , and integrates simple constraints to enforce set-based criteria such as aspect balance , aspect coverage , and term centrality ."]}
{"orig_sents": ["0", "3", "1", "5", "4", "2"], "shuf_sents": ["Sampling functions in Gaussian process ( GP ) models is challenging because of the highly correlated posterior distribution .", "This algorithm uses control variables which are auxiliary function values that provide a low dimensional representation of the function .", "We demonstrate the algorithm on regression and classification problems and we use it to estimate the parameters of a differential equation model of gene regulation .", "We describe an efficient Markov chain Monte Carlo algorithm for sampling from the posterior process of the GP model .", "The control variable input locations are found by minimizing an objective function .", "At each iteration , the algorithm proposes new values for the control variables and generates the function from the conditional GP prior ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["We show that our bound outperforms the state-of-the-art on some inference problems arising in medical diagnosis .", "We propose a novel bound on single-variable marginal probability distributions in factor graphs with discrete variables .", "By construction , the method not only bounds the exact marginal probability distribution of a variable , but also its approximate Belief Propagation marginal ( `` belief '' ) .", "Thus , apart from providing a practical means to calculate bounds on marginals , our contribution also lies in providing a better understanding of the error made by Belief Propagation .", "The bound is obtained by propagating local bounds ( convex sets of probability distributions ) over a subtree of the factor graph , rooted in the variable of interest ."]}
{"orig_sents": ["0", "3", "4", "2", "5", "1"], "shuf_sents": ["Multi-level hierarchical models provide an attractive framework for incorporating correlations induced in a response variable that is organized hierarchically .", "We illustrate through simulation studies and analyses of real world data sets in health care and online advertising .", "For Gaussian response , we show our method provides the maximum a-posteriori ( MAP ) parameter estimates ; for non-Gaussian response , parameter estimation is performed through a Laplace approximation .", "Model fitting is challenging , especially for a hierarchy with a large number of nodes .", "We provide a novel algorithm based on a multi-scale Kalman filter that is both scalable and easy to implement .", "However , the Laplace approximation provides biased parameter estimates that is corrected through a parametric bootstrap procedure ."]}
{"orig_sents": ["4", "5", "1", "2", "0", "3"], "shuf_sents": ["Nevertheless , these nonconvergent estimates can be used for solving the two-sample problem and assessing if two random variables are independent .", "First , we prove that the information theoretic measure estimates using the k-nearest-neighbor density estimation with fixed k converge almost surely , even though the k-nearest-neighbor density estimation with fixed k does not converge to its true measure .", "Second , we show that the information theoretic measure estimates do not converge for k growing linearly with the number of samples .", "We show that the two-sample and independence tests based on these nonconvergent estimates compare favorably with the maximum mean discrepancy test and the Hilbert Schmidt independence criterion .", "We analyze the estimation of information theoretic measures of continuous random variables such as : differential entropy , mutual information or KullbackLeibler divergence .", "The objective of this paper is two-fold ."]}
{"orig_sents": ["0", "2", "1", "4", "3"], "shuf_sents": ["For supervised and unsupervised learning , positive definite kernels allow to use large and potentially infinite dimensional feature spaces with a computational cost that only depends on the number of observations .", "In this paper , we explore penalizing by sparsity-inducing norms such as the 1 -norm or the block 1 -norm .", "This is usually done through the penalization of predictor functions by Euclidean or Hilbertian norms .", "This framework is naturally applied to non linear variable selection ; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efficiently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance .", "We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph ; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework , in polynomial time in the number of selected kernels ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["In this theoretical contribution we provide mathematical proof that two of the most important classes of network learning - correlation-based differential Hebbian learning and reward-based temporal difference learning - are asymptotically equivalent when timing the learning with a local modulatory signal .", "This opens the opportunity to consistently reformulate most of the abstract reinforcement learning framework from a correlation based perspective that is more closely related to the biophysics of neurons ."]}
{"orig_sents": ["3", "0", "2", "5", "6", "4", "7", "8", "1"], "shuf_sents": ["Several methods have been proposed to reduce the computational complexity of evaluating such sums , including tree and analysis based methods .", "Our approach chooses the fastest method at negligible additional cost , and has superior performance in comparisons with previous approaches .", "These achieve varying speedups depending on the bandwidth , dimension , and prescribed error , making the choice between methods difficult for machine learning tasks .", "Many machine learning algorithms require the summation of Gaussian kernel functions , an expensive operation if implemented straightforwardly .", "We address the first problem by employing a tree data structure , resulting in four evaluation methods whose performance varies based on the distribution of sources and targets and input parameters such as desired accuracy and bandwidth .", "We provide an algorithm that combines tree methods with the Improved Fast Gauss Transform ( IFGT ) .", "As originally proposed the IFGT suffers from two problems : ( 1 ) the Taylor series expansion does not perform well for very low bandwidths , and ( 2 ) parameter selection is not trivial and can drastically affect performance and ease of use .", "To solve the second problem , we present an online tuning approach that results in a black box method that automatically chooses the evaluation method and its parameters to yield the best performance for the input data , desired accuracy , and bandwidth .", "In addition , the new IFGT parameter selection approach allows for tighter error bounds ."]}
{"orig_sents": ["4", "1", "3", "2", "0"], "shuf_sents": ["Prominent features of the resulting concept lattices are discussed , including hierarchical face representation and indications for a product-of-experts code in real neurons .", "FCA provides a way of displaying and interpreting such relationships via concept lattices .", "We then analyze neurophysiological data from high-level visual cortical area STSa , using an exact Bayesian approach to construct the formal context needed by FCA .", "We explore the effects of neural code sparsity on the lattice .", "We propose a novel application of Formal Concept Analysis ( FCA ) to neural decoding : instead of just trying to figure out which stimulus was presented , we demonstrate how to explore the semantic relationships in the neural representation of large sets of stimuli ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["We introduce a new bound , the cardinality bound , which can be computed via convex optimization .", "We consider the problem of bounding from above the log-partition function corresponding to second-order Ising models for binary distributions .", "The corresponding error on the logpartition function is bounded above by twice the distance , in model parameter space , to a class of `` standard '' Ising models , for which variable inter-dependence is described via a simple mean field term .", "We compare our bound with the log-determinant bound introduced by Wainwright and Jordan ( 2006 ) , and show that when the l1 -norm of the model parameter vector is small enough , the latter is outperformed by the new bound .", "In the context of maximum-likelihood , using the new bound instead of the exact log-partition function , while constraining the distance to the class of standard Ising models , leads not only to a good approximation to the log-partition function , but also to a model that is parsimonious , and easily interpretable ."]}
{"orig_sents": ["4", "3", "2", "1", "5", "0", "6"], "shuf_sents": ["We provide an algorithm for constructing approximate homomorphisms , by using this metric to identify states that can be grouped together , as well as actions that can be matched .", "2004 , 2005 ) .", "We prove that the difference in the optimal value function of different states can be upper-bounded by the value of this metric , and that the bound is tighter than previous bounds provided by bisimulation metrics ( Ferns et al .", "We show that the kernel of our metric corresponds exactly to the classes of states defined by MDP homomorphisms ( Ravindran & Barto , 2003 ) .", "We define a metric for measuring behavior similarity between states in a Markov decision process ( MDP ) , which takes action similarity into account .", "Our results hold both for discrete and for continuous actions .", "Previous research on this topic is based mainly on heuristics ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["This paper describes a recursive estimation procedure for multivariate binary densities using orthogonal expansions .", "However , for a wide class of densities that satisfy a certain sparsity condition , our estimator runs in probabilistic polynomial time and adapts to the unknown sparsity of the underlying density in two key ways : ( 1 ) it attains near-minimax mean-squared error , and ( 2 ) the computational complexity is lower for sparser densities .", "For d covariates , there are 2d basis coefficients to estimate , which renders conventional approaches computationally prohibitive when d is large .", "Our method also allows for flexible control of the trade-off between mean-squared error and computational complexity ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["We provide statistical performance guarantees for a recently introduced kernel classifier that optimizes the L2 or integrated squared error ( ISE ) of a difference of densities .", "Our results also specialize to give performance guarantees for an existing method of L2 kernel density estimation .", "Unlike SVMs , however , the L2 kernel classifier does not involve a regularization parameter .", "We prove a distribution free concentration inequality for a cross-validation based estimate of the ISE , and apply this result to deduce an oracle inequality and consistency of the classifier on the sense of both ISE and probability of error .", "The classifier is similar to a support vector machine ( SVM ) in that it is the solution of a quadratic program and yields a sparse classifier ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["In experiments , we were surprised to find that in addition to being more efficient , it is also a better sequential Monte Carlo sampler than the best in , when measured in terms of variance of estimated likelihood and effective sample size .", "We propose an efficient sequential Monte Carlo inference scheme for the recently proposed coalescent clustering model .", "Our algorithm has a quadratic runtime while those in is cubic ."]}
{"orig_sents": ["3", "7", "1", "2", "0", "5", "6", "4"], "shuf_sents": ["The prior knowledge is encoded as a network whose vertices are features and whose edges represent similarities and dissimilarities between them .", "Such synonymous or neighboring features are near-duplicates and should be expected to have similar weights in an accurate model .", "Here we present a framework for regularized learning when one has prior knowledge about which features are expected to have similar and dissimilar weights .", "For many supervised learning problems , we possess prior knowledge about which features yield similar information about the target variable .", "For sentiment analysis , feature networks constructed from declarative human knowledge significantly improve prediction accuracy .", "During learning , each feature 's weight is penalized by the amount it differs from the average weight of its neighbors .", "For text classification , regularization using networks of word co-occurrences outperforms manifold learning and compares favorably to other recently proposed semi-supervised learning methods .", "In predicting the topic of a document , we might know that two words are synonyms , and when performing image recognition , we know which pixels are adjacent ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["The algorithm can be formulated as an optimization problem in a reproducing kernel Hilbert space .", "We report encouraging results on the problem of compound-protein interaction network reconstruction from chemical structure data and genomic sequence data .", "The method involves the learning of two mappings of the heterogeneous objects to a unified Euclidean space representing the network topology of the bipartite graph , where the graph is easy to infer .", "We formulate the problem of bipartite graph inference as a supervised learning problem , and propose a new method to solve it from the viewpoint of distance metric learning ."]}
{"orig_sents": ["1", "0", "5", "7", "6", "3", "2", "4"], "shuf_sents": ["Recent impressive results range from humanoid robot movement generation to timing models of human motions .", "Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning .", "As the resulting model is intractable , we introduce a novel approximation method based on variational Bayes , which is especially designed to enable the use of efficient inference algorithms .", "The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization .", "On recorded human Balero movements , this method is not only capable of finding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm .", "The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning .", "In this paper , we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics .", "Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system ."]}
{"orig_sents": ["4", "5", "3", "1", "2", "0", "7", "6"], "shuf_sents": ["It provides a natural representation of multiscale contour models , which is needed in order to cope with unstable contour decompositions .", "The append operator is then applied to map RVs in each tree structure to a single RV .", "We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images .", "We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels .", "We introduce a new interpretation of multiscale random fields ( MSRFs ) that admits efficient optimization in the framework of regular ( single level ) random fields ( RFs ) .", "It is based on a new operator , called append , that combines sets of random variables ( RVs ) to single RVs .", "Alternative methods like Markov Chain Monte Carlo ( MCMC ) could also be used .", "The append operator allows us to find optimal image segment labels using the classical framework of relaxation labeling ."]}
{"orig_sents": ["0", "3", "4", "1", "2", "5"], "shuf_sents": ["It has been shown that the problem of 1 -penalized least-square regression commonly referred to as the Lasso or Basis Pursuit DeNoising leads to solutions that are sparse and therefore achieves model selection .", "We compare our method to Lars and Coordinate Descent , and present an application to compressive sensing with sequential observations .", "Our approach can easily be extended to compute an homotopy from the current solution to the solution that corresponds to removing a data point , which leads to an efficient algorithm for leave-one-out cross-validation .", "We propose in this paper RecLasso , an algorithm to solve the Lasso with online ( sequential ) observations .", "We introduce an optimization problem that allows us to compute an homotopy from the current solution to the solution after observing a new data point .", "We also propose an algorithm to automatically update the regularization parameter after observing a new data point ."]}
{"orig_sents": ["4", "5", "3", "1", "2", "0"], "shuf_sents": ["We complement our theoretical results with simulations that demonstrate the sharpness of the result , even for relatively small problems .", "Here n is the sample size , p is the ambient dimension of the regression model , s is the size of the union of supports , and ( B ) is a sparsity-overlap function that measures a combination of the sparsities and overlaps of the K-regression coefficient vectors that constitute the model .", "This sparsity-overlap function reveals that block 1 / 2 regularization for multivariate regression never harms performance relative to a naive 1 -approach , and can yield substantial improvements in sample complexity ( up to a factor of K ) when the regression vectors are suitably orthogonal relative to the design .", "Studying this problem under high-dimensional scaling ( where the problem parameters as well as sample size n tend to infinity simultaneously ) , our main result is to show that exact recovery is possible once the order parameter given by 1 / 2 ( n , p , s ) : = n/ exceeds a critical threshold .", "We study the behavior of block 1 / 2 regularization for multivariate regression , where a K-dimensional response vector is regressed upon a fixed set of p covariates .", "The problem of support union recovery is to recover the subset of covariates that are active in at least one of the regression problems ."]}
{"orig_sents": ["1", "0", "5", "4", "3", "2"], "shuf_sents": ["To handle such data structures , Grassmann kernels have been proposed and used previously .", "Subspace-based learning problems involve data whose elements are linear subspaces of a vector space .", "We demonstrate the advantages of these extended kernels for classification and recognition tasks with Support Vector Machines and Kernel Discriminant Analysis using synthetic and real image databases .", "Secondly , based on our analysis of the KL distance , we propose extensions of the Projection kernel which can be extended to the set of affine as well as scaled subspaces .", "Firstly , we show that the KL distance in the limit yields the Projection kernel on the Grassmann manifold , whereas the Bhattacharyya kernel becomes trivial in the limit and is suboptimal for subspace-based problems .", "In this paper , we analyze the relationship between Grassmann kernels and probabilistic similarity measures ."]}
{"orig_sents": ["2", "3", "4", "1", "0"], "shuf_sents": ["Our model 's performance identifying artifacts is superior to two other classifiers ' and about as good as a physician 's .", "We show that careful modeling of the sensor , combined with a general technique for detecting sub-interval events and estimating their duration , enables detection of artifacts and accurate estimation of the underlying blood pressure values .", "We describe an application of probabilistic modeling and inference technology to the problem of analyzing sensor data in the setting of an intensive care unit ( ICU ) .", "In particular , we consider the arterial-line blood pressure sensor , which is subject to frequent data artifacts that cause false alarms in the ICU and make the raw data almost useless for automated decision making .", "The problem is complicated by the fact that the sensor data are averaged over fixed intervals whereas the events causing data artifacts may occur at any time and often have durations significantly shorter than the data collection interval ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["Using a novel family of variational approximations , our approach produces segmentations which compare favorably to state-of-the-art methods , while simultaneously discovering categories shared among natural scenes .", "We develop a statistical framework for the simultaneous , unsupervised segmentation and discovery of visual object categories from image databases .", "This nonparametric prior distribution leads to learning algorithms which discover an unknown set of objects , and segmentation methods which automatically adapt their resolution to each image .", "Generalizing previous applications of PY processes , we use Gaussian processes to discover spatially contiguous segments which respect image boundaries .", "Examining a large set of manually segmented scenes , we show that object frequencies and segment sizes both follow power law distributions , which are well modeled by the Pitman-Yor ( PY ) process ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["Under some conditions on the model covariance , we show that model selection can be achieved for sample sizes n = ( d2 log ( p ) ) , with the error decaying as O ( exp ( -c log ( p ) ) ) for some constant c. We illustrate our theoretical results via simulations and show good correspondences between the theoretical predictions and behavior in simulations .", "We consider the problem of estimating the graph structure associated with a Gaussian Markov random field ( GMRF ) from i.i.d .", "samples .", "We study the performance of study the performance of the 1 -regularized maximum likelihood estimator in the high-dimensional setting , where the number of nodes in the graph p , the number of edges in the graph s and the maximum node degree d , are allowed to grow as a function of the number of samples n. Our main result provides sufficient conditions on ( n , p , d ) for the 1 -regularized MLE estimator to recover all the edges of the graph with high probability ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["The ROC curve is known to be the golden standard for measuring performance of a test/scoring statistic regarding its capacity of discrimination between two populations in a wide variety of applications , ranging from anomaly detection in signal processing to information retrieval , through medical diagnosis .", "We investigate the properties of empirical maximizers of such performance criteria and provide preliminary results for the concentration properties of a novel class of random variables that we will call a linear rank process .", "Most practical performance measures used in scoring applications such as the AUC , the local AUC , the p-norm push , the DCG and others , can be seen as summaries of the ROC curve .", "This paper highlights the fact that many of these empirical criteria can be expressed as ( conditional ) linear rank statistics ."]}
{"orig_sents": ["0", "3", "4", "5", "2", "1", "6"], "shuf_sents": ["The visual and auditory map alignment in the Superior Colliculus ( SC ) of barn owl is important for its accurate localization for prey behavior .", "In this model , axon growing process is instructed by an inhibitory network in SC while the strength of the inhibition adjusted by Spike Timing Dependent Plasticity ( STDP ) .", "A model is built to explore this mechanism .", "Prism learning or Blindness may interfere this alignment and cause loss of the capability of accurate prey .", "However , juvenile barn owl could recover its sensory map alignment by shifting its auditory map .", "The adaptation of this map alignment is believed based on activity dependent axon developing in Inferior Colliculus ( IC ) .", "We test and analyze this mechanism by application of the neural structures involved in spatial localization in a robotic system ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We apply this new criterion to independent component analysis and sequence clustering .", "This is achieved by modeling the structures using undirected graphical models and comparing the Hilbert space embeddings of distributions .", "Many machine learning algorithms can be formulated in the framework of statistical independence such as the Hilbert Schmidt Independence Criterion .", "In this paper , we extend this criterion to deal with structured and interdependent observations ."]}
{"orig_sents": ["2", "4", "0", "1", "3"], "shuf_sents": ["In particular , on large alphabets and under loose mismatch constraints our algorithms are several orders of magnitude faster than the existing algorithms for string comparison under the mismatch similarity measure .", "We evaluate our algorithms on synthetic data and real applications in music genre classification , protein remote homology detection and protein fold prediction .", "We present a new family of linear time algorithms for string comparison with mismatches under the string kernels framework .", "The scalability of the algorithms allows us to consider complex sequence transformations , modeled using longer string features and larger numbers of mismatches , leading to a state-of-the-art performance with significantly reduced running times .", "Based on sufficient statistics , our algorithms improve theoretical complexity bounds of existing approaches while scaling well in sequence alphabet size , the number of allowed mismatches and the size of the dataset ."]}
{"orig_sents": ["3", "0", "4", "1", "2"], "shuf_sents": ["In this paper , we present a novel convex supervised dimensionality reduction approach based on exponential family PCA , which is able to avoid the local optima of typical EM learning .", "A training algorithm is then devised based on a subgradient bundle method , whose scalability can be gained using a coordinate descent procedure .", "The advantage of our global optimization approach is demonstrated by empirical results over both synthetic and real data .", "Recently , supervised dimensionality reduction has been gaining attention , owing to the realization that data labels are often available and indicate important underlying structure in the data .", "Moreover , by introducing a sample-based approximation to exponential family models , it overcomes the limitation of the prevailing Gaussian assumptions of standard PCA , and produces a kernelized formulation for nonlinear supervised dimensionality reduction ."]}
{"orig_sents": ["5", "6", "3", "2", "9", "1", "4", "0", "7", "8"], "shuf_sents": ["We analyzed the security of current audio CAP TCHAs from popular Web sites by using AdaBoost , SVM , and k-NN , and achieved correct solutions for test samples with accuracy up to 71 % .", "Some visual CAP TCHAs have been broken using machine learning techniques , and we propose using similar ideas to test the security of audio CAP TCHAs .", "Unfortunately , visual CAP TCHAs limit access to the millions of visually impaired people using the Web .", "Most CAP TCHAs consist of distorted images , usually text , for which a user must provide some description .", "Audio CAP TCHAs are generally composed of a set of words to be identified , layered on top of noise .", "CAP TCHAs are computer-generated tests that humans can pass but current computer systems can not .", "CAP TCHAs provide a method for automatically distinguishing a human from a computer program , and therefore can protect Web services from abuse by so-called `` bots . ''", "Such accuracy is enough to consider these CAPTCHAs broken .", "Training several different machine learning algorithms on different types of audio CAP TCHAs allowed us to analyze the strengths and weaknesses of the algorithms so that we could suggest a design for a more robust audio CAPTCHA .", "Audio CAP TCHAs were created to solve this accessibility issue ; however , the security of audio CAP TCHAs was never formally tested ."]}
{"orig_sents": ["2", "1", "5", "3", "6", "4", "0"], "shuf_sents": ["Empirical results on different datasets show the effectiveness of our approach compared to the same algorithm and the TSVM in which the threshold is fixed manually .", "The first one involves the margin distribution of the classifier and a risk bound on its associate Gibbs classifier .", "We propose two transductive bounds on the risk of majority votes that are estimated over partially labeled training sets .", "In semi-supervised learning , considering the margin as an indicator of confidence constitutes the working hypothesis of algorithms which search the decision boundary on low density regions .", "As an application , we propose a self-learning algorithm which iteratively assigns pseudo-labels to the set of unlabeled training examples that have their margin above a threshold obtained from this bound .", "The bound is tight when so is the Gibbs 's bound and when the errors of the majority vote classifier is concentrated on a zone of low margin .", "Following this assumption , we propose to bound the error probability of the voted classifier on the examples for whose margins are above a fixed threshold ."]}
{"orig_sents": ["3", "2", "4", "0", "1"], "shuf_sents": ["We derive efficient implementation for our algorithms when the approximate value-functions belong to a reproducing kernel Hilbert space .", "We also provide finite-sample performance bounds for our algorithms and show that they are able to achieve optimal rates of convergence under the studied conditions .", "In order to implement a flexible function approximation scheme we propose the use of non-parametric methods with regularization , providing a convenient way to control the complexity of the function approximator .", "In this paper we consider approximate policy-iteration-based reinforcement learning algorithms .", "We propose two novel regularized policy iteration algorithms by adding L2 -regularization to two widely-used policy evaluation methods : Bellman residual minimization ( BRM ) and least-squares temporal difference learning ( LSTD ) ."]}
{"orig_sents": ["2", "4", "5", "6", "3", "0", "1"], "shuf_sents": ["To further boost the practicality of our approach , we develop an online locality-sensitive hashing scheme which leads to efficient updates to data structures used for fast approximate similarity search .", "We demonstrate our algorithm on multiple datasets and show that it outperforms relevant baselines .", "Metric learning algorithms can provide useful distance functions for a variety of domains , and recent work has shown good accuracy for problems where the learner can access all distance constraints at once .", "We prove theoretical worst-case performance bounds , and empirically compare the proposed method against existing online metric learning algorithms .", "However , in many real applications , constraints are only available incrementally , thus necessitating methods that can perform online updates to the learned metric .", "Existing online algorithms offer bounds on worst-case performance , but typically do not perform well in practice as compared to their offline counterparts .", "We present a new online metric learning algorithm that updates a learned Mahalanobis metric based on LogDet regularization and gradient descent ."]}
{"orig_sents": ["1", "3", "4", "2", "0"], "shuf_sents": ["This provides insight on the precise value and limitations of convex programming-based algorithms .", "This paper addresses the problem of sparsity pattern detection for unknown ksparse n-dimensional signals observed through m noisy , random linear measurements .", "We show that m > 2k log ( n - k ) / ( SNR * MAR ) is necessary for any algorithm to succeed , regardless of complexity ; this matches a previous sufficient condition for maximum likelihood estimation within a constant factor under certain scalings of k , SNR and MAR with n. We also show a sufficient condition for a computationally-trivial thresholding algorithm that is larger than the previous expression by only a factor of 4 ( 1 + SNR ) and larger than the requirement for lasso by only a factor of 4/MAR .", "Sparsity pattern recovery arises in a number of settings including statistical model selection , pattern detection , and image acquisition .", "The main results in this paper are necessary and sufficient conditions for asymptotically-reliable sparsity pattern recovery in terms of the dimensions m , n and k as well as the signal-tonoise ratio ( SNR ) and the minimum-to-average ratio ( MAR ) of the nonzero entries of the signal ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["The linear version of the proposed model admits a simple probabilistic interpretation , while its most general variant admits an interpretation in terms of kernels .", "This paper proposes a new step in that direction , with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models .", "Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones .", "It is now well established that sparse signal models are well suited for restoration tasks and can be effectively learned from audio , image , and video data .", "An optimization framework for learning all the components of the proposed model is presented , along with experimental results on standard handwritten digit and texture classification tasks ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["Unlike competing systems , it does not require any alphabet specific preprocessing , and can therefore be used unchanged for any language .", "By combining two recent innovations in neural networks -- multidimensional recurrent neural networks and connectionist temporal classification -- this paper introduces a globally trained offline handwriting recogniser that takes raw pixel data as input .", "Evidence of its generality and power is provided by data from a recent international Arabic recognition competition , where it outperformed all entries ( 91.4 % accuracy compared to 87.2 % for the competition winner ) despite the fact that neither author understands a word of Arabic .", "In most systems the two elements are handled separately , with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions .", "Offline handwriting recognition -- the automatic transcription of images of handwritten text -- is a challenging task that combines computer vision with sequence learning ."]}
{"orig_sents": ["4", "1", "5", "3", "7", "6", "10", "0", "9", "2", "8"], "shuf_sents": ["Secondly , the structure of the HIM allows us to design a rapid inference algorithm , based on dynamic programming , which enables us to parse the image rapidly in polynomial time .", "Natural language researchers have made great progress by exploiting the 1D structure of language to design efficient polynomialtime parsing algorithms .", "We demonstrate that HIM outperforms other state-of-the-art methods by evaluation on the challenging public MSRC image dataset .", "Attempts to adapt representations and algorithms from natural language have only been partially successful .", "Language and image understanding are two major goals of artificial intelligence which can both be conceptually formulated in terms of parsing the input signal into a hierarchical representation .", "By contrast , the two-dimensional nature of images makes it much harder to design efficient image parsers and the form of the hierarchical representations is also unclear .", "This HIM is represented by recursive segmentation and recognition templates in multiple layers and has advantages for representation , inference , and learning .", "In this paper , we propose a Hierarchical Image Model ( HIM ) for 2D image parsing which outputs image segmentation and object recognition .", "Finally , we sketch how the HIM architecture can be extended to model more complex image phenomena .", "Thirdly , we can learn the HIM efficiently in a discriminative manner from a labeled dataset .", "Firstly , the HIM has a coarse-to-fine representation which is capable of capturing long-range dependency and exploiting different levels of contextual information ."]}
{"orig_sents": ["0", "1", "4", "2", "3"], "shuf_sents": ["Large-margin structured estimation methods minimize a convex upper bound of loss functions .", "While they allow for efficient optimization algorithms , these convex formulations are not tight and sacrifice the ability to accurately model the true loss .", "We show that a small modification of existing optimization algorithms suffices to solve this modified problem .", "On structured prediction tasks such as protein sequence alignment and web page ranking , our algorithm leads to improved accuracy .", "We present tighter non-convex bounds based on generalizing the notion of a ramp loss from binary classification to structured estimation ."]}
{"orig_sents": ["0", "4", "1", "2", "3"], "shuf_sents": ["We consider multi-armed bandit problems where the number of arms is larger than the possible number of experiments .", "Our assumption is weaker than in previous works .", "We describe algorithms based on upper-confidence-bounds applied to a restricted set of randomly selected arms and provide upper-bounds on the resulting expected regret .", "We also derive a lower-bound which matches ( up to a logarithmic factor ) the upper-bound in some cases .", "We make a stochastic assumption on the mean-reward of a new selected arm which characterizes its probability of being a near-optimal arm ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We present a novel method for inducing synchronous context free grammars ( SCFGs ) from a corpus of parallel string pairs .", "SCFGs can model equivalence between strings in terms of substitutions , insertions and deletions , and the reordering of sub-strings .", "Using a variational Bayes training procedure , we learn the latent structure of translation equivalence through the induction of synchronous grammar categories for phrasal translations , showing improvements in translation performance over maximum likelihood models .", "We develop a non-parametric Bayesian model and apply it to a machine translation task , using priors to replace the various heuristics commonly used in this field ."]}
{"orig_sents": ["2", "0", "1", "4", "5", "3"], "shuf_sents": ["Given a machine-learned scoring rule and a query distribution , we build a predictive index by precomputing lists of potential results sorted based on an expected score of the result over future queries .", "The predictive index datastructure supports an anytime algorithm for approximate retrieval of the top elements .", "We tackle the computational problem of query-conditioned search .", "We experimentally find substantial improvement over existing methods for internet advertisement and approximate nearest neighbors .", "The general approach is applicable to webpage ranking , internet advertisement , and approximate nearest neighbor search .", "It is particularly effective in settings where standard techniques ( e.g. , inverted indices ) are intractable ."]}
{"orig_sents": ["7", "5", "8", "6", "3", "2", "4", "0", "1"], "shuf_sents": ["We demonstrate empirically that the theory holds , using simulated text data and two text corpora .", "We provide practical guidelines for choosing an approximation .", "We prove that the difference in the tightness of the bound on the likelihood of a document decreases as O ( k - 1 ) + log m/m , where k is the number of topics in the model and m is the number of words in a document .", "We analyze the improvement that the recently proposed collapsed variational inference ( CVB ) provides over mean field variational inference ( VB ) in latent Dirichlet allocation .", "As a consequence , the advantage of CVB over VB is lost for long documents but increases with the number of topics .", "Posterior inference in such models is intractable , and practitioners rely on approximate posterior inference methods such as variational inference or Gibbs sampling .", "In this paper we provide the beginnings of such understanding .", "Hierarchical probabilistic modeling of discrete data has emerged as a powerful tool for text analysis .", "There has been much research in designing better approximations , but there is yet little theoretical understanding of which of the available techniques are appropriate , and in which data analysis settings ."]}
{"orig_sents": ["5", "6", "4", "1", "0", "3", "2"], "shuf_sents": ["Our results indicate that humans are capable of actively selecting informative queries , and in doing so learn better and faster than if they are given random training data , as predicted by learning theory .", "We conduct a series of human category learning experiments inspired by a machine learning task for which active and passive learning error bounds are well understood , and dramatically distinct .", "To the best of our knowledge , this is the first quantitative study comparing human category learning in active versus passive settings .", "However , the improvement over passive learning is not as dramatic as that achieved by machine active learning algorithms .", "Furthermore , we compare human active learning performance with predictions from statistical learning theory .", "We investigate a topic at the interface of machine learning and cognitive science .", "Human active learning , where learners can actively query the world for information , is contrasted with passive learning from random examples ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["Our main result is a sharp bound , that holds with high probability , on the excess risk of the output of an online algorithm in terms of the average regret .", "This paper examines the generalization properties of online convex programming algorithms when the loss function is Lipschitz and strongly convex .", "As a corollary , we characterize the convergence rate of P EGASOS ( with high probability ) , a recently proposed method for solving the SVM optimization problem .", "This allows one to use recent algorithms with logarithmic cumulative regret guarantees to achieve fast convergence rates for the excess risk with high probability ."]}
{"orig_sents": ["6", "3", "5", "1", "0", "2", "4"], "shuf_sents": ["We define novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model ( e.g .", "translation , rotation , and expansion ) and then estimate the velocity using the selected model .", "Green functions of differential operators ) .", "These findings are inconsistent with standard models of motion integration which predict best performance for translation .", "The theory gives good agreement with the trends observed in human experiments .", "To explain this discrepancy , our theory formulates motion perception at two levels of inference : we first perform model selection between the competing models ( e.g .", "Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation ."]}
{"orig_sents": ["2", "4", "0", "1", "3"], "shuf_sents": ["In this paper , we formally define an infinite sequence of nested beliefs about the state of the world at the current time t , and present a filtering algorithm that maintains a finite representation which can be used to generate these beliefs .", "In some cases , this representation can be updated exactly in constant time ; we also present a simple approximation scheme to compact beliefs if they become too complex .", "In partially observable worlds with many agents , nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents .", "In experiments , we demonstrate efficient filtering in a range of multi-agent domains .", "The multi-agent filtering problem is to efficiently represent and update these beliefs through time as the agents act in the world ."]}
{"orig_sents": ["5", "4", "2", "3", "0", "1"], "shuf_sents": ["Furthermore , we provide a detailed technical description about heat kernels , which serves as an example for the readers to apply similar techniques for other kernels .", "Our work provides a preliminary step in a new direction to explore the varying consistency between inductive functions and kernels under various distributions .", "Based on the intuition that a good kernelbased inductive function should be consistent with both the data and the kernel , a novel learning scheme is proposed .", "The advantages of this scheme lie in its corresponding Representer Theorem , its strong interpretation ability about what kind of functions should not be penalized , and its promising accuracy improvements shown in a number of experiments .", "However , we observe that the current RLS algorithms can not provide a satisfactory interpretation even on the penalty of a constant function .", "Regularized Least Squares ( RLS ) algorithms have the ability to avoid over-fitting problems and to express solutions as kernel expansions ."]}
{"orig_sents": ["5", "0", "2", "3", "4", "1"], "shuf_sents": ["One of the most widely-used metrics yields the percentage of the variance in the data that is explained by the model .", "We apply our new estimator to binocular disparity tuning curves of a set of macaque V1 neurons and find that on a population level almost all of the variance unexplained by Gabor functions is attributable to noise .", "Unfortunately , this metric is biased due to the intrinsic variability in the data .", "We derive a simple analytical modification of the traditional formula that significantly improves its accuracy ( as measured by bias ) with similar or better precision ( as measured by mean-square error ) in estimating the true underlying Variance Explained by the model class .", "Our estimator advances on previous work by a ) accounting for overfitting due to free model parameters mitigating the need for a separate validation data set , b ) adjusting for the uncertainty in the noise estimate and c ) adding a conditioning term .", "A crucial part of developing mathematical models of information processing in the brain is the quantification of their success ."]}
{"orig_sents": ["3", "0", "1", "2", "4"], "shuf_sents": ["The duality between regularization and prior leads to interpreting regularization methods in terms of maximum a posteriori estimation and has motivated Bayesian interpretations of kernel methods .", "In this paper we pursue a Bayesian interpretation of sparsity in the kernel setting by making use of a mixture of a point-mass distribution and prior that we refer to as `` Silverman 's g-prior . ''", "We provide a theoretical analysis of the posterior consistency of a Bayesian model choice procedure based on this prior .", "Kernel supervised learning methods can be unified by utilizing the tools from regularization theory .", "We also establish the asymptotic relationship between this procedure and the Bayesian information criterion ."]}
{"orig_sents": ["6", "9", "10", "5", "3", "8", "2", "1", "0", "7", "4"], "shuf_sents": ["The second context is the problem of ranking in machine learning , usually arising in the context of information retrieval .", "In this context , we will compare our model with other well known models .", "The first is the theory of econometrics and study of statistical models explaining human choice of alternatives .", "This offers a new generative approach to ranking which can be used for IR .", "Our model is built rigorously and axiomatically based on very simple desirable properties defined locally for comparisons , and automatically implies the existence of a global score function serving as a natural model parameter which can be efficiently fitted to pairwise comparison judgment data by solving a convex optimization problem .", "The model automatically gives rise to a logistic regression based approach to learning how to rank , for which the score and comparison based approaches are dual views .", "The problem of ranking arises ubiquitously in almost every aspect of life , and in particular in Machine Learning/Information Retrieval .", "Here , much work has been done in the discriminative setting , where different heuristics are used to define ranking risk functions .", "There are two main contexts for this work .", "A statistical model for ranking predicts how humans rank subsets V of some universe U .", "In this work we define a statistical model for ranking that satisfies certain desirable properties ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["Models for near-rigid shape matching are typically based on distance-related features , in order to infer matches that are consistent with the isometric assumption .", "Our experimental results reveal substantial improvements upon recent successful models , while maintaining similar running times .", "The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations .", "However , real shapes from image datasets , even when expected to be related by `` almost isometric '' transformations , are actually subject not only to noise but also , to some limited degree , to variations in appearance and scale .", "In this paper , we introduce a graphical model that parameterises appearance , distance , and angle features and we learn all of the involved parameters via structured prediction ."]}
{"orig_sents": ["3", "2", "4", "8", "0", "7", "5", "6", "1"], "shuf_sents": ["The model assumes that responding is based on the posterior distribution over which response is correct , conditioned on the accumulated evidence .", "We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures .", "Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed , but also to the recent stimulus history .", "In most cognitive and motor tasks , speed-accuracy tradeoffs are observed : Individuals can respond slowly and accurately , or quickly yet be prone to errors .", "When stimuli can be characterized on an easy-hard dimension ( e.g. , word frequency in a naming task ) , items preceded by easy trials are responded to more quickly , and with more errors , than items preceded by hard trials .", "Trial-by-trial tracking of difficulty thus leads to sequential effects in speed and accuracy .", "Simulations show the model explains a variety of phenomena in human speeded decision making .", "We derive this posterior as a function of the drift rate , and show that higher estimates of the drift rate lead to ( normatively ) faster responding .", "We propose a rationally motivated mathematical model of this sequential adaptation of control , based on a diffusion model of the decision process in which difficulty corresponds to the drift rate for the correct response ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["It turns out that these bounds are asymptotically tight under mild assumptions on the data generating distribution .", "In this paper lower and upper bounds for the number of support vectors are derived for support vector machines ( SVMs ) based on the -insensitive loss function .", "Finally , we briefly discuss a trade-off in between sparsity and accuracy if the SVM is used to estimate the conditional median ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer .", "This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation .", "The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences .", "When compared with many spike sorting approaches our algorithm demonstrates improved speed , accuracy and allows unsupervised execution ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We study the underlying cause for this result , and then present several testable predictions of these models .", "Alternative model formulations , differing in their sensory noise models and inference methods , are compared based on their fit to experimental data .", "Heavy-tailed sensory likelihoods yield a better description of the subjects ' response behavior than standard Gaussian noise models .", "We explore a recently proposed mixture model approach to understanding interactions between conflicting sensory cues ."]}
{"orig_sents": ["1", "3", "4", "2", "0"], "shuf_sents": ["We show the consistency and rate of convergence to the optimal ROC curve of this procedure in terms of supremum norm and also , as a byproduct of the analysis , we derive an empirical estimate of the optimal ROC curve .", "ROC curves are one of the most widely used displays to evaluate performance of scoring functions .", "We propose to use classifiers obtained by empirical risk minimization of a weighted classification error and then to construct a scoring rule by overlaying these classifiers .", "In the paper , we propose a statistical method for directly optimizing the ROC curve .", "The target is known to be the regression function up to an increasing transformation and this boils down to recovering the level sets of the latter ."]}
{"orig_sents": ["5", "2", "3", "1", "0", "4"], "shuf_sents": ["While our framework is generally applicable to any type of vector field , we focus in this paper on applying it to solving the EEG/MEG inverse problem .", "All variants discussed lead to second-order cone programming formulations .", "The notion of basis fields , which are an extension of scalar basis functions , arises naturally in our framework from a rotational invariance requirement .", "We consider a regression setting as well as inverse problems .", "It is shown that significantly more precise and neurophysiologically more plausible location and shape estimates of cerebral current sources from EEG/MEG measurements become possible with our method when comparing to the state-of-the-art .", "We introduce a novel framework for estimating vector fields using sparse basis field expansions ( S-FLEX ) ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["The main technical tool is the perturbation analysis on the linear invariant subspace that corresponds to the solution of LTSA .", "We then derive the rate of convergence for LTSA in a special case .", "We derive a worst-case upper bound of errors for LTSA which naturally leads to a convergence result .", "We study the convergence and the rate of convergence of a local manifold learning algorithm : LTSA ."]}
{"orig_sents": ["4", "0", "7", "6", "3", "5", "2", "1"], "shuf_sents": ["This requires solving several sub-problems simultaneously , including object detection , region labeling , and geometric reasoning .", "We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization , object detection , multiclass image segmentation , and 3d reconstruction .", "Our method requires only a limited `` black box '' interface with the models , allowing us to use very sophisticated , state-of-the-art classifiers without having to look under the hood .", "In this work , we consider learning a set of related models in such that they both solve their own problem and help each other .", "One of the original goals of computer vision was to fully understand a natural scene .", "We develop a framework called Cascaded Classification Models ( CCM ) , where repeated instantiations of these classifiers are coupled by their input/output variables in a cascade that improves performance at each level .", "Only recently have researchers returned to the difficult task of considering them jointly .", "The last few decades have seen great progress in tackling each of these problems in isolation ."]}
{"orig_sents": ["2", "4", "0", "3", "1"], "shuf_sents": ["We present a new method , QUIC-SVD , for fast approximation of the whole-matrix SVD based on a new sampling mechanism called the cosine tree .", "Such scalability should enable QUIC-SVD to accelerate and enable a wide array of SVD-based methods and applications .", "The Singular Value Decomposition is a key operation in many machine learning methods .", "Our empirical tests show speedups of several orders of magnitude over exact SVD .", "Its computational cost , however , makes it unscalable and impractical for applications involving large datasets or real-time responsiveness , which are becoming increasingly common ."]}
{"orig_sents": ["0", "3", "1", "2", "6", "5", "4"], "shuf_sents": ["Cognitive control refers to the flexible deployment of memory and attention in response to task demands and current goals .", "In these tasks , participants must maintain information about the current stimulus-response mapping in working memory .", "Prominent theories of cognitive control use recurrent neural nets to implement working memory , and optimize memory utilization via reinforcement learning .", "Control is often studied experimentally by presenting sequences of stimuli , some demanding a response , and others modulating the stimulus-response mapping .", "Moreover , our model provides insight into how task instructions can be directly translated into appropriate behavior and then efficiently refined with subsequent task experience .", "We show that our model provides a parsimonious account of behavioral and neuroimaging data , and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal , subject to limitations on learning and the rate of information processing .", "We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic , and control operations that maintain and update working memory are dynamically determined via probabilistic inference ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["In practice , graphs may exhibit cluster structure ; thus in the last part , we present a modified algorithm which achieves the `` best of both worlds '' : it performs well locally in the presence of cluster structure , and globally on large diameter graphs .", "We continue our study of online prediction of the labelling of a graph .", "We overcome this drawback by means of an efficient algorithm which achieves a logarithmic mistake bound .", "We show a fundamental limitation of Laplacian-based algorithms : if the graph has a large diameter then the number of mistakes made by such algorithms may be proportional to the square root of the number of vertices , even when tackling simple problems .", "It is based on the notion of a spine , a path graph which provides a linear embedding of the original graph ."]}
{"orig_sents": ["2", "3", "1", "4", "0"], "shuf_sents": ["Our data demonstrate that the traditional , rowcolumn code has particular spatial properties that lead to better performance than one would expect from its TTIs and Hamming-distances alone , but nonetheless error-correcting codes can improve performance provided the right stimulus type is used .", "Clearly any change to the stimulus setup must also respect the possible psychophysiological consequences .", "From an information-theoretic perspective , a noisy transmission system such as a visual Brain-Computer Interface ( BCI ) speller could benefit from the use of errorcorrecting codes .", "However , optimizing the code solely according to the maximal minimum-Hamming-distance criterion tends to lead to an overall increase in target frequency of target stimuli , and hence a significantly reduced average target-to-target interval ( TTI ) , leading to difficulties in classifying the individual event-related potentials ( ERPs ) due to overlap and refractory effects .", "Here we report new EEG data from experiments in which we explore stimulus types and codebooks in a within-subject design , finding an interaction between the two factors ."]}
{"orig_sents": ["1", "0", "2", "3", "4"], "shuf_sents": ["Using the so-called Tsybakov low noise condition to parametrize the instance distribution , we show bounds on the convergence rate to the Bayes risk of both the fully supervised and the selective sampling versions of the basic algorithm .", "We provide a new analysis of an efficient margin-based algorithm for selective sampling in classification problems .", "Our analysis reveals that , excluding logarithmic factors , the average risk of the selective sampler converges to the Bayes risk at rate N - ( 1+ ) ( 2+ ) /2 ( 3+ ) where N denotes the number of queried labels , and > 0 is the exponent in the low noise condition .", "For all > 3 - 1 0.73 this convergence rate is asymptotically faster than the rate N - ( 1+ ) / ( 2+ ) achieved by the fully supervised version of the same classifier , which queries all labels , and for the two rates exhibit an exponential gap .", "Experiments on textual data reveal that simple variants of the proposed selective sampler perform much better than popular and similarly efficient competitors ."]}
{"orig_sents": ["3", "4", "6", "2", "0", "5", "1"], "shuf_sents": ["To deal with the most critical issue in a centerbased clustering algorithm ( selection of cluster centers ) , we also introduce the notion of stability of a cluster center , which is a well defined LP-based quantity that plays a key role to our algorithm 's success .", "Promising experimental results demonstrate the potentials of our method .", "Despite its generality , it is independent of initialization ( unlike EM-like methods such as K-means ) , has guaranteed convergence , can automatically determine the number of clusters , and can also provide online optimality bounds about the quality of the estimated clustering solutions .", "A novel center-based clustering algorithm is proposed in this paper .", "We first formulate clustering as an NP-hard linear integer program and we then use linear programming and the duality theory to derive the solution of this optimization problem .", "Furthermore , we also introduce , what we call , the margins ( another key ingredient in our algorithm ) , which can be roughly thought of as dual counterparts to stabilities and allow us to obtain computationally efficient approximations to the latter .", "This leads to an efficient and very general algorithm , which works in the dual domain , and can cluster data based on an arbitrary set of distances ."]}
{"orig_sents": ["5", "3", "1", "4", "2", "0"], "shuf_sents": ["The superior accuracy and efficiency of DynaDecomp is demonstrated .", "MAS translates these local approximations into bounds on the accuracy of the results .", "Applying MAS to the Variable Elimination inference algorithm , we introduce an algorithm we call DynaDecomp which is extremely fast in practice and provides guaranteed error bounds on the result .", "The method uses -decompositions which decompose functions used throughout the inference procedure into functions over smaller sets of variables with a known error .", "We show how to optimize -decompositions and provide a fast closed-form solution for an L2 approximation .", "We propose a multiplicative approximation scheme ( MAS ) for inference problems in graphical models , which can be applied to various inference algorithms ."]}
{"orig_sents": ["4", "5", "3", "2", "0", "1"], "shuf_sents": ["From this result we derive approximate upper bounds on the clustering error .", "We show that this bound is tight empirically across a wide range of problems , suggesting that it can be used in practical settings to determine the amount of data reduction allowed in order to meet a specification of permitted loss in clustering performance .", "We show that the error under perturbation of spectral clustering is closely related to the perturbation of the eigenvectors of the Laplacian matrix .", "In this paper , we use stochastic perturbation theory to study the effects of data perturbation on the performance of spectral clustering .", "Spectral clustering is useful for a wide-ranging set of applications in areas such as biological data analysis , image processing and data mining .", "However , the computational and/or communication resources required by the method in processing large-scale data are often prohibitively high , and practitioners are often required to perturb the original data in various ways ( quantization , downsampling , etc ) before invoking a spectral algorithm ."]}
{"orig_sents": ["5", "2", "7", "1", "3", "0", "6", "4"], "shuf_sents": ["Our results show that the V-SPAM model predicts fMRI responses evoked by natural images better than a benchmark model that only provides linear pooling of model complex cells .", "It has a hierarchical filtering stage that consists of three layers : model simple cells , model complex cells , and a third layer in which the complex cells are linearly pooled ( called `` pooled-complex '' cells ) .", "In the study reported here brain activity was measured by means of functional magnetic resonance imaging ( fMRI ) , a noninvasive technique that provides an indirect measure of neural activity pooled over a small volume ( 2mm cube ) of brain tissue .", "The pooling stage then obtains the measured fMRI signals as a sparse additive model ( SpAM ) in which a sparse nonparametric ( nonlinear ) combination of model complex cell and model pooled-complex cell outputs are summed .", "A visualization procedure applied to the V-SPAM model shows that most of the nonlinear pooling consists of simple compressive or saturating nonlinearities .", "We propose a novel hierarchical , nonlinear model that predicts brain activity in area V1 evoked by natural images .", "Furthermore , the spatial receptive fields , frequency tuning and orientation tuning curves of the V-SPAM model estimated for each voxel appears to be consistent with the known properties of V1 , and with previous analyses of this data set .", "Our model , which we call the V-SPAM model , is based on the reasonable assumption that fMRI measurements reflect the ( possibly nonlinearly ) pooled , rectified output of a large population of simple and complex cells in V1 ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We describe a way of learning matrix representations of objects and relationships .", "We show that the same system can learn first-order propositions such as ( 2 , 5 ) +3 or ( Christopher , Penelope ) has wife , and higher-order propositions such as ( 3 , +3 ) plus and ( +3 , -3 ) inverse or ( has husband , has wife ) higher oppsex .", "The goal of learning is to allow multiplication of matrices to represent symbolic relationships between objects and symbolic relationships between relationships , which is the main novelty of the method .", "We demonstrate that this leads to excellent generalization in two different domains : modular arithmetic and family relationships .", "We further demonstrate that the system understands how higher-order propositions are related to first-order ones by showing that it can correctly answer questions about first-order propositions involving the relations +3 or has wife even though it has not been trained on any first-order examples involving these relations ."]}
{"orig_sents": ["4", "6", "5", "3", "9", "1", "7", "2", "0", "8"], "shuf_sents": ["multi-category and multi-view object detection tasks .", "Each boosting classifier is an aggregation of weak-learners , i.e .", "The obtained classifiers are useful for object detection tasks which exhibit multimodalities , e.g .", "This provides a way of obtaining perceptual joint-clusters of object images and features .", "We present a new co-clustering problem of images and visual features .", "Co-clustering is performed in a way that maximises discrimination of object images from non-object images , thus emphasizing discriminative features .", "The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered .", "simple visual features .", "Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classifiers in object detection tasks .", "We tackle the problem by simultaneously boosting multiple strong classifiers which compete for images by their expertise ."]}
{"orig_sents": ["2", "0", "3", "4", "1", "5"], "shuf_sents": ["Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al .", "In particular , we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations .", "We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms .", ".", "We then show that one can interpolate between these two extreme cases .", "Finally , we further extend our framework for generalized strongly convex functions ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["In this paper , we propose an algorithm which provably minimizes any classification calibrated surrogate strictly convex and differentiable -- a set whose losses span the exponential , logistic and squared losses -- , with boosting-type guaranteed convergence rates under a weak learning assumption .", "A particular subclass of these surrogates , that we call balanced convex surrogates , has a key rationale that ties it to maximum likelihood estimation , zerosum games and the set of losses that satisfy some of the most common requirements for losses in supervised learning .", "We report experiments on more than 50 readily available domains of 11 flavors of the algorithm , that shed light on new surrogates , and the potential of data dependent strategies to tune surrogates .", "Bartlett et al ( 2006 ) recently proved that a ground condition for convex surrogates , classification calibration , ties up the minimization of the surrogates and classification risks , and left as an important problem the algorithmic questions about the minimization of these surrogates ."]}
{"orig_sents": ["7", "3", "9", "0", "8", "4", "2", "6", "1", "5", "10"], "shuf_sents": ["to design a privacy-preserving logistic regression algorithm .", "Experiments demonstrate improved learning performance of our method , versus the sensitivity method .", "We prove that our algorithm preserves privacy in the model due to .", "We focus on privacy-preserving logistic regression .", "We then provide a privacy-preserving regularized logistic regression algorithm based on a new privacy-preserving technique : solving a perturbed optimization problem .", "Our privacy-preserving technique does not depend on the sensitivity of the function , and extends easily to a class of convex loss functions .", "We provide learning guarantees for both algorithms , which are tighter for our new algorithm , in cases in which one would typically apply logistic regression .", "This paper addresses the important tradeoff between privacy and learnability , when designing algorithms for learning from private databases .", "This involves bounding the sensitivity of regularized logistic regression , and perturbing the learned classifier with noise proportional to the sensitivity .", "First we apply an idea of Dwork et al .", "Our work also reveals an interesting connection between regularization and privacy ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["Compressive Sensing ( CS ) combines sampling and compression into a single subNyquist linear measurement process for sparse and compressible signals .", "Our new model-based recovery algorithm , dubbed Lattice Matching Pursuit ( LaMP ) , stably recovers MRF-modeled signals using many fewer measurements and computations than the current state-of-the-art algorithms .", "In particular , we use Markov Random Fields ( MRFs ) to represent sparse signals whose nonzero coefficients are clustered .", "In this paper , we extend the theory of CS to include signals that are concisely represented in terms of a graphical model ."]}
{"orig_sents": ["8", "1", "4", "5", "0", "6", "7", "3", "2"], "shuf_sents": ["Although the SSLW could improve a wide range of classification tasks , in this paper , we focus on text categorization with a small training pool .", "However , if the unlabeled data is merely weakly related to the target classes , it becomes questionable whether driving the decision boundary to the low density regions of the unlabeled data will help the classification .", "We show that SSLW results in a significant improvement in categorization accuracy , equipped with a small training set and an unlabeled resource that is weakly related to the test domain .", "For empirical evaluation , we present a direct comparison with a number of stateof-the-art methods for inductive semi-supervised learning and text categorization .", "In such case , the cluster assumption may not be valid ; and consequently how to leverage this type of unlabeled data to enhance the classification accuracy becomes a challenge .", "We introduce `` Semi-supervised Learning with Weakly-Related Unlabeled Data '' ( SSLW ) , an inductive method that builds upon the maximum-margin approach , towards a better usage of weakly-related unlabeled information .", "The key assumption behind this work is that , even with different topics , the word usage patterns across different corpora tends to be consistent .", "To this end , SSLW estimates the optimal wordcorrelation matrix that is consistent with both the co-occurrence information derived from the weakly-related unlabeled documents and the labeled documents .", "The cluster assumption is exploited by most semi-supervised learning ( SSL ) methods ."]}
{"orig_sents": ["2", "9", "7", "3", "6", "1", "0", "5", "4", "8"], "shuf_sents": ["In particular , they are data-dependent and measure the complexity of a class of hypotheses based on the training sample .", "They benefit from the crucial advantages of Rademacher complexity over other measures of the complexity of hypothesis classes .", "This paper presents the first Rademacher complexity-based error bounds for noni.i.d .", "Our bounds hold in the scenario of dependent samples generated by a stationary -mixing process , which is commonly adopted in many previous studies of noni.i.d .", "We also present the first margin bounds for kernel-based classification in this non-i.i.d .", "The empirical Rademacher complexity can be estimated from such finite samples and lead to tighter generalization bounds .", "settings .", "case .", "setting and briefly study their convergence .", "settings , a generalization of similar existing bounds derived for the i.i.d ."]}
{"orig_sents": ["1", "5", "2", "3", "4", "0"], "shuf_sents": ["Empirical results show that the proposed approach is a reliable and scalable method for semi-supervised learning , regardless of the source of unlabeled data , the specific task to be enhanced , and the prediction model used .", "In this paper , we address the question of what kind of knowledge is generally transferable from unlabeled text .", "This semantic correlation contains structural information of the language space and can be used to control the joint shrinkage of model parameters for any specific task in the same space through regularization .", "In an empirical study , we construct 190 different text classification tasks from a real-world benchmark , and the unlabeled documents are a mixture from all these tasks .", "We test the ability of various algorithms to use the mixed unlabeled text to enhance all classification tasks .", "We suggest and analyze the semantic correlation of words as a generally transferable structure of the language and propose a new method to learn this structure using an appropriately chosen latent variable model ."]}
{"orig_sents": ["8", "1", "7", "4", "0", "5", "3", "6", "9", "2"], "shuf_sents": ["We show that principles like those formulated in Kleinberg 's axioms can be readily expressed in the latter framework without leading to inconsistency .", "In this respect , we follow up on the work of Kleinberg , ( ) that showed an impossibility result for such axiomatization .", "In addition , we analyze the computational complexity of evaluating the quality of a given clustering and show that , for the proposed CQMs , it can be computed in polynomial time .", "We analyze what clustering-quality measures should look like and introduce a set of requirements ( axioms ) for such measures .", "As opposed to previous work focusing on clustering functions , we propose to address clustering quality measures as the object to be axiomatized .", "A clustering-quality measure ( CQM ) is a function that , given a data set and its partition into clusters , returns a non-negative real number representing how strong or conclusive the clustering is .", "Our axioms capture the principles expressed by Kleinberg 's axioms while retaining consistency .", "We argue that an impossibility result is not an inherent feature of clustering , but rather , to a large extent , it is an artifact of the specific formalism used in .", "Aiming towards the development of a general clustering theory , we discuss abstract axiomatization for clustering .", "We propose several natural clustering quality measures , all satisfying the proposed axioms ."]}
{"orig_sents": ["7", "2", "0", "4", "1", "3", "6", "5"], "shuf_sents": ["For example , we might wish to use labeled text data to help learn a model for classifying image data , when the labeled images are difficult to obtain .", "The translated learning solution uses a language model to link the class labels to the features in the source spaces , which in turn is translated to the features in the target spaces .", "Unlike many previous learning tasks , we focus on how to use labeled data from one feature space to enhance the classification of other entirely different learning spaces .", "Finally , this chain of linkages is completed by tracing back to the instances in the target spaces .", "An important aspect of translated learning is to build a `` bridge '' to link one feature space ( known as the `` source space '' ) to another space ( known as the `` target space '' ) through a translator in order to migrate the knowledge from source to target .", "Through experiments on the text-aided image classification and cross-language classification tasks , we demonstrate that our translated learning framework can greatly outperform many state-of-the-art baseline methods .", "We show that this path of linkage can be modeled using a Markov chain and risk minimization .", "This paper investigates a new machine learning strategy called translated learning ."]}
{"orig_sents": ["2", "5", "0", "4", "3", "1"], "shuf_sents": ["The principal advantage of this approach is that we do not need to estimate any basis vectors during computation .", "We report empirical performance , quantitatively using motion capture data , and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion , partially nonrigid motion ( such as a facial expression ) , and highly nonrigid motion ( such as a person dancing ) .", "Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes , which have to be estimated anew for each video sequence .", "This results in a significant reduction in unknowns , and corresponding stability in estimation .", "We show that generic bases over trajectories , such as the Discrete Cosine Transform ( DCT ) basis , can be used to compactly describe most real motions .", "In contrast , we propose that the evolving 3D structure be described by a linear combination of basis trajectories ."]}
{"orig_sents": ["0", "5", "3", "2", "4", "1"], "shuf_sents": ["We consider the problem of extracting smooth , low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials .", "By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons , we found that GPFA provided a better characterization of the population activity than the two-stage methods .", "We then present a novel method for extracting neural trajectories , Gaussian-process factor analysis ( GPFA ) , which unifies the smoothing and dimensionality reduction operations in a common probabilistic framework .", "We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way , and account for spiking variability that may vary both across neurons and across time .", "We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution .", "Current methods for extracting neural trajectories involve a two-stage process : the data are first `` denoised '' by smoothing over time , then a static dimensionality reduction technique is applied ."]}
{"orig_sents": ["9", "5", "4", "0", "11", "1", "3", "8", "6", "10", "7", "2"], "shuf_sents": ["`` Why is the net wired randomly ? '' asked Minsky .", "Minsky then shut his eyes .", "We identify conditions under which these networks exhibit good classification performance , and bound their test error in terms of the size of the dataset and the number of random nonlinearities .", "`` Why do you close your eyes ? '' Sussman asked his teacher .", "`` I am training a randomly wired neural net to play tic-tac-toe , '' Sussman replied .", "`` What are you doing ? '' asked Minsky .", "At that moment , Sussman was enlightened .", "Specifically , we consider architectures that compute a weighted sum of their inputs after passing them through a bank of arbitrary randomized nonlinearities .", "`` So that the room will be empty , '' replied Minsky .", "Randomized neural networks are immortalized in this AI Koan : In the days when Sussman was a novice , Minsky once came to him as he sat hacking at the PDP-6 .", "We analyze shallow random networks with the help of concentration of measure inequalities .", "Sussman replied , `` I do not want it to have any preconceptions of how to play . ''"]}
{"orig_sents": ["0", "8", "5", "6", "3", "2", "7", "1", "4"], "shuf_sents": ["Graph clustering methods such as spectral clustering are defined for general weighted graphs .", "This finding shows that graph clustering criteria can not be studied independently of the kind of graph they are applied to .", "We find that the limit expressions are different for different types of graph , for example the r-neighborhood graph or the k-nearest neighbor graph .", "We first study the convergence of graph clustering criteria such as the normalized cut ( Ncut ) as the sample size tends to infinity .", "We also provide examples which show that these differences can be observed for toy and real data already for rather small sample sizes .", "In this case , first a neighborhood graph is constructed using the similarities between the points and then a graph clustering algorithm is applied to this graph .", "In this paper we investigate the influence of the construction of the similarity graph on the clustering results .", "In plain words : Ncut on a kNN graph does something systematically different than Ncut on an r-neighborhood graph !", "In machine learning , however , data often is not given in form of a graph , but in terms of similarity ( or distance ) values between points ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Identification and comparison of nonlinear dynamical system models using noisy and sparse experimental data is a vital task in many fields , however current methods are computationally expensive and prone to error due in part to the nonlinear nature of the likelihood surfaces induced .", "We demonstrate the speed and statistical accuracy of our approach using examples of both ordinary and delay differential equations , and provide a comprehensive comparison with current state of the art methods .", "We present an accelerated sampling procedure which enables Bayesian inference of parameters in nonlinear ordinary and delay differential equations via the novel use of Gaussian processes ( GP ) .", "Our method involves GP regression over time-series data , and the resulting derivative and time delay estimates make parameter inference possible without solving the dynamical system explicitly , resulting in dramatic savings of computational time ."]}
{"orig_sents": ["4", "1", "7", "6", "5", "0", "3", "2"], "shuf_sents": ["In this paper , we formulate it in the framework of learning with structured outputs .", "Previous prediction efforts have only focused on bonding state , i.e .", "On a data set of 199 non-redundant metalloproteins , we obtained precision/recall levels of 75 % /46 % correct ligand-ion assignments , which improves to 88 % /88 % in the setting where the metal binding state is known .", "Our solution relies on the fact that , from a graph theoretical perspective , metal binding has the algebraic properties of a matroid , enabling the application of greedy algorithms for learning structured outputs .", "Metal binding is important for the structural and functional characterization of proteins .", "deciding which residues are jointly involved in the coordination of a metal ion is a new prediction problem that has been never attempted before from protein sequence alone .", "Identifying the geometry of metal-binding sites , i.e .", "deciding which protein residues act as metal ligands in some binding site ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["In this paper , we assume that tasks are clustered into groups , which are unknown beforehand , and that tasks within a group have similar weight vectors .", "We design a new spectral norm that encodes this a priori assumption , without the prior knowledge of the partition of tasks into groups , resulting in a new convex optimization formulation for multi-task learning .", "In the context of learning linear functions for supervised classification or regression , this can be achieved by including a priori information about the weight vectors associated with the tasks , and how they are expected to be related to each other .", "We show in simulations on synthetic examples and on the IEDB MHC-I binding dataset , that our approach outperforms well-known convex methods for multi-task learning , as well as related non-convex methods dedicated to the same problem .", "In multi-task learning several related tasks are considered simultaneously , with the hope that by an appropriate sharing of information across tasks , each task may benefit from the others ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["As opposed to other nonparametric approaches the MeanNN results in smooth differentiable functions of the data samples with clear geometrical interpretation .", "Then we apply the proposed estimators to the ICA problem and obtain a smooth expression for the mutual information that can be analytically optimized by gradient descent methods .", "The improved performance of the proposed ICA algorithm is demonstrated on several test examples in comparison with state-ofthe-art techniques .", "In this paper we introduce the MeanNN approach for estimation of main information theoretic measures such as differential entropy , mutual information and divergence ."]}
{"orig_sents": ["2", "1", "4", "0", "3"], "shuf_sents": ["In this paper , we show that by using a soft-greedy action selection the policy improvement step used in FQI can be simplified to an inexpensive advantageweighted regression .", "However , these methods remain hard to use for continuous action spaces which frequently occur in real-world tasks , e.g. , in robotics and other technical applications .", "Recently , fitted Q-iteration ( FQI ) based methods have become more popular due to their increased sample efficiency , a more stable learning process and the higher quality of the resulting policy .", "With this result , we are able to derive a new , computationally efficient FQI algorithm which can even deal with high dimensional action spaces .", "The greedy action selection commonly used for the policy improvement step is particularly problematic as it is expensive for continuous actions , can cause an unstable learning process , introduces an optimization bias and results in highly non-smooth policies unsuitable for real-world systems ."]}
{"orig_sents": ["4", "0", "2", "1", "5", "3"], "shuf_sents": ["Unlike standard regression or classification in which we predict outputs independently , in ranking we are interested in predicting structured outputs so that misranking one object can significantly affect whether we correctly rank the other objects .", "We present a probabilistic method for learning to rank using the graphical modelling framework of cumulative distribution networks ( CDNs ) , where we can take into account the structure inherent to the problem of ranking by modelling the joint cumulative distribution functions ( CDFs ) over multiple pairwise preferences .", "In practice , the problem of ranking involves a large number of objects to be ranked and either approximate structured prediction methods are required , or assumptions of independence between object scores must be made in order to make the problem tractable .", "We will show that the RankNet , ListNet and ListMLE probabilistic models can be viewed as particular instances of CDNs and that our proposed framework allows for the exploration of a broad class of flexible structured loss functionals for learning to rank .", "Ranking is at the heart of many information retrieval applications .", "We apply our framework to the problem of document retrieval in the case of the OHSUMED benchmark dataset ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods .", "As a result of its restricted responsibilities , a local model may be far simpler than a complete model of the system .", "We then show how one might combine several local models to produce a more detailed model .", "We present a novel mathematical formalism for the idea of a `` local model '' of an uncontrolled dynamical system , a model that makes only certain predictions in only certain situations ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["In this paper we introduce the new concept of non-deterministic MDP policies , and address the question of finding near-optimal non-deterministic policies .", "We propose two solutions to this problem , one based on a Mixed Integer Program and the other one based on a search algorithm .", "We include experimental results obtained from applying this framework to optimize treatment choices in the context of a medical decision support system .", "Markov Decision Processes ( MDPs ) have been extensively studied and used in the context of planning and decision-making , and many methods exist to find the optimal policy for problems modelled as MDPs .", "Although finding the optimal policy is sufficient in many domains , in certain applications such as decision support systems where the policy is executed by a human ( rather than a machine ) , finding all possible near-optimal policies might be useful as it provides more flexibility to the person executing the policy ."]}
{"orig_sents": ["2", "6", "3", "5", "1", "0", "4"], "shuf_sents": ["This is in contrast to results on MI obtained with bandpower features , and might provide an explanation for the so far only moderate success of connectivity features in BCIs .", "Furthermore , modulation between MI and rest is found to be more pronounced than between MI of different hands .", "EEG connectivity measures could provide a new type of feature space for inferring a subject 's intention in Brain-Computer Interfaces ( BCIs ) .", "In this study , EEG connectivity during motor imagery ( MI ) of the left and right is investigated in a broad frequency range across the whole scalp by combining Beamforming with Transfer Entropy and taking into account possible volume conduction effects .", "It is concluded that future studies on connectivity based BCIs should focus on high frequency bands and consider experimental paradigms that maximally vary cognitive demands between conditions .", "Observed connectivity patterns indicate that modulation intentionally induced by MI is strongest in the -band , i.e. , above 35 Hz .", "However , very little is known on EEG connectivity patterns for BCIs ."]}
{"orig_sents": ["2", "6", "5", "4", "3", "0", "1"], "shuf_sents": ["Although these approaches are related , convolutional networks avoid computational difficulties in MRF approaches that arise from probabilistic learning and inference .", "This makes it possible to learn image processing architectures that have a high degree of representational power ( we train models with over 15,000 parameters ) , but whose computational expense is significantly less than that associated with inference in MRF approaches with even hundreds of parameters .", "We present an approach to low-level vision that combines two main ideas : the use of convolutional networks as an image processing architecture and an unsupervised learning procedure that synthesizes training samples from specific noise models .", "We also show how convolutional networks are mathematically related to MRF approaches by presenting a mean field theory for an MRF specially designed for image denoising .", "Moreover , we find that a convolutional network offers similar performance in the blind denoising setting as compared to other techniques in the non-blind setting .", "Using a test set with a hundred natural images , we find that convolutional networks provide comparable and in some cases superior performance to state of the art wavelet and Markov random field ( MRF ) methods .", "We demonstrate this approach on the challenging problem of natural image denoising ."]}
{"orig_sents": ["2", "1", "4", "3", "0"], "shuf_sents": ["The current study shows clearly that very compelling control with excellent timing and dynamics is possible for a non-invasive BCI .", "In the present study , however , we demonstrate and report on the interaction of subjects with a real device : a pinball machine .", "Compared to invasive Brain-Computer Interfaces ( BCI ) , non-invasive BCI systems based on Electroencephalogram ( EEG ) signals have not been applied successfully for precisely timed control tasks .", "Using machine learning methods for mental state decoding , BCI-based pinball control is possible within the first session without the necessity to employ lengthy subject training .", "Results of this study clearly show that fast and well-timed control well beyond chance level is possible , even though the environment is extremely rich and requires precisely timed and complex predictive behavior ."]}
{"orig_sents": ["4", "1", "2", "3", "6", "0", "5"], "shuf_sents": ["The model successfully solves a benchmark working memory problem , and exhibits limitations similar to those observed in humans .", "However , an often neglected fact is that learning to use working memory effectively is itself a difficult problem .", "The Gating framework is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems .", "We unite Gating with machine learning theory concerning the general problem of memory-based optimal control .", "Working memory is a central topic of cognitive neuroscience because it is critical for solving real-world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior .", "Our purpose is to introduce a concise , normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards .", "We present a normative model that learns , by online temporal difference methods , to use working memory to maximize discounted future reward in partially observable settings ."]}
{"orig_sents": ["3", "4", "5", "0", "1", "2", "6"], "shuf_sents": ["For example , if we believe that the receptive field is well-approximated by a Gabor function , then our method constructs stimuli that optimally constrain the Gabor parameters ( orientation , spatial frequency , etc . )", "using as few experimental trials as possible .", "More generally , we may believe a priori that the receptive field lies near a known sub-manifold of the full parameter space ; in this case , our method chooses stimuli in order to reduce the uncertainty along the tangent space of this sub-manifold as rapidly as possible .", "Sequential optimal design methods hold great promise for improving the efficiency of neurophysiology experiments .", "However , previous methods for optimal experimental design have incorporated only weak prior information about the underlying neural system ( e.g. , the sparseness or smoothness of the receptive field ) .", "Here we describe how to use stronger prior information , in the form of parametric models of the receptive field , in order to construct optimal stimuli and further improve the efficiency of our experiments .", "Applications to simulated and real data indicate that these methods may in many cases improve the experimental efficiency ."]}
{"orig_sents": ["3", "0", "2", "4", "1"], "shuf_sents": ["To this end , we provide sharp bounds for Rademacher and Gaussian complexities of ( constrained ) linear classes , which directly lead to a number of generalization bounds .", "Interestingly , our results show that the uniform convergence rates of empirical risk minimization algorithms tightly match the regret bounds of online learning algorithms for linear prediction , up to a constant factor of 2 .", "This derivation provides simplified proofs of a number of corollaries including : risk bounds for linear prediction ( including settings where the weight vectors are constrained by either L2 or L1 constraints ) , margin bounds ( including both L2 and L1 margins , along with more general notions based on relative entropy ) , a proof of the PAC-Bayes theorem , and upper bounds on L2 covering numbers ( with Lp norm constraints and relative entropy constraints ) .", "This work characterizes the generalization ability of algorithms whose predictions are linear in the input vector .", "In addition to providing a unified analysis , the results herein provide some of the sharpest risk and margin bounds ."]}
{"orig_sents": ["6", "0", "4", "5", "2", "3", "1"], "shuf_sents": ["In this paper , we formulate the variance reduction problem by describing a signal-to-noise ratio ( SNR ) for policy gradient algorithms , and evaluate this SNR carefully for the popular Weight Perturbation ( WP ) algorithm .", "We demonstrate that both modifications produce substantial improvements in learning performance in challenging policy gradient experiments .", "First , we examine WP using anisotropic sampling distributions , which introduces a bias into the update but increases the SNR ; this bias can be interpreted as following the natural gradient of the cost function .", "Second , we show that non-Gaussian distributions can also increase the SNR , and argue that the optimal isotropic distribution is a `shell ' distribution with a constant magnitude and uniform distribution in direction .", "We confirm that SNR is a good predictor of long-term learning performance , and that in our episodic formulation , the cost-to-go function is indeed the optimal baseline .", "We then propose two modifications to traditional model-free policy gradient algorithms in order to optimize the SNR .", "Policy gradient ( PG ) reinforcement learning algorithms have strong ( local ) convergence guarantees , but their learning performance is typically limited by a large variance in the estimate of the gradient ."]}
{"orig_sents": ["0", "1", "4", "2", "5", "3"], "shuf_sents": ["We show that an important and computationally challenging solution space feature of the graph coloring problem ( COL ) , namely the number of clusters of solutions , can be accurately estimated by a technique very similar to one for counting the number of solutions .", "This cluster counting approach can be naturally written in terms of a new factor graph derived from the factor graph representing the COL instance .", "We illustrate the algorithm on instances with up to 100 , 000 vertices .", "This methodology scales up to several hundred variables .", "Using a variant of the Belief Propagation inference framework , we can efficiently approximate cluster counts in random COL problems over a large range of graph densities .", "Moreover , we supply a methodology for computing the number of clusters exactly using advanced techniques from the knowledge compilation literature ."]}
{"orig_sents": ["2", "1", "4", "6", "5", "0", "3", "7"], "shuf_sents": ["A quantitative analysis shows that the data provides strong evidence for a network model in which the afferent input is dominated by strong , balanced contributions of recurrent excitation and inhibition .", "To address this issue , we analyze intracellular recording data of cat V1 , which combine measuring the tuning of a range of neuronal properties with a precise localization of the recording sites in the orientation preference map .", "The computational role of the local recurrent network in primary visual cortex is still a matter of debate .", "This recurrent regime is close to a regime of `` instability '' , where strong , self-sustained activity of the network occurs .", "For the analysis , we consider a network model of Hodgkin-Huxley type neurons arranged according to a biologically plausible two-dimensional topographic orientation preference map .", "Each parametrization gives rise to a different model instance for which the tuning of model neurons at different locations of the orientation map is compared to the experimentally measured orientation tuning of membrane potential , spike output , excitatory , and inhibitory conductances .", "We then systematically vary the strength of the recurrent excitation and inhibition relative to the strength of the afferent input .", "The firing rate of neurons in the best-fitting network is particularly sensitive to small modulations of model parameters , which could be one of the functional benefits of a network operating in this particular regime ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["We present cutoff averaging , a technique for converting any conservative online learning algorithm into a batch learning algorithm .", "We provide a statistical analysis of our technique and back our theoretical claims with experimental results .", "Most online-to-batch conversion techniques work well with certain types of online learning algorithms and not with others , whereas cutoff averaging explicitly tries to adapt to the characteristics of the online algorithm being converted .", "An attractive property of our technique is that it preserves the efficiency of the original online algorithm , making it appropriate for large-scale learning problems ."]}
{"orig_sents": ["5", "6", "2", "4", "1", "0", "3"], "shuf_sents": ["We derive a transfer learning procedure that produces resampling weights which match the pool of all examples to the target distribution of any given task .", "Here , questionnaires offered to a portion of each portal 's users produce biased samples .", "While the unlabeled samples reflect the target distribution , the labeled samples may be biased .", "Transfer learning enables us to make predictions even for new portals with few or no training data and improves the overall prediction accuracy .", "This setting is motivated by the problem of predicting sociodemographic features for users of web portals , based on the content which they have accessed .", "We address the problem of learning classifiers for several related tasks that may differ in their joint distribution of input and output variables .", "For each task , small - possibly even empty - labeled samples and large unlabeled samples are available ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["We argue that this theory presents a challenge to Bayesian theories of attention , and suggest an alternative , statistical , account of key supporting data .", "A critical idea is that of limited capacity , the allocation of which has produced continual conflict about such phenomena as early and late selection .", "Selective attention is a most intensively studied psychological phenomenon , rife with theoretical suggestions and schisms .", "An influential resolution of this debate is based on the notion of perceptual load ( Lavie , 2005 ) , which suggests that low-load , easy tasks , because they underuse the total capacity of attention , mandatorily lead to the processing of stimuli that are irrelevant to the current attentional set ; whereas high-load , difficult tasks grab all resources for themselves , leaving distractors high and dry ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["The approach is demonstrated by applying it to networks of spiking neurons .", "Interestingly , there is growing evidence that actor-critic approaches based on phasic dopamine signals play a key role in biological learning through cortical and basal ganglia loops .", "We derive a temporal difference based actor critic learning algorithm , for which convergence can be proved without assuming widely separated time scales for the actor and the critic .", "The established relation between phasic dopamine and the temporal difference signal lends support to the biological relevance of such algorithms .", "Actor-critic algorithms for reinforcement learning are achieving renewed popularity due to their good convergence properties in situations where other approaches often fail ( e.g. , when function approximation is involved ) ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["We use this stochastic process to build a nonparametric extension of the factorial hidden Markov model .", "This process extends the IBP to allow temporal dependencies in the hidden variables .", "After constructing an inference scheme which combines slice sampling and dynamic programming we demonstrate how the infinite factorial hidden Markov model can be used for blind source separation .", "We introduce a new probability distribution over a potentially infinite number of binary Markov chains which we call the Markov Indian buffet process ."]}
{"orig_sents": ["5", "3", "1", "2", "7", "4", "8", "6", "0"], "shuf_sents": ["This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics , but that they can also learn to tune the processing parameters without explicitly representing probabilities .", "In this work , we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reflect the inadvertent engagement of mechanisms critical for adapting to a changing environment .", "We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm .", "This is often the case even if the local trends arise by chance in the context of a randomized design , such that stimulus history has no real predictive power .", "We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential filter .", "In a variety of behavioral tasks , subjects exhibit an automatic and apparently suboptimal sequential effect : they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history , such as a string of repetitions or alternations , compared to when it violates such a pattern .", "We also show that parameter-tuning of the leaky-integration process is possible , using stochastic gradient descent based only on the noisy binary inputs .", "The Bayesian algorithm is shown to be well approximated by linear-exponential filtering of past observations , a feature also apparent in the behavioral data .", "Since the latter is equivalent to a leaky-integration process , a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies , our model provides a principled account of why such dynamics are useful ."]}
{"orig_sents": ["4", "0", "5", "3", "2", "1"], "shuf_sents": ["In the past , two efficient methods , i.e. , Semi-Infinite Linear Programming ( SILP ) and Subgradient Descent ( SD ) , have been proposed for large-scale multiple kernel learning .", "Empirical study with eight UCI datasets shows that the extended level method can significantly improve efficiency by saving on average 91.9 % of computational time over the SILP method and 70.3 % over the SD method .", "The extended level method overcomes the drawbacks of SILP and SD by exploiting all the gradients computed in past iterations and by regularizing the solution via a projection to a level set .", "In this work , we extend the level method , which was originally designed for optimizing non-smooth objective functions , to convex-concave optimization , and apply it to multiple kernel learning .", "We consider the problem of multiple kernel learning ( MKL ) , which can be formulated as a convex-concave problem .", "Despite their success , both methods have their own shortcomings : ( a ) the SD method utilizes the gradient of only the current solution , and ( b ) the SILP method does not regularize the approximate solution obtained from the cutting plane model ."]}
{"orig_sents": ["2", "3", "1", "0", "4", "5"], "shuf_sents": ["Such a source can not be decomposed into independent components using a linear transform , but we show that a simple nonlinear transformation , which we call radial Gaussianization ( RG ) , is able to remove all dependencies .", "Here , we consider a complementary case , in which the source is non-Gaussian but elliptically symmetric .", "We consider the problem of transforming a signal to a representation in which the components are statistically independent .", "When the signal is generated as a linear transformation of independent Gaussian or non-Gaussian sources , the solution may be computed using a linear transformation ( PCA or ICA , respectively ) .", "We apply this methodology to natural signals , demonstrating that the joint distributions of nearby bandpass filter responses , for both sounds and images , are closer to being elliptically symmetric than linearly transformed factorial sources .", "Consistent with this , we demonstrate that the reduction in dependency achieved by applying RG to either pairs or blocks of bandpass filter responses is significantly greater than that achieved by PCA or ICA ."]}
{"orig_sents": ["4", "2", "6", "0", "1", "7", "5", "3"], "shuf_sents": ["To achieve this , we applied a multivariate Poisson distribution with correlation terms for the output distribution of HMMs .", "We formulated a Variational Bayes ( VB ) inference for the model .", "Hidden Markov Models ( HMMs ) have been used to track the state transition among quasi-stationary discrete neural states .", "We demonstrated the performance of our method on synthetic data and a real spike train recorded from a songbird .", "Neural activity is non-stationary and varies across time .", "We developed an efficient algorithm for computing posteriors using the recursive relationship of a multivariate Poisson distribution .", "Within this context , independent Poisson models have been used for the output distribution of HMMs ; hence , the model is incapable of tracking the change in correlation without modulating the firing rate .", "The VB could automatically determine the appropriate number of hidden states and correlation types while avoiding the overlearning problem ."]}
{"orig_sents": ["5", "2", "4", "6", "0", "3", "1"], "shuf_sents": ["The first justification follows directly from the standard approximation error bounds : using a lower discount factor may decrease the approximation error bounds .", "We thus propose another justification : when the rewards are received only sporadically ( as in the case of Tetris ) , we can derive tighter bounds , which support a significant improvement in the solution quality with a decreased discount factor .", "It is generally assumed that using an artificially low discount factor will improve the convergence rate , while sacrificing the solution quality .", "However , we also show that these bounds are loose , thus their decrease does not entirely justify the improved solution quality .", "We however demonstrate that using an artificially low discount factor may significantly improve the solution quality , when used in approximate dynamic programming .", "Most algorithms for solving Markov decision processes rely on a discount factor , which ensures their convergence .", "We propose two explanations of this phenomenon ."]}
{"orig_sents": ["0", "1", "2", "5", "4", "3"], "shuf_sents": ["Distributed learning is a problem of fundamental interest in machine learning and cognitive science .", "In this paper , we present asynchronous distributed learning algorithms for two well-known unsupervised learning frameworks : Latent Dirichlet Allocation ( LDA ) and Hierarchical Dirichlet Processes ( HDP ) .", "In the proposed approach , the data are distributed across P processors , and processors independently perform Gibbs sampling on their local data and communicate their information in a local asynchronous manner with other processors .", "As a stepping stone in the development of asynchronous HDP , a parallel HDP sampler is also introduced .", "We show speedup results on a 730-million-word text corpus using 32 processors , and we provide perplexity results for up to 1500 virtual processors .", "We demonstrate that our asynchronous algorithms are able to learn global topic models that are statistically as accurate as those learned by the standard LDA and HDP samplers , but with significant improvements in computation time and memory ."]}
{"orig_sents": ["7", "1", "8", "2", "0", "6", "5", "3", "9", "4"], "shuf_sents": ["Similar to algorithms such as IC* and FCI , the proposed approach drops the causal sufficiency assumption and learns a structure that indicates ( potential ) latent causes for pairs of observed variables .", "This is the so-called causal sufficiency assumption .", "In this paper , we present an efficient causal structure-learning algorithm , suited for causally insufficient data .", "We show with experiments that our algorithm is comparable to the state-of-the-art FCI algorithm in accuracy , while being several orders of magnitude faster on large problems .", "Keywords : Graphical Models , Structure Learning , Causal Inference .", "the number of variables .", "Assuming a constant local density of the data-generating graph , our algorithm makes a quadratic number of conditionalindependence tests w.r.t .", "Causal structure-discovery techniques usually assume that all causes of more than one variable are observed .", "In practice , it is untestable , and often violated .", "We conclude that MBCS* makes a new range of causally insufficient problems computationally tractable ."]}
{"orig_sents": ["7", "8", "1", "9", "3", "4", "5", "6", "2", "0"], "shuf_sents": ["Experiments confirm the effectiveness of this method on some simulation and real data .", "A drawback of this approach is the lack of theoretical guarantee showing that the local minimum gives a good solution .", "Our performance bound shows that the procedure is superior to the standard L1 convex relaxation for learning sparse targets .", "However it often leads to sub-optimal sparsity in reality .", "This paper tries to remedy the above gap between theory and practice .", "In particular , we investigate a multi-stage convex relaxation scheme for solving problems with non-convex regularization .", "Theoretically , we analyze the behavior of a resulting two-stage relaxation scheme for the capped-L1 regularization .", "We study learning formulations with non-convex regularizaton that are natural for sparse linear models .", "There are two approaches to this problem : * Heuristic methods such as gradient descent that only find a local minimum .", "* Convex relaxation such as L1 -regularization that solves the problem under some conditions ."]}
{"orig_sents": ["5", "0", "7", "1", "8", "6", "3", "2", "4"], "shuf_sents": ["Groups of VPEs operate in SIMD ( single instruction multiple data ) mode , and each group is connected to an independent memory bank .", "With 256 VPEs , implemented on two FPGAs ( field programmable gate array ) chips , we obtain a sustained speed of 19 GMACS ( billion multiplyaccumulate per sec . )", "Tests with Convolutional Neural Networks show similar compute performances .", "The speed on one FPGA is similar to the fastest speeds published on a Graphics Processor for the MNIST problem , despite a clock rate that is an order of magnitude lower .", "This massively parallel architecture is particularly attractive for embedded applications , where low power dissipation is critical .", "We present a new , massively parallel architecture for accelerating machine learning algorithms , based on arrays of vector processing elements ( VPEs ) with variable-resolution arithmetic .", "This performance is more than an order of magnitude higher than that of any FPGA implementation reported so far .", "The memory bandwidth thus scales with the number of VPEs , while the main data flows are local , keeping power dissipation low .", "for SVM training , and 86 GMACS for SVM classification ."]}
{"orig_sents": ["2", "0", "5", "3", "1", "4"], "shuf_sents": ["Due to the translational invariance of their neuronal interactions , CANNs can hold a continuous family of neutrally stable states .", "We quantify the distortions of the bump shape during tracking , and study their effects on the tracking performance .", "Continuous attractor neural networks ( CANNs ) are emerging as promising models for describing the encoding of continuous stimuli in neural systems .", "We develop a perturbative approach that utilizes the dominant movement of the network stationary states in the state space .", "Results are obtained on the maximum speed for a moving stimulus to be trackable , and the reaction time to catch up an abrupt change in stimulus .", "In this study , we systematically explore how neutral stability of a CANN facilitates its tracking performance , a capacity believed to have wide applications in brain functions ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Accounts of how people learn functional relationships between continuous variables have tended to focus on two possibilities : that people are estimating explicit functions , or that they are performing associative learning supported by similarity .", "We use this insight to define a Gaussian process model of human function learning that combines the strengths of both approaches .", "We provide a rational analysis of function learning , drawing on work on regression in machine learning and statistics .", "Using the equivalence of Bayesian linear regression and Gaussian processes , we show that learning explicit rules and using similarity can be seen as two views of one solution to this problem ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["Orientation selectivity , in contrast , has only a very limited potential for redundancy reduction .", "Bandpass filtering , orientation selectivity , and contrast gain control are prominent features of sensory coding at the level of V1 simple cells .", "Here we employ the class of Lp elliptically contoured distributions to investigate the extent to which the two features -- orientation selectivity and contrast gain control -- are suited to model the statistics of natural images .", "While the effect of bandpass filtering and orientation selectivity can be assessed within a linear model , contrast gain control is an inherently nonlinear computation .", "Within this framework we find that contrast gain control can play a significant role for the removal of redundancies in natural images ."]}
{"orig_sents": ["2", "6", "7", "4", "3", "0", "1", "5"], "shuf_sents": ["By selecting features with large coding length increments , the computational system can achieve attention selectivity in both static and dynamic scenes .", "We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation .", "A visual attention system should respond placidly when common stimuli are presented , while at the same time keep alert to anomalous visual inputs .", "In order to optimize energy consumption , the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length .", "The objective of our model is to maximize the entropy of the sampled visual features .", "Moreover , we also show that our model captures several less-reported dynamic visual search behaviors , such as attentional swing and inhibition of return .", "In this paper , a dynamic visual attention model based on the rarity of features is proposed .", "We introduce the Incremental Coding Length ( ICL ) to measure the perspective entropy gain of each feature ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["This paper presents a fully probabilistic approach to PCA , which is generalised to the exponential family , based on Hybrid Monte Carlo sampling .", "We describe the model which is based on a factorisation of the observed data matrix , and show performance of the model on both synthetic and real data .", "Principal Components Analysis ( PCA ) has become established as one of the key tools for dimensionality reduction when dealing with real valued data .", "Approaches such as exponential family PCA and non-negative matrix factorisation have successfully extended PCA to non-Gaussian data types , but these techniques fail to take advantage of Bayesian inference and can suffer from problems of overfitting and poor generalisation ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["We argue that while object recognition requires modeling relative spatial locations of image features within the object , a bag-of-word is sufficient for representing context .", "Learning such a model from weakly labeled data involves labeling of features into two classes : foreground ( object ) or `` informative '' background ( context ) .", "Our approach iterates between an MCMC-based labeling and contour based labeling of features to integrate co-occurrence of features and shape similarity .", "We present an approach that combines bag-of-words and spatial models to perform semantic and syntactic analysis for recognition of an object based on its internal appearance and its context .", "We present a `` shape-aware '' model which utilizes contour information for efficient and accurate labeling of features in the image ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["This article proposes a novel formulation to overcome such sensitivity and maximizes the margin relative to the spread of the data .", "The proposed formulation can be efficiently solved and experiments on digit datasets show drastic performance improvements over SVMs .", "While the paradigm has been successful , the solution obtained by SVMs is dominated by the directions with large data spread and biased to separate the classes by cutting along large spread directions .", "In classification problems , Support Vector Machines maximize the margin of separation between two classes ."]}
{"orig_sents": ["1", "8", "6", "0", "5", "2", "3", "4", "7"], "shuf_sents": ["The performance of a RC system built from binary neurons seems to depend strongly on the network connectivity structure .", "Randomly connected recurrent neural circuits have proven to be very powerful models for online computations when a trained memoryless readout function is appended .", "In this article we investigate this apparent dichotomy in terms of the in-degree of the circuit nodes .", "Our analyses based amongst others on the Lyapunov exponent reveal that the phase transition between ordered and chaotic network behavior of binary circuits qualitatively differs from the one in analog circuits .", "This explains the observed decreased computational performance of binary circuits of high node in-degree .", "In networks of analog neurons such dependency has not been observed .", "Previous work showed a fundamental difference between these two incarnations of the RC idea .", "Furthermore , a novel mean-field predictor for computational performance is introduced and shown to accurately predict the numerically obtained results .", "Such Reservoir Computing ( RC ) systems are commonly used in two flavors : with analog or binary ( spiking ) neurons in the recurrent circuits ."]}
{"orig_sents": ["5", "1", "2", "3", "6", "0", "4"], "shuf_sents": ["Instead , they are defined implicitly via the energy function and depend on all the parameters in the model .", "This possibility has not been considered before because computing the partition function of an RBM is intractable , which appears to make learning a mixture of RBMs intractable as well .", "Surprisingly , when formulated as a third-order Boltzmann machine , such a mixture model can be learned tractably using contrastive divergence .", "The energy function of the model captures threeway interactions among visible units , hidden units , and a single hidden discrete variable that represents the cluster label .", "We present results for the MNIST and NORB datasets showing that the implicit mixture of RBMs learns clusters that reflect the class structure in the data .", "We present a mixture model whose components are Restricted Boltzmann Machines ( RBMs ) .", "The distinguishing feature of this model is that , unlike other mixture models , the mixing proportions are not explicitly parameterized ."]}
{"orig_sents": ["5", "3", "2", "0", "1", "4"], "shuf_sents": ["We show how to solve the cluster selection and partitioning problem monotonically in the dual LP , using the current beliefs to guide these choices .", "We obtain a dual message passing algorithm and apply it to protein design problems where the variables have large state spaces and the usual cluster-based relaxations are very costly .", "By partitioning the state space of a cluster and enforcing consistency only across partitions , we obtain a class of constraints which , although less tight , are computationally feasible for large clusters .", "Usual cluster-based LP relaxations enforce joint consistency on the beliefs of a cluster of variables , with computational cost increasing exponentially with the size of the clusters .", "The resulting method solves many of these problems exactly , and significantly faster than a method that does not use partitioning .", "We propose a new class of consistency constraints for Linear Programming ( LP ) relaxations for finding the most probable ( MAP ) configuration in graphical models ."]}
{"orig_sents": ["4", "3", "1", "2", "0"], "shuf_sents": ["We demonstrate its effectiveness on a wide variety of applications , and find that online optimization of the parameters of the KL-regularized model can significantly improve prediction performance .", "Additionally , we show how to calculate the derivative of the MAP estimate efficiently with implicit differentiation .", "One prior that can be differentiated this way is KL-regularization .", "We show how smoother priors can preserve the benefits of these sparse priors while adding stability to the Maximum A-Posteriori ( MAP ) estimate that makes it more useful for prediction problems .", "Prior work has shown that features which appear to be biologically plausible as well as empirically useful can be found by sparse coding with a prior such as a laplacian ( L1 ) that promotes sparsity ."]}
{"orig_sents": ["3", "4", "5", "0", "1", "2"], "shuf_sents": ["This new data structure is suitable for reducing the cost of each pairwise distance computation , the most dominant cost in many kernel methods .", "Our algorithm guarantees probabilistic relative error on each kernel sum , and can be applied to high-dimensional Gaussian summations which are ubiquitous inside many kernel methods as the key computational bottleneck .", "We provide empirical speedup results on low to high-dimensional datasets up to 89 dimensions .", "We propose a new fast Gaussian summation algorithm for high-dimensional datasets with high accuracy .", "First , we extend the original fast multipole-type methods to use approximation schemes with both hard and probabilistic error .", "Second , we utilize a new data structure called subspace tree which maps each data point in the node to its lower dimensional mapping as determined by any linear dimension reduction method such as PCA ."]}
{"orig_sents": ["5", "4", "0", "3", "2", "1"], "shuf_sents": ["In this paper we develop a method ( LOOPS ) for learning a shape and image feature model that can be trained on a particular object class , and used to outline instances of the class in novel images .", "These localizations can then be used to address a range of tasks , including descriptive classification , search , and clustering .", "Our model achieves state-of-the-art results in precisely outlining objects that exhibit large deformations and articulations in cluttered natural images .", "Furthermore , while the training data consists of uncorresponded outlines , the resulting LOOPS model contains a set of landmark points that appear consistently across instances , and can be accurately localized in an image .", "Sometimes , however , we are interested in more refined aspects of the object in an image , such as pose or particular regions .", "Discriminative tasks , including object categorization and detection , are central components of high-level computer vision ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["In this paper we aim to train deep neural networks for rapid visual recognition .", "We propose a novel regularization method that takes advantage of kernel methods , where an oracle kernel function represents prior knowledge about the recognition task of interest .", "We derive an efficient algorithm using stochastic gradient descent , and demonstrate encouraging results on a wide range of recognition tasks , in terms of both accuracy and speed .", "The task is highly challenging , largely due to the lack of a meaningful regularizer on the functions realized by the networks ."]}
{"orig_sents": ["1", "0", "4", "2", "3"], "shuf_sents": ["We argue that constraining the mapping between the high and low dimensional spaces to be a diffeomorphism is a natural way of ensuring that pairwise distances are approximately preserved .", "This paper introduces a new approach to constructing meaningful lower dimensional representations of sets of data points .", "The problem of solving for the mapping is transformed into one of solving for an Eulerian flow field which we compute using ideas from kernel methods .", "We demonstrate the efficacy of our approach on various real world data sets .", "Accordingly we develop an algorithm which diffeomorphically maps the data near to a lower dimensional subspace and then projects onto that subspace ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Many interesting problems , including Bayesian network structure-search , can be cast in terms of finding the optimum value of a function over the space of graphs .", "We then test this method on both a small testing set and a real-world Bayesian network ; the results suggest that not only is this method reasonably accurate , but that the BDe score itself varies quadratically over the space of all graphs .", "However , this function is often expensive to compute exactly .", "We here present a method derived from the study of Reproducing Kernel Hilbert Spaces which takes advantage of the regular structure of the space of all graphs on a fixed number of nodes to obtain approximations to the desired function quickly and with reasonable accuracy ."]}
{"orig_sents": ["1", "2", "4", "3", "5", "6", "0"], "shuf_sents": ["The questions considered are also thematically related to Fourier Transforms over the symmetric group and the currently popular topic of compressed sensing .", "Motivated by applications like elections , web-page ranking , revenue maximization etc. , we consider the question of inferring popular rankings using constrained data .", "More specifically , we consider the problem of inferring a probability distribution over the group of permutations using its first order marginals .", "We then provide a simple and novel algorithm that can recover up to O ( n ) permutations under a natural stochastic model ; in this sense , the algorithm is optimal .", "We first prove that it is not possible to recover more than O ( n ) permutations over n elements with the given information .", "In certain applications , the interest is in recovering only the most popular ( or mode ) ranking .", "As a second result , we provide an algorithm based on the Fourier Transform over the symmetric group to recover the mode under a natural majority condition ; the algorithm turns out to be a maximum weight matching on an appropriately defined weighted bipartite graph ."]}
{"orig_sents": ["0", "2", "1", "5", "6", "3", "4"], "shuf_sents": ["Many motor skills in humanoid robotics can be learned using parametrized motor primitives as done in imitation learning .", "In this paper , we extend previous work on policy learning from the immediate reward case to episodic reinforcement learning .", "However , most interesting motor learning problems are high-dimensional reinforcement learning problems often beyond the reach of current methods .", "We compare this algorithm to several well-known parametrized policy search methods and show that it outperforms them .", "We apply it in the context of motor learning and show that it can learn a complex Ball-in-a-Cup task using a real Barrett WAMTM robot arm .", "We show that this results in a general , common framework also connected to policy gradient methods and yielding a novel algorithm for policy learning that is particularly well-suited for dynamic motor primitives .", "The resulting algorithm is an EM-inspired algorithm applicable to complex motor learning tasks ."]}
{"orig_sents": ["3", "4", "1", "0", "2"], "shuf_sents": ["We develop a sampling algorithm that combines a truncated approximation to the Dirichlet process with efficient joint sampling of the mode and state sequences .", "Our nonparametric Bayesian approach utilizes a hierarchical Dirichlet process prior to learn an unknown number of persistent , smooth dynamical modes .", "The utility and flexibility of our model are demonstrated on synthetic data , sequences of dancing honey bees , and the IBOVESPA stock index .", "Many nonlinear dynamical phenomena can be effectively modeled by a system that switches among a set of conditionally linear dynamical modes .", "We consider two such models : the switching linear dynamical system ( SLDS ) and the switching vector autoregressive ( VAR ) process ."]}
{"orig_sents": ["3", "5", "4", "1", "2", "0"], "shuf_sents": ["On a cognitive and neuroscientific level , the theory provides a unifying framework for several different forms of goal-directed action selection , placing emphasis on a novel form , within which orbitofrontal reward representations directly drive policy selection .", "We take three empirically motivated points as founding premises : ( 1 ) Neurons in dorsolateral prefrontal cortex represent action policies , ( 2 ) Neurons in orbitofrontal cortex represent rewards , and ( 3 ) Neural computation , across domains , can be appropriately understood as performing structured probabilistic inference .", "On a purely computational level , the resulting account relates closely to previous work using Bayesian inference to solve Markov decision problems , but extends this work by introducing a new algorithm , which provably converges on optimal plans .", "Research in animal learning and behavioral neuroscience has distinguished between two forms of action control : a habit-based form , which relies on stored action values , and a goal-directed form , which forecasts and compares action outcomes based on a model of the environment .", "In the present paper , we advance a computational framework for goal-directed control in animals and humans .", "While habit-based control has been the subject of extensive computational research , the computational principles underlying goal-directed control in animals have so far received less attention ."]}
{"orig_sents": ["1", "0", "3", "5", "4", "2"], "shuf_sents": ["For continuous-valued data linear acyclic causal models with additive noise are often used because these models are well understood and there are well-known methods to fit them to data .", "The discovery of causal relationships between a set of observed variables is a fundamental problem in science .", "In addition to theoretical results we show simulations and some simple real data experiments illustrating the identification power provided by nonlinearities .", "In reality , of course , many causal relationships are more or less nonlinear , raising some doubts as to the applicability and usefulness of purely linear methods .", "In this extended framework , nonlinearities in the data-generating process are in fact a blessing rather than a curse , as they typically provide information on the underlying causal system and allow more aspects of the true data-generating mechanisms to be identified .", "In this contribution we show that the basic linear framework can be generalized to nonlinear models ."]}
{"orig_sents": ["2", "1", "0", "5", "4", "3", "6"], "shuf_sents": ["We approximate the graph with a spanning tree and then we predict with the kernel perceptron .", "We discuss the application of this technique to fast label prediction on a generic graph .", "Given an n-vertex weighted tree with structural diameter S and a subset of m vertices , we present a technique to compute a corresponding m x m Gram matrix of the pseudoinverse of the graph Laplacian in O ( n + m2 + mS ) time .", "We present experiments on two web-spam classification tasks , one of which includes a graph with 400,000 vertices and more than 10,000,000 edges .", "The fast computation of the pseudoinverse enables us to address prediction problems on large graphs .", "We address the approximation of the graph with either a minimum spanning tree or a shortest path tree .", "The results indicate that the accuracy of our technique is competitive with previous methods using the full graph information ."]}
{"orig_sents": ["6", "4", "5", "2", "7", "0", "3", "1"], "shuf_sents": ["Our main result shows that , remarkably , for any fixed target function , there exists a distribution weighted combining rule that has a loss of at most with respect to any target mixture of the source distributions .", "Finally , we report empirical results for a multiple source adaptation problem with a real-world dataset .", "We present several theoretical results relating to this problem .", "We further generalize the setting from a single target function to multiple consistent target functions and show the existence of a combining rule with error at most 3 .", "For each source domain , the distribution over the input points as well as a hypothesis with error at most are given .", "The problem consists of combining these hypotheses to derive a hypothesis with small error with respect to the target domain .", "This paper presents a theoretical analysis of the problem of domain adaptation with multiple sources .", "In particular , we prove that standard convex combinations of the source hypotheses may in fact perform very poorly and that , instead , combinations weighted by the source distributions benefit from favorable theoretical guarantees ."]}
{"orig_sents": ["0", "4", "2", "3", "1", "5"], "shuf_sents": ["Empirical evidence shows that in favorable situations semi-supervised learning ( SSL ) algorithms can capitalize on the abundance of unlabeled training data to improve the performance of a learning task , in the sense that fewer labeled training data are needed to achieve a target error bound .", "We develop a finite sample analysis that characterizes the value of unlabeled data and quantifies the performance improvement of SSL compared to supervised learning .", "Recent attempts at theoretically characterizing SSL gains only provide a partial and sometimes apparently conflicting explanations of whether , and to what extent , unlabeled data can help .", "In this paper , we attempt to bridge the gap between the practice and theory of semi-supervised learning .", "However , in other situations unlabeled data do not seem to help .", "We show that there are large classes of problems for which SSL can significantly outperform supervised learning , in finite sample regimes and sometimes also in terms of error convergence rates ."]}
{"orig_sents": ["6", "7", "9", "1", "0", "8", "4", "3", "2", "5"], "shuf_sents": ["With copulas it is possible to use arbitrary marginal distributions such as Poisson or negative binomial that are better suited for modeling noise distributions of spike counts .", "In this study , we present copulas as an alternative approach .", "We apply the method to our data recorded from macaque prefrontal cortex .", "Methods for parameter inference based on maximum likelihood estimates and for computation of mutual information are provided .", "We develop a framework to analyze spike count data by means of copulas .", "The data analysis leads to three findings : ( 1 ) copula-based distributions provide significantly better fits than discretized multivariate normal distributions ; ( 2 ) negative binomial margins fit the data significantly better than Poisson margins ; and ( 3 ) the dependence structure carries 12 % of the mutual information between stimuli and responses .", "Correlations between spike counts are often used to analyze neural coding .", "The noise is typically assumed to be Gaussian .", "Furthermore , copulas place a wide range of dependence structures at the disposal and can be used to analyze higher order interactions .", "Yet , this assumption is often inappropriate , especially for low spike counts ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We present a sparse approximation approach for dependent output Gaussian processes ( GP ) .", "Based on these latent functions , we establish an approximation scheme using a conditional independence assumption between the output processes , leading to an approximation of the full covariance which is determined by the locations at which the latent functions are evaluated .", "We show results of the proposed methodology for synthetic data and real world applications on pollution prediction and a sensor network .", "Employing a latent function framework , we apply the convolution process formalism to establish dependencies between output variables , where each latent function is represented as a GP ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Within this framework , we derive a new convex form of the constraint and analyze it in the mistake bound model .", "Confidence-weighted ( CW ) learning , an online learning method for linear classifiers , maintains a Gaussian distributions over weight vectors , with a covariance matrix that represents uncertainty about weights and correlations .", "Confidence constraints ensure that a weight vector drawn from the hypothesis distribution correctly classifies examples with a specified probability .", "Empirical evaluation with both synthetic and text data shows our version of CW learning achieves lower cumulative and out-of-sample errors than commonly used first-order and second-order online methods ."]}
{"orig_sents": ["9", "4", "5", "6", "7", "8", "1", "0", "3", "2"], "shuf_sents": ["These formulations not only help to understand the signal conditioning and classification methods of insect olfactory systems , but also can be leveraged in synthetic problems .", "A local Hebbian learning procedure governs the plasticity in the model .", "We show on a set of records from metal-oxide gas sensors that the cascade of these two new models facilitates fast and accurate discrimination of even highly imbalanced mixtures from pure odors .", "Among them , we consider here the discrimination of odor mixtures from pure odors .", "Therefore , the olfactory code at the sensor/receptor level is in general a slow and highly variable indicator of the input odor in both natural and artificial situations .", "Insects overcome this problem by using a neuronal device in their Antennal Lobe ( AL ) , which transforms the identity code of olfactory receptors to a spatio-temporal code .", "This transformation improves the decision of the Mushroom Bodies ( MBs ) , the subsequent classifier , in both speed and accuracy .", "Here we propose a rate model based on two intrinsic mechanisms in the insect AL , namely integration and inhibition .", "Then we present a MB classifier model that resembles the sparse and random structure of insect MB .", "The odor transduction process has a large time constant and is susceptible to various types of noise ."]}
{"orig_sents": ["1", "4", "2", "0", "6", "3", "5"], "shuf_sents": ["We derive its limiting distribution under the null hypothesis ( no change occurs ) , and establish the consistency under the alternative hypothesis ( a change occurs ) .", "We introduce a kernel-based method for change-point analysis within a sequence of temporal observations .", "We propose a test statistic based upon the maximum kernel Fisher discriminant ratio as a measure of homogeneity between segments .", "If a change actually occurs , the test statistic also yields an estimator of the change-point location .", "Change-point analysis of an unlabelled sample of observations consists in , first , testing whether a change in the distribution occurs within the sample , and second , if a change occurs , estimating the change-point instant after which the distribution of the observations switches from one distribution to another different distribution .", "Promising experimental results in temporal segmentation of mental tasks from BCI data and pop song indexation are presented .", "This allows to build a statistical hypothesis testing procedure for testing the presence of a change-point , with a prescribed false-alarm probability and detection probability tending to one in the large-sample setting ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["Our approach , multi-resolution exploration ( MRE ) , uses a hierarchical mapping to identify regions of the state space that would benefit from additional samples .", "We demonstrate MRE 's broad utility by using it to speed up learning in a prototypical model-based and value-based reinforcement-learning method .", "We propose a new methodology for representing uncertainty in continuous-state control problems .", "The essence of exploration is acting to try to decrease uncertainty .", "Empirical results show that MRE improves upon state-of-the-art exploration approaches ."]}
{"orig_sents": ["2", "0", "1", "4", "3"], "shuf_sents": ["Combining approximate Bayesian inference and natural image statistics with high-performance numerical computation , we propose the first Bayesian experimental design framework for this problem of high relevance to clinical and brain research .", "Our solution requires large-scale approximate inference for dense , non-Gaussian models .", "We show how improved sequences for magnetic resonance imaging can be found through optimization of Bayesian design scores .", "Our approach is evaluated on raw data from a 3T MR scanner .", "We propose a novel scalable variational inference algorithm , and show how powerful methods of numerical mathematics can be modified to compute primitives in our framework ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We explore a new Bayesian model for probabilistic grammars , a family of distributions over discrete structures that includes hidden Markov models and probabilistic context-free grammars .", "We derive a variational EM algorithm for that model , and then experiment with the task of unsupervised grammar induction for natural language dependency parsing .", "We show that our model achieves superior results over previous models that use different priors .", "Our model extends the correlated topic model framework to probabilistic grammars , exploiting the logistic normal distribution as a prior over the grammar parameters ."]}
{"orig_sents": ["8", "5", "4", "2", "3", "0", "6", "7", "9", "1"], "shuf_sents": ["We must also explore the underlying pool constantly to identify promising alternatives , quickly discarding poor performers .", "Our analysis of this application also suggests a number of future research avenues .", "Some of the challenges we face include a dynamic content pool , short article lifetimes , non-stationary click-through rates , and extremely high traffic volumes .", "The fundamental problem we must solve is to quickly identify which items are popular ( perhaps within different user segments ) , and to exploit them while they remain current .", "portal , and selects articles to serve to hundreds of millions of user visits per day , significantly increasing the number of user clicks over the original manual approach , in which editors periodically selected articles to display .", "It is now deployed on a major Yahoo !", "Our approach is based on tracking per article performance in near real time through online models .", "We describe the characteristics and constraints of our application setting , discuss our design choices , and show the importance and effectiveness of coupling online models with a randomization procedure .", "We describe a new content publishing system that selects articles to serve to a user , choosing from an editorially programmed pool that is frequently refreshed .", "We discuss the challenges encountered in a production online content-publishing environment and highlight issues that deserve careful attention ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["This learning problem arises frequently in many application areas ranging from signal processing , computer vision , over robotics to computer graphics .", "We present a new algorithmic scheme for the solution of this general learning problem based on regularized empirical risk minimization .", "This paper discusses non-parametric regression between Riemannian manifolds .", "The regularization functional takes into account the geometry of input and output manifold , and we show that it implements a prior which is particularly natural .", "Moreover , we demonstrate that our algorithm performs well in a difficult surface registration problem ."]}
{"orig_sents": ["3", "0", "2", "4", "1", "5"], "shuf_sents": ["A good clustering of features may be seen as a combinatorial transformation of the data matrix , effectively enforcing a form of regularization that may lead to a better clustering of examples ( and vice-versa ) .", "These algorithms ( i ) support dual supervision in the form of labels for both examples and/or features , ( ii ) provide principled predictive capability on out-of-sample test data , and ( iii ) arise naturally from the classical Representer theorem applied to regularization problems posed on a collection of Reproducing Kernel Hilbert Spaces .", "In many applications , partial supervision in the form of a few row labels as well as column labels may be available to potentially assist co-clustering .", "By attempting to simultaneously partition both the rows ( examples ) and columns ( features ) of a data matrix , Co-clustering algorithms often demonstrate surprisingly impressive performance improvements over traditional one-sided row clustering techniques .", "In this paper , we develop two novel semi-supervised multi-class classification algorithms motivated respectively by spectral bipartite graph partitioning and matrix approximation formulations for co-clustering .", "Empirical results demonstrate the effectiveness and utility of our algorithms ."]}
{"orig_sents": ["3", "0", "7", "8", "2", "5", "4", "1", "6"], "shuf_sents": ["It is also a central theoretical concern in a wide variety of fields and has undergone detailed , in-depth , analyses .", "We show that these behavioral measures capture explicit , questionnaire-based cognitions .", "Helplessness -- a core element in the conceptualizations of MDD that has lead to major advances in its treatment , pharmacological and neurobiological understanding -- is formalized as a simple prior over the outcome entropy of actions in uncertain environments .", "Decision making lies at the very heart of many psychiatric diseases .", "These formulations allow for the design of specific tasks to measure anhedonia and helplessness behaviorally .", "Anhedonia , which is an equally fundamental aspect of the disease , is related to the effective reward size .", "We also provide evidence that these tasks may allow classification of subjects into healthy and MDD groups based purely on a behavioural measure and avoiding any verbal reports .", "We take as an example Major Depressive Disorder ( MDD ) , applying insights from a Bayesian reinforcement learning framework .", "We focus on anhedonia and helplessness ."]}
{"orig_sents": ["4", "3", "2", "0", "1", "5"], "shuf_sents": ["For LM adaptation , unigram and bigram LSA are integrated into the background N-gram LM via marginal adaptation and linear interpolation respectively .", "Experimental results on the Mandarin RT04 test set show that applying unigram and bigram LSA together yields 6 % -8 % relative perplexity reduction and 2.5 % relative character error rate reduction which is statistically significant compared to applying only unigram LSA .", "We address the scalability issue to large training corpora via bootstrapping of bigram LSA from unigram LSA .", "The model is trained using efficient variational EM and smoothed using the proposed fractional Kneser-Ney smoothing which handles fractional counts .", "We present a correlated bigram LSA approach for unsupervised LM adaptation for automatic speech recognition .", "On the large-scale evaluation on Arabic , 3 % relative word error rate reduction is achieved which is also statistically significant ."]}
{"orig_sents": ["3", "1", "5", "0", "2", "4"], "shuf_sents": ["Different from object recognition , our model combines both large-scale global features and local patch features to distinguish various actions .", "Our model is based on the recently proposed hidden conditional random field ( hCRF ) for object recognition .", "Our experimental results show that our model is comparable to other state-of-the-art approaches in action recognition .", "We present a discriminative part-based approach for human action recognition from video sequences using motion features .", "In particular , our experimental results demonstrate that combining large-scale global features and local patch features performs significantly better than directly applying hCRF on local patches alone .", "Similar to hCRF for object recognition , we model a human action by a flexible constellation of parts conditioned on image observations ."]}
{"orig_sents": ["1", "4", "3", "6", "0", "5", "2"], "shuf_sents": ["This paper presents a technique to overcome this problem , and extends it to a unified framework for treating noise , missing data , and outliers in KPCA .", "Kernel Principal Component Analysis ( KPCA ) is a popular generalization of linear PCA that allows non-linear feature extraction .", "Extensive experiments , in both synthetic and real data , show that our algorithm outperforms existing methods .", "The feature space is typically induced implicitly by a kernel function , and linear PCA in the feature space is performed via the kernel trick .", "In KPCA , data in the input space is mapped to higher ( usually ) dimensional feature space where the data can be linearly modeled .", "Our method is based on a novel cost function to perform inference in KPCA .", "However , due to the implicitness of the feature space , some extensions of PCA such as robust PCA can not be directly generalized to KPCA ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["The Temporal Restricted Boltzmann Machine ( TRBM ) is a probabilistic model for sequences that is able to successfully model ( i.e. , generate nice-looking samples of ) several very high dimensional sequences , such as motion capture data and the pixels of low resolution videos of balls bouncing in a box .", "In this paper we introduce the Recurrent TRBM , which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable .", "The major disadvantage of the TRBM is that exact inference is extremely hard , since even computing a Gibbs update for a single variable of the posterior is exponentially expensive .", "We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls .", "This difficulty has necessitated the use of a heuristic inference procedure , that nonetheless was accurate enough for successful learning ."]}
{"orig_sents": ["4", "1", "3", "2", "5", "0"], "shuf_sents": ["Importantly , we also show that by using global operators , we are able to achieve better generalization even when learning Bayesian networks of unbounded treewidth .", "While the method of thin junction trees can , in principle , be used for this purpose , its fully greedy nature makes it prone to overfitting , particularly when data is scarce .", "At the heart of our method is a triangulated graph that we dynamically update in a way that facilitates the addition of chain structures that increase the bound on the model 's treewidth by at most one .", "In this work we present a novel method for learning Bayesian networks of bounded treewidth that employs global structure modifications and that is polynomial in the size of the graph and the treewidth bound .", "With the increased availability of data for complex domains , it is desirable to learn Bayesian network structures that are sufficiently expressive for generalization while also allowing for tractable inference .", "We demonstrate the effectiveness of our `` treewidth-friendly '' method on several real-life datasets ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We assume that the fraction of jobs completed by a schedule is a monotone , submodular function of a set of pairs ( v , ) , where is the time invested in activity v. Under this assumption , our online algorithm performs near-optimally according to two natural metrics : ( i ) the fraction of jobs completed within time T , for some fixed deadline T > 0 , and ( ii ) the average time required to complete each job .", "We evaluate our algorithm experimentally by using it to learn , online , a schedule for allocating CPU time among solvers entered in the 2007 SAT solver competition .", "Our online algorithm can be applied in environments where abstract jobs arrive one at a time , and one can complete the jobs by investing time in a number of abstract activities , according to some schedule .", "We present an algorithm for solving a broad class of online resource allocation problems ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Experimental results agree well with simulation and exhibit expected STD behavior : the transmitted spike train has negative autocorrelation and lower power spectral density at low frequencies which can remove redundancy in the input spike train , and the mean transmission probability is inversely proportional to the input spike rate which has been suggested as an automatic gain control mechanism in neural systems .", "We report a compact realization of short-term depression ( STD ) in a VLSI stochastic synapse .", "The behavior of the circuit is based on a subtractive single release model of STD .", "The dynamic stochastic synapse could potentially be a powerful addition to existing deterministic VLSI spiking neural systems ."]}
{"orig_sents": ["3", "2", "1", "4", "0"], "shuf_sents": ["We define the non-stationary DBN model , present an MCMC sampling algorithm for learning the structure of the model from time-series data under different assumptions , and demonstrate the effectiveness of the algorithm on both simulated and biological data .", "In this paper , we introduce a new class of graphical models called non-stationary dynamic Bayesian networks , in which the conditional dependence structure of the underlying data-generation process is permitted to change over time .", "An important assumption of DBN structure learning is that the data are generated by a stationary process -- an assumption that is not true in many important settings .", "A principled mechanism for identifying conditional dependencies in time-series data is provided through structure learning of dynamic Bayesian networks ( DBNs ) .", "Non-stationary dynamic Bayesian networks represent a new framework for studying problems in which the structure of a network is evolving over time ."]}
{"orig_sents": ["5", "1", "3", "0", "4", "2"], "shuf_sents": ["In particular , we demonstrate the effectiveness of CRS in efficiently computing the Hamming norm , the Hamming distance , the lp distance , and the 2 distance .", "This study modifies the original CRS and extends CRS to handle dynamic or streaming data , which much better reflect the real-world situation than assuming static data .", "We recommend CRS as a promising tool for building highly scalable systems , in machine learning , data mining , recommender systems , and information retrieval .", "Compared with many other sketching algorithms for dimension reductions such as stable random projections , CRS exhibits a significant advantage in that it is `` one-sketch-for-all . ''", "A generic estimator and an approximate variance formula are also provided , for approximating any type of distances .", "Conditional Random Sampling ( CRS ) was originally proposed for efficiently computing pairwise ( l2 , l1 ) distances , in static , large-scale , and sparse data ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We show that this model can reproduce classic results in online sentence comprehension , and that it naturally provides the first rational account of an outstanding problem in psycholinguistics , in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information .", "In contrast , most of the leading psycholinguistic models and fielded algorithms for natural language parsing are non-incremental , have run time superlinear in input length , and/or enforce structural locality constraints on probabilistic dependencies between events .", "We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle filter , a sequential Monte Carlo method , to the problem of incremental parsing .", "Language comprehension in humans is significantly constrained by memory , yet rapid , highly incremental , and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input ."]}
{"orig_sents": ["3", "1", "5", "4", "0", "2"], "shuf_sents": ["In addition , we show that the objective function of the approximate formulation is differentiable with Lipschitz continuous gradient , and hence existing methods can be employed to compute the optimal solution efficiently .", "We formulate the problem in the kernel-induced feature space and propose to learn the kernel matrix as a linear combination of a given collection of kernel matrices in the MKL framework .", "We apply the proposed formulation to the automated annotation of Drosophila gene expression pattern images , and promising results have been reported in comparison with representative algorithms .", "We present a multi-label multiple kernel learning ( MKL ) formulation in which the data are embedded into a low-dimensional space directed by the instancelabel correlations encoded into a hypergraph .", "We further propose an approximate formulation with a guaranteed error bound which involves an unconstrained convex optimization problem .", "The proposed learning formulation leads to a non-smooth min-max problem , which can be cast into a semi-infinite linear program ( SILP ) ."]}
{"orig_sents": ["3", "5", "4", "1", "0", "2"], "shuf_sents": ["We then reformulate the sparse PCA optimization problem to explicitly reflect the maximum additional variance objective on each round .", "To rectify the situation , we first develop several deflation alternatives better suited to the cardinality-constrained context .", "The result is a generalized deflation procedure that typically outperforms more standard techniques on real-world datasets .", "In analogy to the PCA setting , the sparse PCA problem is often solved by iteratively alternating between two subtasks : cardinality-constrained rank-one variance maximization and matrix deflation .", "In this work , we demonstrate that the standard PCA deflation procedure is seldom appropriate for the sparse PCA setting .", "While the former has received a great deal of attention in the literature , the latter is seldom analyzed and is typically borrowed without justification from the PCA context ."]}
{"orig_sents": ["1", "5", "2", "3", "7", "8", "4", "0", "9", "6"], "shuf_sents": ["The resulting contexts of contours are used to perform a final grouping on contours in the original image while simultaneously finding matches in the related image , again by shape matching .", "Contours have been established in the biological and computer vision literature as a compact yet descriptive representation of object shape .", "We present a method for further grouping of contours in an image using their relationship to the contours of a second , related image .", "Stereo , motion , and similarity all provide cues that can aid this task ; contours that have similar transformations relating them to their matching contours in the second image likely belong to a single group .", "For each transformation , groups of contours with matching shape across the two images are identified to provide a context for evaluating matches of individual contour points across the images .", "While individual contours provide structure , they lack the large spatial support of region segments ( which lack internal structure ) .", "Our method also produces qualitatively better results against a baseline method that does not use the inferred contexts .", "To find matches for contours , we rely only on shape , which applies directly to all three modalities without modification , in contrast to the specialized approaches developed for each independently .", "Visually salient contours are extracted in each image , along with a set of candidate transformations for aligning subsets of them .", "We demonstrate grouping results on image pairs consisting of stereo , motion , and similar images ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Neuroimaging datasets often have a very large number of voxels and a very small number of training cases , which means that overfitting of models for this data can become a very serious problem .", "Working with a set of fMRI images from a study on stroke recovery , we consider a classification task for which logistic regression performs poorly , even when L1- or L2- regularized .", "We compare discriminative training of exactly the same set of models , and we also consider convex blends of generative and discriminative training .", "We show that much better discrimination can be achieved by fitting a generative model to each separate condition and then seeing which model is most likely to have generated the data ."]}
{"orig_sents": ["0", "1", "2", "5", "3", "4"], "shuf_sents": ["In many settings , such as protein interactions and gene regulatory networks , collections of author-recipient email , and social networks , the data consist of pairwise measurements , e.g. , presence or absence of links between pairs of objects .", "Analyzing such data with probabilistic models requires non-standard assumptions , since the usual independence or exchangeability assumptions no longer hold .", "In this paper , we introduce a class of latent variable models for pairwise measurements : mixed membership stochastic blockmodels .", "We develop a general variational inference algorithm for fast approximate posterior inference .", "We demonstrate the advantages of mixed membership stochastic blockmodel with applications to social networks and protein interaction networks .", "Models in this class combine a global model of dense patches of connectivity ( blockmodel ) with a local model to instantiate node-specific variability in the connections ( mixed membership ) ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["We use a rational model of preference learning , drawing on ideas from economics and computer science , to explain the behavior of children in several recent experiments .", "However , there exists no overarching account of what children are doing when they learn about preferences or how they use that knowledge .", "Specifically , we show how a simple econometric model can be extended to capture two- to four-year-olds ' use of statistical information in inferring preferences , and their generalization of these preferences .", "Young children demonstrate the ability to make inferences about the preferences of other agents based on their choices ."]}
{"orig_sents": ["4", "5", "2", "6", "0", "3", "1"], "shuf_sents": ["An algorithm needs to choose among a large collection of ads , more than can be fully explored within the typical ad lifetime .", "Empirical studies on various reward distributions , including one derived from a real-world ad serving application , show that the proposed algorithms significantly outperform the standard multi-armed bandit approaches applied to these settings .", "In this setting an algorithm needs to continuously explore new arms , in contrast to the standard k-armed bandit model in which arms are available indefinitely and exploration is reduced once an optimal arm is identified with nearcertainty .", "We present an optimal algorithm for the state-aware ( deterministic reward function ) case , and build on this technique to obtain an algorithm for the state-oblivious ( stochastic reward function ) case .", "We formulate and study a new variant of the k-armed bandit problem , motivated by e-commerce applications .", "In our model , arms have ( stochastic ) lifetime after which they expire .", "The main motivation for our setting is online-advertising , where ads have limited lifetime due to , for example , the nature of their content and their campaign budgets ."]}
{"orig_sents": ["5", "3", "0", "6", "2", "1", "4"], "shuf_sents": ["We define a formal framework for the representation and processing of incongruent events : starting from the notion of label hierarchy , we show how partial order on labels can be deduced from such hierarchies .", "We derive algorithms to detect incongruent events from different types of hierarchies , corresponding to class membership or part membership .", "An incongruent event is an event where the probability computed based on some more specific level ( in accordance with the partial order ) is much smaller than the probability computed based on some more general level , leading to conflicting predictions .", "Here we identify distinct types of unexpected events , focusing on 'incongruent events ' when 'general level ' and 'specific level ' classifiers give conflicting predictions .", "Respectively , we show promising results with real data on two specific problems : Out Of Vocabulary words in speech recognition , and the identification of a new sub-class ( e.g. , the face of a new individual ) in audio-visual facial object recognition .", "Unexpected stimuli are a challenge to any machine learning algorithm .", "For each event , we compute its probability in different ways , based on adjacent levels ( according to the partial order ) in the label hierarchy ."]}
{"orig_sents": ["6", "7", "8", "5", "9", "0", "3", "2", "4", "1"], "shuf_sents": ["We introduce an information theoretically correct quantity for evaluating the information obtained by mismatched decoders .", "We also found that if we assume stationarity for long durations in the information analysis of dynamically changing stimuli like natural movies , pseudo correlations seem to carry a large portion of the information .", "We used 100-ms natural movies as stimuli and computed the information contained in neural activities about these movies .", "We applied our proposed framework to spike data for vertebrate retina .", "We found that the information loss is negligibly small in population activities of ganglion cells even if all orders of correlation are ignored in decoding .", "First , we hierarchically construct simplified probabilistic models of neural responses that ignore more than Kth-order correlations by using a maximum entropy principle .", "`` How is information decoded in the brain ? '' is one of the most difficult and important questions in neuroscience .", "Whether neural correlation is important or not in decoding neural activities is of special interest .", "We have developed a general framework for investigating how far the decoding process in the brain can be simplified .", "Then , we compute how much information is lost when information is decoded using the simplified models , i.e. , `` mismatched decoders '' ."]}
{"orig_sents": ["5", "1", "3", "4", "2", "0"], "shuf_sents": ["We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models .", "The main drawback of NPLMs is their extremely long training and testing times .", "We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data .", "Morin and Bengio have proposed a hierarchical language model built around a binary tree of words , which was two orders of magnitude faster than the nonhierarchical model it was based on .", "However , it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge .", "Neural probabilistic language models ( NPLMs ) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models ."]}
{"orig_sents": ["2", "4", "3", "1", "0"], "shuf_sents": ["We give examples of the new method substantially improving simple variational bounds at modest extra cost .", "The method is much cheaper than gold-standard annealing-based methods and only slightly more expensive than the cheapest Monte Carlo methods .", "We present a simple new Monte Carlo algorithm for evaluating probabilities of observations in complex latent variable models , such as Deep Belief Networks .", "In expectation , the log probability of a test set will be underestimated , and this could form the basis of a probabilistic bound .", "While the method is based on Markov chains , estimates based on short runs are formally unbiased ."]}
{"orig_sents": ["6", "1", "0", "4", "3", "5", "2"], "shuf_sents": ["First , the degree of sparsity is continuous -- a parameter controls the rate of sparsification from no sparsification to total sparsification .", "This method has several essential properties .", "We apply it to several datasets and find for datasets with large numbers of features , substantial sparsity is discoverable .", "We prove small rates of sparsification result in only small additional regret with respect to typical online-learning guarantees .", "Second , the approach is theoretically motivated , and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting .", "Finally , the approach works well empirically .", "We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss ."]}
{"orig_sents": ["6", "4", "3", "2", "0", "1", "5"], "shuf_sents": ["Second , we propose a novel combination that is based on the forward greedy algorithm but takes backward steps adaptively whenever beneficial .", "We prove strong theoretical results showing that this procedure is effective in learning sparse representations .", "First , we show that neither idea is adequate .", "Two heuristics that are widely used in practice are forward and backward greedy algorithms .", "We are interested in the problem of identifying those basis functions with non-zero coefficients and reconstructing the target function from noisy observations .", "Experimental results support our theory .", "Consider linear prediction models where the target function is a sparse linear combination of a set of basis functions ."]}
{"orig_sents": ["3", "1", "5", "0", "6", "2", "4"], "shuf_sents": ["We instead propose a unified model in which sensory and motor adaptation are jointly driven by optimal Bayesian estimation of the sensory and motor contributions to perceived errors .", "wearing prism goggles ) comprises not only motor adaptation but also substantial sensory adaptation , corresponding to shifts in the perceived spatial location of visual and proprioceptive cues .", "This unified model also makes the surprising prediction that force field adaptation will elicit similar perceptual shifts , even though there is never any discrepancy between visual and proprioceptive observations .", "Adaptation of visually guided reaching movements in novel visuomotor environments ( e.g .", "We confirm this prediction with an experiment .", "Previous computational models of the sensory component of visuomotor adaptation have assumed that it is driven purely by the discrepancy introduced between visual and proprioceptive estimates of hand position and is independent of any motor component of adaptation .", "Our model is able to account for patterns of performance errors during visuomotor adaptation as well as the subsequent perceptual aftereffects ."]}
{"orig_sents": ["1", "2", "5", "4", "3", "0"], "shuf_sents": ["Our results provide theoretical and empirical justification for the idea that serial reproduction reflects memory biases .", "Many human interactions involve pieces of information being passed from one person to another , raising the question of how this process of information transmission is affected by the capacities of the agents involved .", "In the 1930s , Sir Frederic Bartlett explored the influence of memory biases in `` serial reproduction '' of information , in which one person 's reconstruction of a stimulus from memory becomes the stimulus seen by the next person .", "We then test the predictions of this account in two experiments using simple one-dimensional stimuli .", "We formally analyze serial reproduction using a Bayesian model of reconstruction from memory , giving a general result characterizing the effect of memory biases on information transmission .", "These experiments were done using relatively uncontrolled stimuli such as pictures and stories , but suggested that serial reproduction would transform information in a way that reflected the biases inherent in memory ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Classical game theoretic approaches that make strong rationality assumptions have difficulty modeling human behaviour in economic games .", "We invert the generative process for a recognition model that is used to classify 200 subjects playing this game against randomly matched opponents .", "We investigate the role of finite levels of iterated reasoning and non-selfish utility functions in a Partially Observable Markov Decision Process model that incorporates game theoretic notions of interactivity .", "Our generative model captures a broad class of characteristic behaviours in a multi-round Investor-Trustee game ."]}
{"orig_sents": ["0", "4", "5", "1", "3", "2"], "shuf_sents": ["Continuously-Adaptive Discretization for Message-Passing ( CAD-MP ) is a new message-passing algorithm for approximate inference .", "Non-uniformity allows CAD-MP to localize interesting features ( such as sharp peaks ) in the marginal belief distributions with time complexity that scales logarithmically with precision , as opposed to uniform discretization which scales at best linearly .", "CAD-MP is shown in experiments to estimate marginal beliefs much more precisely than competing approaches for the same computational expense .", "We give a principled method for altering the non-uniform discretization according to information-based measures .", "Most message-passing algorithms approximate continuous probability distributions using either : a family of continuous distributions such as the exponential family ; a particle-set of discrete samples ; or a fixed , uniform discretization .", "In contrast , CAD-MP uses a discretization that is ( i ) non-uniform , and ( ii ) adaptive to the structure of the marginal distributions ."]}
{"orig_sents": ["0", "6", "3", "2", "5", "1", "4"], "shuf_sents": ["The machine learning problem of classifier design is studied from the perspective of probability elicitation , in statistics .", "A new boosting algorithm , SavageBoost , is derived for the minimization of this loss .", "This has various consequences of practical interest , such as showing that 1 ) the widely adopted practice of relying on convex loss functions is unnecessary , and 2 ) many new losses can be derived for classification problems .", "It is shown that a better alternative is to start from the specification of a functional form for the minimum conditional risk , and derive the loss function .", "Experimental results show that it is indeed less sensitive to outliers than conventional methods , such as Ada , Real , or LogitBoost , and converges in fewer iterations .", "These points are illustrated by the derivation of a new loss which is not convex , but does not compromise the computational tractability of classifier design , and is robust to the contamination of data with outliers .", "This shows that the standard approach of proceeding from the specification of a loss , to the minimization of conditional risk is overly restrictive ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We demonstrate our algorithm on image and text data .", "The resulting taxonomy is a more informative visualization of complex data than simple clustering ; in addition , taking into account the relations between different clusters is shown to substantially improve the quality of the clustering , when compared with state-ofthe-art algorithms in the literature ( both spectral clustering and a previous dependence maximization approach ) .", "We introduce a family of unsupervised algorithms , numerical taxonomy clustering , to simultaneously cluster data , and to learn a taxonomy that encodes the relationship between the clusters .", "The algorithms work by maximizing the dependence between the taxonomy and the original data ."]}
{"orig_sents": ["1", "5", "0", "6", "4", "7", "2", "3"], "shuf_sents": ["Here , we show that both marginal and joint properties of neural responses can be captured using copula models .", "The coding of information by neural populations depends critically on the statistical dependencies between neuronal responses .", "We apply these models to neuronal data collected in macaque pre-motor cortex , and quantify the improvement in coding accuracy afforded by incorporating the dependency structure between pairs of neurons .", "We find that more than one third of neuron pairs shows dependency concentrated in the lower or upper tails for their firing rate distribution .", "Different copulas capture different kinds of dependencies , allowing for a richer and more detailed description of dependencies than traditional summary statistics , such as correlation coefficients .", "However , there is no simple model that can simultaneously account for ( 1 ) marginal distributions over single-neuron spike counts that are discrete and non-negative ; and ( 2 ) joint distributions over the responses of multiple neurons that are often strongly dependent .", "Copulas are joint distributions that allow random variables with arbitrary marginals to be combined while incorporating arbitrary dependencies between them .", "We explore a variety of copula models for joint neural response distributions , and derive an efficient maximum likelihood procedure for estimating them ."]}
{"orig_sents": ["4", "2", "3", "1", "0", "5"], "shuf_sents": ["We cast the problem of minimizing the double hinge loss as a quadratic program akin to the standard SVM optimization problem and propose an active set method to solve it efficiently .", "We show that , for suitable kernel machines , our approach is universally consistent .", "The Bayes decision rule for this setup , known as Chow 's rule , is defined by two thresholds on posterior probabilities .", "From simple desiderata , namely the consistency and the sparsity of the classifier , we derive the double hinge loss function that focuses on estimating conditional probabilities only in the vicinity of the threshold points of the optimal decision rule .", "We consider the problem of binary classification where the classifier may abstain instead of classifying each observation .", "We finally provide preliminary experimental results illustrating the interest of our constructive approach to devising loss functions ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["The utility is illustrated on simulated as well as real data sets .", "A semisupervised version is proposed for the use of unlabeled data .", "It has the advantages of preventing degeneracy , increasing estimation accuracy , and automatic subclass discovery in classification problems .", "We developed localized sliced inverse regression for supervised dimension reduction ."]}
{"orig_sents": ["3", "2", "5", "0", "1", "4"], "shuf_sents": ["We generalize this robust formulation to consider more general uncertainty sets , which all lead to tractable convex optimization problems .", "Therefore , we provide a new methodology for designing regression algorithms , which generalize known formulations .", "We show that this formulation leads to tractable convex optimization problems , and we exhibit a particular uncertainty set for which the robust problem is equivalent to 1 regularized regression ( Lasso ) .", "We consider robust least-squares regression with feature-wise disturbance .", "The advantage is that robustness to disturbance is a physical property that can be exploited : in addition to obtaining new formulations , we use it directly to show sparsity properties of Lasso , as well as to prove a general consistency result for robust regression problems , including Lasso , from a unified robustness perspective .", "This provides an interpretation of Lasso from a robust optimization perspective ."]}
{"orig_sents": ["5", "3", "0", "1", "6", "4", "2"], "shuf_sents": ["We present a novel algorithm that goes beyond hierarchical classification and estimates the latent semantic space that underlies the class hierarchy .", "In this space , each class is represented by a prototype and classification is done with the simple nearest neighbor rule .", "Experiments on the OHSUMED medical journal data base yield state-of-the-art results on topic categorization .", "Recent work has significantly improved the state of the art by moving beyond `` flat '' classification through incorporation of class hierarchies .", "We show that our optimization is convex and can be solved efficiently for large data sets .", "Applications of multi-class classification , such as document categorization , often appear in cost-sensitive settings .", "The optimization of the semantic space incorporates large margin constraints that ensure that for each instance the correct class prototype is closer than any other ."]}
{"orig_sents": ["5", "1", "2", "6", "0", "4", "3"], "shuf_sents": ["After each request , the current classifier is incrementally updated .", "We propose to allow the categorylearner to strategically choose what annotations it receives -- based on both the expected reduction in uncertainty as well as the relative costs of obtaining each annotation .", "We construct a multiple-instance discriminative classifier based on the initial training data .", "As a result , it is possible to learn more accurate category models with a lower total expenditure of manual annotation effort .", "Unlike previous work , our approach accounts for the fact that the optimal use of manual annotation may call for a combination of labels at multiple levels of granularity ( e.g. , a full segmentation on some images and a present/absent flag on others ) .", "We introduce a framework for actively learning visual categories from a mixture of weakly and strongly labeled image examples .", "Then all remaining unlabeled and weakly labeled examples are surveyed to actively determine which annotation ought to be requested next ."]}
{"orig_sents": ["3", "4", "2", "1", "5", "6", "0"], "shuf_sents": ["We compare the predictive power of the latent structure of DiscLDA with unsupervised LDA on the 20 Newsgroups document classification task and show how our model can identify shared topics across classes as well as class-dependent topics .", "Specifically , we present DiscLDA , a discriminative variation on Latent Dirichlet Allocation ( LDA ) in which a class-dependent linear transformation is introduced on the topic mixture proportions .", "In this paper , we discuss an alternative : a discriminative framework in which we assume that supervised side information is present , and in which we wish to take that side information into account in finding a reduced dimensionality representation .", "Probabilistic topic models have become popular as methods for dimensionality reduction in collections of text documents or images .", "These models are usually treated as generative models and trained using maximum likelihood or Bayesian methods .", "This parameter is estimated by maximizing the conditional likelihood .", "By using the transformed topic mixture proportions as a new representation of documents , we obtain a supervised dimensionality reduction algorithm that uncovers the latent structure in a document collection while preserving predictive power for the task of classification ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["We study the profit-maximization problem of a monopolistic market-maker who sets two-sided prices in an asset market .", "We demonstrate that the belief state is well approximated by a Gaussian distribution .", "The algorithm leads to a surprising insight : an optimal monopolist can provide more liquidity than perfectly competitive market-makers in periods of extreme uncertainty , because a monopolist is willing to absorb initial losses in order to learn a new valuation rapidly so she can extract higher profits later .", "The sequential decision problem is hard to solve because the state space is a function .", "We prove a key monotonicity property of the Gaussian state update which makes the problem tractable , yielding the first optimal sequential market-making algorithm in an established model ."]}
{"orig_sents": ["5", "1", "3", "0", "2", "4"], "shuf_sents": ["Reinforcement learning ( RL ) models have been successful in modeling animal ( and human ) behaviour , but their success has been limited because of uncertainty as to how to set meta-parameters ( such as learning rate , exploitation-exploration balance and future reward discount factor ) that strongly influence model performance .", "Can one predict how a given animal , under given experimental conditions , would perform the task ?", "We show that a simple RL model whose metaparameters are controlled by an artificial neural network , fed with inputs such as stress , affective phenotype , previous task performance , and even neuromodulatory manipulations , can successfully predict mouse behaviour in the `` hole-box '' - a simple conditioning task .", "Since various factors such as stress , motivation , genetic background , and previous errors in task performance can influence animal behaviour , this appears to be a very challenging aim .", "Our results also provide important insights on how stress and anxiety affect animal learning , performance accuracy , and discounting of future rewards , and on how noradrenergic systems can interact with these processes .", "Suppose we train an animal in a conditioning experiment ."]}
{"orig_sents": ["2", "0", "1", "4", "5", "3"], "shuf_sents": ["These representations are typically high dimensional and assume diverse forms .", "Thus finding a way to transform them into a unified space of lower dimension generally facilitates the underlying tasks , such as object recognition or clustering .", "In solving complex visual learning tasks , adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance .", "It follows that any dimensionality reduction techniques explainable by graph embedding can be generalized by our method to consider data in multiple feature representations .", "We describe an approach that incorporates multiple kernel learning with dimensionality reduction ( MKL-DR ) .", "While the proposed framework is flexible in simultaneously tackling data in various feature representations , the formulation itself is general in that it is established upon graph embedding ."]}
{"orig_sents": ["3", "2", "0", "4", "1"], "shuf_sents": ["It also maintains separate parameters for treatment and control groups , which allows us to estimate treatment effects explicitly .", "The detection of biologically relevant and plausible signals in both therapy studies demonstrates the effectiveness of the method .", "We present a new hierarchical model that incorporates spatially varying mutation and recombination rates at the nucleotide level .", "Statistical evolutionary models provide an important mechanism for describing and understanding the escape response of a viral population under a particular therapy .", "We use the model to investigate the sequence evolution of HIV populations exposed to a recently developed antisense gene therapy , as well as a more conventional drug therapy ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["In many domains , data are distributed among datasets that share only some variables ; other recorded variables may occur in only one dataset .", "We present a novel , asymptotically correct procedure that discovers a minimal equivalence class of causal DAG structures using local independence information from distributed data of this form and evaluate its performance using synthetic and real-world data against causal discovery algorithms for single datasets and applying Structural EM , a heuristic DAG structure learning procedure for data with missing values , to the concatenated data .", "While there are asymptotically correct , informative algorithms for discovering causal relationships from a single dataset , even with missing values and hidden variables , there have been no such reliable procedures for distributed data with overlapping variables ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["We consider a generalization of stochastic bandit problems where the set of arms , X , is allowed to be a generic topological space .", "In particular , our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a finite number of global maxima around which the behavior of the function is locally Holder with a known exponent , then the expected regret is bounded up to a logarithmic factor by n , i.e. , the rate of the growth of the regret is independent of the dimension of the space .", "We construct an arm selection policy whose regret improves upon previous result for a large class of problems .", "We constraint the mean-payoff function with a dissimilarity function over X in a way that is more general than Lipschitz .", "Moreover , we prove the minimax optimality of our algorithm for the class of mean-payoff functions we consider ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We demonstrate this model by showing results from sorting two publicly available neural data recordings for which a partial ground truth labeling is known .", "Our approach is to augment a known time-varying Dirichlet process that ties together a sequence of infinite Gaussian mixture models , one per action potential waveform observation , with an interspike-interval-dependent likelihood that prohibits refractory period violations .", "In this paper we propose a new incremental spike sorting model that automatically eliminates refractory period violations , accounts for action potential waveform drift , and can handle `` appearance '' and `` disappearance '' of neurons ."]}
{"orig_sents": ["1", "6", "2", "10", "4", "0", "8", "5", "9", "3", "7"], "shuf_sents": ["We first used it to track real hand movements executed by a monkey in a standard 3D reaching task .", "Using machine learning algorithms to decode intended behavior from neural activity serves a dual purpose .", "Second , analyzing the characteristics of such methods can reveal the relative significance of various features of neural activity , task stimuli , and behavior .", "These kernels can be structured to incorporate domain knowledge into the method .", "Our version of this algorithm is used in an online learning setting and is updated after a sequence of inferred movements is completed .", "KARMA is a recurrent method that learns a nonlinear model of output dynamics .", "First , these tools allow patients to interact with their environment through a Brain-Machine Interface ( BMI ) .", "We compare KARMA to various state-of-the-art methods by evaluating tracking performance and present results from the KARMA based BMI experiments .", "We then applied it in a closed-loop BMI setting to infer intended movement , while the monkey 's arms were comfortably restrained , thus performing the task using the BMI alone .", "It uses similarity functions ( termed kernels ) to compare between inputs .", "In this study we adapted , implemented and tested a machine learning method called Kernel Auto-Regressive Moving Average ( KARMA ) , for the task of inferring movements from neural activity in primary motor cortex ."]}
{"orig_sents": ["1", "4", "3", "0", "2"], "shuf_sents": ["This is achieved by maximizing the dependency between matched pairs of observations by means of the Hilbert Schmidt Independence Criterion .", "Object matching is a fundamental operation in data analysis .", "This problem can be cast as one of maximizing a quadratic assignment problem with special structure and we present a simple algorithm for finding a locally optimal solution .", "Instead , we develop an approach which is able to perform matching by requiring a similarity measure only within each of the classes .", "It typically requires the definition of a similarity measure between the classes of objects to be matched ."]}
{"orig_sents": ["0", "2", "3", "1", "4", "5", "6"], "shuf_sents": ["The synchronous brain activity measured via MEG ( or EEG ) can be interpreted as arising from a collection ( possibly large ) of current dipoles or sources located throughout the cortex .", "The resulting algorithm guarantees descent of a cost function uniquely designed to handle unknown orientations and arbitrary correlations .", "Estimating the number , location , and orientation of these sources remains a challenging task , one that is significantly compounded by the effects of source correlations and the presence of interference from spontaneous brain activity , sensor noise , and other artifacts .", "This paper derives an empirical Bayesian method for addressing each of these issues in a principled fashion .", "Robust interference suppression is also easily incorporated .", "In a restricted setting , the proposed method is shown to have theoretically zero bias estimating both the location and orientation of multi-component dipoles even in the presence of correlations , unlike a variety of existing Bayesian localization methods or common signal processing techniques such as beamforming and sLORETA .", "Empirical results on both simulated and real data sets verify the efficacy of this approach ."]}
{"orig_sents": ["2", "3", "0", "1", "4", "5"], "shuf_sents": ["We show by numerical simulations of large asymmetric inhibitory networks with fixed external excitatory drive that if the network has intermediate to sparse connectivity , the individual cells are in the vicinity of a bifurcation between a quiescent and firing state and the network inhibition varies slowly on the spiking timescale , then cells form assemblies whose members show strong positive correlation , while members of different assemblies show strong negative correlation .", "We show that cells and assemblies switch between firing and quiescent states with time durations consistent with a power-law .", "Cell assemblies exhibiting episodes of recurrent coherent activity have been observed in several brain regions including the striatum and hippocampus CA3 .", "Here we address the question of how coherent dynamically switching assemblies appear in large networks of biologically realistic spiking neurons interacting deterministically .", "Our results are in good qualitative agreement with the experimental studies .", "The deterministic dynamical behaviour is related to winner-less competition , shown in small closed loop inhibitory networks with heteroclinic cycles connecting saddle-points ."]}
{"orig_sents": ["0", "5", "1", "2", "6", "4", "3"], "shuf_sents": ["In this work , we consider the problem of learning a positive semidefinite matrix .", "Our algorithm is mainly inspired by LPBoost and the general greedy convex optimization framework of Zhang .", "We demonstrate the essence of the algorithm , termed PSDBoost ( positive semidefinite Boosting ) , by focusing on a few different applications in machine learning .", "Numerical experiments are presented .", "PSDBoost is based on the observation that any trace-one positive semidefinite matrix can be decomposed into linear convex combinations of trace-one rank-one matrices , which serve as base learners of PSDBoost .", "The critical issue is how to preserve positive semidefiniteness during the course of learning .", "The proposed PSDBoost algorithm extends traditional Boosting algorithms in that its parameter is a positive semidefinite matrix with trace being one instead of a classifier ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["We show that this bound is tighter than the KPCA bound of Shawe-Taylor et al and highly predictive of the size of the subspace needed to capture most of the variance in the data .", "We analyse a second matching pursuit algorithm called kernel matching pursuit ( KMP ) which does not correspond to a sample compression scheme .", "Finally we describe how the same bound can be applied to other matching pursuit related algorithms .", "We analyse matching pursuit for kernel principal components analysis ( KPCA ) by proving that the sparse subspace it produces is a sample compression scheme .", "However , we give a novel bound that views the choice of subspace of the KMP algorithm as a compression scheme and hence provide a VC bound to upper bound its future loss ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["A series of corrections is developed for the fixed points of Expectation Propagation ( EP ) , which is one of the most popular methods for approximate probabilistic inference .", "These corrections can lead to improvements of the inference approximation or serve as a sanity check , indicating when EP yields unrealiable results ."]}
{"orig_sents": ["3", "1", "2", "0", "4"], "shuf_sents": ["We propose that interior-point methods are a natural solution .", "Despite its farreaching application , there is almost no work on applying stochastic approximation to learning problems with general constraints .", "The reason for this , we hypothesize , is that no robust , widely-applicable stochastic approximation method exists for handling such problems .", "The stochastic approximation method is behind the solution to many important , actively-studied problems in machine learning .", "We establish the stability of a stochastic interior-point approximation method both analytically and empirically , and demonstrate its utility by deriving an on-line learning algorithm that also performs feature selection via L1 regularization ."]}
{"orig_sents": ["1", "2", "4", "0", "5", "3"], "shuf_sents": ["We formulate the structure learning problem using mixtures of reward models , and solve the optimal action selection problem using Bayesian Reinforcement Learning .", "We use graphical models and structure learning to explore how people learn policies in sequential decision making tasks .", "Studies of sequential decision-making in humans frequently find suboptimal performance relative to an ideal actor that knows the graph model that generates reward in the environment .", "Our argument is supported by the results of experiments that demonstrate humans rapidly learn and exploit new reward structure .", "We argue that the learning problem humans face also involves learning the graph structure for reward generation in the environment .", "We show that structure learning in one and two armed bandit problems produces many of the qualitative behaviors deemed suboptimal in previous studies ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["The algorithms employ a coordinate descent approach that is based on a functional soft-thresholding operator .", "Our approach is based on a regularization method that enforces common sparsity patterns across different function components in a nonparametric additive model .", "The methods are illustrated with experiments on synthetic data and gene microarray data .", "We propose new families of models and algorithms for high-dimensional nonparametric learning with joint sparsity constraints .", "The framework yields several new models , including multi-task sparse additive models , multi-response sparse additive models , and sparse additive multi-category logistic regression ."]}
{"orig_sents": ["4", "3", "0", "1", "2"], "shuf_sents": ["This avoids the commonly-used ad hoc replacement of the Fisher information matrix with the identity which destroys the geometric invariance of the kernel .", "Our construction retains the geometric invariance , resulting in a kernel that is properly invariant under change of coordinates in the model parameter space .", "Experiments on detecting cognitive decline show that classifiers based on the proposed kernel out-perform those based on generative models and other feature extraction routines , and on Fisher kernels that use the identity in place of the Fisher information .", "A key advantage of the new formulation is that one can compute the Fisher information matrix despite varying sequence lengths and varying sampling intervals .", "We develop new techniques for time series classification based on hierarchical Bayesian generative models ( called mixed-effect models ) and the Fisher kernel derived from them ."]}
{"orig_sents": ["1", "4", "8", "6", "7", "0", "2", "5", "3"], "shuf_sents": ["Furthermore , it directly provides us with a primal solution ( unlike TRW and other related methods which solve the dual of the LP ) .", "We consider the problem of obtaining the approximate maximum a posteriori estimate of a discrete random field characterized by pairwise potentials that form a truncated convex model .", "We demonstrate the effectiveness of the proposed approach on both synthetic and standard real data problems .", "We believe that further explorations in this direction would help design efficient algorithms for more complex relaxations .", "For this problem , we propose an improved st-MINCUT based move making algorithm .", "Our analysis also opens up an interesting question regarding the relationship between move making algorithms ( such as -expansion and the algorithms presented in this paper ) and the randomized rounding schemes used with convex relaxations .", "Compared to previous approaches based on the LP relaxation , e.g .", "interior-point algorithms or treereweighted message passing ( TRW ) , our method is faster as it uses only the efficient st-MINCUT algorithm in its design .", "Unlike previous move making approaches , which either provide a loose bound or no bound on the quality of the solution ( in terms of the corresponding Gibbs energy ) , our algorithm achieves the same guarantees as the standard linear programming ( LP ) relaxation ."]}
{"orig_sents": ["0", "6", "1", "5", "2", "7", "9", "3", "8", "4"], "shuf_sents": ["We introduce a new reinforcement-learning model for the role of the hippocampus in classical conditioning , focusing on the differences between trace and delay conditioning .", "These two stimulus representations interact , producing different patterns of learning in trace and delay conditioning .", "For trace conditioning , with no contiguity between cue and reward , these long-latency temporal elements are necessary for learning adaptively timed responses .", "With longer intervals , learning is impaired in both procedures , and , with shorter intervals , in neither .", "These results demonstrate how temporal contiguity , as in delay conditioning , changes the timing problem faced by animals , rendering it both easier and less susceptible to disruption by hippocampal lesions .", "The model proposes that hippocampal lesions eliminate long-latency temporal elements , but preserve short-latency temporal elements .", "In the model , all stimuli are represented both as unindividuated wholes and as a series of temporal elements with varying delays .", "For delay conditioning , the continued presence of the cue supports conditioned responding , and the short-latency elements suppress responding early in the cue .", "In addition , the model makes novel predictions about the response topography with extended cues or post-training lesions .", "In accord with the empirical data , simulated hippocampal damage impairs trace conditioning , but not delay conditioning , at medium-length intervals ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction .", "Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure .", "Extensive labeled data for image annotation systems , which learn to assign class labels to image regions , is difficult to obtain .", "We propose three alternative formulations for imposing a spatial smoothness prior on the image labels ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["Almost all successful machine learning algorithms and cognitive models require powerful representations capturing the features that are relevant to a particular problem .", "We draw on recent work in nonparametric Bayesian statistics to define a rational model of human feature learning that forms a featural representation from raw sensory data without pre-specifying the number of features .", "By comparing how the human perceptual system and our rational model use distributional and category information to infer feature representations , we seek to identify some of the forces that govern the process by which people separate and combine sensory primitives to form features ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["After introducing the Aldous-Hoover representation for jointly and separately exchangeable arrays , we show how the process can be used as a nonparametric prior distribution in Bayesian models of relational data .", "Mondrian processes are multidimensional generalizations of Poisson processes and this connection allows us to construct multidimensional generalizations of the stickbreaking process described by Sethuraman ( 1994 ) , recovering the Dirichlet process in one dimension .", "We describe a novel class of distributions , called Mondrian processes , which can be interpreted as probability distributions over kd-tree data structures ."]}
{"orig_sents": ["0", "2", "1", "5", "3", "4"], "shuf_sents": ["In recent work Long and Servedio presented a `` martingale boosting '' algorithm that works by constructing a branching program over weak classifiers and has a simple analysis based on elementary properties of random walks .", "it can not effectively take advantage of variation in the quality of the weak classifiers it receives .", "showed that this martingale booster can tolerate random classification noise when it is run with a noise-tolerant weak learner ; however , a drawback of the algorithm is that it is not adaptive , i.e .", "This adaptiveness is achieved by modifying the original algorithm so that the random walks that arise in its analysis have different step size depending on the quality of the weak learner at each stage .", "The new algorithm inherits the desirable properties of the original algorithm , such as random classification noise tolerance , and has other advantages besides adaptiveness : it requires polynomially fewer calls to the weak learner than the original algorithm , and it can be used with confidencerated weak hypotheses that output real values rather than Boolean predictions .", "We present an adaptive variant of the martingale boosting algorithm ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["We apply our theory to the modeling of species geographic distributions from presence data , an extreme case of labeling bias since there is no absence data .", "For the generative case , we derive an entropybased weighting that maximizes expected log likelihood under the worst-case true class proportions .", "On a benchmark dataset , we find that entropy-based weighting offers an improvement over constant estimates of class proportions , consistently reducing log loss on unbiased test data .", "For the discriminative case , we derive a multinomial logistic model that minimizes worst-case conditional log loss .", "We apply robust Bayesian decision theory to improve both generative and discriminative learners under bias in class proportions in labeled training data , when the true class proportions are unknown ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["The models generalize matrix factorization to a supervised learning problem that utilizes attributes of entities in a hierarchical Bayesian framework .", "Stochastic relational models ( SRMs ) provide a rich family of choices for learning and predicting dyadic data between two sets of entities .", "Previously variational Bayes inference was applied for SRMs , which is , however , not scalable when the size of either entity set grows to tens of thousands .", "Both superior scalability and predictive accuracy are demonstrated on a collaborative filtering problem , which involves tens of thousands users and half million items .", "In this paper , we introduce a Markov chain Monte Carlo ( MCMC ) algorithm for equivalent models of SRMs in order to scale the computation to very large dyadic data sets ."]}
{"orig_sents": ["3", "1", "2", "5", "4", "0"], "shuf_sents": ["GTD is online and incremental , and does not involve multiplying by products of likelihood ratios as in importance-sampling methods .", "We consider an i.i.d .", "policy-evaluation setting in which the data need not come from on-policy experience .", "We introduce the first temporal-difference learning algorithm that is stable with linear function approximation and off-policy training , for any finite Markov decision process , behavior policy , and target policy , and whose complexity scales linearly in the number of parameters .", "We prove that this algorithm is stable and convergent under the usual stochastic approximation conditions to the same least-squares solution as found by the LSTD , but without LSTD 's quadratic computational complexity .", "The gradient temporal-difference ( GTD ) algorithm estimates the expected update vector of the TD ( 0 ) algorithm and performs stochastic gradient descent on its L2 norm ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We apply this model to two problems ( factor analysis and factor regression ) in gene-expression data analysis .", "To accomplish this , we propose a sparse variant of the Indian Buffet Process and couple this with a hierarchical model over factors , based on Kingman 's coalescent .", "We propose a nonparametric Bayesian factor regression model that accounts for uncertainty in the number of factors , and the relationship between factors ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["These kernel functions can be used in shallow architectures , such as support vector machines ( SVMs ) , or in deep kernel-based architectures that we call multilayer kernel machines ( MKMs ) .", "We evaluate SVMs and MKMs with these kernel functions on problems designed to illustrate the advantages of deep architectures .", "We introduce a new family of positive-definite kernel functions that mimic the computation in large , multilayer neural nets .", "On several problems , we obtain better results than previous , leading benchmarks from both SVMs with Gaussian kernels as well as deep belief nets ."]}
{"orig_sents": ["5", "6", "0", "2", "4", "1", "3"], "shuf_sents": ["Moreover , many hand-designed taxonomies are unbalanced and misrepresent the class structure in the underlying data distribution .", "This leads us off the beaten path of binomial-type estimation and into the unfamiliar waters of geometric-type estimation .", "We attempt to correct these problems by using the data distribution itself to calibrate the hierarchical classification loss function .", "In this paper , we present a new calibrated definition of statistical risk for hierarchical classification , an unbiased estimator for this risk , and a new algorithmic reduction from hierarchical classification to cost-sensitive classification .", "This distribution-based correction must be done with care , to avoid introducing unmanageable statistical dependencies into the learning problem .", "While many advances have already been made in hierarchical classification learning , we take a step back and examine how a hierarchical classification problem should be formally defined .", "We pay particular attention to the fact that many arbitrary decisions go into the design of the label taxonomy that is given with the training data ."]}
{"orig_sents": ["5", "1", "4", "2", "0", "3"], "shuf_sents": ["We describe Markov chain Monte Carlo inference involving Gibbs sampling and three different Metropolis-Hastings proposals to speed up convergence .", "They are used in Bayesian nonparametric models when the usual exchangeability assumption does not hold .", "The result is a set of DPs , each associated with a point in a space such that neighbouring DPs are more dependent .", "We report an empirical study of convergence on a synthetic dataset and demonstrate an application of the model to topic modeling through time .", "We propose a simple and general framework to construct dependent DPs by marginalizing and normalizing a single gamma process over an extended space .", "Dependent Dirichlet processes ( DPs ) are dependent sets of random measures , each being marginally DP distributed ."]}
{"orig_sents": ["1", "8", "6", "5", "4", "3", "2", "0", "7"], "shuf_sents": ["To address the case of short time windows we analyze the Ising model with identical noise correlation structure .", "The relative merits of different population coding schemes have mostly been analyzed in the framework of stimulus reconstruction using Fisher Information .", "That is , for long time window we use the common Gaussian noise approximation .", "Specifically , we assess the impact of different noise correlations structures on coding accuracy in long versus short decoding time windows .", "Second , we use the framework to study population codes of angular variables .", "In particular , it includes Fisher Information as a special case .", "We first explore the relationship between minimum discrimination error , JensenShannon Information and Fisher Information and show that the discrimination framework is more informative about the coding accuracy than Fisher Information as it defines an error for any pair of possible stimuli .", "In this way , we provide a new rigorous framework for assessing the functional consequences of noise correlation structures for the representational accuracy of neural population codes that is in particular applicable to short-time population coding .", "Here , we consider the case of stimulus discrimination in a two alternative forced choice paradigm and compute neurometric functions in terms of the minimal discrimination error and the Jensen-Shannon information to study neural population codes ."]}
{"orig_sents": ["3", "4", "1", "2", "0"], "shuf_sents": ["We provide experimental results on simulated datasets which show that these techniques compare favorably with other algorithms .", "Deviations from this behavior are used to flag anomalies .", "The candidate functionals are estimated in a subspace of a reproducing kernel Hilbert space associated with the original probability space considered .", "We propose new methodologies to detect anomalies in discrete-time processes taking values in a probability space .", "These methods are based on the inference of functionals whose evaluations on successive states visited by the process are stationary and have low autocorrelations ."]}
{"orig_sents": ["7", "0", "5", "3", "2", "1", "6", "4"], "shuf_sents": ["These images come with varying degrees of label information .", "In this paper we show how to utilize recent results in machine learning to obtain highly efficient approximations for semi-supervised learning that are linear in the number of images .", "However , it scales polynomially with the number of images , making it impractical for use on gigantic collections with hundreds of millions of images and thousands of classes .", "Semi-supervised learning is a principled framework for combining these different label sources .", "Our algorithm enables us to apply semi-supervised learning to a database of 80 million images gathered from the Internet .", "`` Clean labels '' can be manually obtained on a small fraction , `` noisy labels '' may be extracted automatically from surrounding text , while for most images there are no labels at all .", "Specifically , we use the convergence of the eigenvectors of the normalized graph Laplacian to eigenfunctions of weighted Laplace-Beltrami operators .", "With the advent of the Internet it is now possible to collect hundreds of millions of images ."]}
{"orig_sents": ["6", "10", "5", "9", "1", "2", "3", "8", "4", "0", "7"], "shuf_sents": ["This method allows us to compute more expressive strategies without increasing the size of abstract games that we are required to solve .", "This abstract game is then solved and the resulting strategy is played in the original game .", "Most top programs in recent AAAI Computer Poker Competitions use this approach .", "The trend in this competition has been that strategies found in larger abstract games tend to beat strategies found in smaller abstract games .", "In this paper we present a new method for computing strategies in large games .", "Despite these improvements , many interesting games are still too large for such techniques .", "Extensive games are often used to model the interactions of multiple agents within an environment .", "We demonstrate the power of the approach experimentally in both small and large games , while also providing a theoretical justification for the resulting improvement .", "These larger abstract games have more expressive strategy spaces and therefore contain better strategies .", "A common approach for computing strategies in these large games is to first employ an abstraction technique to reduce the original game to an abstract game that is of a manageable size .", "Much recent work has focused on increasing the size of an extensive game that can be feasibly solved ."]}
{"orig_sents": ["3", "1", "5", "4", "6", "2", "0"], "shuf_sents": ["Among other benefits , the replica method provides a computationally-tractable method for exactly computing various performance metrics including mean-squared error and sparsity pattern recovery probability .", "This paper applies the replica method to non-Gaussian maximum a posteriori ( MAP ) estimation .", "In the case of lasso estimation the scalar estimator reduces to a soft-thresholding operator , and for zero normregularized estimation it reduces to a hard-threshold .", "The replica method is a non-rigorous but widely-accepted technique from statistical physics used in the asymptotic analysis of large , random , nonlinear problems .", "The result is a counterpart to Guo and Verdu 's replica analysis of minimum mean-squared error estimation .", "It is shown that with random linear measurements and Gaussian noise , the asymptotic behavior of the MAP estimate of an n-dimensional vector `` decouples '' as n scalar MAP estimators .", "The replica MAP analysis can be readily applied to many estimators used in compressed sensing , including basis pursuit , lasso , linear estimation with thresholding , and zero norm-regularized estimation ."]}
{"orig_sents": ["1", "6", "5", "0", "3", "7", "2", "4"], "shuf_sents": ["This measure proves to be a suitable decoding scheme for generalizing the classical Shannon entropy to spike-based neural codes .", "We study an encoding/decoding mechanism accounting for the relative spike timing of the signals propagating from peripheral nerve fibers to second-order somatosensory neurons in the cuneate nucleus ( CN ) .", "It is shown that the CN population code performs a complete discrimination of 81 distinct stimuli already within 35 ms of the first afferent spike , whereas a partial discrimination ( 80 % of the maximum information transmission ) is possible as rapidly as 15 ms .", "It permits an assessment of neurotransmission in the presence of a large output space ( i.e .", "This study suggests that the CN may not constitute a mere synaptic relay along the somatosensory pathway but , rather , it may convey optimal contextual accounts ( in terms of fast and reliable information transfer ) of peripheral tactile inputs to downstream structures of the central nervous system .", "The efficiency of the haptic discrimination process is quantified by a novel definition of entropy that takes into full account the metrical properties of the spike train space .", "The CN is modeled as a population of spiking neurons receiving as inputs the spatiotemporal responses of real mechanoreceptors obtained via microneurography recordings in humans .", "hundreds of spike trains ) with 1 ms temporal precision ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We present a sequence of unsupervised , nonparametric Bayesian models for clustering complex linguistic objects .", "In this approach , we consider a potentially infinite number of features and categorical outcomes .", "All the models we investigated show significant improvements when compared against an existing baseline for this task .", "We evaluated these models for the task of within- and cross-document event coreference on two corpora ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["The Indian buffet process ( IBP ) is an exchangeable distribution over binary matrices used in Bayesian nonparametric featural models .", "In this paper we propose a three-parameter generalization of the IBP exhibiting power-law behavior .", "We achieve this by generalizing the beta process ( the de Finetti measure of the IBP ) to the stable-beta process and deriving the IBP corresponding to it .", "We find interesting relationships between the stable-beta process and the Pitman-Yor process ( another stochastic process used in Bayesian nonparametric models with interesting power-law properties ) .", "We derive a stick-breaking construction for the stable-beta process , and find that our power-law IBP is a good model for word occurrences in document corpora ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["Simulation experiments with kernel ridge regression and multiple kernel learning show that the proposed algorithm often improves significantly existing calibration procedures such as 10-fold cross-validation or generalized cross-validation .", "Then , plugging our variance estimate in Mallows ' CL penalty is proved to lead to an algorithm satisfying an oracle inequality .", "This paper tackles the problem of selecting among several linear estimators in non-parametric regression ; this includes model selection for linear regression , the choice of a regularization parameter in kernel ridge regression or spline smoothing , and the choice of a kernel in multiple kernel learning .", "We propose a new algorithm which first estimates consistently the variance of the noise , based upon the concept of minimal penalty which was previously introduced in the context of model selection ."]}
{"orig_sents": ["3", "2", "4", "1", "0"], "shuf_sents": ["We apply this approach to learn a neurostimulation policy that suppresses epileptic seizures on animal brain slices .", "We demonstrate that the embedding of a system can change as a result of learning , and we argue that the best performing embeddings well-represent the dynamics of both the uncontrolled and adaptively controlled system .", "If partial observability can be overcome , these constraints suggest the use of model-based reinforcement learning .", "Interesting real-world datasets often exhibit nonlinear , noisy , continuous-valued states that are unexplorable , are poorly described by first principles , and are only partially observable .", "We experiment with manifold embeddings to reconstruct the observable state-space in the context of offline , model-based reinforcement learning ."]}
{"orig_sents": ["1", "3", "5", "4", "0", "2"], "shuf_sents": ["Furthermore , we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs .", "The human brain can be described as containing a number of functional regions .", "We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level ( the classifier combining information from all ROIs ) and ROI-level prediction accuracy , as well as uncover some meaningful connections between ROIs .", "These regions , as well as the connections between them , play a key role in information processing in the brain .", "In this paper we propose to model such connections in an Hidden Conditional Random Field ( HCRF ) framework , where the classifier of one region of interest ( ROI ) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to .", "However , most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions , ignoring the connections between them ."]}
{"orig_sents": ["1", "0", "6", "4", "7", "2", "5", "3"], "shuf_sents": ["This class generalizes the family of spherically and Lp -spherically symmetric distributions which have recently been successfully used for natural image modeling .", "We introduce a new family of distributions , called Lp -nested symmetric distributions , whose densities are expressed in terms of a hierarchical cascade of Lp norms .", "By fitting the generalized Lp -nested model to 8 x 8 image patches , we show that the subspaces obtained from ISA are in fact more dependent than the individual filter coefficients within a subspace .", "This suggests that complex cell modeling can only be useful for redundancy reduction in larger image patches .", "With suitable choices of the parameters and norms , this family includes the Independent Subspace Analysis ( ISA ) model as a special case , which has been proposed as a means of deriving filters that mimic complex cells found in mammalian primary visual cortex .", "When first applying contrast gain control as preprocessing , however , there are no dependencies left that could be exploited by ISA .", "Similar to those distributions it allows for a nonlinear mechanism to reduce the dependencies between its variables .", "Lp -nested distributions are relatively easy to estimate and allow us to explore the variety of models between ISA and the Lp -spherically symmetric models ."]}
{"orig_sents": ["4", "1", "3", "2", "0", "5"], "shuf_sents": ["To model the spacing effect , we introduce a generic prior in the temporal updating stage to capture a learning preference , namely , less change for repetition and more change for variation .", "The sequential model updates two category parameters , the mean and the variance , over time .", "This model can be easily extended to supervised and unsupervised learning involving multiple categories .", "We define conjugate temporal priors to enable closed form solutions to be obtained .", "We develop a Bayesian sequential model for category learning .", "Finally , we show how this approach can be generalized to efficiently perform model selection to decide whether observations are from one or multiple categories ."]}
{"orig_sents": ["3", "6", "5", "1", "4", "0", "2"], "shuf_sents": ["In this paper we present a probabilistic model and use it to simultaneously infer the label of each image , the expertise of each labeler , and the difficulty of each image .", "However , using these services brings interesting theoretical and practical challenges : ( 1 ) The labelers may have wide ranging levels of expertise which are unknown a priori , and in some cases may be adversarial ; ( 2 ) images may vary in their level of difficulty ; and ( 3 ) multiple labels for the same image must be combined to provide an estimate of the actual label of the image .", "On both simulated and real data , we demonstrate that the model outperforms the commonly used `` Majority Vote '' heuristic for inferring image labels , and is robust to both noisy and adversarial labelers .", "Modern machine learning-based approaches to computer vision require very large databases of hand labeled images .", "Probabilistic approaches provide a principled way to approach these problems .", "New Internet-based services allow for a large number of labelers to collaborate around the world at very low cost .", "Some contemporary vision systems already require on the order of millions of images for training ( e.g. , Omron face detector ) ."]}
{"orig_sents": ["7", "2", "6", "4", "3", "0", "5", "1"], "shuf_sents": ["By sampling from the posterior distribution , we can get error bars on statistical properties such as preferred orientations , pinwheel locations or pinwheel counts .", "We demonstrate our model both on simulated data and on intrinsic signaling data from ferret visual cortex .", "Here , we present Bayesian methods based on Gaussian processes for extracting topographic maps from functional imaging data .", "The posterior mean can be interpreted as an optimally smoothed estimate of the map , and can be used for model based interpolations of the map from sparse measurements .", "We model the underlying map as a bivariate Gaussian process , with a prior covariance function that reflects known properties of OPMs , and a noise covariance adjusted to the data .", "Finally , the use of an explicit probabilistic model facilitates interpretation of parameters and quantitative model comparisons .", "In particular , we focus on the estimation of orientation preference maps ( OPMs ) from intrinsic signal imaging data .", "Imaging techniques such as optical imaging of intrinsic signals , 2-photon calcium imaging and voltage sensitive dye imaging can be used to measure the functional organization of visual cortex across different spatial and temporal scales ."]}
{"orig_sents": ["8", "6", "5", "9", "7", "0", "1", "3", "2", "4"], "shuf_sents": ["In this paper , we follow a different reasoning and show how Zangwill 's global convergence theory of iterative algorithms provides a natural framework to prove the convergence of CCCP , allowing a more elegant and simple proof .", "This underlines Zangwill 's theory as a powerful and general framework to deal with the convergence issues of iterative algorithms , after also being used to prove the convergence of algorithms like expectation-maximization , generalized alternating minimization , etc .", "( ii ) When does the sequence generated by CCCP converge ?", "In this paper , we provide a rigorous analysis of the convergence of CCCP by addressing these questions : ( i ) When does CCCP find a local minimum or a stationary point of the d.c. program under consideration ?", "We also present an open problem on the issue of local convergence of CCCP .", "Though widely used in many applications , the convergence behavior of CCCP has not gotten a lot of specific attention .", "In machine learning , CCCP is extensively used in many learning algorithms like sparse support vector machines ( SVMs ) , transductive SVMs , sparse principal component analysis , etc .", "Although the convergence of CCCP can be derived from the convergence of the d.c. algorithm ( DCA ) , its proof is more specialized and technical than actually required for the specific case of CCCP .", "The concave-convex procedure ( CCCP ) is a majorization-minimization algorithm that solves d.c. ( difference of convex functions ) programs as a sequence of convex programs .", "Yuille and Rangarajan analyzed its convergence in their original paper , however , we believe the analysis is not complete ."]}
{"orig_sents": ["5", "3", "1", "4", "0", "2"], "shuf_sents": ["We evaluate our model on Torralba 's proposed Context Challenge against a baseline category-based system .", "In this paper we seek to move beyond categories to provide a richer appearancebased model of context .", "Our experiments suggest that moving beyond categories for context modeling appears to be quite beneficial , and may be the critical missing ingredient in scene understanding systems .", "Most current approaches rely on modeling the relationships between object categories as a source of context .", "We present an exemplar-based model of objects and their relationships , the Visual Memex , that encodes both local appearance and 2D spatial context between object instances .", "The use of context is critical for scene understanding in computer vision , where the recognition of an object is driven by both local appearance and the object 's relationship to other elements of the scene ( context ) ."]}
{"orig_sents": ["0", "6", "3", "4", "5", "1", "2"], "shuf_sents": ["This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces .", "We derive an IPA estimator for the gradient of the log-likelihood , which may be used in a gradient method for the purpose of likelihood maximization .", "We illustrate the method with several numerical experiments .", "We describe a methodology for using any algorithm that estimates the filtering density , such as Sequential Monte Carlo methods , to design an algorithm that estimates its gradient .", "The resulting IPA estimator is proven to be asymptotically unbiased , consistent and has computational complexity linear in the number of particles .", "We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations .", "We propose an Infinitesimal Perturbation Analysis ( IPA ) on the filtering distribution with respect to some parameters of the model ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["In this paper we focus on the case of regression with manifold-valued input and output .", "Motivated by recent developments in manifold-valued regression we propose a family of nonparametric kernel-smoothing estimators with metric-space valued output including several robust versions .", "Depending on the choice of the output space and the metric the estimator reduces to partially well-known procedures for multi-class classification , multivariate regression in Euclidean space , regression with manifold-valued output and even some cases of structured output learning .", "We show pointwise and Bayes consistency for all estimators in the family for the case of manifold-valued output and illustrate the robustness properties of the estimators with experiments ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["To achieve this , we define the notion of a semantic output code classifier ( SOC ) which utilizes a knowledge base of semantic properties of Y to extrapolate to novel classes .", "As a case study , we build a SOC classifier for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images ( fMRI ) of their neural activity , even without training examples for those words .", "We consider the problem of zero-shot learning , where the goal is to learn a classifier f : X Y that must predict novel values of Y that were omitted from the training set .", "We provide a formalism for this type of classifier and study its theoretical properties in a PAC framework , showing conditions under which the classifier can accurately predict novel classes ."]}
{"orig_sents": ["3", "2", "4", "5", "0", "1"], "shuf_sents": ["In particular , we apply SICE to learn and analyze functional brain connectivity patterns from different subject groups , based on a key property of SICE , called the `` monotone property '' we established in this paper .", "Our experimental results on neuroimaging PET data of 42 AD , 116 MCI , and 67 NC subjects reveal several interesting connectivity patterns consistent with literature findings , and also some new patterns that can help the knowledge discovery of AD .", "Previous studies have shown that AD is closely related to the alternation in the functional brain network , i.e. , the functional connectivity among different brain regions .", "Recent advances in neuroimaging techniques provide great potentials for effective diagnosis of Alzheimer 's disease ( AD ) , the most common form of dementia .", "In this paper , we consider the problem of learning functional brain connectivity from neuroimaging , which holds great promise for identifying image-based markers used to distinguish Normal Controls ( NC ) , patients with Mild Cognitive Impairment ( MCI ) , and patients with AD .", "More specifically , we study sparse inverse covariance estimation ( SICE ) , also known as exploratory Gaussian graphical models , for brain connectivity modeling ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We show that in Rd , d 2 , the method is actually not well-posed , and as the number of unlabeled points increases the solution degenerates to a noninformative function .", "We study the behavior of the popular Laplacian Regularization method for SemiSupervised Learning at the regime of a fixed number of labeled points but a large number of unlabeled points .", "We also contrast the method with the Laplacian Eigenvector method , and discuss the `` smoothness '' assumptions associated with this alternate method ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand .", "While active learning centers on the collection of information about training cases in order to build better predictive models , diagnosis uses fixed predictive models for guiding the collection of observations about a specific test case at hand .", "To date , the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis .", "The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis ."]}
{"orig_sents": ["2", "4", "0", "5", "3", "1"], "shuf_sents": ["Rather than using a declarative language , such as SQL or first-order logic , we advocate using an imperative language to express various aspects of model structure , inference , and learning .", "In experimental comparisons to Markov Logic Networks on joint segmentation and coreference , we find our approach to be 3-15 times faster while reducing error by 20-25 % -- achieving a new state of the art .", "Discriminatively trained undirected graphical models have had wide empirical success , and there has been increasing interest in toolkits that ease their application to complex relational data .", "We have implemented such imperatively defined factor graphs in a system we call FACTORIE , a software library for an object-oriented , strongly-typed , functional language .", "The power in relational models is in their repeated structure and tied parameters ; at issue is how to define these structures in a powerful and flexible way .", "By combining the traditional , declarative , statistical semantics of factor graphs with imperative definitions of their construction and operation , we allow the user to mix declarative and procedural domain knowledge , and also gain significant efficiencies ."]}
{"orig_sents": ["1", "5", "2", "3", "6", "0", "4"], "shuf_sents": ["To constitute spatially contiguous objects , a new logistic stick-breaking process is developed .", "A non-parametric Bayesian model is proposed for processing multiple images .", "The model clusters the images into classes , and each image is segmented into a set of objects , also allowing the opportunity to assign a word to each object ( localized labeling ) .", "Each object is assumed to be represented as a heterogeneous mix of components , with this realized via mixture models linking image features to object types .", "Inference is performed efficiently via variational Bayesian analysis , with example results presented on two image databases .", "The analysis employs image features and , when present , the words associated with accompanying annotations .", "The number of image classes , number of object types , and the characteristics of the object-feature mixture models are inferred nonparametrically ."]}
{"orig_sents": ["1", "7", "6", "4", "0", "2", "5", "3"], "shuf_sents": ["This learning rule utilizes neuronal noise for exploration and performs Hebbian weight updates that are modulated by a global reward signal .", "The control of neuroprosthetic devices from the activity of motor cortex neurons benefits from learning effects where the function of these neurons is adapted to the control task .", "In contrast to most previously proposed reward-modulated Hebbian learning rules , this rule does not require extraneous knowledge about what is noise and what is signal .", "When the neuronal noise is fitted to experimental data , the model produces learning effects similar to those found in monkey experiments .", "In this article , we show that the experimentally observed self-tuning properties of the system can be explained on the basis of a simple learning rule .", "The learning rule is able to optimize the performance of the model system within biologically realistic periods of time and under high noise levels .", "In particular , it was shown that the tuning curves of those neurons whose preferred directions had been misinterpreted changed more than those of other neurons .", "It was recently shown that tuning properties of neurons in monkey motor cortex are adapted selectively in order to compensate for an erroneous interpretation of their activity ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["By casting predefined classes as latent Dirichlet variables ( i.e. , instance level labels ) , and modeling the multi-label of each pattern as Bernoulli variables conditioned on the weighted empirical average of topic assignments , DBA automatically aligns the latent topics discovered from data to human-defined classes .", "DBA is useful for both pattern classification and instance disambiguation , which are tested on text classification and named entity disambiguation in web search queries respectively .", "We propose Dirichlet-Bernoulli Alignment ( DBA ) , a generative model for corpora in which each pattern ( e.g. , a document ) contains a set of instances ( e.g. , paragraphs in the document ) and belongs to multiple classes ."]}
{"orig_sents": ["4", "0", "5", "7", "3", "6", "1", "2"], "shuf_sents": ["In this work , we propose a boosting-based technique , termed B OOST M ETRIC , for learning a Mahalanobis distance metric .", "The resulting method is easy to implement , does not require tuning , and can accommodate various types of constraints .", "Experiments on various datasets show that the proposed algorithm compares favorably to those state-of-the-art methods in terms of classification accuracy and running time .", "B OOST M ETRIC is instead based on a key observation that any positive semidefinite matrix can be decomposed into a linear positive combination of trace-one rank-one matrices .", "The learning of appropriate distance metrics is a critical problem in image classification and retrieval .", "One of the primary difficulties in learning such a metric is to ensure that the Mahalanobis matrix remains positive semidefinite .", "B OOST M ETRIC thus uses rank-one positive semidefinite matrices as weak learners within an efficient and scalable boosting-based learning process .", "Semidefinite programming is sometimes used to enforce this constraint , but does not scale well ."]}
{"orig_sents": ["1", "2", "0", "3", "4"], "shuf_sents": ["Our model learns abstract schemata that specify the relational similarities shared by instances of a category , and our emphasis on abstraction departs from previous theoretical proposals that focus instead on comparison of concrete instances .", "Most models of categorization learn categories defined by characteristic features but some categories are described more naturally in terms of relations .", "We present a generative model that helps to explain how relational categories are learned and used .", "Our first experiment suggests that abstraction can help to explain some of the findings that have previously been used to support comparison-based approaches .", "Our second experiment focuses on one-shot schema learning , a problem that raises challenges for comparison-based approaches but is handled naturally by our abstraction-based account ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["We propose a novel data-driven approach to capture emergent features using functional brain networks extracted from fMRI data , and demonstrate its advantage over traditional region-of-interest ( ROI ) and local , task-specific linear activation analyzes .", "Schizophrenia is a complex psychiatric disorder that has eluded a characterization in terms of local abnormalities of brain activity , and is hypothesized to affect the collective , `` emergent '' working of the brain .", "Our results suggest that schizophrenia is indeed associated with disruption of global brain properties related to its functioning as a network , which can not be explained by alteration of local activation patterns .", "Moreover , further exploitation of interactions by sparse Markov Random Field classifiers shows clear gain over linear methods , such as Gaussian Naive Bayes and SVM , allowing to reach 86 % accuracy ( over 50 % baseline - random guess ) , which is quite remarkable given that it is based on a single fMRI experiment using a simple auditory task ."]}
{"orig_sents": ["4", "6", "7", "5", "2", "3", "1", "0"], "shuf_sents": ["Experiments on various benchmark datasets validate our analysis and demonstrate the efficiency of our proposed algorithms .", "Based on our analysis , we further develop Nesterov 's smooth optimization approach for indefinite SVM which has an optimal convergence rate for smooth problems .", "The main idea behind our analysis is that the objective function is smoothed by the penalty term , in its saddle ( min-max ) representation , measuring the distance between the indefinite kernel matrix and the proxy positive semi-definite one .", "Our elementary result greatly facilitates the application of gradient-based algorithms .", "The recent introduction of indefinite SVM by Luss and d'Aspremont has effectively demonstrated SVM classification with a non-positive semi-definite kernel ( indefinite kernel ) .", "Indeed , we further show that its gradient is Lipschitz continuous .", "This paper studies the properties of the objective function introduced there .", "In particular , we show that the objective function is continuously differentiable and its gradient can be explicitly computed ."]}
{"orig_sents": ["2", "1", "4", "0", "3"], "shuf_sents": ["To employ variational methods , we derive a tree-based stick-breaking construction of the nCRP mixture model , and a novel variational algorithm that efficiently explores a posterior over a large set of combinatorial structures .", "Since its posterior distribution is intractable , current inference methods have all relied on MCMC sampling .", "The nested Chinese restaurant process ( nCRP ) is a powerful nonparametric Bayesian model for learning tree-based hierarchies from data .", "We demonstrate the use of this approach for text and hand written digits modeling , where we show we can adapt the nCRP to continuous data as well .", "In this paper , we develop an alternative inference technique based on variational methods ."]}
{"orig_sents": ["2", "4", "6", "0", "1", "5", "3"], "shuf_sents": ["We present an ideal observer model of depth estimation for this situation where structural or ordinal information is important and then fit the model to human data from a stereo-matching task .", "To test whether subjects are truly using ordinal cues in a probabilistic manner we then vary the uncertainty of the task .", "In many domains , humans appear to combine perceptual cues in a near-optimal , probabilistic fashion : two noisy pieces of information tend to be combined linearly with weights proportional to the precision of each cue .", "Our results indicate that the nervous system estimates depth ordering in a probabilistic fashion and estimates the structure of the visual scene during depth perception .", "Here we present a case where structural information plays an important role .", "We find that the model accurately predicts shifts in subject 's behavior .", "The presence of a background cue gives rise to the possibility of occlusion , and places a soft constraint on the location of a target - in effect propelling it forward ."]}
{"orig_sents": ["6", "3", "7", "5", "4", "2", "0", "1"], "shuf_sents": ["Interestingly , our theoretical analysis reveals the close connection between the proposed reformulation and multiple kernel learning .", "Our simulation studies demonstrate the scalability of the proposed algorithm .", "In this paper , we propose a new ( dual ) reformulation of the convex optimization problem in MMV and develop an efficient algorithm based on the prox-method .", "MMV is an extension of the single measurement vector ( SMV ) model employed in standard compressive sensing ( CS ) .", "Existing algorithms reformulate it as a second-order cone programming ( SOCP ) or semidefinite programming ( SDP ) problem , which is computationally expensive to solve for problems of moderate size .", "However , the resulting convex optimization problem in MMV is significantly much more difficult to solve than the one in SMV .", "We consider the reconstruction of sparse signals in the multiple measurement vector ( MMV ) model , in which the signal , represented as a matrix , consists of a set of jointly sparse vectors .", "Recent theoretical studies focus on the convex relaxation of the MMV problem based on the ( 2 , 1 ) -norm minimization , which is an extension of the well-known 1-norm minimization employed in SMV ."]}
{"orig_sents": ["3", "1", "2", "0", "4"], "shuf_sents": ["When the prediction error is large we show that the network responds robustly to changepoints in a way that is qualitatively compatible with the optimal Bayesian model .", "Despite this progress , the neural underpinnings of this computation are still poorly understood .", "In this paper we focus on the Bayesian filtering of stochastic time series and introduce a novel neural network , derived from a line attractor architecture , whose dynamics map directly onto those of the Kalman filter in the limit of small prediction error .", "Recent experimental evidence suggests that the brain is capable of approximating Bayesian inference in the face of noisy input stimuli .", "The model suggests ways in which probability distributions are encoded in the brain and makes a number of testable experimental predictions ."]}
{"orig_sents": ["0", "3", "1", "2", "5", "4"], "shuf_sents": ["Many transductive inference algorithms assume that distributions over training and test estimates should be related , e.g .", "We use this idea to design a transduction algorithm which can be used without modification for classification , regression , and structured estimation .", "At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match .", "by providing a large margin of separation on both sets .", "It turns out that a number of existing heuristics can be viewed as special cases of our approach .", "This is a classical two-sample problem which can be solved efficiently in its most general form by using distance measures in Hilbert Space ."]}
{"orig_sents": ["4", "2", "3", "0", "1"], "shuf_sents": ["Unlike existing methods such as semantic hashing and spectral hashing , our method is easily kernelized and does not require restrictive assumptions about the underlying distribution of the data .", "We present results over several domains to demonstrate that our method outperforms existing state-of-the-art techniques .", "In this paper , we develop an algorithm for learning hash functions based on explicitly minimizing the reconstruction error between the original distances and the Hamming distances of the corresponding binary embeddings .", "We develop a scalable coordinate-descent algorithm for our proposed hashing objective that is able to efficiently learn hash functions in a variety of settings .", "Fast retrieval methods are increasingly critical for many large-scale analysis tasks , and there have been several recent methods that attempt to learn hash functions for fast and accurate nearest neighbor searches ."]}
{"orig_sents": ["3", "4", "0", "2", "1"], "shuf_sents": ["In contrast to popular methods that attempt to extract compact generalizable models for each sound from training data , we employ the training data itself as a representation of the sources in the mixture .", "Keywords : Example-Based Representation , Signal Separation , Sparse Models .", "We show that mixtures of known sounds can be described as sparse combinations of the training data itself , and in doing so produce significantly better separation results as compared to similar systems based on compact statistical models .", "In this paper we present an algorithm for separating mixed sounds from a monophonic recording .", "Our approach makes use of training data which allows us to learn representations of the types of sounds that compose the mixture ."]}
{"orig_sents": ["4", "0", "1", "2", "3", "5"], "shuf_sents": ["Unfortunately , the high-dimensional averages required for Bayesian methods can be slow , especially with the unbounded representations used by nonparametric models .", "We address the challenge of scaling Bayesian inference to the increasingly large datasets found in real-world applications .", "We focus on parallelisation of inference in the Indian Buffet Process ( IBP ) , which allows data points to have an unbounded number of sparse latent features .", "Our novel MCMC sampler divides a large data set between multiple processors and uses message passing to compute the global likelihoods and posteriors .", "Nonparametric Bayesian models provide a framework for flexible probabilistic modelling of complex datasets .", "This algorithm , the first parallel inference scheme for IBP-based models , scales to datasets orders of magnitude larger than have previously been possible ."]}
{"orig_sents": ["0", "2", "4", "6", "7", "3", "1", "5"], "shuf_sents": ["In this paper we introduce a multi-step linear Dyna-style planning algorithm .", "Results on Mountain-car show that multi-step linear Dyna leads to much better online performance than single-step linear Dyna and model-free algorithms ; however , the performance of multi-step linear Dyna does not always improve as the number of projection steps increases .", "The key element of the multi-step linear Dyna is a multi-step linear model that enables multi-step projection of a sampled feature and multi-step planning based on the simulated multi-step transition experience .", "Policy evaluation on Boyan Chain shows that multi-step linear Dyna learns a policy faster than single-step linear Dyna , and generally learns faster as the number of projection steps increases .", "We propose two multi-step linear models .", "Our results also suggest that previous attempts on extending LSTD for online control were unsuccessful because LSTD looks infinite steps into the future , and suffers from the model errors in non-stationary ( control ) environments .", "The first iterates the one-step linear model , but is generally computationally complex .", "The second interpolates between the one-step model and the infinite-step model ( which turns out to be the LSTD solution ) , and can be learned efficiently online ."]}
{"orig_sents": ["0", "1", "2", "4", "3"], "shuf_sents": ["In the quest to make Brain Computer Interfacing ( BCI ) more usable , dry electrodes have emerged that get rid of the initial 30 minutes required for placing an electrode cap .", "Another time consuming step is the required individualized adaptation to the BCI user , which involves another 30 minutes calibration for assessing a subject 's brain signature .", "In this paper we aim to also remove this calibration proceedure from BCI setup time by means of machine learning .", "Our offline results indicate that BCI-naive users could start real-time BCI use with no prior calibration at only a very moderate performance loss .", "In particular , we harvest a large database of EEG BCI motor imagination recordings ( 83 subjects ) for constructing a library of subject-specific spatio-temporal filters and derive a subject independent BCI classifier ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["It is open how neurons in the brain are able to learn without supervision to discriminate between spatio-temporal firing patterns of presynaptic neurons .", "We show that a known unsupervised learning algorithm , Slow Feature Analysis ( SFA ) , is able to acquire the classification capability of Fisher 's Linear Discriminant ( FLD ) , a powerful algorithm for supervised learning , if temporally adjacent samples are likely to be from the same class .", "We also demonstrate that it enables linear readout neurons of cortical microcircuits to learn the detection of repeating firing patterns within a stream of spike trains with the same firing statistics , as well as discrimination of spoken digits , in an unsupervised manner ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["In addition , given ( partially ) labeled data , our algorithm can also be used as a ( semi ) supervised dimensionality reduction technique , and can be applied to learn useful predictive features in the context of learning a set of related tasks .", "Building upon the recently suggested probabilistic interpretation of CCA , we propose a nonparametric , fully Bayesian framework that can automatically select the number of correlation components , and effectively capture the sparsity underlying the projections .", "Experimental results demonstrate the efficacy of the proposed approach for both CCA as a stand-alone problem , and when applied to multi-label prediction .", "Canonical Correlation Analysis ( CCA ) is a useful technique for modeling dependencies between two ( or more ) sets of variables ."]}
{"orig_sents": ["3", "1", "0", "4", "2", "5"], "shuf_sents": ["In this paper , we apply convolutional deep belief networks to audio data and empirically evaluate them on various audio classification tasks .", "However , to our knowledge , these deep learning approaches have not been extensively studied for auditory data .", "In addition , our feature representations learned from unlabeled audio data show very good performance for multiple audio classification tasks .", "In recent years , deep learning approaches have gained significant interest as a way of building hierarchical representations from unlabeled data .", "In the case of speech data , we show that the learned features correspond to phones/phonemes .", "We hope that this paper will inspire more research on deep learning approaches applied to a wide range of audio recognition tasks ."]}
{"orig_sents": ["3", "2", "6", "5", "0", "1", "4"], "shuf_sents": ["We devise new insights on the connection between several existing MKL formulations and develop two efficient interleaved optimization strategies for arbitrary p > 1 .", "Empirically , we demonstrate that the interleaved optimization strategies are much faster compared to the traditionally used wrapper approaches .", "Previous approaches to multiple kernel learning ( MKL ) promote sparse kernel combinations to support interpretability .", "Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown .", "Finally , we apply p -norm MKL to real-world problems from computational biology , showing that non-sparse MKL achieves accuracies that go beyond the state-of-the-art .", "To allow for robust kernel mixtures , we generalize MKL to arbitrary p -norms .", "Unfortunately , 1 -norm MKL is hardly observed to outperform trivial baselines in practical applications ."]}
{"orig_sents": ["1", "0", "4", "3", "2"], "shuf_sents": ["Our analysis is in the agnostic framework of Kearns , Schapire and Sellie ( 1994 ) , giving polynomial-time guarantees in presence of arbitrary noise .", "We prove strong noise-tolerance properties of a potential-based boosting algorithm , similar to MadaBoost ( Domingo and Watanabe , 2000 ) and SmoothBoost ( Servedio , 2003 ) .", "Experiments suggest that the algorithm performs similarly to MadaBoost .", "Our boosting theorem gives , as easy corollaries , alternative derivations of two recent nontrivial results in computational learning theory : agnostically learning decision trees ( Gopalan et al , 2008 ) and agnostically learning halfspaces ( Kalai et al , 2005 ) .", "A remarkable feature of our algorithm is that it can be implemented without reweighting examples , by randomly relabeling them instead ."]}
{"orig_sents": ["0", "4", "5", "1", "3", "2"], "shuf_sents": ["We propose a new approach to the problem of robust estimation in multiview geometry .", "The proposed procedure is fairly fast since the outlier removal is done by solving one linear program ( LP ) .", "We present strong theoretical results assessing the accuracy of our procedure , as well as a numerical example illustrating its efficiency on real data .", "An important difference compared to existing algorithms is that for our estimator it is not necessary to specify neither the number nor the proportion of the outliers .", "Inspired by recent advances in the sparse recovery problem of statistics , we define our estimator as a Bayesian maximum a posteriori with multivariate Laplace prior on the vector describing the outliers .", "This leads to an estimator in which the fidelity to the data is measured by the L -norm while the regularization is done by the L1 -norm ."]}
{"orig_sents": ["3", "5", "2", "4", "6", "0", "1"], "shuf_sents": ["We also present an efficient learning algorithm for the proposed scheme for distance function learning .", "The extensive experiments with semi-supervised clustering show the proposed technique ( i ) outperforms the state-of-the-art approaches for distance function learning , and ( ii ) is computationally efficient for high dimensional data .", "These approaches are limited in two aspects : ( i ) they are computationally expensive ( even infeasible ) for high dimensional data because the size of the metric is in the square of dimensionality ; ( ii ) they assume a fixed metric for the entire input space and therefore are unable to handle heterogeneous data .", "Learning distance functions with side information plays a key role in many machine learning and data mining applications .", "In this paper , we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines .", "Conventional approaches often assume a Mahalanobis distance function .", "The proposed scheme avoids the assumption of fixed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function ."]}
{"orig_sents": ["2", "0", "4", "1", "5", "3"], "shuf_sents": ["An optimal solution to the problem is a Markov boundary , which is a minimal set of features that make the probability distribution of a target variable conditionally invariant to the state of all other features in the domain .", "We address this by introducing the Markov Boundary Theorem that precisely characterizes the properties of an ideal Markov boundary , and use it to develop algorithms that learn a more general boundary that can capture complex interactions that only appear when the values of multiple features are considered together .", "In this paper we address the problem of provably correct feature selection in arbitrary domains .", "Throughout the paper we make minimal assumptions that consist of only a general set of axioms that hold for every probability distribution , which gives these algorithms universal applicability .", "While numerous algorithms for this problem have been proposed , their theoretical correctness and practical behavior under arbitrary probability distributions is unclear .", "We introduce two algorithms : an exact , provably correct one as well a more practical randomized anytime version , and show that they perform well on artificial as well as benchmark and real-world data sets ."]}
{"orig_sents": ["4", "0", "3", "2", "5", "1"], "shuf_sents": ["The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions : ( 1 ) choose the exemplar set ( i.e .", "Also , we test the scalability of our approach with five objects in Flickr dataset consisting of more than 200K images .", "These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis .", "a small number of highly ranked reference ROIs ) across the dataset and ( 2 ) refine the ROIs of each image with respect to the exemplar set .", "This paper proposes a fast and scalable alternating optimization technique to detect regions of interest ( ROIs ) in cluttered Web images without labels .", "The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods ."]}
{"orig_sents": ["6", "5", "2", "0", "1", "3", "7", "4"], "shuf_sents": ["Although based on a highly non-convex underlying cost function , in the context of canonical sparse estimation problems , we prove uniform superiority of this method over the Lasso in that , ( i ) it can never do worse , and ( ii ) for any dictionary and sparsity profile , there will always exist cases where it does better .", "These results challenge the prevailing reliance on strictly convex penalty functions for finding sparse solutions .", "The first method under consideration arises from the sparse Bayesian learning ( SBL ) framework .", "We then derive a new non-factorial variant with similar properties that exhibits further performance improvements in some empirical tests .", "As a byproduct of this development , a rigorous reformulation of sparse Bayesian classification ( e.g. , the relevance vector machine ) is derived that , unlike the original , involves no approximation steps and descends a well-defined objective function .", "While typically the prior is factorial , here we examine non-factorial alternatives that have a number of desirable properties relevant to sparse estimation and are easily implemented using an efficient and globally-convergent , reweighted 1 -norm minimization procedure .", "Finding maximally sparse representations from overcomplete feature dictionaries frequently involves minimizing a cost function composed of a likelihood ( or data fit ) term and a prior ( or penalty function ) that favors sparsity .", "For both of these methods , as well as traditional factorial analogs , we demonstrate the effectiveness of reweighted 1 -norm algorithms in handling more general sparse estimation problems involving classification , group feature selection , and non-negativity constraints ."]}
{"orig_sents": ["5", "4", "0", "3", "2", "1"], "shuf_sents": ["However , extending these methods to continuous-valued systems has lagged behind .", "The resulting algorithms behave similarly to their purely discrete counterparts , extending the benefits of these more advanced inference techniques to the continuous domain .", "In this context we extend a recently proposed particle-based belief propagation algorithm to provide a general framework for adapting discrete message-passing algorithms to inference in continuous systems .", "While several methods have been developed to use belief propagation on systems with continuous values , recent advances for discrete variables have not as yet been incorporated .", "Improvements include guarantees of convergence , approximations that are provably more accurate , and bounds on the results of exact inference .", "Since the development of loopy belief propagation , there has been considerable work on advancing the state of the art for approximate inference over distributions defined on discrete random variables ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["We demonstrate experimentally that it creates appropriate skills and achieves performance benefits in a challenging continuous domain .", "We introduce a skill discovery method for reinforcement learning in continuous domains that constructs chains of skills leading to an end-of-task reward ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["We prove that the proposed graph Laplacian based regularization is convergent at rate root-n .", "The projection directions of the regularized SIR are optimized by using a conjugate gradient method on the Grassmann manifold .", "In this paper , we study the manifold regularization for the Sliced Inverse Regression ( SIR ) .", "The manifold regularization improves the standard SIR in two aspects : 1 ) it encodes the local geometry for SIR and 2 ) it enables SIR to deal with transductive and semi-supervised learning problems .", "Experimental results support our theory ."]}
{"orig_sents": ["4", "0", "1", "2", "3", "5"], "shuf_sents": ["Using a beta process prior , our approach is based on the discovery of a set of latent dynamical behaviors that are shared among multiple time series .", "The size of the set and the sharing pattern are both inferred from data .", "We develop an efficient Markov chain Monte Carlo inference method that is based on the Indian buffet process representation of the predictive distribution of the beta process .", "In particular , our approach uses the sum-product algorithm to efficiently compute Metropolis-Hastings acceptance probabilities , and explores new dynamical behaviors via birth/death proposals .", "We propose a Bayesian nonparametric approach to the problem of modeling related time series .", "We validate our sampling algorithm using several synthetic datasets , and also demonstrate promising results on unsupervised segmentation of visual motion capture data ."]}
{"orig_sents": ["4", "2", "5", "1", "3", "0"], "shuf_sents": ["We also develop a theory that motivates the algorithm .", "We propose directed regression , an efficient algorithm that combines merits of ordinary least squares and empirical optimization .", "When there are multiple response variables and features do not perfectly capture their relationships , it is beneficial to account for the decision objective when computing regression coefficients .", "We demonstrate through a computational study that directed regression can generate significant performance gains over either alternative .", "When used to guide decisions , linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions .", "Empirical optimization does so but sacrifices performance when features are well-chosen or training data are insufficient ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["In the present article , we propose a non-stationary dynamic Bayesian network for continuous data , in which parameters are allowed to vary among segments , and in which a common network structure provides essential information sharing across segments .", "Recent research efforts addressing this shortcoming have considered undirected graphs , directed graphs for discretized data , or over-flexible models that lack any information sharing among time series segments .", "Our model is based on a Bayesian multiple change-point process , where the number and location of the change-points is sampled from the posterior distribution .", "The standard approach is based on the assumption of a homogeneous Markov chain , which is not valid in many realworld scenarios .", "Dynamic Bayesian networks have been applied widely to reconstruct the structure of regulatory processes from time series data ."]}
{"orig_sents": ["12", "8", "1", "2", "13", "10", "7", "11", "0", "9", "3", "6", "4", "5"], "shuf_sents": ["Given n i.i.d .", ".", ".", "components from some distribution P , we determine lower bounds on the minimax rate for estimating the regression function with respect to squared-L2 ( P ) error .", "The first term reflects the sample size required for n performing subset selection , and is independent of the function class H. The second term s 2n ( H ) is an s-dimensional estimation term corresponding to the sample size required for estimating a sum of s univariate functions , each chosen from the function class H. It depends linearly on the sparsity index s but is independent of the global dimension p. As a special case , if H corresponds to functions that are m-times differentiable ( an mth -order Sobolev space ) , then the s-dimensional estimation term takes the form s2n ( H ) s n-2m/ ( 2m+1 ) .", "Either of the two terms may be dominant in different regimes , depending on the relation between the sparsity and smoothness of the additive decomposition .", "Our main result is a lower bound on the minimax rate that scales as max s log ( p/s ) , s 2n ( H ) .", ".", "More precisely , our goal is to estimate a function f : Rp R that has an additive decomposition of the form f ( X1 , .", "observations of f ( X ) corrupted with additive white Gaussian noise where the covariate vectors ( X1 , X2 , X3 , ... , Xp ) are drawn with i.i.d .", ".", ", p } is an unknown subset with cardinality s = |S| .", "We study minimax rates for estimating high-dimensional nonparametric regression models with sparse additive structure and smoothness constraints .", ", Xp ) = jS hj ( Xj ) , where each component function hj lies in some class H of `` smooth '' functions , and S { 1 , ."]}
{"orig_sents": ["1", "4", "0", "3", "2"], "shuf_sents": ["In this paper , we study the complexity of stochastic convex optimization in an oracle model of computation .", "Despite a large literature on upper bounds on complexity of convex optimization , relatively less attention has been paid to the fundamental hardness of these problems .", "We also discuss implications of these results for the understanding the inherent complexity of large-scale learning and estimation problems .", "We improve upon known results and obtain tight minimax complexity estimates for various function classes .", "Given the extensive use of convex optimization in machine learning and statistics , gaining a understanding of these complexity-theoretic issues is important ."]}
{"orig_sents": ["3", "6", "1", "5", "7", "0", "8", "4", "2"], "shuf_sents": ["Our result uncovers a trade-off between the size of the training set , the number of views , and the quality of the view generating functions .", "This situation corresponds for example to learning text classifiers from multilingual collections where documents are not available in all languages .", "Experimental results on a subset of the Reuters RCV1/RCV2 collections support our findings by showing that additional views obtained from MT may significantly improve the classification performance in the cases identified by our trade-off .", "We address the problem of learning classifiers when observations have multiple views , some of which may not be observed for all examples .", "An extension of this framework is a natural way to leverage unlabeled multi-view data in semi-supervised learning .", "In that case , Machine Translation ( MT ) systems may be used to translate each document in the missing languages .", "We assume the existence of view generating functions which may complete the missing views in an approximate way .", "We derive a generalization error bound for classifiers learned on examples with multiple artificially created views .", "As a consequence , we identify situations where it is more interesting to use multiple views for learning instead of classical single view learning ."]}
{"orig_sents": ["3", "1", "6", "7", "0", "4", "2", "5"], "shuf_sents": ["While favoring a sparse representation at the level of visual descriptors , those methods however do not ensure that images have sparse representation .", "While it is relatively easy to determine a suitable word dictionary for text documents , there is no simple mapping from raw images or videos to dictionary terms .", "This approach can also be used to encourage using the same dictionary words for all the images in a class , providing a discriminative signal in the construction of image representations .", "Bag-of-words document representations are often used in text , image and video processing .", "In this work , we use mixed-norm regularization to achieve sparsity at the image level as well as a small overall dictionary .", "Experimental results on a benchmark image classification dataset show that when compact image or dictionary representations are needed for computational efficiency , the proposed approach yields better mean average precision in classification .", "The classical approach builds a dictionary using vector quantization over a large set of useful visual descriptors extracted from a training set , and uses a nearest-neighbor algorithm to count the number of occurrences of each dictionary word in documents to be encoded .", "More robust approaches have been proposed recently that represent each visual descriptor as a sparse weighted combination of dictionary words ."]}
{"orig_sents": ["3", "1", "2", "4", "0"], "shuf_sents": ["Finally , we report the results of extensive experiments with this algorithm using several publicly available datasets demonstrating the effectiveness of our technique .", "We analyze this problem in the case of regression and the kernel ridge regression algorithm .", "We examine the corresponding learning kernel optimization problem , show how that minimax problem can be reduced to a simpler minimization problem , and prove that the global solution of this problem always lies on the boundary .", "This paper studies the general problem of learning kernels based on a polynomial combination of base kernels .", "We give a projection-based gradient descent algorithm for solving the optimization problem , shown empirically to converge in few iterations ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Many types of regularization schemes have been employed in statistical learning , each motivated by some assumption about the problem domain .", "In this paper , we present a unified asymptotic analysis of smooth regularizers , which allows us to see how the validity of these assumptions impacts the success of a particular regularizer .", "We apply our analysis to several examples , including hybrid generative-discriminative learning and multi-task learning .", "In addition , our analysis motivates an algorithm for optimizing regularization parameters , which in turn can be analyzed within our framework ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["Rather than evaluating a fitted function at the lattice nodes without regard to the fact that samples will be interpolated , the proposed lattice regression approach estimates the lattice to minimize the interpolation error on the given training samples .", "Simulations confirm that lattice regression performs consistently better than the naive approach to learning the lattice .", "Experiments show that lattice regression can reduce mean test error by as much as 25 % compared to Gaussian process regression ( GPR ) for digital color management of printers , an application for which linearly interpolating a look-up table is standard .", "Surprisingly , in some cases the proposed method -- although motivated by computational efficiency -- performs better than directly applying GPR with no lattice at all .", "We present a new empirical risk minimization framework for approximating functions from training samples for low-dimensional regression applications where a lattice ( look-up table ) is stored and interpolated at run-time for an efficient implementation ."]}
{"orig_sents": ["6", "3", "7", "2", "5", "4", "0", "1", "8"], "shuf_sents": ["This suggests that major efforts to reduce noise from electronics are not well spent .", "The measured noise from in vivo experiments shows a family of 1/f x spectrum that can be reduced using noise shaping techniques .", "In this work , the spectrum variability of spikes is addressed , based on which the concept of adaptive bandpass filter that fits the spectrum of individual spikes is proposed .", "Important issues exist in this research including the variant spectrum spans of neural spikes that make it difficult to choose a globally optimal bandpass filter .", "The dominant noise source is identified as neuron noise followed by interface noise of the electrode .", "Multiple noise sources have been studied through analytical models as well as empirical measurements .", "Studying signal and noise properties of recorded neural data is critical in developing more efficient algorithms to recover the encoded information .", "Also , multiple sources produce aggregated noise that deviates from the conventional white Gaussian noise .", "In summary , the methods of adaptive bandpass filtering and noise shaping together result in several dB signal-to-noise ratio ( SNR ) enhancement ."]}
{"orig_sents": ["0", "5", "1", "2", "4", "3"], "shuf_sents": ["By adding a spatial regularization kernel to a standard loss function formulation of the boosting problem , we develop a framework for spatially informed boosting .", "We prove that the proposed algorithm exhibits a `` grouping effect '' , which encourages the selection of all spatially local , discriminative base classifiers .", "The algorithm 's primary advantage is in applications where the trained classifier is used to identify the spatial pattern of discriminative information , e.g .", "We demonstrate the algorithm 's performance on various data sets .", "the voxel selection problem in fMRI .", "From this regularized loss framework we derive an efficient boosting algorithm that uses additional weights/priors on the base classifiers ."]}
{"orig_sents": ["0", "1", "3", "2", "4"], "shuf_sents": ["Given n noisy samples with p dimensions , where n p , we show that the multistep thresholding procedure can accurately estimate a sparse vector Rp in a linear model , under the restricted eigenvalue conditions ( Bickel-Ritov-Tsybakov 09 ) .", "Thus our conditions for model selection consistency are considerably weaker than what has been achieved in previous works .", "For example , it works for cases where the ordinary Lasso would have failed .", "More importantly , this method allows very significant values of s , which is the number of non-zero elements in the true parameter .", "Finally , we show that if X obeys a uniform uncertainty principle and if the true parameter is sufficiently sparse , the Gauss-Dantzig selector ( CandesTao 07 ) achieves the 2 loss within a logarithmic factor of the ideal mean square error one would achieve with an oracle which would supply perfect information about which coordinates are non-zero and which are above the noise level , while selecting a sufficiently sparse model ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["We apply the analysis to Least-Squares ( LS ) regression and discuss the excess risk and numerical complexity of the resulting `` Compressed Least Squares Re gression '' ( CLSR ) in terms of N , K , and M .", "From any algorithm minimizing the ( possibly penalized ) empirical risk , we provide bounds on the excess risk of the estimate computed in the projected subspace ( compressed domain ) in terms of the excess risk of the estimate built in the high-dimensional space ( initial domain ) .", "When we choose M = O ( K ) , we show that CLSR has an estimation error of order O ( log K/ K ) .", "We show that solving the problem in the compressed domain instead of the initial domain reduces the estimation error at the price of an increased ( but controlled ) approximation error .", "We consider the problem of learning , from K data , a regression function in a linear space of high dimension N using projections onto a random subspace of lower dimension M ."]}
{"orig_sents": ["4", "3", "2", "1", "0", "5"], "shuf_sents": ["We then provide an algorithm that learns an equivalence class for such models from data , by combining a PC style search using recent advances in kernel measures of conditional dependence with local searches for additive noise models in substructures of the Markov equivalence class .", "We introduce weakly additive noise models , which extends this framework to cases where the additive noise model is invertible and when additive noise is not present .", "linear Gaussians , the additive noise model is invertible and thus not useful for structure learning , and it was originally proposed for the two variable case with a multivariate extension which requires enumerating all possible DAGs .", "However , for certain distributions , e.g .", "The recently proposed additive noise model has advantages over previous directed structure learning approaches since it ( i ) does not assume linearity or Gaussianity and ( ii ) can discover a unique DAG rather than its Markov equivalence class .", "This results in a more computationally efficient approach that is useful for arbitrary distributions even when additive noise models are invertible ."]}
{"orig_sents": ["2", "3", "4", "0", "6", "5", "1"], "shuf_sents": ["However , whether the latent space is interpretable is in need of quantitative evaluation .", "Surprisingly , topic models which perform better on held-out likelihood may infer less semantically meaningful topics .", "Probabilistic topic models are a popular tool for the unsupervised analysis of text , providing both a predictive model of future text and a latent topic representation of the corpus .", "Practitioners typically assume that the latent space is semantically meaningful .", "It is used to check models , summarize the corpus , and guide exploration of its contents .", "We back these measures with large-scale user studies , showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood .", "In this paper , we present new quantitative methods for measuring semantic meaning in inferred topics ."]}
{"orig_sents": ["2", "3", "4", "5", "6", "8", "1", "9", "0", "7"], "shuf_sents": ["Experiments based on the standard bars benchmark test for object learning show that the algorithm performs well in comparison to other recent component extraction approaches .", "In numerical experiments it is shown that these approximations recover the correct set of object parameters .", "We study unsupervised learning in a probabilistic generative model for occlusion .", "The model uses two types of latent variables : one indicates which objects are present in the image , and the other how they are ordered in depth .", "This depth order then determines how the positions and appearances of the objects present , specified in the model parameters , combine to form the image .", "We show that the object parameters can be learnt from an unlabelled set of images in which objects occlude one another .", "Exact maximum-likelihood learning is intractable .", "The model and the learning algorithm thus connect research on occlusion with the research field of multiple-causes component extraction methods .", "However , we show that tractable approximations to Expectation Maximization ( EM ) can be found if the training images each contain only a small number of objects on average .", "Experiments on a novel version of the bars test using colored bars , and experiments on more realistic data , show that the algorithm performs well in extracting the generating causes ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["It has been established that the second-order stochastic gradient descent ( 2SGD ) method can potentially achieve generalization performance as well as empirical optimum in a single pass ( i.e. , epoch ) through the training examples .", "However , 2SGD requires computing the inverse of the Hessian matrix of the loss function , which is prohibitively expensive .", "This paper presents Periodic Step-size Adaptation ( PSA ) , which approximates the Jacobian matrix of the mapping function and explores a linear relation between the Jacobian and Hessian to approximate the Hessian periodically and achieve near-optimal results in experiments on a wide variety of models and tasks ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["In this paper , we examine the generalization error of regularized distance metric learning .", "In addition , we present an efficient online learning algorithm for regularized distance metric learning .", "Our empirical studies with data classification and face recognition show that the proposed algorithm is ( i ) effective for distance metric learning when compared to the state-of-the-art methods , and ( ii ) efficient and robust for high dimensional data .", "We show that with appropriate constraints , the generalization error of regularized distance metric learning could be independent from the dimensionality , making it suitable for handling high dimensional data ."]}
{"orig_sents": ["3", "6", "4", "2", "5", "1", "0"], "shuf_sents": ["Simulations and real-data examples corroborate the theoretical results , and suggest potential applications in computer vision .", "A by-product of our analysis is the first proportional growth results for the related problem of completing a low-rank matrix from a small fraction of its entries .", "We prove that most matrices A can be efficiently and exactly recovered from most error sign-and-support patterns by solving a simple convex program , for which we give a fast and provably convergent algorithm .", "Principal component analysis is a fundamental operation in computational data analysis , with myriad applications ranging from web search to bioinformatics to computer vision and image analysis .", "This paper considers the idealized `` robust principal component analysis '' problem of recovering a low rank matrix A from corrupted observations D = A + E. Here , the corrupted entries E are unknown and the errors can be arbitrarily large ( modeling grossly corrupted observations common in visual and bioinformatic data ) , but are assumed to be sparse .", "Our result holds even when the rank of A grows nearly proportionally ( up to a logarithmic factor ) to the dimensionality of the observation space and the number of errors E grows in proportion to the total number of entries in the matrix .", "However , its performance and applicability in real scenarios are limited by a lack of robustness to outlying or corrupted observations ."]}
{"orig_sents": ["7", "9", "2", "3", "8", "6", "4", "5", "1", "0"], "shuf_sents": ["This suggests an approach for learning a metric from data that is larger by orders of magnitude than was handled before .", "The nonmetric similarities learned by OASIS can be transformed into metric similarities , achieving higher precisions than similarities that are learned as metrics in the first place .", "In these tasks , users look for objects that are not only visually similar but also semantically related to a given object .", "Unfortunately , current approaches for learning similarity do not scale to large datasets , especially when imposing metric constraints on the learned similarity .", "OASIS is accurate at a wide range of scales : on a standard benchmark with thousands of images , it is more precise than state-of-the-art methods , and faster by orders of magnitude .", "On 2.7 million images collected from the web , OASIS can be trained within 3 days on a single CPU .", "Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost .", "Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning .", "We describe OASIS , a method for learning pairwise similarity that is fast and scales linearly with the number of objects and the number of non-zero features .", "It stands in the core of classification methods like kernel machines , and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video ."]}
{"orig_sents": ["4", "2", "6", "3", "0", "1", "5"], "shuf_sents": ["We formulate this problem as a combination of linear regressions and logistic regressions , and model the joint sparsity as L1 /L or L1 /L2 norm of the model parameters .", "Among several possible applications , our approach addresses an important open problem in genetic association mapping , where the goal is to discover genetic markers that influence multiple correlated traits jointly .", "Previous approaches to multitask learning usually deal with homogeneous tasks , such as purely regression tasks , or entirely classification tasks .", "All of the tasks are related in the sense that they share the same set of relevant input variables , but the amount of influence of each input on different outputs may vary .", "Multitask learning addresses the problem of learning related tasks that presumably share some commonalities on their input-output mapping functions .", "In our experiments , we demonstrate our method in this setting , using simulated and clinical asthma datasets , and we show that our method can effectively recover the relevant inputs with respect to all of the tasks .", "In this paper , we consider the problem of learning multiple related tasks of predicting both continuous and discrete outputs from a common set of input variables that lie in a highdimensional feature space ."]}
{"orig_sents": ["2", "1", "0", "4", "8", "6", "3", "7", "5"], "shuf_sents": ["However , the use of sparse distributions makes the problem non-convex and impractically slow to solve for multi-megapixel images .", "These distributions are well modeled by a hyper-Laplacian p ( x ) e-k|x| , typically with 0.5 0.8 .", "The heavy-tailed distribution of gradients in natural scenes have proven effective priors for a range of problems such as denoising , deblurring and super-resolution .", "Alternatively , for two specific values of , 1/2 and 2/3 an analytic solution can be found , by finding the roots of a cubic and quartic polynomial , respectively .", "In this paper we describe a deconvolution approach that is several orders of magnitude faster than existing techniques that use hyper-Laplacian priors .", "Furthermore , our method is quite general and can easily be extended to related image processing problems , beyond the deconvolution application demonstrated .", "This per-pixel sub-problem may be solved with a lookup table ( LUT ) .", "Our approach ( using either LUTs or analytic formulae ) is able to deconvolve a 1 megapixel image in less than 3 seconds , achieving comparable quality to existing methods such as iteratively reweighted least squares ( IRLS ) that take 20 minutes .", "We adopt an alternating minimization scheme where one of the two phases is a non-convex problem that is separable over pixels ."]}
{"orig_sents": ["2", "3", "4", "8", "7", "5", "0", "6", "1"], "shuf_sents": ["We have proved that the essential loss is both an upper bound of the measure-based ranking errors , and a lower bound of the loss functions in the aforementioned methods .", "Experimental results on benchmark datasets show that the modifications can lead to better ranking performances , demonstrating the correctness of our theoretical analysis .", "Learning to rank has become an important research topic in machine learning .", "While most learning-to-rank methods learn the ranking functions by minimizing loss functions , it is the ranking measures ( such as NDCG and MAP ) that are used to evaluate the performance of the learned ranking functions .", "In this work , we reveal the relationship between ranking measures and loss functions in learningto-rank methods , such as Ranking SVM , RankBoost , RankNet , and ListMLE .", "The key to obtaining this result is to model ranking as a sequence of classification tasks , and define a so-called essential loss for ranking as the weighted sum of the classification errors of individual tasks in the sequence .", "Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors .", "As a result , the minimization of these loss functions will lead to the maximization of the ranking measures .", "We show that the loss functions of these methods are upper bounds of the measurebased ranking errors ."]}
{"orig_sents": ["2", "4", "5", "3", "6", "1", "0"], "shuf_sents": ["Experimental results are also presented to show the superb computational efficiency of our approach .", "These constraints are much easier to process numerically , and the gain in speedup over previous approaches is at least of the order m2.5 , where m is the matrix dimension .", "Kernel learning is a powerful framework for nonlinear data modeling .", "Although in theory SDPs can be efficiently solved , the high computational complexity incurred in numerically processing the huge linear matrix inequality constraints has rendered the SDP approach unscalable .", "Using the kernel trick , a number of problems have been formulated as semidefinite programs ( SDPs ) .", "These include Maximum Variance Unfolding ( MVU ) ( Weinberger et al. , 2004 ) in nonlinear dimensionality reduction , and Pairwise Constraint Propagation ( PCP ) ( Li et al. , 2008 ) in constrained clustering .", "In this paper , we show that a large class of kernel learning problems can be reformulated as semidefinite-quadratic-linear programs ( SQLPs ) , which only contain a simple positive semidefinite constraint , a second-order cone constraint and a number of linear constraints ."]}
{"orig_sents": ["2", "1", "0", "3", "5", "4"], "shuf_sents": ["We present a novel approach which employs a randomized sequence of pruning masks .", "However , any single pruning mask will introduce bias .", "Pruning can massively accelerate the computation of feature expectations in large models .", "Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .", "Empirically , we demonstrate our method on bilingual parsing , showing decreasing bias as more masks are incorporated , and outperforming fixed tic-tac-toe pruning .", "Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high-degree algorithms ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["As a case study , we show how several phenomena of perceptual multistability can be explained as MCMC inference in simple graphical models for low-level vision .", "We explore the proposal that for some tasks , humans use a form of Markov Chain Monte Carlo to approximate the posterior distribution over hidden variables .", "While many perceptual and cognitive phenomena are well described in terms of Bayesian inference , the necessary computations are intractable at the scale of realworld tasks , and it remains unclear how the human mind approximates Bayesian computations algorithmically ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Our approach can be scaled up to high-resolution images by reductions to numerical mathematics primitives and parallelization on several levels .", "In a first study , designs are found that improve significantly on others chosen independently for each slice or drawn at random .", "We show how to sequentially optimize magnetic resonance imaging measurement designs over stacks of neighbouring image slices , by performing convex variational inference on a large scale non-Gaussian linear dynamical system , tracking dominating directions of posterior covariance without imposing any factorization constraints ."]}
{"orig_sents": ["1", "4", "6", "3", "2", "7", "5", "8", "0"], "shuf_sents": ["We show empirically that , although the sample-based algorithms require more iterations , their lower cost per iteration can lead to dramatically faster convergence in various games .", "Sequential decision-making with multiple agents and imperfect information is commonly modeled as an extensive game .", "We start by showing that MCCFR performs the same regret updates as CFR on expectation .", "In this paper , we describe a general family of domain-independent CFR sample-based algorithms called Monte Carlo counterfactual regret minimization ( MCCFR ) of which the original and poker-specific versions are special cases .", "One efficient method for computing Nash equilibria in large , zero-sum , imperfect information games is counterfactual regret minimization ( CFR ) .", "Thus , they can compute an approximate equilibrium using self-play .", "In the domain of poker , CFR has proven effective , particularly when using a domain-specific augmentation involving chance outcome sampling .", "Then , we introduce two sampling schemes : outcome sampling and external sampling , showing that both have bounded overall regret with high probability .", "Finally , we prove a new tighter bound on the regret for the original CFR algorithm and relate this new bound to MCCFR 's bounds ."]}
{"orig_sents": ["2", "5", "6", "0", "3", "4", "1"], "shuf_sents": ["In contrast to the classical approach , we attempt to provide a meaningful formalization of the very notion of a cluster and we show that game theory offers an attractive and unexplored perspective that serves well our purpose .", "Experiments are presented which show the superiority of our approach over state-of-the-art hypergraph clustering techniques .", "Hypergraph clustering refers to the process of extracting maximally coherent groups from a set of objects using high-order ( rather than pairwise ) similarities .", "Specifically , we show that the hypergraph clustering problem can be naturally cast into a non-cooperative multi-player `` clustering game '' , whereby the notion of a cluster is equivalent to a classical game-theoretic equilibrium concept .", "From the computational viewpoint , we show that the problem of finding the equilibria of our clustering game is equivalent to locally optimizing a polynomial function over the standard simplex , and we provide a discrete-time dynamics to perform this optimization .", "Traditional approaches to this problem are based on the idea of partitioning the input data into a user-defined number of classes , thereby obtaining the clusters as a by-product of the partitioning process .", "In this paper , we provide a radically different perspective to the problem ."]}
{"orig_sents": ["0", "1", "3", "4", "2"], "shuf_sents": ["We develop a structured output model for object category detection that explicitly accounts for alignment , multiple aspects and partial truncation in both training and inference .", "The model is formulated as large margin learning with latent variables and slack rescaling , and both training and inference are computationally efficient .", "We demonstrate the method by training and testing on the PASCAL VOC 2007 data set - training includes the truncated examples , and in testing object instances are detected at multiple scales , alignments , and with significant truncations .", "We make the following contributions : ( i ) we note that extending the Structured Output Regression formulation of Blaschko and Lampert to include a bias term significantly improves performance ; ( ii ) that alignment ( to account for small rotations and anisotropic scalings ) can be included as a latent variable and efficiently determined and implemented ; ( iii ) that the latent variable extends to multiple aspects ( e.g .", "left facing , right facing , front ) with the same formulation ; and ( iv ) , most significantly for performance , that truncated and truncated instances can be included in both training and inference with an explicit truncation mask ."]}
{"orig_sents": ["0", "1", "4", "7", "3", "6", "5", "2"], "shuf_sents": ["Directed graphical models such as Bayesian networks are a favored formalism for modeling the dependency structures in complex multivariate systems such as those encountered in biology and neural science .", "When a system is undergoing dynamic transformation , temporally rewiring networks are needed for capturing the dynamic causal influences between covariates .", "In both cases , TV-DBNs reveal interesting dynamics underlying the respective biological systems .", "We present a kernel reweighted 1 -regularized auto-regressive procedure for this problem which enjoys nice properties such as computational efficiency and provable asymptotic consistency .", "In this paper , we propose time-varying dynamic Bayesian networks ( TV-DBN ) for modeling the structurally varying directed dependency structures underlying non-stationary biological/neural time series .", "We applied TV-DBNs to time series measurements during yeast cell cycle and brain response to visual stimuli .", "To our knowledge , this is the first practical and statistically sound method for structure learning of TVDBNs .", "This is a challenging problem due the non-stationarity and sample scarcity of time series data ."]}
{"orig_sents": ["0", "4", "3", "1", "2"], "shuf_sents": ["Markov random fields ( MRF 's ) , or undirected graphical models , provide a powerful framework for modeling complex dependencies among random variables .", "We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions , which considerably improves parameter estimates in large , densely-connected MRF 's .", "Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional , richly structured data that perform well on digit and object recognition tasks .", "In this paper we consider a class of stochastic approximation algorithms of the Robbins-Monro type that use Markov chain Monte Carlo to do approximate maximum likelihood learning .", "Maximum likelihood learning in MRF 's is hard due to the presence of the global normalizing constant ."]}
{"orig_sents": ["5", "2", "4", "3", "0", "1"], "shuf_sents": ["The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions .", "We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database .", "In contrast to recent work in semantic alignment of scenes , we allow an input image to be explained by partial matches of similar scenes .", "We perform MRF-based segmentation that optimizes over matches , while respecting boundary information .", "This allows for a better explanation of the input scenes .", "In this paper , we investigate how , given an image , similar images sharing the same global description can help with unsupervised scene segmentation ."]}
{"orig_sents": ["0", "4", "1", "6", "3", "2", "5"], "shuf_sents": ["Which ads should we display in sponsored search in order to maximize our revenue ?", "These applications exhibit strong diminishing returns : Redundancy decreases the marginal utility of each ad or information source .", "Our algorithm possesses strong theoretical guarantees , such as a performance ratio that converges to the optimal constant of 1 - 1/e .", "We present an efficient algorithm for this general problem and analyze it in the no-regret model .", "How should we dynamically rank information sources to maximize the value of the ranking ?", "We empirically evaluate our algorithm on two real-world online optimization problems on the web : ad allocation with submodular utilities , and dynamically ranking blogs to detect information cascades .", "We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one ."]}
{"orig_sents": ["4", "0", "1", "2", "6", "7", "5", "3"], "shuf_sents": ["In these experiments , a subject first studies a list of words and then tries to recall them .", "To model these data , we draw on both previous psychological research and statistical topic models of text documents .", "We assume that memories are formed by assimilating the semantic meaning of studied words ( represented as a distribution over topics ) into a slowly changing latent context ( represented in the same space ) .", "By specifying the model hierarchically , we are also able to capture inter-subject variability .", "We develop a probabilistic model of human memory performance in free recall experiments .", "We present a particle filter algorithm for performing approximate posterior inference , and evaluate our model on the prediction of recalled words in experimental data .", "During recall , this context is reinstated and used as a cue for retrieving studied words .", "By conceptualizing memory retrieval as a dynamic latent variable model , we are able to use Bayesian inference to represent uncertainty and reason about the cognitive processes underlying memory ."]}
{"orig_sents": ["5", "3", "4", "1", "0", "6", "2"], "shuf_sents": ["In most of these cases , the responses to queries can be noisy .", "GBS is used in many applications , including fault testing , machine diagnostics , disease diagnosis , job scheduling , image processing , computer vision , and active learning .", "This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions .", "GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries .", "At each step , a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets , a natural generalization of the idea underlying classic binary search .", "This paper addresses the problem of noisy Generalized Binary Search ( GBS ) .", "Past work has provided a partial characterization of GBS , but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity ."]}
{"orig_sents": ["0", "4", "5", "6", "1", "2", "3"], "shuf_sents": ["In this paper we introduce a new algorithm for updating the parameters of a heuristic evaluation function , by updating the heuristic towards the values computed by an alpha-beta search .", "We implemented our algorithm in a chess program Meep , using a linear heuristic function .", "After initialising its weight vector to small random values , Meep was able to learn high quality weights from self-play alone .", "When tested online against human opponents , Meep played at a master level , the best performance of any chess program with a heuristic learned entirely from self-play .", "Our algorithm differs from previous approaches to learning from search , such as Samuel 's checkers player and the TD-Leaf algorithm , in two key ways .", "First , we update all nodes in the search tree , rather than a single node .", "Second , we use the outcome of a deep search , instead of the outcome of a subsequent search , as the training signal for the evaluation function ."]}
{"orig_sents": ["5", "4", "1", "3", "0", "2"], "shuf_sents": ["It does not require choosing complicated tuning parameters or function approximation classes and it can adapt to local structure such as local change in dimensionality .", "The resulting anomaly detector is shown to be asymptotically optimal in that it is uniformly most powerful for the specified false alarm level , , for the case when the anomaly density is a mixture of the nominal and a known density .", "We demonstrate the algorithm on both artificial and real data sets in high dimensional feature spaces .", "Our algorithm is computationally efficient , being linear in dimension and quadratic in data size .", "Anomalies are declared whenever the score of a test sample falls below , which is supposed to be the desired false alarm level .", "We propose a novel non-parametric adaptive anomaly detection algorithm for high dimensional data based on score functions derived from nearest neighbor graphs on n-point nominal data ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We prove that , if we run any -approximate k-means algorithm ( 1 ) on the features selected using our method , we can find a ( 1 + ( 1 + ) ) -approximate partition with high probability .", "Our algorithm is randomized and , assuming an accuracy parameter ( 0 , 1 ) , selects and appropriately rescales in an unsupervised manner ( k log ( k/ ) /2 ) features from a dataset of arbitrary dimensions .", "We present a novel feature selection algorithm for the k-means clustering problem ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Belief polarization is frequently offered as evidence of human irrationality , but we demonstrate that this phenomenon is consistent with a fully Bayesian approach to belief revision .", "Empirical studies have documented cases of belief polarization , where two people with opposing prior beliefs both strengthen their beliefs after observing the same evidence .", "Simulation results indicate that belief polarization is not only possible but relatively common within the set of Bayesian models that we consider ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["By constructing the differential motion opponency in response to motions in two different spatial regions , varying motion contrasts can be detected , where similar motion is detected by zero phase shifts and differences in motion by non-zero phase shifts .", "We demonstrate that the motion contrast can be detected by phase shifts between motion neuronal responses in different spatial regions .", "We extend the concept of phase tuning , a ubiquitous mechanism among sensory neurons including motion and disparity selective neurons , to the motion contrast detection .", "A primary advantage of the model is that the responses are selective to relative motion instead of absolute motion , which could model neurons found in neurophysiological experiments responsible for motion pop-out detection .", "The model can exhibit either enhancement or suppression of responses by either different or similar motion in the surrounding ."]}
{"orig_sents": ["1", "2", "3", "0", "5", "4"], "shuf_sents": ["Both models assume that each individual 's reconstruction is based on either a random permutation of the unobserved ground truth , or by a pure guessing strategy .", "When individuals independently recollect events or retrieve facts from memory , how can we aggregate these retrieved memories to reconstruct the actual set of events or facts ?", "In this research , we report the performance of individuals in a series of general knowledge tasks , where the goal is to reconstruct from memory the order of historic events , or the order of items along some physical dimension .", "We introduce two Bayesian models for aggregating order information based on a Thurstonian approach and Mallows model .", "The models demonstrate a `` wisdom of crowds `` effect , where the aggregated or derings are closer to the true ordering than the orderings of the best individual .", "We apply MCMC to make inferences about the underlying truth and the strategies employed by individuals ."]}
{"orig_sents": ["0", "5", "1", "3", "2", "4"], "shuf_sents": ["Alignment of time series is an important problem to solve in many scientific disciplines .", "In this paper we present canonical time warping ( CTW ) , an extension of canonical correlation analysis ( CCA ) for spatio-temporal alignment of human motion between two subjects .", "We show CTW 's effectiveness in three experiments : alignment of synthetic data , alignment of motion capture data of two subjects performing similar actions , and alignment of similar facial expressions made by two people .", "CTW extends previous work on CCA in two ways : ( i ) it combines CCA with dynamic time warping ( DTW ) , and ( ii ) it extends CCA by allowing local spatial deformations .", "Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on DTW .", "In particular , temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability ."]}
{"orig_sents": ["4", "5", "2", "0", "6", "1", "3", "7"], "shuf_sents": ["The HDP makes use of Dirichlet process prior which favors regular textures by penalizing the model complexity .", "The HDP-2DHMM results in a compact representation of textures which allows fast texture synthesis with comparable rendering quality over the state-of-the-art patch-based rendering methods .", "The 2DHMM is coupled with the Hierarchical Dirichlet process ( HDP ) which allows the number of textons and the complexity of transition matrix grow as the input texture becomes irregular .", "We also show that the HDP2DHMM can be applied to perform image segmentation and synthesis .", "We present a nonparametric Bayesian method for texture learning and synthesis .", "A texture image is represented by a 2D Hidden Markov Model ( 2DHMM ) where the hidden states correspond to the cluster labeling of textons and the transition matrix encodes their spatial layout ( the compatibility between adjacent textons ) .", "This framework ( HDP-2DHMM ) learns the texton vocabulary and their spatial layout jointly and automatically .", "The preliminary results suggest that HDP-2DHMM is generally useful for further applications in low-level vision problems ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Recent work has led to the ability to perform space efficient , approximate counting over large vocabularies in a streaming context .", "Experiments on news articles show our approach gives high accuracy on real world data .", "Motivated by the existence of data structures of this type , we explore the computation of associativity scores , otherwise known as pointwise mutual information ( PMI ) , in a streaming context .", "We give theoretical bounds showing the impracticality of perfect online PMI computation , and detail an algorithm with high expected accuracy ."]}
{"orig_sents": ["1", "3", "2", "6", "9", "5", "0", "4", "8", "7"], "shuf_sents": ["On the surface , these models are unrelated and incompatible , but we show they share a core feature that allows them to be integrated .", "When individuals learn facts ( e.g. , foreign language vocabulary ) over multiple study sessions , the temporal spacing of study has a significant impact on memory retention .", "Appropriate spacing of study can double retention on educationally relevant time scales .", "Behavioral experiments have shown a nonmonotonic relationship between spacing and retention : short or long intervals between study sessions yield lower cued-recall accuracy than intermediate intervals .", "MCM can determine study schedules that maximize the durability of learning , and has implications for education and training .", "MCM is a synthesis of two existing memory models ( Staddon , Chelaru , & Higa , 2002 ; Raaijmakers , 2003 ) .", "We introduce a Multiscale Context Model ( MCM ) that is able to predict the influence of a particular study schedule on retention for specific material .", "MCM is intriguingly similar to a Bayesian multiscale model of memory ( Kording , Tenenbaum , & Shadmehr , 2007 ) , yet MCM is better able to account for human declarative memory .", "MCM can be cast either as a neural network with inputs that fluctuate over time , or as a cascade of leaky integrators .", "MCM 's prediction is based on empirical data characterizing forgetting of the material following a single study session ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["Analyses in specific cases of particular relevance to computer vision and text processing are given , yielding insight into how and when invariance can be achieved .", "In this work we provide a general group-theoretic framework for characterizing and understanding invariance in a family of hierarchical models .", "We show that by taking an algebraic perspective , one can provide a concise set of conditions which must be met to establish invariance , as well as a constructive prescription for meeting those conditions .", "We find that the minimal intrinsic properties of a hierarchical model needed to support a particular invariance can be clearly described , thereby encouraging efficient computational implementations .", "A goal of central importance in the study of hierarchical models for object recognition - and indeed the mammalian visual cortex - is that of understanding quantitatively the trade-off between invariance and selectivity , and how invariance and discrimination properties contribute towards providing an improved representation useful for learning from data ."]}
{"orig_sents": ["2", "5", "3", "0", "6", "4", "1"], "shuf_sents": ["For illustration , we present policy-gradient rules for three different example codes - a spike count code , a spike timing code and the most general `` full spike train '' code - and test them on simple model problems .", "If the distribution of the relevant spike train features belongs to the natural exponential family , the learning rules have a characteristic shape that raises interesting prediction problems .", "Although it is widely believed that reinforcement learning is a suitable tool for describing behavioral learning , the mechanisms by which it can be implemented in networks of spiking neurons are not fully understood .", "We use the framework of Williams ( 1992 ) to derive learning rules for arbitrary neural codes .", "The spike count learning rule has structural similarities with established Bienenstock-Cooper-Munro rules .", "Here , we show that different learning rules emerge from a policy gradient approach depending on which features of the spike trains are assumed to influence the reward signals , i.e. , depending on which neural code is in effect .", "In addition to classical synaptic learning , we derive learning rules for intrinsic parameters that control the excitability of the neuron ."]}
{"orig_sents": ["4", "0", "2", "5", "1", "3"], "shuf_sents": ["Drawing inspiration from robust statistical model fitting , we estimate putative subspace hypotheses from the data .", "The method operates well under severe outliers arising from spurious trajectories or mistracks .", "However , instead of ranking them we encapsulate the hypotheses in a novel Mercer kernel which elicits the potential of two point trajectories to have emerged from the same subspace .", "Detailed experiments on a recent benchmark dataset ( Hopkins 155 ) show that our method is superior to other stateof-the-art approaches in terms of recovering the number of motions , segmentation accuracy , robustness against gross outliers and computational efficiency .", "We present a novel and highly effective approach for multi-body motion segmentation .", "The kernel permits the application of well-established statistical learning methods for effective outlier rejection , automatic recovery of the number of motions and accurate segmentation of the point trajectories ."]}
{"orig_sents": ["1", "3", "0", "5", "4", "2"], "shuf_sents": ["It has been shown that adaptive design optimization ( ADO ) allows one to discriminate models as efficiently as possible in simulation experiments .", "In cognitive science , empirical data collected from participants are the arbiters in model selection .", "Results demonstrate the usefulness of ADO and also reveal some challenges in its implementation .", "Model discrimination thus depends on designing maximally informative experiments .", "Using an optimality criterion based on mutual information , ADO is able to find designs that are maximally likely to increase our certainty about the true model upon observation of the experiment outcomes .", "In this paper we use ADO in a series of experiments with people to discriminate the Power , Exponential , and Hyperbolic models of memory retention , which has been a long-standing problem in cognitive science , providing an ideal setting in which to test the application of ADO for addressing questions about human cognition ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["To illustrate this oracle inequality , we use it to derive learning rates for some learning methods including least squares SVMs .", "We prove an oracle inequality for generic regularized empirical risk minimization algorithms learning from -mixing processes .", "case .", "Since the proof of the oracle inequality uses recent localization ideas developed for independent and identically distributed ( i.i.d . )", "processes , it turns out that these learning rates are close to the optimal rates known in the i.i.d ."]}
{"orig_sents": ["2", "5", "0", "1", "4", "3", "6"], "shuf_sents": ["Our approach applies a standard tool of stochastic process theory , the construction of stochastic processes from their finite-dimensional marginal distributions .", "The main contribution of the paper is a generalization of the classic Kolmogorov extension theorem to conditional probabilities .", "We consider the general problem of constructing nonparametric Bayesian models on infinite-dimensional random objects , such as functions , infinite graphs or infinite permutations .", "Using this approach , we show ( i ) how existence of a conjugate posterior for the nonparametric model can be guaranteed by choosing conjugate finite-dimensional models in the construction , ( ii ) how the mapping to the posterior parameters of the nonparametric model can be explicitly determined , and ( iii ) that the construction of conjugate models in essence requires the finite-dimensional models to be in the exponential family .", "This extension allows a rigorous construction of nonparametric Bayesian models from systems of finitedimensional , parametric Bayes equations .", "The problem has generated much interest in machine learning , where it is treated heuristically , but has not been studied in full generality in nonparametric Bayesian statistics , which tends to focus on models over probability distributions .", "As an application of our constructive framework , we derive a model on infinite permutations , the nonparametric Bayesian analogue of a model recently proposed for the analysis of rank data ."]}
{"orig_sents": ["3", "1", "0", "4", "5", "2"], "shuf_sents": ["Prior finite sample approximations to the null distribution include using bootstrap resampling , which yields a consistent estimate but is computationally costly ; and fitting a parametric model with the low order moments of the test statistic , which can work well in practice but has no consistency or accuracy guarantees .", "In using this distance as a statistic for a test of whether two samples are from different distributions , a major difficulty arises in computing the significance threshold , since the empirical statistic has as its null distribution ( where P = Q ) an infinite weighted sum of 2 random variables .", "The performance of the null distribution estimate is compared with the bootstrap and parametric approaches on an artificial example , high dimensional multivariate data , and text .", "A kernel embedding of probability distributions into reproducing kernel Hilbert spaces ( RKHS ) has recently been proposed , which allows the comparison of two probability measures P and Q based on the distance between their respective embeddings : for a sufficiently rich RKHS , this distance is zero if and only if P and Q coincide .", "The main result of the present work is a novel estimate of the null distribution , computed from the eigenspectrum of the Gram matrix on the aggregate sample from P and Q , and having lower computational cost than the bootstrap .", "A proof of consistency of this estimate is provided ."]}
{"orig_sents": ["0", "1", "5", "4", "3", "2"], "shuf_sents": ["We prove certain theoretical properties of a graph-regularized transductive learning objective that is based on minimizing a Kullback-Leibler divergence based loss .", "These include showing that the iterative alternating minimization procedure used to minimize the objective converges to the correct solution and deriving a test for convergence .", "In one instance , we solve a problem on a 120 million node graph .", "By making use of empirical evaluation on the TIMIT and Switchboard I corpora , we show this approach is able to outperform other state-of-the-art SSL approaches .", "This ensures that the algorithm scales to large data sets .", "We also propose a graph node ordering algorithm that is cache cognizant and leads to a linear speedup in parallel computations ."]}
{"orig_sents": ["6", "1", "0", "3", "7", "4", "5", "2"], "shuf_sents": ["Here we show that the two approaches can be combined , resulting in a conditional renewal ( CR ) model for neural spike trains .", "Typically , these models incorporate spike-history dependencies via either : ( A ) a conditionally-Poisson process with rate dependent on a linear projection of the spike train history ( e.g. , generalized linear model ) ; or ( B ) a modulated non-Poisson renewal process ( e.g. , inhomogeneous gamma process ) .", "We illustrate the CR model with applications to both real and simulated neural data .", "This model captures both real-time and rescaled-time history effects , and can be fit by maximum likelihood using a simple application of the time-rescaling theorem .", "gamma with shape = 1 ) , suggesting that real-time history effects are easier to estimate than non-Poisson renewal properties .", "Moreover , we show that goodness-of-fit tests based on the time-rescaling theorem quantify relative-time effects , but do not reliably assess accuracy in spike prediction or stimulus-response modeling .", "Recent work on the statistical modeling of neural responses has focused on modulated renewal processes in which the spike rate is a function of the stimulus and recent spiking history .", "We show that for any modulated renewal process model , the log-likelihood is concave in the linear filter parameters only under certain restrictive conditions on the renewal density ( ruling out many popular choices , e.g ."]}
{"orig_sents": ["4", "1", "3", "5", "0", "2"], "shuf_sents": ["The preference of `'linear '' functions on manifolds renders the Hessian energy particularly suited for the task of semi-supervised dimensionality reduction , where the goal is to find a user-defined embedding function given some labeled points which varies smoothly ( and ideally linearly ) along the manifold .", "Based on these observations , we propose to use the second-order Hessian energy for semi-supervised regression which overcomes both these problems .", "The experimental results suggest superior performance of our method compared with semi-supervised regression using Laplacian regularization or standard supervised regression techniques applied to this task .", "If the data lies on or close to a low-dimensional submanifold in feature space , the Hessian energy prefers functions whose values vary linearly with respect to geodesic distance .", "Semi-supervised regression based on the graph Laplacian suffers from the fact that the solution is biased towards a constant and the lack of extrapolating power .", "We first derive the Hessian energy for smooth manifolds and continue to give a stable estimation procedure for the common case where only samples of the underlying manifold are given ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We provide an empirical study on retrieval tasks based on Wikipedia documents , where we obtain state-of-the-art performance while providing realistically scalable methods .", "We propose a low-rank ( but diagonal preserving ) representation of our polynomial models to induce feasible memory and computation requirements .", "We present a class of nonlinear ( polynomial ) models that are discriminatively trained to directly map from the word content in a query-document or documentdocument pair to a ranking score .", "Dealing with polynomial models on word features is computationally challenging ."]}
{"orig_sents": ["1", "4", "0", "6", "2", "3", "5"], "shuf_sents": ["Clustering sets of sequences yields clusters of coherent motifs , improving signal-to-noise ratio or enabling us to identify multiple motifs .", "Most of existing methods for DNA motif discovery consider only a single set of sequences to find an over-represented motif .", "Our model infers cluster-indicating latent variables and learns motifs simultaneously , where these two tasks interact with each other .", "We show that our model can handle various motif discovery problems , depending on how to construct multiple sets of sequences .", "In contrast , we consider multiple sets of sequences where we group sets associated with the same motif into a cluster , assuming that each set involves a single motif .", "Experiments on three different problems for discovering DNA motifs emphasize the useful behavior and confirm the substantial gains over existing methods where only a single set of sequences is considered .", "We present a probabilistic model for DNA motif discovery where we identify multiple motifs through searching for patterns which are shared across multiple sets of sequences ."]}
{"orig_sents": ["0", "5", "2", "6", "1", "4", "3"], "shuf_sents": ["The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits , and how spike-timing-dependent plasticity ( STDP ) of synaptic weights could generate and maintain this computational function , are unknown .", "We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles .", "Hence these neurons will fire after learning whenever the current input best matches their internal model .", "A corresponding result is shown for Hebbian learning in artificial neural networks .", "In particular , we show that STDP is able to approximate a stochastic online Expectation-Maximization ( EM ) algorithm for modeling the input data .", "We show here that STDP , in conjunction with a stochastic soft winner-take-all ( WTA ) circuit , induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses ( or `` causes '' ) of the high-dimensional spike patterns of hundreds of pre-synaptic neurons .", "The resulting computational function of soft WTA circuits , a common network motif of cortical microcircuits , could therefore be a drastic dimensionality reduction of information streams , together with the autonomous creation of internal models for the probability distributions of their input patterns ."]}
{"orig_sents": ["5", "1", "0", "3", "2", "4"], "shuf_sents": ["We prove that , for tree graphs ( and junction trees in general ) , this polytope has a particularly simple form and differs from the marginal polytope in a single inequality constraint .", "We show how this problem can be formulated as a linear program ( LP ) on a particular polytope .", "The method we present puts the M -best inference problem in the context of LP relaxations , which have recently received considerable attention and have proven useful in solving difficult inference problems .", "We use this characterization to provide an approximation scheme for non-tree graphs , by using the set of spanning trees over such graphs .", "We show empirically that our method often finds the provably exact M best configurations for problems of high tree-width .", "We consider the problem of finding the M assignments with maximum probability in a probabilistic graphical model ."]}
{"orig_sents": ["2", "6", "3", "1", "4", "5", "0"], "shuf_sents": ["domains like time-series forecasting , discriminative learning , and reinforcement learning are discussed .", "No independence , ergodicity , stationarity , identifiability , or other assumption on the model class need to be made .", "The Minimum Description Length ( MDL ) principle selects the model that has the shortest code for data plus model .", "The result is completely general .", "More formally , we show that for any countable class of models , the distributions selected by MDL ( or MAP ) asymptotically predict ( merge with ) the true measure in the class in total variation distance .", "Implications for non-i.i.d .", "We show that for a countable class of models , MDL predictions are close to the true distribution in a strong sense ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["Everyday social interactions are heavily influenced by our snap judgments about others ' goals .", "We also present behavioral evidence in support of this model over a simpler , perceptual cue-based alternative .", "We propose a model for how people can infer these social goals from actions , based on inverse planning in multiagent Markov decision problems ( MDPs ) .", "The model infers the goal most likely to be driving an agent 's behavior by assuming the agent acts approximately rationally given environmental constraints and its model of other agents present .", "Even young infants can infer the goals of intentional agents from observing how they interact with objects and other agents in their environment : e.g. , that one agent is `helping ' or `hindering ' another 's attempt to get up a hill or open a box ."]}
{"orig_sents": ["4", "3", "1", "2", "0"], "shuf_sents": ["We evaluate this setting empirically yielding three main results : ( i ) regression tends to be improved by the use of Laplacian regularization even when no additional unlabeled data are available , ( ii ) resting state data seem to have a similar marginal distribution to that recorded during the execution of a visual processing task implying largely similar types of activation , and ( iii ) this source of information can be broadly exploited to improve the robustness of empirical inference in fMRI studies , an inherently data poor domain .", "While certain networks of brain areas have different levels of activation at rest and during a task , there is nevertheless significant similarity between activations in the two cases .", "This suggests that recordings of resting state activity can be used as a source of unlabeled data to augment discriminative regression techniques in a semi-supervised setting .", "It has been recognized in recent years that resting state activity is implicated in a wide variety of brain function .", "Resting state activity is brain activation that arises in the absence of any task , and is usually measured in awake subjects during prolonged fMRI scanning sessions where the only instruction given is to close the eyes and do nothing ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["This paper addresses the problem of designing binary codes for high-dimensional data such that vectors that are similar in the original space map to similar binary strings .", "We introduce a simple distribution-free encoding scheme based on random projections , such that the expected Hamming distance between the binary codes of two vectors is related to the value of a shift-invariant kernel ( e.g. , a Gaussian kernel ) between the vectors .", "We present a full theoretical analysis of the convergence properties of the proposed scheme , and report favorable experimental performance as compared to a recent state-of-the-art method , spectral hashing ."]}
{"orig_sents": ["6", "1", "0", "5", "2", "3", "8", "9", "4", "7", "10"], "shuf_sents": ["An important requirement of the embedding RKHS is that it be characteristic : in this case , the MMD between two distributions is zero if and only if the distributions coincide .", "In particular , the distance between embeddings ( the maximum mean discrepancy , or MMD ) has several key advantages over many classical metrics on distributions , namely easy computability , fast convergence and low bias of finite sample estimates .", "First , it is established that MMD corresponds to the optimal risk of a kernel classifier , thus forming a natural link between the distance between distributions and their ease of classification .", "An important consequence is that a kernel must be characteristic to guarantee classifiability between distributions in the RKHS .", "This extension is necessary to obtain a single distance measure if a large selection or class of characteristic kernels is potentially appropriate .", "Three new results on the MMD are introduced in the present study .", "Embeddings of probability measures into reproducing kernel Hilbert spaces have been proposed as a straightforward and practical means of representing and comparing probabilities .", "This generalization is reasonable , given that it corresponds to the problem of learning the kernel by minimizing the risk of the corresponding kernel classifier .", "Second , the class of characteristic kernels is broadened to incorporate all strictly positive definite kernels : these include non-translation invariant kernels and kernels on non-compact domains .", "Third , a generalization of the MMD is proposed for families of kernels , as the supremum over MMDs on a class of kernels ( for instance the Gaussian kernels with different bandwidths ) .", "The generalized MMD is shown to have consistent finite sample estimates , and its performance is demonstrated on a homogeneity testing example ."]}
{"orig_sents": ["0", "4", "5", "1", "3", "2"], "shuf_sents": ["We introduce a novel multivariate Laplace ( MVL ) distribution as a sparsity promoting prior for Bayesian source localization that allows the specification of constraints between and within sources .", "The computational bottleneck amounts to computing the diagonal elements of a sparse matrix inverse .", "We show that spatial coupling leads to sources which are active over larger cortical areas as compared with an uncoupled prior .", "Our approach is illustrated using a mismatch negativity paradigm for which MEG data and a structural MRI have been acquired .", "We represent the MVL distribution as a scale mixture that induces a coupling between source variances instead of their means .", "Approximation of the posterior marginals using expectation propagation is shown to be very efficient due to properties of the scale mixture representation ."]}
{"orig_sents": ["6", "0", "4", "3", "2", "1", "5"], "shuf_sents": ["We specifically study methods which choose a single batch of labeled vertices ( i.e .", "Some of these bounds give new motivations for previously proposed algorithms , and some suggest new algorithms which we evaluate .", "These methods bound prediction error in terms of the smoothness of the true labels with respect to the graph .", "In this setting , we find common graph smoothness assumptions directly motivate simple label selection methods with interesting theoretical guarantees .", "offline , non sequential methods ) .", "We show improved performance over baseline methods on several real world data sets .", "We investigate methods for selecting sets of labeled vertices for use in predicting the labels of vertices on a graph ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["The multiplicative updates are exponentiated skew-symmetric matrices which comprise the Lie algebra of the rotation group .", "The proposed algorithm involves matrix exponentiated gradient updates and is motivated by the von Neumann divergence .", "A complexity reduction result is presented that exploits the eigenstructure of the matrix updates to simplify matrix exponentiation to a quadratic form .", "An algorithm is presented for online learning of rotations .", "The orthonormality and unit determinant of the matrix parameter are preserved using matrix logarithms and exponentials and the algorithm lends itself to intuitive interpretation in terms of the differential geometry of the manifold associated with the rotation group ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["In contrast to previous minimum conditional entropy semi-supervised discriminative learning methods , our approach is grounded on a more solid foundation , the rate distortion theory in information theory .", "We propose a novel information theoretic approach for semi-supervised learning of conditional random fields that defines a training objective to combine the conditional likelihood on labeled data and the mutual information on unlabeled data .", "Our experimental results show the rate distortion approach outperforms standard l2 regularization , minimum conditional entropy regularization as well as maximum conditional entropy regularization on both multi-class classification and sequence labeling problems .", "We analyze the tractability of the framework for structured prediction and present a convergent variational training algorithm to defy the combinatorial explosion of terms in the sum over label configurations ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["We identify conditions under which the prediction game has a unique Nash equilibrium , and derive algorithms that will find the equilibrial prediction models .", "We study single-shot prediction games in which the cost functions of learner and adversary are not necessarily antagonistic .", "In a case study , we explore properties of Nash-equilibrial prediction models for email spam filtering empirically .", "In a prediction game , a learner produces a predictive model while an adversary may alter the distribution of input data .", "The standard assumption of identically distributed training and test data is violated when an adversary can exercise some control over the generation of the test data ."]}
{"orig_sents": ["10", "6", "2", "0", "3", "9", "7", "8", "4", "5", "1"], "shuf_sents": ["This problem is NP-hard , therefore most algorithms find approximate solutions by relaxing the original problem .", "In our experiments on MAP inference our algorithm proved its effectiveness by significantly outperforming , ICM and Max-Product Belief Propagation .", "Recent graph matching algorithms are based on a general quadratic programming formulation , which takes in consideration both unary and second-order terms reflecting the similarities in local appearance as well as in the pairwise geometric relationships between the matched features .", "They find the optimal continuous solution of the modified problem , ignoring during optimization the original discrete constraints .", "In practice it outperforms state-or-the art graph matching algorithms and it also significantly improves their performance if used in combination .", "When applied to MAP inference , the algorithm is a parallel extension of Iterated Conditional Modes ( ICM ) with climbing and convergence properties that make it a compelling alternative to the sequential ICM .", "We introduce a novel algorithm that can accommodate both problems and solve them efficiently .", "In this paper we argue that the stage in which a discrete solution is found is crucial for good performance .", "We propose an efficient algorithm , with climbing and convergence properties , that optimizes in the discrete domain the quadratic score , and it gives excellent results either by itself or by starting from the solution returned by any graph matching algorithm .", "Then the continuous solution is quickly binarized at the end , but very little attention is put into this final discretization step .", "Graph matching and MAP inference are essential problems in computer vision and machine learning ."]}
{"orig_sents": ["0", "1", "4", "2", "8", "7", "5", "6", "3"], "shuf_sents": ["Image representation based on image bases provides a framework for understanding neural representation of visual perception .", "A recent fMRI study has shown that arbitrary contrast-defined visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases .", "But the shapes of the images bases were fixed , and thus may not be optimal for reconstruction .", "The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns .", "In the reconstruction model , the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images .", "The mapping from the latent variables to the visual image space can be regarded as a set of image bases .", "We found that spatially localized , multi-scale image bases were estimated near the fovea , and that the model using the estimated image bases was able to accurately reconstruct novel visual images .", "We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables .", "Here , we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data ."]}
{"orig_sents": ["5", "3", "1", "6", "2", "4", "0"], "shuf_sents": ["Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets .", "Until recently , most learning to rank algorithms were not using a loss function related to the above mentioned evaluation measures .", "We propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents .", "The ranking algorithms are often evaluated using information retrieval measures , such as Normalized Discounted Cumulative Gain ( NDCG ) and Mean Average Precision ( MAP ) .", "A relaxation strategy is used to approximate the average of NDCG over the space of permutation , and a bound optimization approach is proposed to make the computation efficient .", "Learning to rank is a relatively new field of study , aiming to learn a ranking function from a set of training data with relevancy labels .", "The main difficulty in direct optimization of these measures is that they depend on the ranks of documents , not the numerical values output by the ranking function ."]}
{"orig_sents": ["0", "4", "1", "2", "3"], "shuf_sents": ["Given a corpus of news items consisting of images accompanied by text captions , we want to find out `` who 's doing what '' , i.e .", "We present a joint model for simultaneously solving the image-caption correspondences and learning visual appearance models for the face and pose classes occurring in the corpus .", "These models can then be used to recognize people and actions in novel images without captions .", "We demonstrate experimentally that our joint `face and pose ' model solves the correspondence problem better than earlier models covering only the face , and that it can perform recognition of new uncaptioned images .", "associate names and action verbs in the captions to the face and body pose of the persons in the images ."]}
{"orig_sents": ["4", "6", "5", "1", "0", "2", "3"], "shuf_sents": ["The former analyses assume that learners seek to identify grammatical sentences in a way that is robust to the distribution from which the sentences are generated , analogous to discriminative approaches in machine learning .", "These two kinds of learnability analyses differ in their assumptions about the distribution from which linguistic input is generated .", "The latter assume that learners are trying to estimate a generative model , with sentences being sampled from that model .", "We show that these two learning approaches differ in their use of implicit negative evidence - the absence of a sentence - when learning verb alternations , and demonstrate that human learners can produce results consistent with the predictions of both approaches , depending on how the learning problem is presented .", "A classic debate in cognitive science revolves around understanding how children learn complex linguistic rules , such as those governing restrictions on verb alternations , without negative evidence .", "However , recently , researchers have shown that statistical models are capable of learning complex rules from only positive evidence .", "Traditionally , formal learnability arguments have been used to claim that such learning is impossible without the aid of innate language-specific knowledge ."]}
{"orig_sents": ["2", "5", "3", "0", "4", "6", "1"], "shuf_sents": ["Solving a bilinear program optimally is NP-hard , but this is unavoidable because the Bellman-residual minimization itself is NP-hard .", "Finally , we demonstrate that the proposed approach can consistently minimize the Bellman residual on a simple benchmark problem .", "Existing value function approximation methods have been successfully used in many applications , but they often lack useful a priori error bounds .", "In particular , this approach provably finds an approximate value function that minimizes the Bellman residual .", "We therefore employ and analyze a common approximate algorithm for bilinear programs .", "We propose approximate bilinear programming , a new formulation of value function approximation that provides strong a priori guarantees .", "The analysis shows that this algorithm offers a convergent generalization of approximate policy iteration ."]}
{"orig_sents": ["6", "3", "5", "7", "1", "0", "4", "2"], "shuf_sents": ["Moreover , we also provide a method that produces successively decreasing upper-bounds of the optimal solution , while our algorithm provides successively increasing lower-bounds .", "Our algorithm is guaranteed to find the exact solution finitely many iterations , and it converges fast in practice due to the efficiency of the cutting-plane mechanism .", "We evaluate our algorithm on sensor placement and feature selection applications showing good performance .", "We present herein a novel algorithm for maximizing a submodular set function under a cardinality constraint -- the algorithm is based on a cutting-plane method and is implemented as an iterative small-scale binary-integer linear programming procedure .", "Thus , the accuracy of the current solution can be estimated at any point , and the algorithm can be stopped early once a desired degree of tolerance is met .", "It is well known that this problem is NP-hard , and the approximation factor achieved by the greedy algorithm is the theoretical limit for polynomial time .", "Several key problems in machine learning , such as feature selection and active learning , can be formulated as submodular set function maximization .", "As for ( non-polynomial time ) exact algorithms that perform reasonably in practice , there has been very little in the literature although the problem is quite important for many applications ."]}
{"orig_sents": ["4", "0", "2", "5", "3", "6", "8", "1", "7"], "shuf_sents": ["Recently , , and obtained the first non-trivial theoretical results for the problem assuming that the observed entries are sampled uniformly at random .", "Furthermore , our method is easy to implement and is substantially faster than existing methods .", "Unfortunately , most real-world datasets do not satisfy this assumption , but instead exhibit power-law distributed samples .", "Our method is simpler to analyze than previous methods with the analysis reducing to computing the threshold for complete cascades in random graphs , a problem of independent interest .", "The low-rank matrix completion problem is a fundamental problem with many important applications .", "In this paper , we propose a graph theoretic approach to matrix completion that solves the problem for more realistic sampling models .", "By analyzing the graph theoretic problem , we show that our method achieves exact recovery when the observed entries are sampled from the Chung-Lu-Vu model , which can generate power-law distributed graphs .", "We demonstrate the effectiveness of our method on random instances where the low-rank matrix is sampled according to the prevalent random graph models for complex networks and present promising preliminary results on the Netflix challenge dataset .", "We also hypothesize that our algorithm solves the matrix completion problem from an optimal number of entries for the popular preferential attachment model and provide strong empirical evidence for the claim ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["The inter-subject alignment of functional MRI ( fMRI ) data is important for improving the statistical power of fMRI group analyses .", "We test our method on fMRI data collected during a movie viewing experiment .", "By cross-validating the results of our algorithm , we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment .", "In contrast to existing anatomically-based methods , we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["The goal of this paper is to provide a unified framework for establishing consistency and convergence rates for such regularized M estimators under high-dimensional scaling .", "We state one main theorem and show how it can be used to re-derive several existing results , and also to obtain several new results on consistency and convergence rates .", "Our analysis also identifies two key properties of loss and regularization functions , referred to as restricted strong convexity and decomposability , that ensure the corresponding regularized M -estimators have fast convergence rates .", "High-dimensional statistical inference deals with models in which the the number of parameters p is comparable to or larger than the sample size n. Since it is usually impossible to obtain consistent procedures unless p/n 0 , a line of recent work has studied models with various types of structure ( e.g. , sparse vectors ; block-structured matrices ; low-rank matrices ; Markov assumptions ) .", "In such settings , a general approach to estimation is to solve a regularized convex program ( known as a regularized M -estimator ) which combines a loss function ( measuring how well the model fits the data ) with some regularization function that encourages the assumed structure ."]}
{"orig_sents": ["3", "0", "5", "4", "2", "6", "1"], "shuf_sents": ["However , current state-of-the-art models use a separate representation for each task making joint inference clumsy and leaving the classification of many parts of the scene ambiguous .", "We run experiments on the challenging Street Scene dataset and show significant improvement over state-of-the-art results for object detection accuracy .", "Pixel appearance features allow us to perform well on classifying amorphous background classes , while the explicit representation of regions facilitate the computation of more sophisticated features necessary for object detection .", "Object detection and multi-class image segmentation are two closely related tasks that can be greatly improved when solved jointly by feeding information from one task to the other .", "Our approach simultaneously reasons about pixels , regions and objects in a coherent probabilistic model .", "In this work , we propose a hierarchical region-based approach to joint object detection and image segmentation .", "Importantly , our model gives a single unified description of the scene -- we explain every pixel in the image and enforce global consistency between all random variables in our model ."]}
{"orig_sents": ["4", "6", "1", "2", "0", "5", "3"], "shuf_sents": ["The gNAC algorithm involves a near optimal auxiliary function to reduce the variance of the gNG estimates .", "Though there are two candidate metrics , Kakade 's Fisher Information Matrix ( FIM ) for the policy ( action ) distribution and Morimura 's FIM for the stateaction joint distribution , but all RL algorithms with NG have followed Kakade 's approach .", "In this paper , we describe a generalized Natural Gradient ( gNG ) that linearly interpolates the two FIMs and propose an efficient implementation for the gNG learning based on a theory of the estimating function , the generalized Natural Actor-Critic ( gNAC ) algorithm .", "Numerical experiments showed that the proposed gNAC algorithm can estimate gNG efficiently and outperformed the NAC algorithm .", "Policy gradient Reinforcement Learning ( RL ) algorithms have received substantial attention , seeking stochastic policies that maximize the average ( or discounted cumulative ) reward .", "Interestingly , the gNAC can be regarded as a natural extension of the current state-of-the-art NAC algorithm , as long as the interpolating parameter is appropriately selected .", "In addition , extensions based on the concept of the Natural Gradient ( NG ) show promising learning efficiency because these regard metrics for the task ."]}
{"orig_sents": ["6", "5", "0", "3", "1", "4", "2"], "shuf_sents": ["We then infer from the relaxation its deficiencies , and compensate for them .", "First , we find that max-product belief propagation can be viewed as a way to compensate for a relaxation , based on a particular idealized case for exactness .", "We go on to propose a new class of algorithms that , starting with a relaxation , iteratively seeks tighter approximations .", "This perspective allows us to identify two distinct classes of approximations .", "We identify a second approach to compensation that is based on a more refined idealized case , resulting in a new approximation with distinct properties .", "First , we start with a structural relaxation of the original model .", "We introduce a new perspective on approximations to the maximum a posteriori ( MAP ) task in probabilistic graphical models , that is based on simplifying a given instance , and then tightening the approximation ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["It was recently shown that certain nonparametric regressors can escape the curse of dimensionality when the intrinsic dimension of data is low ( ) .", "In particular , we consider a regressor which , by combining aspects of both tree-based regression and kernel regression , adapts to intrinsic dimension , operates on general metrics , yields a smooth function , and evaluates in time O ( log n ) .", "We prove some stronger results in more general settings .", "We derive a tight convergence rate of the form n-2/ ( 2+d ) where d is the Assouad dimension of the input space ."]}
{"orig_sents": ["1", "6", "2", "5", "0", "7", "4", "3"], "shuf_sents": ["With this generalization , we are presented with two difficulties .", "Stochastic Neighbor Embedding ( SNE ) has shown to be quite promising for data visualization .", "Moreover , it uses a gradient descent algorithm that may require users to tune parameters such as the learning step size , momentum , etc. , in finding its optimum .", "Based on this finding , we present a parameterized subset of similarity functions for choosing the best tail-heaviness for HSSNE ; ( 2 ) we present a fixed-point optimization algorithm that can be applied to all heavy-tailed functions and does not require the user to set any parameters ; and ( 3 ) we present two empirical studies , one for unsupervised visualization showing that our optimization algorithm runs as fast and as good as the best known t-SNE implementation and the other for semi-supervised visualization showing quantitative superiority using the homogeneity measure as well as qualitative advantage in cluster separation over t-SNE .", "Our contributions then are : ( 1 ) we point out that various heavy-tailed embedding similarities can be characterized by their negative score functions .", "In this paper , we propose the Heavy-tailed Symmetric Stochastic Neighbor Embedding ( HSSNE ) method , which is a generalization of the t-SNE to accommodate various heavytailed embedding similarity functions .", "Currently , the most popular implementation , t-SNE , is restricted to a particular Student t-distribution as its embedding distribution .", "The first is how to select the best embedding similarity among all heavy-tailed functions and the second is how to optimize the objective function once the heavy-tailed function has been selected ."]}
{"orig_sents": ["1", "2", "0", "3", "5", "4"], "shuf_sents": ["We first review the definition of Rademacher complexity and its generalization bound .", "We propose to use Rademacher complexity , originally developed in computational learning theory , as a measure of human learning capacity .", "Rademacher complexity measures a learner 's ability to fit random labels , and can be used to bound the learner 's true error based on the observed training sample error .", "We then describe a `` learning the noise '' procedure to experimentally measure human Rademacher complexities .", "Finally , we discuss the potential applications of human Rademacher complexity in cognitive science .", "The results from empirical studies showed that : ( i ) human Rademacher complexity can be successfully measured , ( ii ) the complexity depends on the domain and training sample size in intuitive ways , ( iii ) human learning respects the generalization bounds , ( iv ) the bounds can be useful in predicting the danger of overfitting in human learning ."]}
{"orig_sents": ["7", "5", "6", "2", "4", "8", "0", "3", "1"], "shuf_sents": ["We use computer simulations to find optimal stimulation parameters and explore the feasibility of our reconstruction method under realistic experimental conditions including noise and non-linear synaptic integration .", "By using calcium indicators , voltage-sensitive dyes , or multi-electrode arrays one could monitor activity of multiple postsynaptic neurons simultaneously , thus mapping their synaptic inputs in parallel , potentially reconstructing a complete neural circuit .", "Instead , we propose to measure a post-synaptic neuron 's voltage while stimulating sequentially random subsets of multiple potentially pre-synaptic neurons .", "Multineuronal stimulation allows reconstructing synaptic connectivity just from the spiking activity of post-synaptic neurons , even when sub-threshold voltage is unavailable .", "To reconstruct these synaptic connections from the recorded voltage we apply a decoding algorithm recently developed for compressive sensing .", "Synapses onto a neuron can be probed by sequentially stimulating potentially pre-synaptic neurons while monitoring the membrane voltage of the post-synaptic neuron .", "Reconstructing a large neural circuit using such a `` brute force '' approach is rather time-consuming and inefficient because the connectivity in neural circuits is sparse .", "One of the central problems in neuroscience is reconstructing synaptic connectivity in neural circuits .", "Compared to the brute force approach , our method promises significant time savings that grow with the size of the circuit ."]}
{"orig_sents": ["5", "0", "4", "2", "3", "1"], "shuf_sents": ["In these services , since users can attach annotations freely , some annotations do not describe the semantics of the content , thus they are noisy , i.e .", "We demonstrate the effectiveness of the proposed method by using synthetic data and real social annotation data for text and images .", "The extraction of content-related annotations can be used as a preprocessing step in machine learning tasks such as text classification and image recognition , or can improve information retrieval performance .", "The proposed model is a generative model for content and annotations , in which the annotations are assumed to originate either from topics that generated the content or from a general distribution unrelated to the content .", "not content-related .", "We propose a probabilistic topic model for analyzing and extracting contentrelated annotations from noisy annotated discrete data such as web pages stored in social bookmarking services ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["Here we analyze neural responses to natural movies in the primary visual cortex of ferrets at different stages of development and of rats while awake and under different levels of anesthesia .", "However , direct experimental evidence for optimal sparse coding remains inconclusive , mostly due to the lack of reference values on which to judge the measured sparseness .", "The proposal that cortical activity in the visual cortex is optimized for sparse neural activity is one of the most established ideas in computational neuroscience .", "These results suggest that the representation in the primary visual cortex is not actively optimized to maximize sparseness .", "In contrast with prediction from a sparse coding model , our data shows that population and lifetime sparseness decrease with visual experience , and increase from the awake to anesthetized state ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["Representing distributions over permutations can be a daunting task due to the fact that the number of permutations of n objects scales factorially in n. One recent way that has been used to reduce storage complexity has been to exploit probabilistic independence , but as we argue , full independence assumptions impose strong sparsity constraints on distributions and are unsuitable for modeling rankings .", "We identify a novel class of independence structures , called riffled independence , which encompasses a more expressive family of distributions while retaining many of the properties necessary for performing efficient inference and reducing sample complexity .", "In riffled independence , one draws two permutations independently , then performs the riffle shuffle , common in card games , to combine the two permutations to form a single permutation .", "In ranking , riffled independence corresponds to ranking disjoint sets of objects independently , then interleaving those rankings .", "We provide a formal introduction and present algorithms for using riffled independence within Fourier-theoretic frameworks which have been explored by a number of recent papers ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["We present a simple statistical model that helps to explain these abilities and evaluate it in three behavioral experiments .", "Humans are typically able to infer how many objects their environment contains and to recognize when the same object is encountered twice .", "Our first experiment suggests that humans rely on prior knowledge when deciding whether an object token has been previously encountered .", "Our second and third experiments suggest that humans can infer how many objects they have seen and can learn about categories and their properties even when they are uncertain about which tokens are instances of the same object ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We prove performance guarantees that are order-optimal in a number of circumstances .", "We study a low complexity algorithm introduced in , based on a combination of spectral techniques and manifold optimization , that we call here O PT S PACE .", "The problem arises in a variety of applications , from collaborative filtering ( the `Netflix problem ' ) to structure-from-motion and positioning .", "Given a matrix M of low-rank , we consider the problem of reconstructing it from noisy observations of a small , random subset of its entries ."]}
{"orig_sents": ["7", "5", "6", "2", "1", "4", "3", "0"], "shuf_sents": ["Experiments on realworld data sets show that PRPCA can effectively utilize the relational information to dramatically outperform PCA and achieve state-of-the-art performance .", "Although the i.i.d .", "In this paper , by explicitly modeling covariance between instances as derived from the relational information , we propose a novel probabilistic dimensionality reduction method , called probabilistic relational PCA ( PRPCA ) , for relational data analysis .", "assumption .", "assumption is no longer adopted in PRPCA , the learning algorithms for PRPCA can still be devised easily like those for PPCA which makes explicit use of the i.i.d .", "However , this common i.i.d .", "assumption is unreasonable for relational data .", "One crucial assumption made by both principal component analysis ( PCA ) and probabilistic PCA ( PPCA ) is that the instances are independent and identically distributed ( i.i.d . ) ."]}
{"orig_sents": ["3", "0", "2", "1", "4"], "shuf_sents": ["The formula has a number of theoretical implications on LBP .", "The formula clarifies the relation between the local stability of a fixed point of LBP and local minima of the Bethe free energy .", "It is applied to give a sufficient condition that the Hessian of the Bethe free energy is positive definite , which shows non-convexity for graphs with multiple cycles .", "We propose a new approach to the analysis of Loopy Belief Propagation ( LBP ) by establishing a formula that connects the Hessian of the Bethe free energy with the edge zeta function .", "We also propose a new approach to the uniqueness of LBP fixed point , and show various conditions of uniqueness ."]}
{"orig_sents": ["5", "1", "2", "4", "3", "0"], "shuf_sents": ["We demonstrate the iPOMDP on several standard problems .", "Unfortunately , most POMDPs are complex structures with a large number of parameters .", "In many real-world problems , both the structure and the parameters are difficult to specify from domain knowledge alone .", "We define an infinite POMDP ( iPOMDP ) model that does not require knowledge of the size of the state space ; instead , it assumes that the number of visited states will grow as the agent explores its world and only models visited states explicitly .", "Recent work in Bayesian reinforcement learning has made headway in learning POMDP models ; however , this work has largely focused on learning the parameters of the POMDP model .", "The Partially Observable Markov Decision Process ( POMDP ) framework has proven useful in planning domains where agents must balance actions that provide knowledge and actions that provide reward ."]}
{"orig_sents": ["0", "5", "3", "2", "1", "6", "4"], "shuf_sents": ["Search engines today present results that are often oblivious to recent shifts in intent .", "We present a meta-algorithm that marries a classifier with a bandit algorithm to achieve regret that depends logarithmically on the number of query impressions , under certain assumptions .", "This paper shows that the signals a search engine receives can be used to both determine that a shift in intent happened , as well as find a result that is now more relevant .", "While no studies exactly quantify the magnitude of intent-shifting traffic , studies suggest that news events , seasonal topics , pop culture , etc account for 1/2 the search queries .", "Finally , via a series of experiments , we demonstrate that our algorithm outperforms prior approaches , particularly as the amount of intent-shifting traffic increases .", "For example , the meaning of the query `independence day ' shifts in early July to a US holiday and to a movie around the time of the box office release .", "We provide strong evidence that this regret is close to the best achievable ."]}
{"orig_sents": ["5", "0", "3", "6", "2", "1", "4"], "shuf_sents": ["Human behavior is consistent with the optimal statistical solution to this problem in many tasks , including cue combination and orientation detection .", "Moreover , a simple extension to recursive importance sampling can be used to perform hierarchical Bayesian inference .", "This mechanism is based on a Monte Carlo method known as importance sampling , commonly used in computer science and statistics .", "Understanding the neural mechanisms underlying this behavior is of particular importance , since probabilistic computations are notoriously challenging .", "We identify a scheme for implementing importance sampling with spiking neurons , and show that this scheme can account for human behavior in cue combination and the oblique effect .", "The goal of perception is to infer the hidden states in the hierarchical process by which sensory data are generated .", "Here we propose a simple mechanism for Bayesian inference which involves averaging over a few feature detection neurons which fire at a rate determined by their similarity to a sensory stimulus ."]}
{"orig_sents": ["2", "0", "3", "1", "5", "4"], "shuf_sents": ["The approach is based on a Gaussian observation model and Gaussian priors with bilinear equality and inequality constraints .", "Special cases of the proposed model are Bayesian formulations of nonnegative matrix factorization and factor analysis .", "We present a general Bayesian approach to probabilistic matrix factorization subject to linear constraints .", "We present an efficient Markov chain Monte Carlo inference procedure based on Gibbs sampling .", "We demonstrate that our algorithm can be used to extract meaningful and interpretable features that are remarkably different from features extracted using existing related matrix factorization techniques .", "The method is evaluated on a blind source separation problem ."]}
{"orig_sents": ["1", "2", "0", "4", "3"], "shuf_sents": ["More generally , when the sparsity level satisfies kmin k kmax but is unknown , m = 2kmax log ( n - kmin ) measurements is sufficient .", "A well-known analysis of Tropp and Gilbert shows that orthogonal matching pursuit ( OMP ) can recover a k-sparse n-dimensional real vector from m = 4k log ( n ) noise-free linear measurements obtained through a random Gaussian measurement matrix with a probability that approaches one as n .", "This work strengthens this result by showing that a lower number of measurements , m = 2k log ( n - k ) , is in fact sufficient for asymptotic recovery .", "The scaling m = 2k log ( n - k ) exactly matches the number of measurements required by the more complex lasso method for signal recovery in a similar SNR scaling .", "Furthermore , this number of measurements is also sufficient for detection of the sparsity pattern ( support ) of the vector with measurement errors provided the signal-to-noise ratio ( SNR ) scales to infinity ."]}
{"orig_sents": ["7", "6", "3", "8", "9", "1", "2", "4", "5", "0"], "shuf_sents": ["Together , these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification .", "We used this model to predict the EEG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses .", "In almost 90 percent of the cases our model accurately predicted the observed scene .", "Here we investigated whether a neural response model based on the Wei bull contrast distribution captures visual information that humans use to rapidly identify natural scenes .", "Moreover , in most failed cases , the scene mistaken for the observed scene was visually similar to the observed scene itself .", "Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images .", "This property of natural images may facilitate efficient and very rapid extraction of a scene 's visual gist .", "Contrast statistics of the majority of natural images conform to a Weibull distribution .", "In a learning phase , we measured EEG activity of 32 subjects viewing brief flashes of 700 natural scenes .", "From these neural measurements and the contrast statistics of the natural image stimuli , we derived an across subject Wei bull response model ."]}
{"orig_sents": ["0", "4", "2", "1", "3"], "shuf_sents": ["We provide some insights into how task correlations in multi-task Gaussian process ( GP ) regression affect the generalization error and the learning curve .", "Our approach admits intuitive understandings of the multi-task GP by relating it to single-task GPs .", "Within this setting , we give bounds on the generalization error and the learning curve of the primary task .", "For the case of one-dimensional input-space under optimal sampling with data only for the secondary task , the limitations of multi-task GP can be quantified explicitly .", "We analyze the asymmetric two-tasks case , where a secondary task is to help the learning of a primary task ."]}
{"orig_sents": ["2", "3", "1", "5", "4", "0"], "shuf_sents": ["Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms .", "In this paper , we propose a new online learning method , termed Double Updating Online Learning , or DUOL for short .", "In most online learning algorithms , the weights assigned to the misclassified examples ( or support vectors ) remain unchanged during the entire learning process .", "This is clearly insufficient since when a new misclassified example is added to the pool of support vectors , we generally expect it to affect the weights for the existing support vectors .", "We show that the mistake bound can be significantly improved by the proposed online learning method .", "Instead of only assigning a fixed weight to the misclassified example received in current trial , the proposed online learning algorithm also tries to update the weight for one of the existing support vectors ."]}
{"orig_sents": ["2", "6", "0", "7", "1", "5", "4", "3"], "shuf_sents": ["To address limited memory constraints on GPUs , we propose a novel data partitioning scheme that effectively reduces the memory cost .", "We use data streaming to handle extremely large datasets .", "The recent emergence of Graphics Processing Units ( GPUs ) as general-purpose parallel computing devices provides us with new opportunities to develop scalable learning methods for massive data .", "Furthermore , they can be used as general techniques to parallelize other machine learning models .", "The proposed partitioning scheme and data streaming make our approach scalable with more multiprocessors .", "Extensive experiments showed that our parallel inference methods consistently produced LDA models with the same predictive power as sequential training methods did but with 26x speedup for CGS and 196x speedup for CVB on a GPU with 30 multiprocessors .", "In this work , we consider the problem of parallelizing two inference methods on GPUs for latent Dirichlet Allocation ( LDA ) models , collapsed Gibbs sampling ( CGS ) and collapsed variational Bayesian ( CVB ) .", "This partitioning scheme also balances the computational cost on each multiprocessor and enables us to easily avoid memory access conflicts ."]}
{"orig_sents": ["1", "2", "3", "7", "0", "5", "8", "10", "6", "9", "4"], "shuf_sents": ["For example , a rank-one scanning-window classifier yields a separable filter .", "We describe an algorithm for learning bilinear SVMs .", "Bilinear classifiers are a discriminative variant of bilinear models , which capture the dependence of data on multiple factors .", "Such models are particularly appropriate for visual data that is better represented as a matrix or tensor , rather than a vector .", "We demonstrate bilinear SVMs on difficult problems of people detection in video sequences and action classification of video sequences , achieving state-of-the-art results in both .", "Low-rank models have fewer parameters and so are easier to regularize and faster to score at run-time .", "Bilinear classifiers are trained with biconvex programs .", "Matrix encodings allow for more natural regularization through rank restriction .", "We learn low-rank models with bilinear classifiers .", "Such programs are optimized with coordinate descent , where each coordinate step requires solving a convex program - in our case , we use a standard off-the-shelf SVM solver .", "We also use bilinear classifiers for transfer learning by sharing linear factors between different classification tasks ."]}
{"orig_sents": ["4", "2", "7", "0", "3", "5", "6", "1"], "shuf_sents": ["In this paper , we propose a number of empirical tests that directly measure the degree to which these learned features are invariant to different input transformations .", "Our evaluation metrics can also be used to evaluate future work in deep learning , and thus help the development of future algorithms .", "Recently , deep architectures trained in an unsupervised manner have been proposed as an automatic method for extracting useful features .", "We find that stacked autoencoders learn modestly increasingly invariant features with depth when trained on natural images .", "For many pattern recognition tasks , the ideal input feature would be invariant to multiple confounding properties ( such as illumination and viewing angle , in computer vision applications ) .", "We find that convolutional deep belief networks learn substantially more invariant features in each layer .", "These results further justify the use of `` deep '' vs. `` shallower '' representations , but suggest that mechanisms beyond merely stacking one autoencoder on top of another may be important for achieving invariance .", "However , it is difficult to evaluate the learned features by any means other than using them in a classifier ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["The operators are based on matrix exponentials , which are the solution to a system of first-order linear differential equations .", "The method is applied to recover topological structure from low dimensional synthetic data , and to model local structure in how natural images change over time and scale .", "The matrix exponents are represented by a basis that is adapted to the statistics of the data so that the infinitesimal generator for a trajectory along the underlying manifold can be produced by linearly composing a few elements .", "We describe an unsupervised manifold learning algorithm that represents a surface through a compact description of operators that traverse it ."]}
{"orig_sents": ["3", "0", "2", "1", "4"], "shuf_sents": ["The model is trained using execution traces of passing test runs ; it reflects the distribution over transitional patterns of code positions .", "The model is designed such that Bayesian inference has a closed-form solution .", "Given a failing test case , the model determines the least likely transitional pattern in the execution trace .", "We devise a graphical model that supports the process of debugging software by guiding developers to code that is likely to contain defects .", "We evaluate the Bernoulli graph model on data of the software projects AspectJ and Rhino ."]}
{"orig_sents": ["2", "8", "4", "7", "6", "1", "9", "5", "3", "0"], "shuf_sents": ["We demonstrate the potential of the proposed framework in experiments with synthetic and natural datasets .", "Furthermore , the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity , such as 1 .", "We describe , analyze , and experiment with a new framework for empirical loss minimization with regularization .", "We further extend the algorithms and give efficient implementations for very high-dimensional data with sparsity .", "On each iteration we first perform an unconstrained gradient descent step .", "We also show how to construct efficient algorithms for mixed-norm 1 /q regularization .", "This yields a simple yet effective algorithm for both batch penalized risk minimization and online learning .", "We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the first phase .", "Our algorithmic framework alternates between two phases .", "We derive concrete and very simple algorithms for minimization of loss functions with 1 , 2 , 22 , and regularization ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["Here , we consider an approximate model of linear and non-linear correlations between the responses of spatially distributed Gaborlike receptive fields , which , when trained on an ensemble of natural scenes , unifies a range of spatial context effects .", "However , these accounts are based on an incomplete view of the visual context surrounding each point .", "Simple versions of this lead to Gabor-like receptive fields and divisive gain modulation from local surrounds ; these have led to influential neural and psychological models of visual processing .", "A central hypothesis about early visual processing is that it represents inputs in a coordinate system matched to the statistics of natural scenes .", "The full model accounts for neural surround data in primary visual cortex ( V1 ) , provides a statistical foundation for perceptual phenomena associated with Li 's ( 2002 ) hypothesis that V1 builds a saliency map , and fits data on the tilt illusion ."]}
{"orig_sents": ["3", "2", "4", "0", "1"], "shuf_sents": ["In this paper we tie the two approaches , and design an investment strategy which is universal in the worst-case , and yet capable of exploiting the mostly valid GBM model .", "Our method is based on new and improved regret bounds for online convex optimization with exp-concave loss functions .", "While often an acceptable approximation , the GBM model is not always valid empirically .", "In practice , most investing is done assuming a probabilistic model of stock price returns known as the Geometric Brownian Motion ( GBM ) .", "This motivates a worst-case approach to investing , called universal portfolio management , where the objective is to maximize wealth relative to the wealth earned by the best fixed portfolio in hindsight ."]}
{"orig_sents": ["0", "2", "1", "3", "4"], "shuf_sents": ["Several key computational bottlenecks in machine learning involve pairwise distance computations , including all-nearest-neighbors ( finding the nearest neighbor ( s ) for each point , e.g .", "in kernel density estimation or kernel machines ) .", "in manifold learning ) and kernel summations ( e.g .", "We consider the general , bichromatic case for these problems , in addition to the scientific problem of N-body simulation .", "In this paper we show for the first time O ( ) worst case runtimes for practical algorithms for these problems based on the cover tree data structure ."]}
{"orig_sents": ["1", "4", "3", "5", "0", "2"], "shuf_sents": ["Multivariate information analysis is able to find strong information sharing between PPA and RSC , consistent with existing neuroscience studies on scenes .", "In this study , we present a new method for establishing fMRI pattern-based functional connectivity between brain regions by estimating their multivariate mutual information .", "Furthermore , an exploratory whole-brain analysis uncovered other brain regions that share information with the PPA-RSC scene network .", "We also show that selecting voxels based on the multivariate mutual information of local activity patterns with respect to ground truth labels leads to higher decoding accuracy than established voxel selection methods .", "Recent advances in the numerical approximation of highdimensional probability distributions allow us to successfully estimate mutual information from scarce fMRI data .", "We validate our approach with a 6-way scene categorization fMRI experiment ."]}
{"orig_sents": ["5", "8", "4", "7", "1", "2", "6", "10", "9", "0", "3"], "shuf_sents": ["We explore and compare their computational behavior ( space and time ) and detection performance as a function of the number of learned object classes on several recognition datasets .", "In this paper , we provide a rigorous experimental analysis of various multiple object class learning strategies within a generative hierarchical framework .", "Specifically , we propose , evaluate and compare three important types of multi-class learning : 1 . )", "We show that sequential training achieves the best trade-off between inference and training times at a comparable detection performance and could thus be used to learn the classes on a larger scale .", "Conveniently , sequential class learning cuts down training time by transferring existing knowledge to novel classes , but can not fully exploit the shareability of features among object classes and might depend on ordering of classes during learning .", "Multi-class object learning and detection is a challenging problem due to the large number of object classes and their high visual variability .", "independent training of individual categories , 2 . )", "In hierarchical frameworks these issues have been little explored .", "Specialized detectors usually excel in performance , while joint representations optimize sharing and reduce inference time -- but are complex to train .", "sequential learning of classes .", "joint training of classes , and 3 . )"]}
{"orig_sents": ["3", "4", "1", "2", "0"], "shuf_sents": ["Second , experiments with our approach on a challenging problem ( the game of Tetris ) show that the approach outperforms the existing LP approach ( which has previously been shown to be competitive with several ADP algorithms ) by an order of magnitude .", "Our program - the `smoothed approximate linear program ' - relaxes this restriction in an appropriate fashion while remaining computationally tractable .", "Doing so appears to have several advantages : First , we demonstrate superior bounds on the quality of approximation to the optimal cost-to-go function afforded by our approach .", "We present a novel linear program for the approximation of the dynamic programming cost-to-go function in high-dimensional stochastic control problems .", "LP approaches to approximate DP naturally restrict attention to approximations that are lower bounds to the optimal cost-to-go function ."]}
{"orig_sents": ["1", "6", "8", "7", "5", "2", "4", "3", "0"], "shuf_sents": ["Our method outperforms the state-of-the-art structure learning techniques for Gaussian graphical models both for small and large datasets .", "Locality information is crucial in datasets where each variable corresponds to a measurement in a manifold ( silhouettes , motion trajectories , 2D and 3D images ) .", "Second , we propose an efficient algorithm which decomposes the strictly convex maximum likelihood estimation into a sequence of problems with closed form solutions .", "We also test the generalization performance of our method in a wide range of complex real-world datasets and demonstrate that it captures useful structures such as the rotation and shrinking of a beating heart , motion correlations between body parts during walking and functional interactions of brain regions .", "Through synthetic experiments , we evaluate the closeness of the recovered models to the ground truth .", "Hence , in this paper we first propose a new class of Gaussian graphical models which , together with sparseness , imposes local constancy through 1 -norm penalization .", "Although these datasets are typically under-sampled and high-dimensional , they often need to be represented with low-complexity statistical models , which are comprised of only the important probabilistic dependencies in the datasets .", "However , sparseness can not describe inherent regularities in the structure .", "Most methods attempt to reduce model complexity by enforcing structure sparseness ."]}
{"orig_sents": ["6", "2", "4", "7", "5", "1", "8", "0", "3"], "shuf_sents": ["Using the IPDF framework , we show that many current techniques are simple variations of each other .", "The framework uses inner products between the parameter vectors of GMM models motivated by several statistical methods .", "Speaker comparison can be placed in a geometric framework by casting the problem as a model comparison process .", "We demonstrate , on a 2006 NIST speaker recognition evaluation task , new scoring methods using IPDFs which produce excellent error rates and require significantly less computation than current techniques .", "For a given speech signal , feature vectors are produced and used to adapt a Gaussian mixture model ( GMM ) .", "We propose a framework , inner product discriminant functions ( IPDFs ) , which extends many common techniques for speaker comparison -- support vector machines , joint factor analysis , and linear scoring .", "Speaker comparison , the process of finding the speaker similarity between two speech signals , occupies a central role in a variety of applications -- speaker verification , clustering , and identification .", "Speaker comparison can then be viewed as the process of compensating and finding metrics on the space of adapted models .", "Compensation of nuisances is performed via linear transforms on GMM parameter vectors ."]}
{"orig_sents": ["1", "4", "3", "2", "0"], "shuf_sents": ["Experimental results on a collection of benchmark datasets validate the effectiveness of the optimal discriminant clustering algorithm .", "We are often interested in casting classification and clustering problems as a regression framework , because it is feasible to achieve some statistical properties in this framework by imposing some penalty criteria .", "We associate our algorithm with the existing unsupervised learning algorithms such as spectral clustering , discriminative clustering and sparse principal component analysis .", "In particular , we devise a novel clustering algorithm that we call optimal discriminant clustering .", "In this paper we illustrate optimal scoring , which was originally proposed for performing the Fisher linear discriminant analysis by regression , in the application of unsupervised learning ."]}
{"orig_sents": ["1", "0", "5", "4", "2", "7", "6", "3"], "shuf_sents": ["Conventional single incremental decremental SVM can update the trained model efficiently when single data point is added to or removed from the training set .", "We propose a multiple incremental decremental algorithm of Support Vector Machine ( SVM ) .", "The single incremental decremental algorithm is built on an optimization technique called parametric programming .", "Our approach is especially useful for online SVM learning in which we need to remove old data points and add new data points in a short amount of time .", "The proposed algorithm is computationally more efficient when multiple data points are added and/or removed simultaneously .", "When we add and/or remove multiple data points , this algorithm is time-consuming because we need to repeatedly apply it to each data point .", "Experimental results on synthetic and real data sets indicate that the proposed algorithm can significantly reduce the computational cost of multiple incremental decremental operation .", "We extend the idea and introduce multi-parametric programming for developing the proposed algorithm ."]}
{"orig_sents": ["5", "1", "2", "4", "3", "0"], "shuf_sents": ["The results suggest that the proposed model can outperform the state-of-the-art reconstruction systems .", "The spatial and temporal structure is modeled by using Gaussian process priors both for the loading matrix and the factors .", "The posterior distributions are approximated using the variational Bayesian framework .", "The model is used to compute the reconstructions of the global sea surface temperatures from a historical dataset .", "High computational cost of Gaussian process modeling is reduced by using sparse approximations .", "We present a probabilistic factor analysis model which can be used for studying spatio-temporal datasets ."]}
{"orig_sents": ["5", "3", "2", "1", "4", "0"], "shuf_sents": ["We compare our approach to a variational approximation and a Markov chain Monte Carlo scheme , which utilize the commonly used scale mixture representation of the Student-t distribution .", "The problem , however , is the analytically intractable inference .", "A robust observation model , such as the Student-t distribution , reduces the influence of outlying observations and improves the predictions .", "However , the drawback is that the predictive accuracy of the model can be significantly compromised if the observations are contaminated by outliers .", "In this work , we discuss the properties of a Gaussian process regression model with the Student-t likelihood and utilize the Laplace approximation for approximate inference .", "In the Gaussian process regression the observation model is commonly assumed to be Gaussian , which is convenient in computational perspective ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We model this problem as one of adaptively pruning a known decision tree , but with additional challenges : ( 1 ) severe space requirements , since the underlying decision tree has over 4 billion leaves , and ( 2 ) a changing target function , since malicious activity on the Internet is dynamic .", "We formulate and address the problem of discovering dynamic malicious regions on the Internet .", "We prove guarantees on our algorithm 's performance as a function of the best possible pruning of a similar size , and our experiments show that our algorithm achieves high accuracy on large real-world data sets , with significant improvements over existing approaches .", "We present a novel algorithm that addresses this problem , by putting together a number of different `` experts '' algorithms and online paging algorithms ."]}
{"orig_sents": ["3", "4", "2", "0", "5", "1"], "shuf_sents": ["We model transparent local patch appearance using an additive model of latent factors : background factors due to scene content , and factors which capture a local edge energy distribution characteristic of the refraction .", "No knowledge of the background scene is required at test time ; we show examples recognizing transparent glasses in a domestic environment .", "The appearance of a transparent patch is determined in part by the refraction of a background pattern through a transparent medium : the energy from the background usually dominates the patch appearance .", "Existing methods for visual recognition based on quantized local features can perform poorly when local features exist on transparent surfaces , such as glass or plastic objects .", "There are characteristic patterns to the local appearance of transparent objects , but they may not be well captured by distances to individual examples or by a local pattern codebook obtained by vector quantization .", "We implement our method using a novel LDA-SIFT formulation which performs LDA prior to any vector quantization step ; we discover latent topics which are characteristic of particular transparent patches and quantize the SIFT space into transparent visual words according to the latent topic dimensions ."]}
{"orig_sents": ["10", "2", "0", "6", "5", "9", "7", "1", "4", "3", "8"], "shuf_sents": ["However , it is well known that off-policy sampling , as well as nonlinear function approximation , can cause these algorithms to become unstable ( i.e. , the parameters of the approximator may diverge ) .", "We present a Bellman error objective function and two gradient-descent TD algorithms that optimize it .", "Conventional temporal-difference ( TD ) methods , such as TD ( ) , Q-learning and Sarsa have been used successfully with function approximation in many applications .", "The algorithms are incremental and the computational complexity per time step scales linearly with the number of parameters of the approximator .", "We prove the asymptotic almost-sure convergence of both algorithms , for any finite Markov decision process and any smooth value function approximator , to a locally optimal solution .", "( 2009a , 2009b ) solved the problem of off-policy learning with linear TD algorithms by introducing a new objective function , related to the Bellman error , and algorithms that perform stochastic gradient-descent on this function .", "Sutton et al .", "We generalize this work to nonlinear function approximation .", "Empirical results obtained in the game of Go demonstrate the algorithms ' effectiveness .", "These methods can be viewed as natural generalizations to previous TD methods , as they converge to the same limit points when used with linear function approximation methods .", "We introduce the first temporal-difference learning algorithms that converge with smooth value function approximators , such as neural networks ."]}
{"orig_sents": ["3", "0", "4", "2", "1", "5"], "shuf_sents": ["We present a randomized iterative algorithm based on simple local updates .", "MRF graph with polynomial growth ) with the approximation error depending on ( in a reasonable manner ) the geometric growth rate of the graph and the average radius of the local neighborhood - this allows for a graceful tradeoff between the complexity of the algorithm and the approximation error .", "Somewhat surprisingly , we show that this algorithm finds a near optimal assignment within n log 2 n iterations with high probability for any n node pair-wise MRF with geometry ( i.e .", "We consider the question of computing Maximum A Posteriori ( MAP ) assignment in an arbitrary pair-wise Markov Random Field ( MRF ) .", "The algorithm , starting with an arbitrary initial assignment , updates it in each iteration by first , picking a random node , then selecting an ( appropriately chosen ) random local neighborhood and optimizing over this local neighborhood .", "Through extensive simulations , we show that our algorithm finds extremely good approximate solutions for various kinds of MRFs with geometry ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["By combining our results with classic univariate inequalities , we provide new worst-case analyses for natural risk criteria arising in classification , optimization , portfolio selection and Markov decision processes .", "We further extend this property to distribution families that respect additional constraints , such as symmetry , unimodality and log-concavity .", "Surjectivity of linear projections between distribution families with fixed mean and covariance ( regardless of dimension ) is re-derived by a new proof ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["We provide a clustering algorithm that approximately optimizes the k-means objective , in the one-pass streaming setting .", "Empirical evaluations on real and simulated data reveal the practical utility of our method .", "The two main ingredients of our theoretical work are : a derivation of an extremely simple pseudo-approximation batch algorithm for k-means ( based on the recent k-means++ ) , in which the algorithm is allowed to output more than k centers , and a streaming clustering algorithm in which batch clustering algorithms are performed on small inputs ( fitting in memory ) and combined in a hierarchical manner .", "We make no assumptions about the data , and our algorithm is very light-weight in terms of memory , and computation .", "This setting is applicable to unsupervised learning on massive data sets , or resource-constrained devices ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["In this article , we propose fast subtree kernels on graphs .", "On graphs with n nodes and m edges and maximum degree d , these kernels comparing subtrees of height h can be computed in O ( mh ) , whereas the classic subtree kernel by Ramon & Gartner scales as O ( n2 4d h ) .", "Our fast subtree kernels can deal with labeled graphs , scale up easily to large graphs and outperform state-of-the-art graph kernels on several classification benchmark datasets in terms of accuracy and runtime .", "Key to this efficiency is the observation that the Weisfeiler-Lehman test of isomorphism from graph theory elegantly computes a subtree kernel as a byproduct ."]}
{"orig_sents": ["0", "5", "3", "2", "6", "1", "4"], "shuf_sents": ["A fundamental objective in reinforcement learning is the maintenance of a proper balance between exploration and exploitation .", "Theoretical guarantees are provided concerning the optimality of the balancing of exploration and exploitation .", "The method subsumes traditional exploration , in which the agent takes actions to gather information about the environment , and active learning , in which the agent queries an oracle for optimal actions ( with an associated cost for employing the oracle ) .", "In this paper we propose a dual-policy method for jointly learning the agent behavior and the balance between exploration exploitation , in partially observable environments .", "The effectiveness of the method is demonstrated by experimental results on benchmark problems .", "This problem becomes more challenging when the agent can only partially observe the states of its environment .", "The form of the employed exploration is dictated by the specific problem ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective .", "Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems .", "In this paper , we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences ( high-order features ) , as long as the number of distinct label sequences used in the features is small .", "However , only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account .", "This leads to efficient learning algorithms for these conditional random fields ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["To support this proposal we present behavioral results from a concept learning study inspired by the work of Shepard , Hovland and Jenkins .", "As yet , however , there are few concrete proposals about the nature of this language .", "Many researchers have suggested that the psychological complexity of a concept is related to the length of its representation in a language of thought .", "This paper makes one such proposal : the language of thought allows first order quantification ( quantification over objects ) more readily than second-order quantification ( quantification over features ) ."]}
{"orig_sents": ["0", "4", "5", "1", "2", "3"], "shuf_sents": ["Regularized risk minimization often involves non-smooth optimization , either because of the loss function ( e.g. , hinge loss ) or the regularizer ( e.g. , 1 -regularizer ) .", "The proposed algorithm , called SAGE ( Stochastic Accelerated GradiEnt ) , exhibits fast convergence rates on stochastic composite optimization with convex or strongly convex objectives .", "Experimental results show that SAGE is faster than recent ( sub ) gradient methods including FOLOS , SMIDAS and SCD .", "Moreover , SAGE can also be extended for online learning , resulting in a simple algorithm but with the best regret bounds currently known for these problems .", "Gradient methods , though highly scalable and easy to implement , are known to converge slowly .", "In this paper , we develop a novel accelerated gradient method for stochastic optimization while still preserving their computational simplicity and scalability ."]}
{"orig_sents": ["3", "5", "1", "2", "4", "0"], "shuf_sents": ["We show that under some noise condition , if the Bayesian classification boundary and the underlying distribution are smooth to a finite order , active learning achieves polynomial improvement in the label complexity ; if the boundary and the distribution are infinitely smooth , the improvement is exponential .", "Previous works have shown that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space .", "Although there are many cases on which active learning is very useful , it is also easy to construct examples that no active learning algorithm can have advantage .", "We study pool-based active learning in the presence of noise , i.e .", "In this paper , we propose intuitively reasonable sufficient conditions under which agnostic active learning algorithm is strictly superior to passive supervised learning .", "the agnostic setting ."]}
{"orig_sents": ["2", "3", "1", "4", "0"], "shuf_sents": ["More precisely , this phenomenon appears to be related to the Ising model phase transition ( although it does not coincide with it ) .", "While several methods have been proposed to accomplish this task , their relative merits and limitations remain somewhat obscure .", "We consider the problem of learning the structure of Ising models ( pairwise binary Markov random fields ) from i.i.d .", "samples .", "By analyzing a number of concrete examples , we show that low-complexity algorithms systematically fail when the Markov random field develops long-range correlations ."]}
{"orig_sents": ["2", "5", "1", "0", "8", "4", "7", "9", "6", "3"], "shuf_sents": ["chairs ) .", "Model topologies are learned across groups of images , and one or more such topologies is linked to an object category ( e.g .", "We present an approach for learning stochastic geometric models of object categories from single view images .", "Experiments on images of furniture objects such as tables and chairs suggest that this is an effective approach for learning models that encode simple representations of category geometry and the statistics thereof , and support inferring both category and geometry on held out single view images .", "The latter goes beyond labeling objects , as it provides the geometric structure of particular instances .", "We focus here on models expressible as a spatially contiguous assemblage of blocks .", "We use trans-dimensional sampling to explore topology hypotheses , and alternate between Metropolis-Hastings and stochastic dynamics to explore instance parameters .", "We learn the models using joint statistical inference over category parameters , camera parameters , and instance parameters .", "Fitting learned topologies to an image can be used to identify the object class , as well as detail its geometry .", "These produce an image likelihood through a statistical imaging model ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We show that standard p -regularized objective functions currently used , such as ridge regression and p -regularized boosting , are obtained from a relaxation of the KL divergence between the quasi uniform posterior and the uniform prior .", "By restricting ourselves to a class of posteriors , that we call quasi uniform , we propose a simple coordinate descent learning algorithm to minimize the proposed KL-regularized cost function .", "We show that convex KL-regularized objective functions are obtained from a PAC-Bayes risk bound when using convex loss functions for the stochastic Gibbs classifier that upper-bound the standard zero-one loss used for the weighted majority vote .", "We present numerical experiments where the proposed learning algorithm generally outperforms ridge regression and AdaBoost ."]}
{"orig_sents": ["3", "1", "4", "5", "2", "0"], "shuf_sents": ["We evaluate the methods against Expectation-Maximization in a real problem of motion segmentation from video data .", "Although our relaxation involves a semidefinite matrix variable , we reformulate the problem to eliminate the need for general semidefinite programming .", "The second is a min-min reformulation consisting of fast alternating steps of closed-form updates .", "We develop a convex relaxation of maximum a posteriori estimation of a mixture of regression models .", "In particular , we provide two reformulations that admit fast algorithms .", "The first is a max-min spectral reformulation exploiting quasi-Newton descent ."]}
{"orig_sents": ["5", "2", "4", "3", "1", "0"], "shuf_sents": ["The results of these experiments suggest that our method can offer improvements in stability and accuracy over existing methods , and at a comparable cost .", "We conduct experiments on a difficult inference problem in population genetics , a problem that is related to inference for LDA .", "Our framework adopts the methodology of variational inference , but unlike existing variational methods such as mean field and expectation propagation it is not restricted to tractable classes of approximating distributions .", "Significantly , our framework offers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation .", "Our approach can also be viewed as a `` population-based '' sequential Monte Carlo ( SMC ) method , but unlike existing SMC methods there is no need to design the artificial sequence of distributions .", "We describe a new algorithmic framework for inference in probabilistic models , and apply it to inference for latent Dirichlet allocation ( LDA ) ."]}
{"orig_sents": ["4", "2", "1", "3", "0"], "shuf_sents": ["We also state and prove robustness guarantees for this method in the form of regret transform bounds ( in general ) , and also provide a more detailed analysis for the linear prediction setting .", "The method can be regarded as a simple reduction from multi-label regression problems to binary regression problems .", "We develop a general theory for a variant of the popular error correcting output code scheme , using ideas from compressed sensing for exploiting this sparsity .", "We show that the number of subproblems need only be logarithmic in the total number of possible labels , making this approach radically more efficient than others .", "We consider multi-label prediction problems with large output spaces under the assumption of output sparsity - that the target ( label ) vectors have small support ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Solving multi-agent reinforcement learning problems has proven difficult because of the lack of tractable algorithms .", "We provide the first approximation algorithm which solves stochastic games with cheap-talk to within absolute error of the optimal game-theoretic solution , in time polynomial in 1/ .", "Further , we empirically validate our algorithm and find the computational cost to be orders of magnitude less than what the theory predicts .", "Our algorithm extends Murray 's and Gordon 's ( 2007 ) modified Bellman equation which determines the set of all possible achievable utilities ; this provides us a truly general framework for multi-agent learning ."]}
{"orig_sents": ["1", "5", "4", "2", "3", "0"], "shuf_sents": ["We conclude with empirical results demonstrating the behavior predicted by our theory .", "Kernel density estimation is the most widely-used practical method for accurate nonparametric density estimation .", "We propose a small modification to kernel density estimation for estimating probability density functions on Riemannian submanifolds of Euclidean space .", "Using ideas from Riemannian geometry , we prove the consistency of this modified estimator and show that the convergence rate is determined by the intrinsic dimension of the submanifold .", "In practice , it has been recognized that often such data have a much lower-dimensional intrinsic structure .", "However , long-standing worst-case theoretical results showing that its performance worsens exponentially with the dimension of the data have quashed its application to modern high-dimensional datasets for decades ."]}
{"orig_sents": ["4", "2", "5", "6", "1", "0", "3"], "shuf_sents": ["Our third contribution is a hybrid method combining the complementary strengths of NF and SLS .", "This graph proposal method , which we call `` Neighborhood Fusion '' ( NF ) , samples candidate Markov blankets at each node using sparse regression techniques .", "Our first contribution is to show how to efficiently compute a BIC or Laplace approximation to the marginal likelihood of non-decomposable graphs using convex methods for precision matrix estimation .", "Experimental results in structural recovery and prediction tasks demonstrate that NF and hybrid NF/SLS out-perform state-of-the-art local search methods , on both synthetic and real-world datasets , when realistic computational limits are imposed .", "We make several contributions in accelerating approximate Bayesian structural inference for non-decomposable GGMs .", "This optimization technique can be used as a fast scoring function inside standard Stochastic Local Search ( SLS ) for generating posterior samples .", "Our second contribution is a novel framework for efficiently generating large sets of high-quality graph topologies without performing local search ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["We find that many human performance phenomena , measured through novel behavioral experiments , are naturally produced by the operation of our ideal observer model ( a Rao-Blackwelized particle filter ) .", "Multiple object tracking is a task commonly used to investigate the architecture of human visual attention .", "Human participants show a distinctive pattern of successes and failures in tracking experiments that is often attributed to limits on an object system , a tracking module , or other specialized cognitive structures .", "The tradeoff between the speed and number of objects being tracked , however , can only arise from the allocation of a flexible cognitive resource , which can be formalized as either memory or attention .", "Here we use a computational analysis of the task of object tracking to ask which human failures arise from cognitive limitations and which are consequences of inevitable perceptual uncertainty in the tracking task ."]}
{"orig_sents": ["2", "1", "4", "3", "5", "0"], "shuf_sents": ["The improved performance of the proposed algorithm is demonstrated on the problem of MIMO detection .", "The factor graph that corresponds to this problem is very loopy ; in fact , it is a complete graph .", "This paper proposes a new algorithm for the linear least squares problem where the unknown variables are constrained to be in a finite set .", "The algorithm described here is based on an optimal tree approximation of the Gaussian density of the unconstrained linear system .", "Hence , applying the Belief Propagation ( BP ) algorithm yields very poor results .", "It is shown that even though the approximation is not directly applied to the exact discrete distribution , applying the BP algorithm to the modified factor graph outperforms current methods in terms of both performance and complexity ."]}
{"orig_sents": ["0", "2", "3", "1", "5", "4"], "shuf_sents": ["A score function induced by a generative model of the data can provide a feature vector of a fixed dimension for each data sample .", "In this paper , we present a novel score space that exploits the free energy associated with a generative model .", "Data samples themselves may be of differing lengths ( e.g. , speech segments , or other sequence data ) , but as a score function is based on the properties of the data generation process , it produces a fixed-length vector in a highly informative space , typically referred to as a `` score space '' .", "Discriminative classifiers have been shown to achieve higher performance in appropriately chosen score spaces than is achievable by either the corresponding generative likelihood-based classifiers , or the discriminative classifiers using standard feature extractors .", "We also show that in several typical vision and computational biology applications the classifiers optimized in FESS outperform the corresponding pure generative approaches , as well as a number of previous approaches to combining discriminating and generative models .", "The resulting free energy score space ( FESS ) takes into account latent structure of the data at various levels , and can be trivially shown to lead to classification performance that at least matches the performance of the free energy classifier based on the same generative model , and the same factorization of the posterior ."]}
{"orig_sents": ["0", "3", "5", "1", "2", "6", "4"], "shuf_sents": ["Second-order maximum-entropy models have recently gained much interest for describing the statistics of binary spike trains .", "This model has the same computational complexity as pure binary models and fitting it to data is a convex problem .", "We show that the model can be seen as an extension to the classical spike-triggered average/covariance analysis and can be used as a non-linear method for extracting features which a neural population is sensitive to .", "Here , we extend this approach to take continuous stimuli into account as well .", "Therefore , extending the framework of maximum-entropy models to continuous variables allows us to gain novel insights into the relationship between the firing patterns of neural ensembles and the stimuli they are processing .", "By constraining the joint secondorder statistics , we obtain a joint Gaussian-Boltzmann distribution of continuous stimuli and binary neural firing patterns , for which we also compute marginal and conditional distributions .", "Further , by calculating the posterior distribution of stimuli given an observed neural response , the model can be used to decode stimuli and yields a natural spike-train metric ."]}
{"orig_sents": ["4", "6", "0", "2", "5", "1", "3"], "shuf_sents": ["However , because of limitations in the design and parameterization of the jump function , these samplingbased methods suffer from local minima -- the system must transition through lower-scoring configurations before arriving at a better MAP solution .", "Our method allows efficient gradient updates since only factors in the neighborhood of variables affected by an action need to be computed -- we bypass the need to compute marginals entirely .", "This paper presents a new method of explicitly selecting fruitful downward jumps by leveraging reinforcement learning ( RL ) .", "Our method yields dramatic empirical success , producing new state-of-the-art results on a complex joint model of ontology alignment , with a 48 % reduction in error over state-of-the-art in that domain .", "Large , relational factor graphs with structure defined by first-order logic or other languages give rise to notoriously difficult inference problems .", "Rather than setting parameters to maximize the likelihood of the training data , parameters of the factor graph are treated as a log-linear function approximator and learned with methods of temporal difference ( TD ) ; MAP inference is performed by executing the resulting policy on held out test data .", "Because unrolling the structure necessary to represent distributions over all hypotheses has exponential blow-up , solutions are often derived from MCMC ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["Here we extend the latent factor model framework to two or more unbounded layers of latent factors .", "The Indian Buffet Process is a Bayesian nonparametric approach that models objects as arising from an infinite number of latent factors .", "From a generative perspective , each layer defines a conditional factorial prior distribution over the binary latent variables of the layer below via a noisy-or mechanism .", "We explore the properties of the model with two empirical studies , one digit recognition task and one music tag data experiment ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["We propose a new model for natural image statistics .", "We observe that after learning , these pairs of filters are predominantly of similar orientations but different phases , so their joint energy resembles models of complex cells .", "Instead of minimizing dependency between components of natural images , we maximize a simple form of dependency in the form of tree-dependencies .", "Calculating the likelihood of an image patch using our model requires estimating the squared output of pairs of filters connected in the tree .", "By learning filters and tree structures which are best suited for natural images we observe that the resulting filters are edge filters , similar to the famous ICA on natural images results ."]}
{"orig_sents": ["4", "0", "1", "3", "5", "2"], "shuf_sents": ["In the sparse topic model ( sparseTM ) , each topic is represented by a bank of selector variables that determine which terms appear in the topic .", "Thus each topic is associated with a subset of the vocabulary , and topic smoothness is modeled on this subset .", "Compared to traditional approaches , the empirical results will show that sparseTMs give better predictive performance with simpler inferred models .", "We develop an efficient Gibbs sampler for the sparseTM that includes a general-purpose method for sampling from a Dirichlet mixture with a combinatorial number of components .", "We present a nonparametric hierarchical Bayesian model of document collections that decouples sparsity and smoothness in the component distributions ( i.e. , the `` topics '' ) .", "We demonstrate the sparseTM on four real-world datasets ."]}
{"orig_sents": ["1", "0", "5", "3", "2", "4", "6"], "shuf_sents": ["In this paper , we investigate sparsistent learning of a sub-family of this model -- piecewise constant VCVS models .", "To estimate the changing structure of a varying-coefficient varying-structure ( VCVS ) model remains an important and open problem in dynamic system modelling , which includes learning trajectories of stock prices , or uncovering the topology of an evolving gene network .", "We provide an asymptotic analysis of the procedure , showing that with the increasing sample size , number of structural changes , and number of variables , the true model can be consistently selected .", "We propose a two-stage adaptive procedure , which first identifies jump points of structural changes and then identifies relevant covariates to a response on each of the segments .", "We demonstrate the performance of the method on synthetic data and apply it to the brain computer interface dataset .", "We analyze two main issues in this problem : inferring time points where structural changes occur and estimating model structure ( i.e. , model selection ) on each of the constant segments .", "We also consider how this applies to structure estimation of time-varying probabilistic graphical models ."]}
{"orig_sents": ["0", "3", "6", "5", "4", "2", "1"], "shuf_sents": ["The method of common spatio-spectral patterns ( CSSPs ) is an extension of common spatial patterns ( CSPs ) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram ( EEG ) classification .", "The experimental results show that our method significantly outperforms the previous multi-class CSPs ( MCSPs ) methods in the EEG classification .", "To demonstrate the effectiveness of the proposed method , we conduct extensive experiments on the BCI competition 2005 data set .", "Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classification , this method is only suitable for two-class EEG classification problems .", "By minimizing the estimated closed-form Bayes error , we obtain the optimal spatio-spectral filters of MCSSPs .", "To this end , we first develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs ( MCSSPs ) method based on this Bayes error theoretical framework .", "In this paper , we generalize the two-class CSSPs method to multi-class cases ."]}
{"orig_sents": ["7", "2", "5", "6", "4", "1", "3", "0"], "shuf_sents": ["The results of a numerical experiment are eventually displayed in order to show the efficiency of the method .", "The last step amounts to performing a standard Mann-Whitney Wilcoxon test in the onedimensional framework .", "The latter problem has recently received much attention in the statistical learning literature .", "We show that the learning step of the procedure does not affect the consistency of the test as well as its properties in terms of power , provided the ranking produced is accurate enough in the AUC sense .", "Data from the remaining half-sample are then projected onto the real line and eventually ranked according to the scoring function computed at the first stage .", "From the elementary observation that , in the two-sample problem setup , the null assumption corresponds to the situation where the area under the optimal ROC curve is equal to 1/2 , we propose a two-stage testing method based on data splitting .", "A nearly optimal scoring function in the AUC sense is first learnt from one of the two half-samples .", "The purpose of the paper is to explore the connection between multivariate homogeneity tests and AUC optimization ."]}
{"orig_sents": ["3", "1", "4", "0", "6", "2", "5"], "shuf_sents": ["To this end , we construct a copula that allows to keep the spike counts uncorrelated while varying their dependence strength .", "Here , we show that the correlation coefficient is in general insufficient to characterize these dependencies .", "We find that the entropy of uncorrelated but dependent spike count distributions can deviate from the corresponding distribution with independent components by more than 25 % and that weakly correlated but strongly dependent spike counts are very likely to occur in biological networks .", "The linear correlation coefficient is typically used to characterize and analyze dependencies of neural spike counts .", "We construct two neuron spike count models with Poisson-like marginals and vary their dependence structure using copulas .", "Finally , we introduce a test for deciding whether the dependence structure of distributions with Poissonlike marginals is well characterized by the linear correlation coefficient and verify it for different copula-based models .", "Moreover , we employ a network of leaky integrate-and-fire neurons to investigate whether weakly correlated spike counts with strong dependencies are likely to occur in real networks ."]}
{"orig_sents": ["5", "0", "2", "4", "6", "1", "3", "7"], "shuf_sents": ["Random-walk based kernels are shown to have some non-trivial properties : within the standard approximation of a locally tree-like graph structure , the kernel does not become constant , i.e .", "Our main subject are learning curves of Bayes error versus training set size .", "neighbouring function values do not become fully correlated , when the lengthscale of the kernel is made large .", "We show that these are qualitatively well predicted by a simple approximation using only the spectrum of a large tree as input , and generically scale with n/V , the number of training examples per vertex .", "Instead the kernel attains a non-trivial limiting form , which we calculate .", "We investigate how well Gaussian process regression can learn functions defined on graphs , using large regular random graphs as a paradigmatic example .", "The fully correlated limit is reached only once loops become relevant , and we estimate where the crossover to this regime occurs .", "We also explore how this behaviour changes for kernel lengthscales that are large enough for loops to become important ."]}
{"orig_sents": ["2", "0", "4", "5", "1", "6", "3", "7"], "shuf_sents": ["From the perspective of a fixed computational operation in a network , this seems like a most unacceptable degree of added variability .", "We suggest that a synapse solves the inverse problem of estimating the pre-synaptic membrane potential from the spikes it receives , acting as a recursive filter .", "Synapses exhibit an extraordinary degree of short-term malleability , with release probabilities and effective synaptic strengths changing markedly over multiple timescales .", "Under this account , the local postsynaptic potential and the level of synaptic resources track the ( scaled ) mean and variance of the estimated presynaptic membrane potential .", "We suggest an alternative theory according to which short-term synaptic plasticity plays a normatively-justifiable role .", "This theory starts from the commonplace observation that the spiking of a neuron is an incomplete , digital , report of the analog quantity that contains all the critical information , namely its membrane potential .", "We show that the dynamics of short-term synaptic depression closely resemble those required for optimal filtering , and that they indeed support high quality estimation .", "We make experimentally testable predictions for how the statistics of subthreshold membrane potential fluctuations and the form of spiking non-linearity should be related to the properties of short-term plasticity in any particular cell type ."]}
{"orig_sents": ["4", "5", "11", "2", "3", "10", "7", "6", "9", "8", "0", "1"], "shuf_sents": ["The ideas of optimality and compositionality are both very prominent in the field of motor control , yet they have been difficult to reconcile .", "Our work makes this possible .", "The resulting composite control law is provably optimal when the problem belongs to a certain class .", "This class is rather general and yet has a number of unique properties - one of which is that the Bellman equation can be made linear even for non-linear or discrete dynamics .", "We present a theory of compositionality in stochastic optimal control , showing how task-optimal controllers can be constructed from certain primitives .", "The primitives are themselves feedback controllers pursuing their own agendas .", "non-linear mixtures of LQG controllers ) without requiring the final cost to be quadratic .", "In the special case of linear dynamics and Gaussian noise our framework yields analytical solutions ( i.e .", "We illustrate the theory in the context of human arm movements .", "More generally , a natural set of control primitives can be constructed by applying SVD to Green 's function of the Bellman equation .", "This gives rise to the compositionality developed here .", "They are mixed in proportion to how much progress they are making towards their agendas and how compatible their agendas are with the present task ."]}
{"orig_sents": ["1", "4", "3", "5", "2", "0"], "shuf_sents": ["Experiments on a set of benchmark data sets indicate the promising results of the proposed work compared with state-of-the-art TSVM algorithms .", "We discuss the framework of Transductive Support Vector Machine ( TSVM ) from the perspective of the regularization strength induced by the unlabeled data .", "Furthermore , we introduce a method of adaptive regularization that is data dependant and is based on the smoothness assumption .", "Therefore , to supplement this framework of the regularization strength , it is necessary to introduce data-dependant partial regularization .", "In this framework , SVM and TSVM can be regarded as a learning machine without regularization and one with full regularization from the unlabeled data , respectively .", "To this end , we reformulate TSVM into a form with controllable regularization strength , which includes SVM and TSVM as special cases ."]}
{"orig_sents": ["6", "0", "2", "1", "3", "4", "5"], "shuf_sents": ["Within this context , we consider the task of learning a mixture of tree distributions .", "We propose an efficient strategy for obtaining a good initial set of trees that attempts to cover the entire observed distribution by minimizing the -divergence with = .", "Although mixtures of trees can be learned by minimizing the KL-divergence using an EM algorithm , its success depends heavily on the initialization .", "We formulate the problem using the fractional covering framework and present a convergent sequential algorithm that only relies on solving a convex program at each iteration .", "Compared to previous methods , our approach results in a significantly smaller mixture of trees that provides similar or better accuracies .", "We demonstrate the usefulness of our approach by learning pictorial structures for face recognition .", "The problem of approximating a given probability distribution using a simpler distribution plays an important role in several areas of machine learning , for example variational inference and classification ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["We consider the problem of using nearest neighbor methods to provide a conditional probability estimate , P ( y|a ) , when the number of labels y is large and the labels share some underlying structure .", "We demonstrate significant improvements in terms of word error rate ( WER ) on a lecture recognition task over a state-of-the-art baseline GMM model .", "The learned ECOCs and nearest neighbor information are used to provide conditional probability estimates .", "We apply these estimates to the problem of acoustic modeling for speech recognition .", "We propose a method for learning label embeddings ( similar to error-correcting output codes ( ECOCs ) ) to model the similarity between labels within a nearest neighbor framework ."]}
{"orig_sents": ["0", "5", "4", "1", "3", "2"], "shuf_sents": ["As the availability and importance of relational data -- such as the friendships summarized on a social networking website -- increases , it becomes increasingly important to have good models for such data .", "We pursue a similar approach with a richer kind of latent variable -- latent features -- using a Bayesian nonparametric approach to simultaneously infer the number of features at the same time we learn which entities have each feature .", "We demonstrate that the greater expressiveness of this approach allows us to improve performance on three datasets .", "Our model combines these inferred features with known covariates in order to perform link prediction .", "In particular , the machine learning community has focused on latent class models , adapting Bayesian nonparametric methods to jointly infer how many latent classes there are while learning which entities belong to each class .", "The kinds of latent structure that have been considered for use in predicting links in such networks have been relatively limited ."]}
{"orig_sents": ["4", "3", "2", "5", "0", "1"], "shuf_sents": ["From this saddle representation , we develop an efficient smooth optimization approach for sparse metric learning , although the learning model is based on a nondifferentiable loss function .", "Finally , we run experiments to validate the effectiveness and efficiency of our sparse metric learning model on various datasets .", "The sparse representation involves a mixed-norm regularization which is non-convex .", "We propose a novel metric learning model which can simultaneously conduct dimension reduction and learn a distance matrix .", "In this paper we study the problem of learning a low-rank ( sparse ) distance matrix .", "We then show that it can be equivalently formulated as a convex saddle ( min-max ) problem ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["AROW performs adaptive regularization of the prediction function upon seeing each new instance , allowing it to perform especially well in the presence of label noise .", "We present AROW , a new online learning algorithm that combines several useful properties : large margin training , confidence weighting , and the capacity to handle non-separable data .", "We also relate our algorithm to recent confidence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data .", "We derive a mistake bound , similar in form to the second order perceptron bound , that does not assume separability ."]}
{"orig_sents": ["6", "0", "7", "3", "5", "2", "4", "1"], "shuf_sents": ["While from a mathematical point of view , an infinite number of basis sets can be used to represent points in this space , the choice of basis set is psychologically crucial .", "The learning behaviour of the model captures the developmental shift from roughly `` isotropic '' for children to the axis-aligned generalization that adults show .", "Specifically , we present a rational model that does not assume dimensions , but learns the same type of dimensional generalizations that people display .", "What makes some choices of dimension special ?", "This bias is shaped by exposing the model to many categories with a structure hypothesized to be like those which children encounter .", "We explore the idea that the dimensions used by people echo the natural variation in the environment .", "Existing models of categorization typically represent to-be-classified items as points in a multidimensional space .", "People generally choose the same basis dimensions - and have a strong preference to generalize along the axes of these dimensions , but not `` diagonally '' ."]}
{"orig_sents": ["2", "3", "4", "0", "1"], "shuf_sents": ["We also present a theoretical analysis of these algorithms , including novel error bounds guaranteeing a better convergence rate than the standard Nystrom method .", "Finally , we report results of extensive experiments with several data sets containing up to 1M points demonstrating the significant improvement over the standard Nystrom approximation .", "A crucial technique for scaling kernel methods to very large data sets reaching or exceeding millions of instances is based on low-rank approximation of kernel matrices .", "We introduce a new family of algorithms based on mixtures of Nystrom approximations , ensemble Nystrom algorithms , that yield more accurate low-rank approximations than the standard Nystrom method .", "We give a detailed study of variants of these algorithms based on simple averaging , an exponential weight method , or regression-based methods ."]}
{"orig_sents": ["6", "0", "5", "2", "1", "4", "3"], "shuf_sents": ["The beta process is employed as a prior for learning the dictionary , and this non-parametric method naturally infers an appropriate dictionary size .", "Further , the noise variance need not be known , and can be nonstationary .", "The proposed method can learn a sparse dictionary in situ ; training images may be exploited if available , but they are not required .", "Several example results are presented , using both Gibbs and variational Bayesian inference , with comparisons to other state-of-the-art approaches .", "Another virtue of the proposed method is that sequential inference can be readily employed , thereby allowing scaling to large images .", "The Dirichlet process and a probit stick-breaking process are also considered to exploit structure within an image .", "Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations , with applications in denoising , inpainting and compressive sensing ( CS ) ."]}
{"orig_sents": ["4", "1", "2", "0", "3", "5"], "shuf_sents": ["By first choosing an appropriate basis of these eigenvectors from unlabeled data and then using labeled data with Lasso to select a classifier in the span of these eigenvectors , we obtain a classifier , which has a very sparse representation in this basis .", "It turns out that when the data has clustered , that is , when the high density regions are sufficiently separated by low density valleys , each high density area corresponds to a unique representative eigenvector .", "Linear combination of such eigenvectors ( or , more precisely , of their Nystrom extensions ) provide good candidates for good classification functions when the cluster assumption holds .", "Importantly , the sparsity corresponds naturally to the cluster assumption .", "We present a new framework for semi-supervised learning with sparse eigenfunction bases of kernel matrices .", "Experimental results on a number of real-world data-sets show that our method is competitive with the state of the art semi-supervised learning algorithms and outperforms the natural base-line algorithm ( Lasso in the Kernel PCA basis ) ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["These models are attractive because they ensure exchangeability ( over samples ) .", "Over recent years Dirichlet processes and the associated Chinese restaurant process ( CRP ) have found many applications in clustering while the Indian buffet process ( IBP ) is increasingly used to describe latent feature models .", "We propose here extensions of these models where the dependency between samples is given by a known decomposable graph .", "These models have appealing properties and can be easily learned using Monte Carlo techniques ."]}
{"orig_sents": ["1", "0", "4", "2", "5", "3"], "shuf_sents": ["In this paper , we explore several classes of structured priors for topic models .", "Implementations of topic models typically use symmetric Dirichlet priors with fixed concentration parameters , with the implicit assumption that such `` smoothing parameters '' have little practical effect .", "Approximation of this prior structure through simple , efficient hyperparameter optimization steps is sufficient to achieve these performance gains .", "Since this prior structure can be implemented using efficient algorithms that add negligible cost beyond standard inference techniques , we recommend it as a new standard for topic modeling .", "We find that an asymmetric Dirichlet prior over the document-topic distributions has substantial advantages over a symmetric prior , while an asymmetric prior over the topic-word distributions provides no real benefit .", "The prior structure we advocate substantially increases the robustness of topic models to variations in the number of topics and to the highly skewed word frequency distributions common in natural language ."]}
{"orig_sents": ["7", "4", "2", "1", "3", "0", "6", "8", "5"], "shuf_sents": ["We cast this ensemble task as an optimization problem on a bipartite graph , where the objective function favors the smoothness of the prediction over the graph , as well as penalizing deviations from the initial labeling provided by supervised models .", "Although unsupervised models , such as clustering , do not directly generate label prediction for each individual , they provide useful constraints for the joint prediction of a set of related objects .", "In this paper , we study ensemble learning with output from multiple supervised and unsupervised models , a topic where little work has been done .", "We propose to consolidate a classification solution by maximizing the consensus among both supervised predictions and unsupervised constraints .", "Their potential , however , is limited in applications which have no access to raw data but to the meta-level model output .", "Experimental results on three real applications demonstrate the benefits of the proposed method over existing alternatives1 .", "We solve this problem through iterative propagation of probability estimates among neighboring nodes .", "Ensemble classifiers such as bagging , boosting and model averaging are known to have improved accuracy and robustness over a single model .", "Our method can also be interpreted as conducting a constrained embedding in a transformed space , or a ranking on the graph ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["We present efficient learning and inference algorithms for this model , and show how a Monte-Carlo based method , Annealed Importance Sampling , can be used to produce an accurate estimate of the log-probability the model assigns to test data .", "This allows us to demonstrate that the proposed model is able to generalize much better compared to Latent Dirichlet Allocation in terms of both the log-probability of held-out documents and the retrieval accuracy .", "We introduce a two-layer undirected graphical model , called a `` Replicated Softmax '' , that can be used to model and automatically extract low-dimensional latent semantic representations from a large unstructured collection of documents ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We show that these results are somewhat limited : when these independence assumptions are relaxed in very small ways , complexity returns to that of the general case .", "Some reductions in complexity have been achieved by exploiting independence relations in some models .", "The worst-case complexity of general decentralized POMDPs , which are equivalent to partially observable stochastic games ( POSGs ) is very high , both for the cooperative and competitive cases ."]}
{"orig_sents": ["1", "3", "0", "4", "2"], "shuf_sents": ["We propose a novel recursive method to derive these moments theoretically and analytically without any permutation .", "In this paper , we develop an efficient moments-based permutation test approach to improve the test 's computational efficiency by approximating the permutation distribution of the test statistic with Pearson distribution series .", "The proposed strategy takes advantage of nonparametric permutation tests and parametric Pearson distribution approximation to achieve both accuracy and efficiency .", "This approach involves the calculation of the first four moments of the permutation distribution .", "Experimental results using different test statistics are demonstrated using simulated data and real data ."]}
{"orig_sents": ["4", "0", "1", "2", "3", "5"], "shuf_sents": ["Many computational problems related to such chains have been solved , including determining state distributions as a function of time , parameter estimation , and control .", "However , the problem of inferring most likely trajectories , where a trajectory is a sequence of states as well as the amount of time spent in each state , appears unsolved .", "We study three versions of this problem : ( i ) an initial value problem , in which an initial state is given and we seek the most likely trajectory until a given final time , ( ii ) a boundary value problem , in which initial and final states and times are given , and we seek the most likely trajectory connecting them , and ( iii ) trajectory inference under partial observability , analogous to finding maximum likelihood trajectories for hidden Markov models .", "We show that maximum likelihood trajectories are not always well-defined , and describe a polynomial time test for well-definedness .", "Continuous-time Markov chains are used to model systems in which transitions between states as well as the time the system spends in each state are random .", "When well-definedness holds , we show that each of the three problems can be solved in polynomial time , and we develop efficient dynamic programming algorithms for doing so ."]}
{"orig_sents": ["0", "7", "5", "1", "6", "3", "4", "2"], "shuf_sents": ["We propose an unsupervised method that , given a word , automatically selects non-abstract senses of that word from an online ontology and generates images depicting the corresponding entities .", "We argue that images associated with an abstract word sense should be excluded when training a visual classifier to learn a model of a physical object .", "We show results of retrieving concrete-sense images in two available multimodal , multi-sense databases , as well as experiment with object classifiers trained on concrete-sense images returned by our method for a set of ten common office objects .", "We propose a method that uses both image features and the text associated with the images to relate latent topics to particular senses .", "Our model does not require any human supervision , and takes as input only the name of an object category .", "As words are generally polysemous , this approach can lead to relatively noisy models if many examples due to outlier senses are added to the model .", "While image clustering can group together visually coherent sets of returned images , it can be difficult to distinguish whether an image cluster relates to a desired object or to an abstract sense of the word .", "When faced with the task of learning a visual model based only on the name of an object , a common approach is to find images on the web that are associated with the object name and train a visual classifier from the search result ."]}
{"orig_sents": ["4", "5", "3", "1", "0", "2"], "shuf_sents": ["Finally we outline a method to generate a topological map from loop closure data .", "A locally optimal labeling is found using Loopy-BP .", "Results , presented on four urban sequences and one indoor sequence , outperform the state of the art .", "Additionally , an MRF is constructed to model the probability of loop-closures .", "We present a system which constructs a topological map of an environment given a sequence of images .", "This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["This problem is central to areas within operations research , marketing and econometrics .", "We visit the following fundamental problem : For a `generic ' model of consumer choice ( namely , distributions over preference lists ) and a limited amount of data on how consumers actually make decisions ( such as marginal preference information ) , how may one predict revenues from offering a particular assortment of choices ?", "We present a framework to answer such questions and design a number of tractable algorithms ( from a data and computational standpoint ) for the same ."]}
{"orig_sents": ["1", "5", "4", "2", "0", "3"], "shuf_sents": ["Inference is fully Bayesian but scales well to large data sets .", "We consider the problem of learning probabilistic models for complex relational structures between various types of objects .", "We introduce the Bayesian Clustered Tensor Factorization ( BCTF ) model , which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework .", "The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data .", "Often there is a tradeoff between these two aims : cluster-based models yield more easily interpretable representations , while factorization-based approaches have given better predictive performance on large data sets .", "A model can help us `` understand '' a dataset of relational facts in at least two ways , by finding interpretable structure in the data , and by supporting predictions , or inferences about whether particular unobserved relations are likely to be true ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["This paper presents a simple , practical algorithm allowing the user to , for the first time , directly control the true accuracy of NN search ( in terms of ranks ) while still achieving the large speedups over exact NN .", "The long-standing problem of efficient nearest-neighbor ( NN ) search has ubiquitous applications ranging from astrophysics to MP3 fingerprinting to bioinformatics to movie recommendations .", "Experiments on high-dimensional datasets show that our algorithm often achieves faster and more accurate results than the best-known distance-approximate method , with much more stable behavior .", "As the dimensionality of the dataset increases , exact NN search becomes computationally prohibitive ; ( 1+ ) distance-approximate NN search can provide large speedups but risks losing the meaning of NN search present in the ranks ( ordering ) of the distances ."]}
{"orig_sents": ["5", "2", "1", "0", "3", "4"], "shuf_sents": ["We evaluate our methods on three languages -- English , Bulgarian and Portuguese -- showing consistent and significant accuracy improvement over EM-trained HMMs , and HMMs with sparsity-inducing Dirichlet priors trained by variational EM .", "In order to express this bias of posterior sparsity as opposed to parametric sparsity , we extend the posterior regularization framework .", "For example , in unsupervised part-of-speech ( POS ) induction using hidden Markov models , we introduce a bias for words to be labeled by a small number of tags .", "We increase accuracy with respect to EM by 2.3 % -6.5 % in a purely unsupervised setting as well as in a weaklysupervised setting where the closed-class words are provided .", "Finally , we show improvements using our method when using the induced clusters as features of a discriminative model in a semi-supervised setting .", "We address the problem of learning structured unsupervised models with moment sparsity typical in many natural language induction tasks ."]}
{"orig_sents": ["7", "2", "6", "1", "5", "4", "3", "0"], "shuf_sents": ["Finally , we describe how to learn the hyperparameters of compressible priors in underdetermined regression problems by exploiting the geometry of their order statistics during signal recovery .", "We show that the membership of generalized Pareto , Student 's t , log-normal , Frechet , and log-logistic distributions to the set of compressible priors depends only on the distribution parameters and is independent of N .", "A signal x RN is called p-compressible with magnitude R if its sorted coefficients exhibit a power-law decay as |x| ( i ) R * i-d , where the decay rate d is equal to 1/p .", "We also leverage the connections between compressible priors and sparse signals to develop new iterative re-weighted sparse signal recovery algorithms that outperform the standard 1 -norm minimization .", "As stylized examples , we show via experiments that the wavelet coefficients of natural images are 1.67-compressible whereas their pixel gradients are 0.95 log ( N/0.95 ) -compressible , on the average .", "In contrast , we demonstrate that the membership of the generalized Gaussian distribution ( GGD ) depends both on the signal dimension and the GGD parameters : the expected decay rate of N -sample iid realizations from the GGD with the shape parameter q is given by 1/ .", "p-compressible signals live close to K-sparse signals ( K N ) in the r -norm ( r > p ) since their best K-sparse approximation error decreases with O R * K 1/r-1/p .", "We describe a set of probability distributions , dubbed compressible priors , whose independent and identically distributed ( iid ) realizations result in p-compressible signals ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["In this paper we present a novel approach to learn directed acyclic graphs ( DAGs ) and factor models within the same framework while also allowing for model comparison between them .", "For this purpose , we exploit the connection between factor models and DAGs to propose Bayesian hierarchies based on spike and slab priors to promote sparsity , heavy-tailed priors to ensure identifiability and predictive densities to perform the model comparison .", "We require identifiability to be able to produce variable orderings leading to valid DAGs and sparsity to learn the structures .", "The effectiveness of our approach is demonstrated through extensive experiments on artificial and biological data showing that our approach outperform a number of state of the art methods ."]}
{"orig_sents": ["4", "5", "0", "1", "3", "2"], "shuf_sents": ["We also introduce an existing criterion for learning slow , decorrelated features as a pretraining strategy for image models .", "This pretraining strategy results in orientation-selective features , similar to the receptive fields of complex cells .", "To implement this pretraining strategy , we derive a fast algorithm for online learning of decorrelated features such that each iteration of the algorithm runs in linear time with respect to the number of features .", "With this pretraining , the same single-hidden-layer model achieves 1.34 % error , even though the pretraining sample distribution is very different from the fine-tuning distribution .", "We introduce a new type of neural network activation function based on recent physiological rate models for complex cells in visual area V1 .", "A single-hiddenlayer neural network of this kind of model achieves 1.50 % error on MNIST ."]}
{"orig_sents": ["1", "7", "4", "6", "2", "0", "8", "5", "3"], "shuf_sents": ["The middle layer consists of a number of gate functions , each acting as a local neuron or feature extractor to capture the nonlinear relationship between input and output .", "Conditional random fields ( CRF ) are widely used for sequence labeling such as natural language processing and biological sequence analysis .", "CNF extends CRF by adding one ( or possibly more ) middle layer between input and output .", "In particular , CNF is the best among approximately 10 machine learning methods for protein secondary structure prediction and also among a few of the best methods for handwriting recognition .", "However , in many real-world applications such as protein structure prediction and handwriting recognition , the relationship between input features and output is highly complex and nonlinear , which can not be accurately modeled by a linear function .", "Experiments on two widely-used benchmarks indicate that CNF performs significantly better than a number of popular methods .", "To model the nonlinear relationship between input and output we propose a new conditional probabilistic graphical model , Conditional Neural Fields ( CNF ) , for sequence labeling .", "Most CRF models use a linear potential function to represent the relationship between input features and output .", "Therefore , conceptually CNF is much more expressive than CRF ."]}
{"orig_sents": ["2", "7", "3", "6", "1", "5", "4", "0"], "shuf_sents": ["Furthermore , the model predicts dissociations in behavioral ( Maloney , Martello , Sahm , and Spillmann , 2005 ) and electrophysiological studies ( Jentzsch and Sommer , 2002 ) , supporting the psychological and neurobiological reality of its two components .", "Experimental results suggest that first-order statistics ( base rates ) also influence sequential effects .", "Across a wide range of cognitive tasks , recent experience influences behavior .", "These sequential effects have been interpreted as adaptation to the statistical structure of an uncertain , changing environment ( e.g. , Jones and Sieck , 2003 ; Mozer , Kinoshita , and Shettel , 2007 ; Yu and Cohen , 2008 ) .", "This model , the Dynamic Belief Mixture Model ( DBM2 ) , obtains precise , parsimonious fits to data .", "We propose a model that learns both first- and second-order sequence properties , each according to the basic principles of the DBM but under a unified inferential framework .", "The Dynamic Belief Model ( DBM ) ( Yu and Cohen , 2008 ) explains sequential effects in 2AFC tasks as a rational consequence of a dynamic internal representation that tracks second-order statistics of the trial sequence ( repetition rates ) and predicts whether the upcoming trial will be a repetition or an alternation of the previous trial .", "For example , when individuals repeatedly perform a simple two-alternative forcedchoice task ( 2AFC ) , response latencies vary dramatically based on the immediately preceding trial sequence ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We consider an online decision problem over a discrete space in which the loss function is submodular .", "We give algorithms which are computationally efficient and are Hannan-consistent in both the full information and bandit settings ."]}
{"orig_sents": ["2", "0", "4", "3", "1", "5", "6"], "shuf_sents": ["The top-level model is a third-order Boltzmann machine , trained using a hybrid algorithm that combines both generative and discriminative gradients .", "It substantially outperforms shallow models such as SVMs ( 11.6 % ) .", "We introduce a new type of top-level model for Deep Belief Nets and evaluate it on a 3D object recognition task .", "Our model achieves 6.5 % error on the test set , which is close to the best published result for NORB ( 5.9 % ) using a convolutional neural net that has built-in knowledge of translation invariance .", "Performance is evaluated on the NORB database ( normalized-uniform version ) , which contains stereo-pair images of objects under different lighting conditions and viewpoints .", "DBNs are especially suited for semi-supervised learning , and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database .", "With the extra unlabeled data ( and the same amount of labeled data as before ) , our model achieves 5.2 % error ."]}
{"orig_sents": ["6", "8", "2", "4", "3", "0", "5", "7", "1"], "shuf_sents": ["Finally , we report the experimental results using Yahoo 's vast datasets , and show that our approach substantially outperform the state-of-the-art methods in prediction accuracy .", "We therefore provide insights into the underlying principles of large-scale learning .", "Learning from click-through data is intrinsically large scale , even more so for ads .", "Specifically , we demonstrate two somewhat orthogonal philosophies of scaling algorithms to large-scale problems , through the SS and BT implementations , respectively .", "We scale up the algorithm to terabytes of real-world SS and BT data that contains hundreds of millions of users and hundreds of thousands of features , by leveraging the scalability characteristics of the algorithm and the inherent structure of the problem including data sparsity and locality .", "For BT in particular , the ROC area achieved by GaP is exceeding 0.95 , while one prior approach using Poisson regression yielded 0.83 .", "We adapt a probabilistic latent variable model , namely GaP ( Gamma-Poisson ) , to ad targeting in the contexts of sponsored search ( SS ) and behaviorally targeted ( BT ) display advertising .", "For computational performance , we compare a single-node sparse implementation with a parallel implementation using Hadoop MapReduce , the results are counterintuitive yet quite interesting .", "We also approach the important problem of ad positional bias by formulating a one-latent-dimension GaP factorization ."]}
{"orig_sents": ["4", "5", "6", "1", "3", "0", "2", "7"], "shuf_sents": ["The local feature maps are learned so their inner products preserve , to the best possible , the values of the specified kernel function .", "However , it is impractical to use such kernels for large datasets due to their significant computational cost .", "Classifiers based on EMK are linear both in the number of images and in the number of local features .", "To address this problem , we propose efficient match kernels ( EMK ) that map local features to a low dimensional feature space and average the resulting vectors to form a setlevel feature .", "In visual recognition , the images are frequently modeled as unordered collections of local features ( bags ) .", "We show that bag-of-words representations commonly used in conjunction with linear classifiers can be viewed as special match kernels , which count 1 if two local features fall into the same regions partitioned by visual words and 0 otherwise .", "Despite its simplicity , this quantization is too coarse , motivating research into the design of match kernels that more accurately measure the similarity between local features .", "We demonstrate that EMK are extremely efficient and achieve the current state of the art in three difficult computer vision datasets : Scene-15 , Caltech-101 and Caltech-256 ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["We show that a high dimensional nonlinear function can be approximated by a global linear function with respect to this coding scheme , and the approximation quality is ensured by the locality of such coding .", "The method turns a difficult nonlinear learning problem into a simple global linear learning problem , which overcomes some drawbacks of traditional local learning methods .", "This paper introduces a new method for semi-supervised learning on high dimensional nonlinear manifolds , which includes a phase of unsupervised basis learning and a phase of supervised function learning .", "The learned bases provide a set of anchor points to form a local coordinate system , such that each data point x on the manifold can be locally approximated by a linear combination of its nearby anchor points , and the linear weights become its local coordinate coding ."]}
{"orig_sents": ["1", "3", "5", "0", "2", "4"], "shuf_sents": ["Being able to specify a different domain for the representative features allows to incorporate prior knowledge about relevant characteristics of data and detaches the functional form of the covariance and basis functions .", "We present a general inference framework for inter-domain Gaussian Processes ( GPs ) and focus on its usefulness to build sparse GP models .", "We will show how previously existing models fit into this framework and will use it to develop two new sparse GP models .", "The state-of-the-art sparse GP model introduced by Snelson and Ghahramani in relies on finding a small , representative pseudo data set of m elements ( from the same domain as the n available data elements ) which is able to explain existing data well , and then uses it to perform inference .", "Tests on large , representative regression data sets suggest that significant improvement can be achieved , while retaining computational efficiency .", "This reduces inference and model selection computation time from O ( n3 ) to O ( m2 n ) , where m n. Inter-domain GPs can be used to find a ( possibly more compact ) representative set of features lying in a different domain , at the same computational cost ."]}
{"orig_sents": ["0", "2", "3", "5", "6", "4", "1"], "shuf_sents": ["An automated recovery system is a key component in a large data center .", "We describe the complete process , starting with data gathering , model learning , model checking procedures , and computing a policy .", "Such a system typically employs a hand-made controller created by an expert .", "While such controllers capture many important aspects of the recovery process , they are often not systematically optimized to reduce costs such as server downtime .", "We suggest learning an indefinite horizon Partially Observable Markov Decision Process , a model for decision making under uncertainty , and solve it using a point-based algorithm .", "In this paper we describe a passive policy learning approach for improving existing recovery policies without exploration .", "We explain how to use data gathered from the interactions of the hand-made controller with the system , to create an improved controller ."]}
{"orig_sents": ["2", "0", "4", "5", "3", "1"], "shuf_sents": ["We show that this problem can be efficiently addressed by using a certain greedy style algorithm .", "Experimental results on simulated and real world datasets indicate that Group-OMP compares favorably to Group Lasso , OMP and Lasso , both in terms of variable selection and prediction accuracy .", "We consider the problem of variable group selection for least squares regression , namely , that of selecting groups of variables for best regression performance , leveraging and adhering to a natural grouping structure within the explanatory variables .", "We also provide an upperbound on the l norm of the difference between the estimated regression coefficients and the true coefficients .", "More precisely , we propose the Group Orthogonal Matching Pursuit algorithm ( Group-OMP ) , which extends the standard OMP procedure ( also referred to as `` forward greedy feature selection algorithm '' for least squares regression ) to perform stage-wise group variable selection .", "We prove that under certain conditions Group-OMP can identify the correct ( groups of ) variables ."]}
{"orig_sents": ["4", "5", "1", "2", "6", "3", "7", "0"], "shuf_sents": ["Experimental results show that after the modifications , the methods can work significantly better than their original versions .", "Most listwise ranking methods manage to optimize ranking on the whole list ( permutation ) of objects , however , in practical applications such as information retrieval , correct ranking at the top k positions is much more important .", "This paper aims to analyze whether existing listwise ranking methods are statistically consistent in the top-k setting .", "This framework can include the permutationlevel ranking framework proposed in previous work as a special case .", "This paper is concerned with the consistency analysis on listwise ranking methods .", "Among various ranking methods , the listwise methods have competitive performances on benchmark datasets and are regarded as one of the state-of-the-art approaches .", "For this purpose , we define a top-k ranking framework , where the true loss ( and thus the risks ) are defined on the basis of top-k subgroup of permutations .", "Based on the new framework , we derive sufficient conditions for a listwise ranking method to be consistent with the top-k true loss , and show an effective way of modifying the surrogate loss functions in existing methods to satisfy these conditions ."]}
{"orig_sents": ["0", "1", "2", "4", "3", "5"], "shuf_sents": ["Motivated from real world problems , like object categorization , we study a particular mixed-norm regularization for Multiple Kernel Learning ( MKL ) .", "It is assumed that the given set of kernels are grouped into distinct components where each component is crucial for the learning task at hand .", "The formulation hence employs l regularization for promoting combinations at the component level and l1 regularization for promoting sparsity among kernels in each component .", "The MD procedure optimizes over product of simplexes , which is not a well-studied case in literature .", "While previous attempts have formulated this as a non-convex problem , the formulation given here is an instance of non-smooth convex optimization problem which admits an efficient Mirror-Descent ( MD ) based procedure .", "Results on real-world datasets show that the new MKL formulation is well-suited for object categorization tasks and that the MD based algorithm outperforms stateof-the-art MKL solvers like simpleMKL in terms of computational effort ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We also report the results of large-scale experiments comparing these three methods which demonstrate the benefits of the mixture weight method : this method consumes less resources , while achieving a performance comparable to that of standard approaches .", "We analyze and compare the CPU and network time complexity of each of these methods and present a theoretical analysis of conditional maxent models , including a study of the convergence of the mixture weight method , the most resource-efficient technique .", "We examine three common distributed training methods for conditional maxent : a distributed gradient computation method , a majority vote method , and a mixture weight method .", "Training conditional maximum entropy models on massive data sets requires significant computational resources ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["In particular , at each iteration , the learning variables are adjusted by solving a simple optimization problem that involves the running average of all past subgradients of the loss functions and the whole regularization term , not just its subgradient .", "Computational experiments show that the RDA method can be very effective for sparse online learning with 1 -regularization .", "We consider regularized stochastic learning and online optimization problems , where the objective function is the sum of two convex terms : one is the loss function of the learning task , and the other is a simple regularization term such as 1 -norm for promoting sparsity .", "We develop a new online algorithm , the regularized dual averaging ( RDA ) method , that can explicitly exploit the regularization structure in an online setting ."]}
{"orig_sents": ["5", "0", "1", "3", "4", "2"], "shuf_sents": ["Motivated by practical applications , we focus on DTOL when the number of actions is very large .", "Previous algorithms for learning in this framework have a tunable learning rate parameter , and a barrier to using online-learning in practical applications is that it is not understood how to set this parameter optimally , particularly when the number of actions is large .", "We show that our algorithm achieves good performance with respect to this new notion of regret ; in addition , it also achieves performance close to that of the best bounds achieved by previous algorithms with optimally-tuned parameters , according to previous notions of regret .", "In this paper , we offer a clean solution by proposing a novel and completely parameter-free algorithm for DTOL .", "We introduce a new notion of regret , which is more natural for applications with a large number of actions .", "We study the problem of decision-theoretic online learning ( DTOL ) ."]}
{"orig_sents": ["0", "1", "2", "4", "6", "3", "7", "5"], "shuf_sents": ["We develop an algorithm for efficient range search when the notion of dissimilarity is given by a Bregman divergence .", "The range search task is to return all points in a potentially large database that are within some specified distance of a query .", "It arises in many learning algorithms such as locally-weighted regression , kernel density estimation , neighborhood graph-based algorithms , and in tasks like outlier detection and information retrieval .", "This broad class of dissimilarity measures includes the relative entropy , Mahalanobis distance , Itakura-Saito divergence , and a variety of matrix divergences .", "In metric spaces , efficient range search-like algorithms based on spatial data structures have been deployed on a variety of statistical tasks .", "We derive geometric properties of Bregman divergences that yield an efficient algorithm for range search based on a recently proposed space decomposition for Bregman divergences .", "Here we describe an algorithm for range search for an arbitrary Bregman divergence .", "Metric methods can not be directly applied since Bregman divergences do not in general satisfy the triangle inequality ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["This joint model of appearance and context allows our framework to be less sensitive to noise and drawing variations , improving accuracy and robustness .", "We propose a new sketch recognition framework that combines a rich representation of low level visual appearance with a graphical model for capturing high level relationships between symbols .", "The result is a recognizer that is better able to handle the wide range of drawing styles found in messy freehand sketches .", "We evaluate our work on two real-world domains , molecular diagrams and electrical circuit diagrams , and show that our combined approach significantly improves recognition performance ."]}
{"orig_sents": ["1", "0", "3", "4", "5", "2", "6"], "shuf_sents": ["While many methods have been proposed that jointly measure a model 's descriptive adequacy and its complexity , few measures exist that measure complexity in itself .", "In the last few decades , model complexity has received a lot of press .", "It starts from the observation that model complexity is the property of the model that enables it to fit a wide range of outcomes .", "Moreover , existing measures ignore the parameter prior , which is an inherent part of the model and affects the complexity .", "This paper presents a stand alone measure for model complexity , that takes the number of parameters , the functional form , the range of the parameters and the parameter prior into account .", "This Prior Predictive Complexity ( PPC ) is an intuitive and easy to compute measure .", "The PPC then measures how wide this range exactly is ."]}
{"orig_sents": ["5", "2", "0", "6", "3", "4", "1"], "shuf_sents": ["However , this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph .", "Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs , which are predictive of the pixel-pair connectivity .", "Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates .", "The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation .", "By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph , we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning .", "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation .", "We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index , a well known segmentation performance measure ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["However , they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures .", "Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems .", "In this paper we prove that online learning with delayed updates converges well , thereby facilitating parallel online learning ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["Our main emphasis is empirical : on both simulated and real data , these two simple greedy methods can clearly outperform several state-ofthe-art competitors , including LASSO , a nonparametric version of LASSO called the sparse additive model ( SpAM ) and a recently proposed adaptive parametric forward-backward algorithm called Foba .", "For additive models , we propose an algorithm called additive forward regression ; for general multivariate models , we propose an algorithm called generalized forward regression .", "Both algorithms simultaneously conduct estimation and variable selection in nonparametric settings for the high dimensional sparse learning problem .", "We also provide some theoretical justifications of specific versions of the additive forward regression .", "This paper studies the forward greedy strategy in sparse nonparametric regression ."]}
{"orig_sents": ["0", "4", "5", "1", "2", "3"], "shuf_sents": ["The CUR decomposition provides an approximation of a matrix X that has low reconstruction error and that is sparse in the sense that the resulting approximation lies in the span of only a few columns of X .", "In this paper , we try to understand CUR from a sparse optimization viewpoint .", "We show that CUR is implicitly optimizing a sparse regression objective and , furthermore , can not be directly cast as a sparse PCA method .", "We also observe that the sparsity attained by CUR possesses an interesting structure , which leads us to formulate a sparse PCA method that achieves a CUR-like sparsity .", "In this regard , it appears to be similar to many sparse PCA methods .", "However , CUR takes a randomized algorithmic approach , whereas most sparse PCA methods are framed as convex optimization problems ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["We study the behavior of the commute distance as the size of the underlying graph increases .", "The commute distance between two vertices in a graph is the expected time it takes a random walk to travel from the first to the second vertex and back .", "We prove that the commute distance converges to an expression that does not take into account the structure of the graph at all and that is completely meaningless as a distance function on the graph .", "As an alternative we introduce the amplified commute distance that corrects for the undesired large sample effects .", "Consequently , the use of the raw commute distance for machine learning purposes is strongly discouraged for large graphs and in high dimensions ."]}
{"orig_sents": ["6", "3", "1", "4", "2", "5", "7", "0"], "shuf_sents": ["In an empirical evaluation on publicly available wind data from two geographically distinct regions , our approach makes significantly more accurate predictions than baseline models , and uncovers meteorologically relevant regimes .", "Two major challenges confronting these efforts are missing observations and weather-regime induced dependency shifts among wind variables .", "We describe a new regime-aware approach to STWF that use auto-regressive hidden Markov models ( AR-HMM ) , a subclass of conditional linear Gaussian ( CLG ) models .", "Physical models based on numerical weather predictions are currently not competitive , and research on machine learning approaches is ongoing .", "In this paper we introduce approaches that address both of these challenges .", "Although AR-HMMs are a natural representation for weather regimes , as with CLG models in general , exact inference is NP-hard when observations are missing ( Lerner and Parr , 2001 ) .", "Accurate short-term wind forecasts ( STWFs ) , with time horizons from 0.5 to 6 hours , are essential for efficient integration of wind power to the electrical power grid .", "We introduce a simple approximate inference method for AR-HMMs , which we believe has applications in other problem domains ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["We introduce a new family of online learning algorithms based upon constraining the velocity flow over a distribution of weight vectors .", "We compare the resulting algorithms on a variety of real world datasets , and demonstrate how these algorithms achieve state-of-the-art robust performance , especially with high label noise in the training data .", "By uniformly bounding this loss function , we demonstrate how to solve the resulting optimization analytically .", "In particular , we show how to effectively herd a Gaussian weight vector distribution by trading off velocity constraints with a loss function ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["HR2n + HL Rn for ERM with an H-smooth loss We establish an excess risk bound of O function and a hypothesis class with Rademacher complexity Rn , where L is the best risk achievable by the hypothesis class .", "For typical hypothesis classes where Rn = R/n , this translates to ( RH/n ) in the separable ( L = 0 ) case and O RH/n + L RH/n more a learning rate of O generally .", "We also provide similar guarantees for online and stochastic convex optimization of a smooth non-negative objective ."]}
{"orig_sents": ["2", "3", "1", "0", "4"], "shuf_sents": ["The bilinear score-functions are defined using a three-dimensional weight tensor , and we show that factorizing this tensor allows the model to encode invariances inherent in a task by learning a dictionary of invariant basis functions .", "This makes it possible to get the exact gradient of the log likelihood .", "We describe a `` log-bilinear '' model that computes class probabilities by combining an input vector multiplicatively with a vector of binary latent variables .", "Even though the latent variables can take on exponentially many possible combinations of values , we can efficiently compute the exact probability of each class by marginalizing over the latent variables .", "Experiments on a set of benchmark problems show that this fully probabilistic model can achieve classification performance that is competitive with ( kernel ) SVMs , backpropagation , and deep belief nets ."]}
{"orig_sents": ["5", "4", "3", "0", "7", "8", "2", "6", "1"], "shuf_sents": ["In this paper , we use sensitivity and specificity as the performance metrics of the meta-algorithm .", "To our best knowledge , this is the first algorithm that addresses the problem of the average tp-rate maximization under average fp-rate constraints in the online setting .", "Hence , we pose a relaxed goal and propose a corresponding practical online learning meta-algorithm that attains it .", "An online classification meta-algorithm is an algorithm that combines the outputs of the classifiers in order to attain a certain goal , without having prior knowledge on the form and statistics of the input , and without prior knowledge on the performance of the given classifiers .", "At each stage , the classifiers map the input to the probability that the input belongs to the positive class .", "We consider the online binary classification problem , where we are given m classifiers .", "In the case of two classifiers , we show that this algorithm takes a very simple form .", "In particular , our goal is to design an algorithm that satisfies the following two properties ( asymptotically ) : ( i ) its average false positive rate ( fp-rate ) is under some given threshold ; and ( ii ) its average true positive rate ( tp-rate ) is not worse than the tp-rate of the best convex combination of the m given classifiers that satisfies fprate constraint , in hindsight .", "We show that this problem is in fact a special case of the regret minimization problem with constraints , and therefore the above goal is not attainable ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We find that probabilistic inference can improve accuracy , integrate multiple observations , measure uncertainty , and even provide posterior distributions over quantities that were not directly measured .", "We identify and investigate a strong connection between probabilistic inference and differential privacy , the latter being a recent privacy definition that permits only indirect observation of data through noisy measurement .", "Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own .", "We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof ."]}
{"orig_sents": ["0", "4", "2", "3", "6", "1", "5", "7"], "shuf_sents": ["This paper explores links between basis construction methods in Markov decision processes and power series expansions of value functions .", "The first two terms in the Laurent series represent the scaled average-reward and the average-adjusted sum of rewards , and subsequent terms expand the discounted value function using powers of a generalized inverse called the Drazin ( or group inverse ) of a singular matrix derived from the transition matrix .", "Krylov and Bellman error bases are based on the Neumann series expansion .", "These bases incur very large initial Bellman errors , and can converge rather slowly as the discount factor approaches unity .", "This perspective provides a useful framework to analyze properties of existing bases , as well as provides insight into constructing more effective bases .", "Experiments show that Drazin bases converge considerably more quickly than several other bases , particularly for large values of the discount factor .", "The Laurent series expansion , which relates discounted and average-reward formulations , provides both an explanation for this slow convergence as well as suggests a way to construct more efficient basis representations .", "An incremental variant of Drazin bases called Bellman average-reward bases ( BARBs ) is described , which provides some of the same benefits at lower computational cost ."]}
{"orig_sents": ["2", "5", "1", "6", "4", "7", "0", "3"], "shuf_sents": ["We demonstrate that our systematic approach to utilizing the sparsity represented by the junction tree yields significant performance improvements over the general symbolic differentiation programs Mathematica and D* .", "Cumulative distribution networks ( CDNs ) provide a means to tractably specify multivariate heavy-tailed models as a product of cumulative distribution functions ( CDFs ) .", "Many problem domains including climatology and epidemiology require models that can capture both heavy-tailed statistics and local dependencies .", "Using two real-world datasets , we demonstrate that non-tree structured ( loopy ) CDNs are able to provide significantly better fits to the data as compared to tree-structured and unstructured CDNs and other heavy-tailed multivariate distributions such as the multivariate copula and logistic models .", "In this paper , we develop inference and learning algorithms for CDNs with arbitrary topology .", "Specifying such distributions using graphical models for probability density functions ( PDFs ) generally lead to intractable inference and learning .", "Existing algorithms for inference and learning in CDNs are limited to those with tree-structured ( nonloopy ) graphs .", "Our approach to inference and learning relies on recursively decomposing the computation of mixed derivatives based on a junction trees over the cumulative distribution functions ."]}
{"orig_sents": ["2", "3", "4", "5", "1", "6", "0"], "shuf_sents": ["A phase diagram of the emergent activity patterns with respect to two control parameters , respectively accounting for ant sociability and receptivity , is presented and discussed .", "Each ant makes its decision ( among foraging , sleeping and self-grooming ) from the competition between its two neurons , after the signals received from its neighbor ants .", "Many complex systems , ranging from neural cell assemblies to insect societies , involve and rely on some division of labor .", "How to enforce such a division in a decentralized and distributed way , is tackled in this paper , using a spiking neuron network architecture .", "Specifically , a spatio-temporal model called SpikeAnts is shown to enforce the emergence of synchronized activities in an ant colony .", "Each ant is modelled from two spiking neurons ; the ant colony is a sparsely connected spiking neuron network .", "Interestingly , three types of temporal patterns emerge in the ant colony : asynchronous , synchronous , and synchronous periodic foraging activities - similar to the actual behavior of some living ant colonies ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["A numerical implementation of our technique and experiments on a large face images dataset verify the speed and the accuracy of our theoretical results .", "We prove that any set of n points in d dimensions ( rows in a matrix A Rnxd ) can be projected into t = ( k/2 ) dimensions , for any ( 0 , 1/3 ) , in O ( nd-2 k/ log ( d ) ) time , such that with constant probability the optimal k-partition of the point set is preserved within a factor of 2 + .", "This paper discusses the topic of dimensionality reduction for k-means clustering .", "The projection is done by post-multiplying A with a d x t random matrix R having entries +1/ t or -1/ t with equal probability ."]}
{"orig_sents": ["3", "1", "2", "0", "4"], "shuf_sents": ["We study the performance of online LDA in several ways , including by fitting a 100-topic topic model to 3.3M articles from Wikipedia in a single pass .", "Online LDA is based on online stochastic optimization with a natural gradient step , which we show converges to a local optimum of the VB objective function .", "It can handily analyze massive document collections , including those arriving in a stream .", "We develop an online variational Bayes ( VB ) algorithm for Latent Dirichlet Allocation ( LDA ) .", "We demonstrate that online LDA finds topic models as good or better than those found with batch VB , and in a fraction of the time ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["CST uses a changepoint detection method to segment each trajectory into a skill chain by detecting a change of appropriate abstraction , or that a segment is too complex to model as a single skill .", "We demonstrate that CST constructs an appropriate skill tree that can be further refined through learning in a challenging continuous domain , and that it can be used to segment demonstration trajectories on a mobile manipulator into chains of skills where each skill is assigned an appropriate abstraction .", "The skill chains from each trajectory are then merged to form a skill tree .", "We introduce CST , an algorithm for constructing skill trees from demonstration trajectories in continuous reinforcement learning domains ."]}
{"orig_sents": ["3", "0", "6", "2", "1", "7", "4", "5"], "shuf_sents": ["In this paper we propose a simple and fast algorithm SVP ( Singular Value Projection ) for rank minimization under affine constraints ( ARMP ) and show that SVP recovers the minimum rank solution for affine constraints that satisfy a restricted isometry property ( RIP ) .", "Next , we address a practically important application of ARMP - the problem of lowrank matrix completion , for which the defining affine constraints do not directly obey RIP , hence the guarantees of SVP do not hold .", "We also introduce a Newton-step for our SVP framework to speed-up the convergence with substantial empirical gains .", "Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics .", "We also demonstrate empirically that our algorithms outperform existing methods , such as those of , for ARMP and the matrix completion problem by an order of magnitude and are also more robust to noise and sampling schemes .", "In particular , results show that our SVP-Newton method is significantly robust to noise and performs impressively on a more realistic power-law sampling scheme for the matrix completion problem .", "Our method guarantees geometric convergence rate even in the presence of noise and requires strictly weaker assumptions on the RIP constants than the existing methods .", "However , we provide partial progress towards a proof of exact recovery for our algorithm by showing a more restricted isometry property and observe empirically that our algorithm recovers low-rank incoherent matrices from an almost optimal number of uniformly sampled entries ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["While manifold learning is well-known in machine learning , the use of manifolds in human learning is largely unstudied .", "We perform a set of experiments which test a human 's ability to use a manifold in a semisupervised learning task , under varying conditions .", "We show that humans may be encouraged into using the manifold , overcoming the strong preference for a simple , axis-parallel linear boundary .", "When the distribution of unlabeled data in feature space lies along a manifold , the information it provides may be used by a learner to assist classification in a semi-supervised setting ."]}
{"orig_sents": ["6", "7", "1", "0", "8", "5", "2", "4", "3"], "shuf_sents": ["To avoid these limitations , in this paper , we propose a new model , which is defined with a coset-permutation distance , and models the generation of a permutation as a stagewise process .", "However , these models have their limitations in either poor expressiveness or high computational complexity .", "The complexity of the CPS model is low because of the stagewise decomposition of the permutation probability and the efficient computation of most coset-permutation distances .", "Experiments on public datasets show that the derived algorithms based on the CPS model can achieve state-ofthe-art ranking accuracy , and are much more efficient than previous algorithms .", "We apply the CPS model to supervised rank aggregation , derive the learning and inference algorithms , and empirically study their effectiveness and efficiency .", "The CPS model has rich expressiveness and can therefore be used in versatile applications , because many different permutation distances can be used to induce the coset-permutation distance .", "This paper is concerned with rank aggregation , which aims to combine multiple input rankings to get a better ranking .", "A popular approach to rank aggregation is based on probabilistic models on permutations , e.g. , the Luce model and the Mallows model .", "We refer to the new model as coset-permutation distance based stagewise ( CPS ) model ."]}
{"orig_sents": ["3", "5", "4", "0", "1", "2"], "shuf_sents": ["To avoid this problem , we introduce a local approximation of this cost function , which in turn leads to a quadratic non-convex optimization problem over a product of simplices .", "In order to maximize quadratic functions , we propose an efficient algorithm based on convex relaxations and lowrank representations of the data , capable of handling large-scale problems .", "Experiments on text document classification show that the new model outperforms other supervised dimensionality reduction methods , while simulations on unsupervised clustering show that our probabilistic formulation has better properties than existing discriminative clustering methods .", "Dimensionality reduction is commonly used in the setting of multi-label supervised classification to control the learning capacity and to provide a meaningful representation of the data .", "While the expectation-maximization ( EM ) algorithm is commonly used to learn these probabilistic models , it usually leads to local maxima because it relies on a non-convex cost function .", "We introduce a simple forward probabilistic model which is a multinomial extension of reduced rank regression , and show that this model provides a probabilistic interpretation of discriminative clustering methods with added benefits in terms of number of hyperparameters and optimization ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We define a data dependent permutation complexity for a hypothesis set H , which is similar to a Rademacher complexity or maximum discrepancy .", "The permutation complexity is based ( like the maximum discrepancy ) on dependent sampling .", "We prove a uniform bound on the generalization error , as well as a concentration result which means that the permutation estimate can be efficiently estimated ."]}
{"orig_sents": ["8", "2", "9", "4", "3", "7", "6", "1", "5", "10", "0"], "shuf_sents": ["Our empirical evaluation on the benchmark Berkeley segmentation dataset shows that the new algorithm eliminates the need for hand-picking optimal input parameters of the state-of-the-art segmenters , and outperforms their best , manually optimized results .", "The algorithm seeks a solution directly in the discrete domain , instead of relaxing MWIS to a continuous problem , as common in previous work .", "Knowledge about any specific objects and surfaces present in the image is not available .", "We construct such a graph from all segments in the ensemble .", "MWIS is the heaviest subset of mutually non-adjacent nodes of an attributed graph .", "It iteratively finds a candidate discrete solution of the Taylor series expansion of the original MWIS objective function around the previous solution .", "A new MWIS algorithm is presented .", "Then , MWIS selects maximally distinctive segments that together partition the image .", "Given an ensemble of distinct , low-level segmentations of an image , our goal is to identify visually `` meaningful '' segments in the ensemble .", "The selection of image regions occupied by objects is formalized as the maximum-weight independent set ( MWIS ) problem .", "The algorithm is shown to converge to an optimum ."]}
{"orig_sents": ["1", "4", "2", "0", "5", "3"], "shuf_sents": ["Our model consists of two key components : a data likelihood that proposes multiple motion hypotheses using nonlinear matching , and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion field at multiple scales .", "The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes .", "In this paper , we propose a hierarchical model as a unified framework for modeling both short-range and long-range motion perception .", "We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments .", "Previous work has assumed that two different mechanisms are involved in processing these two types of motion .", "We tested our model on two types of stimuli , random dot kinematograms and multiple-aperture stimuli , both commonly used in human vision research ."]}
{"orig_sents": ["3", "4", "1", "2", "5", "6", "0"], "shuf_sents": ["We show experiments with both simulated and real data which reveal the interest of our methodology .", "The absence of an edge on a certain snapshot can not be distinguished from a missing entry in the adjacency matrix .", "Additional information can be provided by examining the dynamics of the graph through a set of topological features , such as the degrees of the vertices .", "We consider the problem of discovering links of an evolving undirected graph given a series of past snapshots of that graph .", "The graph is observed through the time sequence of its adjacency matrix and only the presence of edges is observed .", "We develop a novel methodology by building on both static matrix completion methods and the estimation of the future state of relevant graph features .", "Our procedure relies on the formulation of an optimization problem which can be approximately solved by a fast alternating linearized algorithm whose properties are examined ."]}
{"orig_sents": ["1", "0", "4", "2", "3"], "shuf_sents": ["We assume that voxels within a unit respond similarly to all stimuli from the same category , and design a nonparametric hierarchical model to capture inter-subject variability among the units .", "We present a model that describes the structure in the responses of different brain areas to a set of stimuli in terms of stimulus categories ( clusters of stimuli ) and functional units ( clusters of voxels ) .", "A variational inference algorithm derived based on the model learns categories , units , and a set of unit-category activation probabilities from data .", "When applied to data from an fMRI study of object recognition , the method finds meaningful and consistent clusterings of stimuli into categories and voxels into units .", "The model explicitly encodes the relationship between brain activations and fMRI time courses ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["We first relate CRFs and structured SVMs and show that in CRFs a variant of the log-partition function , known as the soft-max , smoothly approximates the hinge loss function of structured SVMs .", "Unlike existing approaches , this allows us to learn efficiently graphical models with cycles and very large number of parameters .", "In this paper we propose an approximated structured prediction framework for large scale graphical models and derive message-passing algorithms for learning their parameters efficiently .", "We then propose an intuitive approximation for the structured prediction problem , using duality , based on a local entropy approximation and derive an efficient messagepassing algorithm that is guaranteed to converge ."]}
{"orig_sents": ["4", "5", "1", "2", "0", "7", "3", "6"], "shuf_sents": ["This paper introduces a framework to spatially regularize SVM for brain image analysis .", "However , the features ' spatial distribution is not taken into account .", "As a consequence , the optimal margin hyperplane is often scattered and lacks spatial coherence , making its anatomical interpretation difficult .", "The proposed framework is applied to the classification of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer 's disease and 30 elderly controls .", "Support vector machines ( SVM ) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data .", "Moreover , when the kernel is linear , SVMs can be used to localize spatial patterns of discrimination between two groups of subjects .", "The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classifier .", "We show that Laplacian regularization provides a flexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images ."]}
{"orig_sents": ["5", "4", "6", "1", "8", "3", "2", "7", "0"], "shuf_sents": ["The work here provides dramatic evidence about the efficacy of two very different approaches to multimodal speech detection on a challenging database .", "Here we show that with the proper visual features ( in this case movements of various facial muscle groups ) , a very accurate detector of speech can be created that does not use the audio signal at all .", "in the case of a mobile robot ) .", "The voice model has the advantage of being able to identify when a particular person is speaking even when they are not visible to the camera ( e.g .", "One popular approach to this problem is audio-visual synchrony detection .", "Determining whether someone is talking has applications in many areas such as speech recognition , speaker diarization , social robotics , facial expression recognition , and human computer interaction .", "A candidate speaker is deemed to be talking if the visual signal around that speaker correlates with the auditory signal .", "Moreover , we show that a simple sensory fusion scheme between the auditory and visual models improves performance on the task of talking detection .", "Further we show that this person independent visual-only detector can be used to train very accurate audio-based person dependent voice models ."]}
{"orig_sents": ["6", "5", "1", "4", "3", "2", "0"], "shuf_sents": ["We also demonstrate the application of Go-CART to a meteorological dataset , showing how graph-valued regression can provide a useful tool for analyzing complex data .", "We refer to the problem of estimating the graph G ( x ) of Y conditioned on X = x as `` graph-valued regression '' .", "We study the theoretical properties of Go-CART using dyadic partitioning trees , establishing oracle inequalities on risk minimization and tree partition consistency .", "We call the method `` Graph-optimized CART '' , or GoCART .", "In this paper , we propose a semiparametric method for estimating G ( x ) that builds a tree on the X space just as in CART ( classification and regression trees ) , but at each leaf of the tree estimates a graph .", "In many applications , it is of interest to model Y given another random vector X as input .", "Undirected graphical models encode in a graph G the dependency structure of a random vector Y ."]}
{"orig_sents": ["4", "5", "3", "9", "6", "2", "10", "7", "0", "1", "8"], "shuf_sents": ["We also find emphasis of specific baseline spike rates and suppression for high background rates .", "The latter suggests a mechanism of network activity regulation inherent in STDP .", "We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic firing rates for which our model can be solved .", "We find that our model reproduces data from to recent experimental studies with a small number of biophysically interpretable parameters .", "When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity ( STDP ) with modulated pre- and postsynaptic contributions to long-term synaptic modifications .", "In order to investigate the functional consequences of these contribution dynamics ( CD ) we propose a minimal model formulated in terms of differential equations .", "its nonlinear filter properties .", "Modifications are dominant in the theta frequency range , a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning .", "Furthermore , our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models .", "The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities , i.e .", "It predicts synaptic strengthening for synchronous rate modulations ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["We present an algorithm that instead constructs reward features from a large collection of component features , by building logical conjunctions of those component features that are relevant to the example policy .", "Current IRL techniques generally rely on user-supplied features that form a concise basis for the reward .", "The goal of inverse reinforcement learning is to find a reward function for a Markov decision process , given example traces from its optimal policy .", "The reward function can be used to recover a full , deterministic , stationary policy , and the features can be used to transplant the reward function into any novel environment on which the component features are well defined .", "Given example traces , the algorithm returns a reward function as well as the constructed features ."]}
{"orig_sents": ["4", "1", "3", "5", "0", "2"], "shuf_sents": ["The proposed active learning approach is independent of employed classification models .", "In this paper , we propose a novel batch-mode active learning approach that selects a batch of queries in each iteration by maximizing a natural mutual information criterion between the labeled and unlabeled instances .", "Our empirical studies show this approach can achieve comparable or superior performance to discriminative batch-mode active learning methods .", "By employing a Gaussian process framework , this mutual information based instance selection problem can be formulated as a matrix partition problem .", "Recently , batch-mode active learning has attracted a lot of attention .", "Although matrix partition is an NP-hard combinatorial optimization problem , we show that a good local solution can be obtained by exploiting an effective local optimization technique on a relaxed continuous optimization problem ."]}
{"orig_sents": ["1", "4", "3", "0", "2"], "shuf_sents": ["By viewing the problem from this perspective , the most popular quality measures for assessing the performance of multi-label classification admit relaxations that can be efficiently optimised .", "Multi-label classification is the task of predicting potentially multiple labels for a given instance .", "We optimise these relaxations with standard algorithms and compare our results with several stateof-the-art methods , showing excellent performance .", "In this paper we present a formulation for this problem based on reverse prediction : we predict sets of instances given the labels .", "This is common in several applications such as image annotation , document classification and gene function prediction ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We show that our new method achieves consistency , and illustrate empirically that it indeed approaches the performance of exact methods when sufficiently large training sets are used .", "However , for general graph structure both learning and inference are intractable .", "Here we show that it is possible to circumvent this difficulty when the distribution of training examples is rich enough , via a method similar in spirit to pseudo-likelihood .", "The problem of learning to predict structured labels is of key importance in many applications ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["We describe how the likelihood ratio policy gradient can be derived from an importance sampling perspective .", "We present a new policy search method , which leverages both of these observations as well as generalized baselines -- a new technique which generalizes commonly used baseline techniques for policy gradient methods .", "This derivation highlights how likelihood ratio methods under-use past experience by ( i ) using the past experience to estimate only the gradient of the expected return U ( ) at the current policy parameterization , rather than to obtain a more complete estimate of U ( ) , and ( ii ) using past experience under the current policy only rather than using all past experience to improve the estimates .", "Our algorithm outperforms standard likelihood ratio policy gradient algorithms on several testbeds .", "Likelihood ratio policy gradient methods have been some of the most successful reinforcement learning algorithms , especially for learning on physical systems ."]}
{"orig_sents": ["1", "4", "6", "7", "0", "2", "3", "5"], "shuf_sents": ["The main challenge is that often we are not provided with a readily computable measure of the easiness of samples .", "Latent variable models are a powerful tool for addressing several tasks in machine learning .", "We address this issue by proposing a novel , iterative self-paced learning algorithm where each iteration simultaneously selects easy samples and learns a new parameter vector .", "The number of samples selected is governed by a weight that is annealed until the entire training data has been considered .", "However , the algorithms for learning the parameters of latent variable models are prone to getting stuck in a bad local optimum .", "We empirically demonstrate that the self-paced learning algorithm outperforms the state of the art method for learning a latent structural SVM on four applications : object localization , noun phrase coreference , motif finding and handwritten digit recognition .", "To alleviate this problem , we build on the intuition that , rather than considering all samples simultaneously , the algorithm should be presented with the training data in a meaningful order that facilitates learning .", "The order of the samples is determined by how easy they are ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["Based on the variational EM framework , we propose a fast alternative that uses component-specific data partitions to obtain a sub-linear E-step in sample size , while the algorithm still maintains provable convergence .", "On the downside , the E-step is linear in both the sample size and the number of mixture components , making it impractical for large-scale data .", "Remarkably easy implementation and guaranteed convergence has made the EM algorithm one of the most used algorithms for mixture modeling .", "We demonstrate this speedup by experiments on large-scale synthetic and real data .", "Our approach builds on previous work , but is significantly faster and scales much better in the number of mixture components ."]}
{"orig_sents": ["1", "4", "3", "0", "2"], "shuf_sents": ["Furthermore , we introduce two loss functions which are appropriate for our problem and show how to use structural SVMs to optimize the learned mapping for these losses .", "We cast the problem of identifying basic blocks of code in a binary executable as learning a mapping from a byte sequence to a segmentation of the sequence .", "Finally , we present experimental results that demonstrate the advantages of our method against a strong baseline .", "By taking advantage of the structure of our problem , we derive a linear-time inference algorithm which makes our approach practical , given that even small programs are tens or hundreds of thousands bytes long .", "In general , inference in segmentation models , such as semi-CRFs , can be cubic in the length of the sequence ."]}
{"orig_sents": ["2", "3", "5", "1", "4", "6", "0"], "shuf_sents": ["Experiments on synthetic and real datasets demonstrate the competitiveness of the approach .", "It is shown that likelihood ratio estimation is generally a good surrogate for the 0-1 loss , and separates positive and negative instances well .", "We propose an approach to multiple-instance learning that reformulates the problem as a convex optimization on the likelihood ratio between the positive and the negative class for each training instance .", "This is casted as joint estimation of both a likelihood ratio predictor and the target ( likelihood ratio variable ) for instances .", "The likelihood ratio estimates provide a ranking of instances within a bag and are used as input features to learn a linear classifier on bags of instances .", "Theoretically , we prove a quantitative relationship between the risk estimated under the 0-1 classification loss , and under a loss function for likelihood ratio .", "Instance-level classification is achieved from the bag-level predictions and the individual likelihood ratios ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["We propose a decision criterion based on distributional robustness : the optimal policy maximizes the expected total reward under the most adversarial probability distribution over realizations of the uncertain parameters that is admissible ( i.e. , it agrees with the a-priori information ) .", "We consider Markov decision processes where the values of the parameters are uncertain .", "This uncertainty is described by a sequence of nested sets ( that is , each set contains the previous one ) , each of which corresponds to a probabilistic guarantee for a different confidence level so that a set of admissible probability distributions of the unknown parameters is specified .", "We show that finding the optimal distributionally robust policy can be reduced to a standard robust MDP where the parameters belong to a single uncertainty set , hence it can be computed in polynomial time under mild technical conditions .", "This formulation models the case where the decision maker is aware of and wants to exploit some ( yet imprecise ) a-priori information of the distribution of parameters , and arises naturally in practice where methods to estimate the confidence region of parameters abound ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["The two-layer approach can be easily generalized to deeper structures in a hierarchical multiple-layer manner .", "This paper proposes a principled extension of the traditional single-layer flat sparse coding scheme , where a two-layer coding scheme is derived based on theoretical analysis of nonlinear functional approximation that extends recent results for local coordinate coding .", "Empirically , it is shown that the deep coding approach yields improved performance in benchmark datasets ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["Sparse coding has recently become a popular approach in computer vision to learn dictionaries of natural images .", "We formulated the problem as a tensor factorization problem with tensor group norm constraints over the primitives , diagonal constraints on the activations that provide interpretability as well as smoothness constraints that are inherent to human motion .", "We demonstrate the effectiveness of our approach to learn interpretable representations of human motion from motion capture data , and show that our approach outperforms recently developed matching pursuit and sparse coding algorithms .", "In this paper we extend the sparse coding framework to learn interpretable spatio-temporal primitives ."]}
{"orig_sents": ["3", "6", "0", "5", "4", "1", "7", "2"], "shuf_sents": ["Such a regularization can help uncover the structured sparsity , which is desirable for applications with some meaningful tree structures on the features .", "One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped tree structure .", "Our experimental results on the AR and JAFFE face data sets demonstrate the efficiency and effectiveness of the proposed algorithm .", "We consider the tree structured group Lasso where the structure over the features can be represented as a tree with leaf nodes as features and internal nodes as clusters of the features .", "In this paper , we develop an efficient algorithm for the tree structured group Lasso .", "However , the tree structured group Lasso is challenging to solve due to the complex regularization .", "The structured regularization with a pre-defined tree structure is based on a group-Lasso penalty , where one group is defined for each node in the tree .", "The main technical contributions of this paper include ( 1 ) we show that the associated Moreau-Yosida regularization admits an analytical solution , and ( 2 ) we develop an efficient algorithm for determining the effective interval for the regularization parameter ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["We obtained satisfactory results on several real-world tasks , suggesting that the low rank assumption may not be as restrictive as it seems .", "By assuming the underlying matrix has a low rank , our formulation is able to handle three problems simultaneously : i ) multi-label learning , where each item has more than one label , ii ) transduction , where most of these labels are unspecified , and iii ) missing data , where a large number of features are missing .", "The resulting nuclear norm minimization problem is solved with a modified fixed-point continuation method that is guaranteed to find the global optimum .", "We pose transductive classification as a matrix completion problem .", "Our method allows for different loss functions to apply on the feature and label entries of the matrix ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["Sparse methods for supervised learning aim at finding good linear predictors from as few variables as possible , i.e. , with small cardinality of their supports .", "By selecting specific submodular functions , we can give a new interpretation to known norms , such as those based on rank-statistics or grouped norms with potentially overlapping groups ; we also define new norms , in particular ones that can be used as non-factorial priors for supervised learning .", "In this paper , we investigate more general set-functions than the cardinality , that may incorporate prior knowledge or structural constraints which are common in many applications : namely , we show that for nondecreasing submodular set-functions , the corresponding convex envelope can be obtained from its Lovasz extension , a common tool in submodular analysis .", "This defines a family of polyhedral norms , for which we provide generic algorithmic tools ( subgradients and proximal operators ) and theoretical results ( conditions for support recovery or high-dimensional inference ) .", "This combinatorial selection problem is often turned into a convex optimization problem by replacing the cardinality function by its convex envelope ( tightest convex lower bound ) , in this case the 1 -norm ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["The proposed shadow Dirichlet distribution manipulates the support in order to model probability mass functions ( pmfs ) with dependencies or constraints that often arise in real world problems , such as regularized pmfs , monotonic pmfs , and pmfs with bounded variation .", "Although the Dirichlet distribution is widely used , the independence structure of its components limits its accuracy as a model .", "We describe some properties of this new class of distributions , provide maximum entropy constructions , give an expectation-maximization method for estimating the mean parameter , and illustrate with real data ."]}
{"orig_sents": ["1", "2", "6", "3", "4", "0", "5"], "shuf_sents": ["Instead of relying on separating hyperplanes , its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural fit for multi-task learning .", "Multi-task learning ( MTL ) improves the prediction performance on multiple , different but related , learning problems through shared parameters or representations .", "One of the most prominent multi-task learning algorithms is an extension to support vector machines ( svm ) by Evgeniou et al .", "Although very elegant , multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which , in a multi-task setting , requires the different learning tasks to share the same set of classes .", "This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor ( lmnn ) algorithm to the MTL paradigm .", "We evaluate the resulting multi-task lmnn on real-world insurance data and speech classification problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classifiers .", "."]}
{"orig_sents": ["0", "1", "3", "2", "4"], "shuf_sents": ["Robust regression and classification are often thought to require non-convex loss functions that prevent scalable , global training .", "However , such a view neglects the possibility of reformulated training methods that can yield practically solvable alternatives .", "We demonstrate that a relaxation of this form of `` loss clipping '' can be made globally solvable and applicable to any standard loss while guaranteeing robustness against outliers .", "A natural way to make a loss function more robust to outliers is to truncate loss values that exceed a maximum threshold .", "We present a generic procedure that can be applied to standard loss functions and demonstrate improved robustness in regression and classification problems ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["The requisite ability to dynamically modify or cancel planned actions is known as inhibitory control in psychology .", "Our normative model accounts for a range of behavioral data in humans and animals in the stop-signal task , suggesting that the brain implements statistically optimal , dynamically adaptive , and reward-sensitive decision-making in the context of inhibitory control problems .", "Using Bayesian inference and stochastic control tools , we show that the optimal policy systematically depends on various parameters of the problem , such as the relative costs of different action choices , the noise level of sensory inputs , and the dynamics of changing environmental demands .", "Intelligent agents are often faced with the need to choose actions with uncertain consequences , and to modify those actions according to ongoing sensory processing and changing task demands .", "We formalize inhibitory control as a rational decision-making problem , and apply to it to the classical stop-signal task ."]}
{"orig_sents": ["0", "4", "3", "1", "2"], "shuf_sents": ["The sequence memoizer is a model for sequence data with state-of-the-art performance on language modeling and compression .", "( 2009 ) .", "We present some experimental results supporting our improvements .", "Our derivations are based on precise definitions of the various processes that will also allow us to provide an elementary proof of the `` mysterious '' coagulation and fragmentation properties used in the original paper on the sequence memoizer by Wood et al .", "We propose a number of improvements to the model and inference algorithm , including an enlarged range of hyperparameters , a memory-efficient representation , and inference algorithms operating on the new representation ."]}
{"orig_sents": ["3", "4", "0", "2", "1"], "shuf_sents": ["We find that the network with STD can generate both static and traveling bumps , and STD enhances the performance of the network in tracking external inputs .", "We argue that this provides a mechanism for neural systems to hold short-term memory easily and shut off persistent activities naturally .", "In particular , we find that STD endows the network with slow-decaying plateau behaviors , namely , the network being initially stimulated to an active state will decay to silence very slowly in the time scale of STD rather than that of neural signaling .", "Neuronal connection weights exhibit short-term depression ( STD ) .", "The present study investigates the impact of STD on the dynamics of a continuous attractor neural network ( CANN ) and its potential roles in neural information processing ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["Apart from synthesizing data under a Gaussian model , the proposed technique directly leads to an efficient unbiased estimator of marginal variances .", "Beyond Gaussian models , the proposed algorithm is also very useful for handling highly non-Gaussian continuously-valued MRFs such as those arising in statistical image modeling or in the first layer of deep belief networks describing real-valued data , where the non-quadratic potentials coupling different sites can be represented as finite or infinite mixtures of Gaussians with the help of local or distributed latent mixture assignment variables .", "We present a technique for exact simulation of Gaussian Markov random fields ( GMRFs ) , which can be interpreted as locally injecting noise to each Gaussian factor independently , followed by computing the mean/mode of the perturbed GMRF .", "Coupled with standard iterative techniques for the solution of symmetric positive definite systems , this yields a very efficient sampling algorithm with essentially linear complexity in terms of speed and memory requirements , well suited to extremely large scale probabilistic models .", "The Bayesian treatment of such models most naturally involves a block Gibbs sampler which alternately draws samples of the conditionally independent latent mixture assignments and the conditionally multivariate Gaussian continuous vector and we show that it can directly benefit from the proposed methods ."]}
{"orig_sents": ["5", "4", "2", "0", "1", "3"], "shuf_sents": ["Based on kernel principal component analysis , we define a projection constraint for each positive bag to classify its constituent instances far away from the separating hyperplane while place positive instances and negative instances at opposite sides .", "We apply the Constrained Concave-Convex Procedure to solve the resulted problem .", "We attempt to utilize the geometric distribution of instances inside positive bags to avoid both the former and the latter .", "Empirical results demonstrate that our approach offers improved generalization performance .", "Current research mainly focus on avoiding the former .", "In multi-instance learning , there are two kinds of prediction failure , i.e. , false negative and false positive ."]}
{"orig_sents": ["4", "2", "3", "1", "0"], "shuf_sents": ["On the problem of collective classification , we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of confidence .", "Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning .", "We prove that marginal computation for constrained continuous MRFs is # P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random field .", "Moreover , we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efficiency .", "Continuous Markov random fields are a general formalism to model joint probability distributions over events with continuous outcomes ."]}
{"orig_sents": ["5", "0", "3", "2", "7", "6", "1", "4"], "shuf_sents": ["However , EVOI-optimization is usually computationally prohibitive .", "We also examine the case where user responses to choice queries are error-prone ( using both constant and mixed multinomial logit noise models ) and provide worst-case guarantees .", "We show that , under very general assumptions , the optimal choice query w.r.t .", "In this paper , we examine EVOI optimization using choice queries , queries in which a user is ask to select her most preferred product from a set .", "Finally we present a local search technique for query optimization that works extremely well with large outcome spaces .", "Bayesian approaches to utility elicitation typically adopt ( myopic ) expected value of information ( EVOI ) as a natural criterion for selecting queries .", "Since recommendation set optimization is a simpler , submodular problem , this can greatly reduce the complexity of both exact and approximate ( greedy ) computation of optimal choice queries .", "EVOI coincides with the optimal recommendation set , that is , a set maximizing the expected utility of the user selection ."]}
{"orig_sents": ["2", "5", "4", "0", "3", "1"], "shuf_sents": ["In the present paper we investigate three regularization schemes based on inter-segment information sharing , choosing different prior distributions and different coupling schemes between nodes .", "We conclude our evaluation with an application to synthetic biology , where the objective is to predict a known in vivo regulatory network of five genes in yeast .", "Conventional dynamic Bayesian networks ( DBNs ) are based on the homogeneous Markov assumption , which is too restrictive in many practical applications .", "We apply our method to gene expression time series obtained during the Drosophila life cycle , and compare the predicted segmentation with other state-of-the-art techniques .", "However , unless time series are very long , this flexibility leads to the risk of overfitting and inflated inference uncertainty .", "Various approaches to relax the homogeneity assumption have recently been proposed , allowing the network structure to change with time ."]}
{"orig_sents": ["3", "4", "7", "6", "2", "1", "0", "5"], "shuf_sents": ["The generative model is validated using a goodness-of-fit test evaluated with a standard database of fingerprints .", "In the specific probability of random correspondence step the evidence probability is used to determine the probability of match among n for a given tolerance ; the last evaluation is similar to the birthday correspondence probability for a specific birthday .", "In the evidence probability evaluation step a generative model based on Bayesian networks is used to determine the probability of the evidence ; it takes into account both the dependency of each minutia on nearby minutiae and the confidence of their presence in the evidence .", "A method for computing the rarity of latent fingerprints represented by minutiae is given .", "It allows determining the probability of finding a match for an evidence print in a database of n known prints .", "The probability of random correspondence for several latent fingerprints are evaluated for varying numbers of minutiae .", "In the registration step the latent print is aligned by finding its core point ; which is done using a procedure based on a machine learning approach based on Gaussian processes .", "The probability of random correspondence between evidence and database is determined in three procedural steps ."]}
{"orig_sents": ["4", "1", "0", "3", "2"], "shuf_sents": ["These models simultaneously segment phoneme sequences into words and learn the relationship between non-linguistic objects to the words that refer to them .", "The models themselves are novel kinds of Adaptor Grammars that are an extension of an embedding of topic models into PCFGs .", "We argue that these results support an interactive view of language acquisition that can take advantage of synergies such as these .", "We show ( i ) that modelling inter-word dependencies not only improves the accuracy of the word segmentation but also of word-object relationships , and ( ii ) that a model that simultaneously learns word-object relationships and word segmentation segments more accurately than one that just learns word segmentation on its own .", "This paper presents Bayesian non-parametric models that simultaneously learn to segment words from phoneme strings and learn the referents of some of those words , and shows that there is a synergistic interaction in the acquisition of these two kinds of linguistic information ."]}
{"orig_sents": ["5", "0", "4", "1", "2", "3"], "shuf_sents": ["The algorithm is based on a simple quadratic bound to the log-sum-exp function .", "We show that EM is significantly more robust in the presence of missing data compared to treating the latent factors as parameters , which is the approach used by exponential family PCA and other related matrix-factorization methods .", "A further benefit of the variational approach is that it can easily be extended to the case of mixtures of factor analyzers , as we show .", "We present results on synthetic and real data sets demonstrating several desirable properties of our proposed method .", "In the special case of fully observed binary data , the bound we propose is significantly faster than previous variational methods .", "We propose a new variational EM algorithm for fitting factor analysis models with mixed continuous and categorical observations ."]}
{"orig_sents": ["8", "6", "5", "7", "4", "0", "2", "1", "10", "3", "9"], "shuf_sents": ["In our first experimental session we estimate the weights of the three terms for each functional form to maximize the fit to human performance .", "We note that the L1-norm is also a better fit to the statistics of motion in natural environments .", "We then measured human performance for motion tasks and found that we obtained better fit for the L1-norm ( Laplace ) than for the L2-norm ( Gaussian ) .", "To validate our results further , we used the best fit models using the L1-norm to predict human performance in a second session with different experimental setups .", "We focused on two functional forms for prior distributions : L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively .", "More specifically , we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks .", "The basic goal of our work is to discover experimentally which prior distribution is used .", "We restricted ourselves to priors which combine three terms for motion slowness , first-order smoothness , and second-order smoothness .", "It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal , or rational , manner .", "Our results showed excellent agreement between human performance and model prediction - ranging from 3 % to 8 % for five human subjects over ten experimental conditions - and give further support that the human visual system uses an L1-norm ( Laplace ) prior .", "In addition , we found large weights for the second-order smoothness term , indicating the importance of high-order smoothness compared to slowness and lower-order smoothness ."]}
{"orig_sents": ["4", "2", "5", "0", "3", "6", "1"], "shuf_sents": ["Using stable distributions , a heavy-tailed family of distributions which is a generalization of Cauchy , Levy and Gaussian distributions , we show for the first time , how to compute both exact and approximate inference in such a linear multivariate graphical model .", "Other potential application is iterative decoding of linear channels with non-Gaussian noise .", "Unfortunately , it is typically not possible to compute inference in closed-form in graphical models which involve such heavy-tailed distributions .", "LCMs are not limited to stable distributions , in fact LCMs are always defined for any random variables ( discrete , continuous or a mixture of both ) .", "Heavy-tailed distributions naturally occur in many real life problems .", "In this work , we propose a novel simple linear graphical model for independent latent random variables , called linear characteristic model ( LCM ) , defined in the characteristic function domain .", "We provide a realistic problem from the field of computer networks to demonstrate the applicability of our construction ."]}
{"orig_sents": ["1", "5", "6", "2", "4", "3", "0"], "shuf_sents": ["The simulation results demonstrate that the DN in VLSI is able to regenerate various types of continuous paths in real-time .", "The Diffusion Network ( DN ) is a stochastic recurrent network which has been shown capable of modeling the distributions of continuous-valued , continuoustime paths .", "Moreover , the logdomain representation is applied to the DN , allowing the supply voltage and thus the power consumption to be reduced without limiting the dynamic ranges for diffusion processes .", "The design of component circuits will be described , so will the simulation of the full system be presented .", "A VLSI chip containing a DN with two stochastic units has been designed and fabricated .", "However , the dynamics of the DN are governed by stochastic differential equations , making the DN unfavourable for simulation in a digital computer .", "This paper presents the implementation of the DN in analogue Very Large Scale Integration , enabling the DN to be simulated in real time ."]}
{"orig_sents": ["3", "0", "1", "4", "2", "6", "5"], "shuf_sents": ["We study inference and communication in a television game called Password , where speakers must convey secret words to hearers by providing one-word clues .", "Our working hypothesis is that human communication is relatively efficient , and we use game show data to examine three predictions .", "Second , we predict that speakers and hearers are calibrated , and that both make accurate assumptions about the strategy used by the other .", "Communication between a speaker and hearer will be most efficient when both parties make accurate inferences about the other .", "First , we predict that speakers and hearers are both considerate , and that both take the other 's perspective into account .", "We find evidence in support of all three predictions , and demonstrate in addition that efficient communication tends to break down when speakers and hearers are placed under time pressure .", "Finally , we predict that speakers and hearers are collaborative , and that they tend to share the cognitive burden of communication equally ."]}
{"orig_sents": ["8", "9", "5", "0", "1", "6", "7", "2", "4", "3"], "shuf_sents": ["By comparison , subspace identification ( SSID ) methods are designed to select a feature set which preserves as much information as possible about state .", "In this paper we connect the two approaches , looking at the problem of reinforcement learning with a large set of features , each of which may only be marginally useful for value function approximation .", "As in RL , PSTD then uses a Bellman recursion to estimate a value function .", "We prove that PSTD is statistically consistent , perform several experiments that illustrate its properties , and demonstrate its potential on a difficult optimal stopping problem .", "We discuss the connection between PSTD and prior approaches in RL and SSID .", "Therefore , RL methods are designed to work with features of state rather than state itself , and the success or failure of learning is often determined by the suitability of the selected features .", "We introduce a new algorithm for this situation , called Predictive State Temporal Difference ( PSTD ) learning .", "As in SSID for predictive state representations , PSTD finds a linear compression operator that projects a large set of features down to a small set that preserves the maximum amount of predictive information .", "We propose a new approach to value function approximation which combines linear temporal difference reinforcement learning with subspace identification .", "In practical applications , reinforcement learning ( RL ) is complicated by the fact that state is either high-dimensional or partially observable ."]}
{"orig_sents": ["1", "3", "4", "0", "5", "2"], "shuf_sents": ["In particular , we show that structured sparsity allows us to address the multiview learning problem by alternately solving two convex optimization problems .", "Recent approaches to multi-view learning have shown that factorizing the information into parts that are shared across all views and parts that are private to each view could effectively account for the dependencies and independencies between the different input modalities .", "We show that our approach outperforms state-of-the-art methods on the task of human pose estimation .", "Unfortunately , these approaches involve minimizing non-convex objective functions .", "In this paper , we propose an approach to learning such factorized representations inspired by sparse coding techniques .", "Furthermore , the resulting factorized latent spaces generalize over existing approaches in that they allow having latent dimensions shared between any subset of the views instead of between all the views only ."]}
{"orig_sents": ["2", "5", "4", "0", "3", "1"], "shuf_sents": ["This formulation is invariant to scalings of learned kernels , and when learning linear combination of basis kernels it is also invariant to scalings of basis kernels and to the types ( e.g. , L1 or L2 ) of norm constraints on combination coefficients .", "Experiments show that our method significantly outperforms both SVM with the uniform combination of basis kernels and other state-of-art MKL approaches .", "In this paper , we point out that there exist scaling and initialization problems in most existing multiple kernel learning ( MKL ) approaches , which employ the large margin principle to jointly learn both a kernel and an SVM classifier .", "We establish the differentiability of our formulation , and propose a gradient projection algorithm for kernel learning .", "We use the ratio between the margin and the radius of the minimum enclosing ball to measure the goodness of a kernel , and present a new minimization formulation for kernel learning .", "The reason is that the margin itself can not well describe how good a kernel is due to the negligence of the scaling ."]}
{"orig_sents": ["7", "3", "0", "2", "8", "6", "5", "1", "4"], "shuf_sents": ["Typically , interactive expert guided segmentation has been the method of choice for such applications , but this is tedious for large datasets common today .", "Making use of recent results on image co-segmentation , we derive effective solution strategies for our problem .", "To address this problem , we endow an image segmentation algorithm with `` advice '' encoding some global characteristics of the region ( s ) we want to extract .", "This is an important requirement in many Neuroimaging studies : for instance , to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images .", "We provide an analysis of solution quality , and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm .", "We present combinatorial approximation algorithms to incorporate such domain specific constraints for Markov Random Field ( MRF ) segmentation .", "Now , given such a representation , the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-specified histogram over features .", "We study the problem of segmenting specific white matter structures of interest from Diffusion Tensor ( DT-MR ) images of the human brain .", "This is accomplished by constructing ( using expert-segmented images ) an epitome of a specific region - as a histogram over a bag of `words ' ( e.g. , suitable feature descriptors ) ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature .", "Using a novel copula-based reparameterization of a conditional density , joined with a graph that encodes independencies , our model offers great flexibility in modeling high-dimensional densities , while maintaining control over the form of the univariate marginals .", "We present the Copula Bayesian Network model for representing multivariate continuous distributions , while taking advantage of the relative ease of estimating univariate distributions ."]}
{"orig_sents": ["3", "1", "5", "6", "0", "4", "2"], "shuf_sents": ["The proposed method offers an efficient dimension reduction strategy using Laplacian eigenmaps with Neumann boundary conditions , and provides a flexible inference framework for analysis of subnetworks , based on a group-penalized principal component regression model on graphs .", "To understand their behavior , it is often necessary to analyze functionally related components of the system , corresponding to subsystems .", "The performance of the proposed methodology is illustrated using simulated and real data examples from biology .", "Network models are widely used to capture interactions among component of complex systems , such as social and biological .", "Asymptotic properties of the proposed inference method , as well as the choice of the tuning parameter for control of the false positive rate are discussed in high dimensional settings .", "Therefore , the analysis of subnetworks may provide additional insight into the behavior of the system , not evident from individual components .", "We propose a novel approach for incorporating available network information into the analysis of arbitrary subnetworks ."]}
{"orig_sents": ["5", "8", "3", "6", "7", "1", "0", "4", "2"], "shuf_sents": ["Here is the desired bound on the error and is a bound on the probability of failure .", "Whether the known lower bound of O ( k2 + 2 ) for the sample complexity of Empirical Risk minimization on k-means applied to data in a unit ball of arbitrary dimension is tight , has been an open question since 1997 .", "Based on these results , we devise a simple algorithm for k-means and another that uses a family of convex programs to fit a piecewise linear curve of a specified length to high dimensional data , where the sample complexity is independent of the ambient dimension .", "Given upper bounds on the dimension , volume , and curvature , we show that Empirical Risk Minimization can produce a nearly optimal manifold using a number of random samples that is independent of the ambient dimension of the space in which data lie .", "We improve the best currently known upper bound of 2 log 1 log4 k log 1 O ( k2 + 2 ) to O k2 min k , 2 + 2 .", "The hypothesis that high dimensional data tends to lie in the vicinity of a low dimensional manifold is the basis of a collection of methodologies termed Manifold Learning .", "We obtain an upper bound on the required number of samples that depends polynomially on the curvature , exponentially on the intrinsic dimension , and linearly on the intrinsic volume .", "For constant error , we prove a matching minimax lower bound on the sample complexity that shows that this dependence on intrinsic dimension , volume log 1 and curvature is unavoidable .", "In this paper , we study statistical aspects of the question of fitting a manifold with a nearly optimal least squared error ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Our algorithm does not need to store old statistics for all data .", "The proposed algorithm is much faster than a batch algorithm and is comparable to the batch algorithm in terms of perplexity in experiments .", "We develop a deterministic single-pass algorithm for latent Dirichlet allocation ( LDA ) in order to process received documents one at a time and then discard them in an excess text stream ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We consider an empirical risk minimization algorithm , called Privileged ERM , that takes into account the privileged information in order to find a good function in the decision space .", "The goal of the learner is to find a classifier with a low generalization error in the decision space .", "In Learning Using Privileged Information ( LUPI ) paradigm , along with the standard training data in the decision space , a teacher supplies a learner with the privileged information in the correcting space .", "We outline the conditions on the correcting space that , if satisfied , allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization ."]}
{"orig_sents": ["4", "6", "0", "2", "5", "3", "1"], "shuf_sents": ["We present the MCI-algorithm as the first method that can infer provably valid causal relations in the large sample limit from different experiments .", "The method shows promising signs that it can be adapted to suit causal discovery in real-world application areas as well , including large databases .", "It is fast , reliable and produces very clear and easily interpretable output .", "We test the algorithm on a variety of synthetic input model sets to assess its behavior and the quality of the output .", "A long-standing open research problem is how to use information from different experiments , including background knowledge , to infer causal relations .", "It is based on a result that shows that constraint-based causal discovery is decomposable into a candidate pair identification and subsequent elimination step that can be applied separately from different models .", "Recent developments have shown ways to use multiple data sets , provided they originate from identical experiments ."]}
{"orig_sents": ["3", "0", "1", "2", "4"], "shuf_sents": ["The goal is to minimize the regret with respect to total reward of the best slate computed in hindsight .", "We consider unordered and ordered versions of the problem , and give efficient algorithms which have regret O ( T ) , where the constant depends on the specific nature of the problem .", "We also consider versions of the problem where we have access to a number of policies whichmake recommendations for slates in every round , and give algorithms with O ( T ) regret for competing with the best such policy as well .", "We consider bandit problems , motivated by applications in online advertising and news story selection , in which the learner must repeatedly select a slate , that is , a subset of size s from K possible actions , and then receives rewards for just the selected actions .", "We make use of the technique of relative entropy projections combined with the usual multiplicative weight update algorithm to obtain our algorithms ."]}
{"orig_sents": ["2", "6", "1", "5", "4", "3", "0"], "shuf_sents": ["Finally , we illustrate the application of the model to the problem of updating Wikipedia category graphs .", "The proposed model can learn different types of concept graph structures and is capable of utilizing partial prior knowledge about graph structure as well as labeled documents .", "We present a generative probabilistic model for learning general graph structures , which we term concept graphs , from text .", "We also show that the proposed model is competitive in terms of empirical log likelihood with existing structure-based topic models ( hPAM and hLDA ) on real-world text data sets .", "Experiments on simulated data show that the model can recover known graph structure when learning in both unsupervised and semi-supervised modes .", "We describe a generative model that is based on a stick-breaking process for graphs , and a Markov Chain Monte Carlo inference procedure .", "Concept graphs provide a visual summary of the thematic content of a collection of documents -- a task that is difficult to accomplish using only keyword search ."]}
{"orig_sents": ["0", "4", "6", "1", "3", "2", "5"], "shuf_sents": ["In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly .", "We introduce an alternative way to approximate the maximum expected value for any set of random variables .", "We apply the double estimator to Q-learning to construct Double Q-learning , a new off-policy reinforcement learning algorithm .", "The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value .", "This poor performance is caused by large overestimations of action values .", "We show the new algorithm converges to the optimal policy and that it performs well in some settings in which Q-learning performs poorly due to its overestimation .", "These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value ."]}
{"orig_sents": ["1", "5", "2", "3", "0", "6", "4"], "shuf_sents": ["We propose an efficient procedure which computes its solution exactly in polynomial time .", "We consider a class of learning problems that involve a structured sparsityinducing norm defined as the sum of -norms over groups of variables .", "To this end , we show that the corresponding optimization problem is related to network flow optimization .", "More precisely , the proximal problem associated with the norm we consider is dual to a quadratic min-cost flow problem .", "We present several experiments on image and video data , demonstrating the applicability and scalability of our approach for various problems .", "Whereas a lot of effort has been put in developing fast optimization methods when the groups are disjoint or embedded in a specific hierarchical structure , we address here the case of general overlapping groups .", "Our algorithm scales up to millions of variables , and opens up a whole new range of applications for structured sparse models ."]}
{"orig_sents": ["3", "1", "6", "8", "7", "4", "9", "2", "5", "0"], "shuf_sents": ["StARS outperforms all these competing procedures .", "The standard techniques include K-fold cross-validation ( K-CV ) , Akaike information criterion ( AIC ) , and Bayesian information criterion ( BIC ) .", "with high probability , all the true edges will be included in the selected model even when the graph size diverges with the sample size .", "A challenging problem in estimating high-dimensional graphical models is to choose the regularization parameter in a data-dependent way .", "This interpretation requires essentially no conditions .", "Empirically , the performance of StARS is compared with the state-of-the-art model selection procedures , including K-CV , AIC , and BIC , on both synthetic data and a real microarray dataset .", "Though these methods work well for low-dimensional problems , they are not suitable in high dimensional settings .", "The method has a clear interpretation : we use the least amount of regularization that simultaneously makes a graph sparse and replicable under random sampling .", "In this paper , we present StARS : a new stability-based method for choosing the regularization parameter in high dimensional inference for undirected graphs .", "Under mild conditions , we show that StARS is partially sparsistent in terms of graph estimation : i.e ."]}
{"orig_sents": ["4", "5", "1", "3", "0", "2", "6"], "shuf_sents": ["Here , we show how goodness-of-fit tests from point-process theory can still be applied to GLMs by constructing equivalent surrogate point processes out of time-series observations .", "the time-rescaling theorem .", "Furthermore , two additional tests based on thinning and complementing point processes are introduced .", "However , high neural firing rates or coarse discretization lead to a breakdown of the assumptions necessary for this connection .", "Generalized Linear Models ( GLMs ) are an increasingly popular framework for modeling neural spike trains .", "They have been linked to the theory of stochastic point processes and researchers have used this relation to assess goodness-of-fit using methods from point-process theory , e.g .", "They augment the instruments available for checking model adequacy of point processes as well as discretized models ."]}
{"orig_sents": ["4", "9", "3", "1", "2", "7", "5", "8", "0", "6"], "shuf_sents": ["We develop a novel variant of the latent SVM framework to model them as latent variables .", "This mapping allows us to relate image regions to their corresponding annotation terms .", "We also model the overall scene label as latent information .", "In particular , we model the mapping that translates image regions to annotations .", "We propose a discriminative latent model for annotating images with unaligned object-level textual annotations .", "Our training data consist of images and their associated annotations .", "Our experimental results demonstrate the effectiveness of the proposed model compared with other baseline methods .", "This allows us to cluster test images .", "But we do not have access to the ground-truth regionto-annotation mapping or the overall scene label .", "Instead of using the bag-of-words image representation currently popular in the computer vision community , our model explicitly captures more intricate relationships underlying visual and textual information ."]}
{"orig_sents": ["3", "5", "1", "6", "0", "2", "4"], "shuf_sents": ["We show how this factorization leads to tractable algorithms for exact inference , including computing marginals , computing conditional probabilities , and sampling .", "Our model is a marriage of structured probabilistic models , like Markov random fields and context free grammars , with determinantal point processes , which arise in quantum physics as models of particles with repulsive interactions .", "Our algorithms exploit a novel polynomially-sized dual representation of determinantal point processes , and use message passing over a special semiring to compute relevant quantities .", "We present a novel probabilistic model for distributions over sets of structures -- for example , sets of sequences , trees , or graphs .", "We illustrate the advantages of the model on tracking and articulated pose estimation problems .", "The critical characteristic of our model is a preference for diversity : sets containing dissimilar structures are more likely .", "We extend the determinantal point process model to handle an exponentially-sized set of particles ( structures ) via a natural factorization of the model into parts ."]}
{"orig_sents": ["2", "0", "1", "4", "6", "3", "5"], "shuf_sents": ["The classic Hodgkin-Huxley model of action potential generation is notoriously inefficient in that regard with about 4 times more charges flowing through the membrane than the theoretical minimum required to achieve the observed depolarization .", "Yet , recent experimental results show that mammalian neurons are close to the optimal metabolic efficiency and that the dynamics of their voltage-gated channels is significantly different than the one exhibited by the classic Hodgkin-Huxley model during the action potential .", "Sodium entry during an action potential determines the energy efficiency of a neuron .", "We speak here about a family of models because the model is parameterized by a unique parameter the variations of which allow to reproduce the entire range of experimental observations from cortical pyramidal neurons to Purkinje cells , yielding a very economical framework to model a wide range of different central neurons .", "Nevertheless , the original Hodgkin-Huxley model is still widely used and rarely to model the squid giant axon from which it was extracted .", "The present paper demonstrates the performances and discuss the properties of this new family of models .", "Here , we introduce a novel family of HodgkinHuxley models that correctly account for sodium entry , action potential width and whose voltage-gated channels display a dynamics very similar to the most recent experimental observations in mammalian neurons ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["To that end , we introduce POMDPs , an extension of POMDPs where the reward function depends on the belief state .", "Partially Observable Markov Decision Processes ( POMDPs ) model sequential decision-making problems under uncertainty and partial observability .", "Unfortunately , some problems can not be modeled with state-dependent reward functions , e.g. , problems whose objective explicitly implies reducing the uncertainty on the state .", "We show that , under the common assumption that is convex , the value function is also convex , what makes it possible to ( 1 ) approximate arbitrarily well with a piecewise linear and convex ( PWLC ) function , and ( 2 ) use state-of-the-art exact or approximate solving algorithms with limited changes ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["In the setting of online convex optimization and repeated games , the algorithm yields low regret and presents a novel efficient method for implementing mixture forecasting strategies .", "We propose a computationally efficient random walk on a convex body which rapidly mixes to a time-varying Gibbs distribution ."]}
{"orig_sents": ["2", "6", "1", "8", "5", "3", "4", "9", "0", "7"], "shuf_sents": ["Randomization enables to adapt to any possible distribution .", "GP is defined as the span of P random features that are linear combinations of the basis functions of F weighted by random Gaussian i.i.d .", "We consider least-squares regression using a randomly generated subspace GP F of finite dimension P , where F is a function space of infinite dimension , e.g .", "In this latter case , the resulting Gaussian objects are called scrambled wavelets and we show that they enable to approximate functions in Sobolev spaces H s ( d ) .", "As a result , given N data , the least-squares estimate g built from P scrambled wavelets has excess risk ||f - g||2P = O ( ||f ||2H s ( d ) ( log N ) /P + P ( log N ) /N ) for target functions f H s ( d ) of smoothness order s > d/2 .", "In particular , we consider multi-resolution random combinations at all scales of a given mother function , such as a hat function or a wavelet .", "L2 ( d ) .", "We conclude by describing an efficient numerical implementation using lazy ex d N 3/2 log N + N 2 ) , where d is the dipansions with numerical complexity O ( 2 mension of the input space .", "coefficients .", "An interesting aspect of the resulting bounds is that they do not depend on the distribution P from which the data are generated , which is important in a statistical regression setting considered here ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["This procedure provides a scalable alternative with no need for data duplication , and allows to deal with high dimensional problems without pre-processing for dimensionality reduction .", "While in the proposed implementation requires explicit replication of the variables belonging to more than one group , our iterative procedure is based on a combination of proximal methods in the primal space and projected Newton method in a reduced dual space , corresponding to the active groups .", "The computational advantages of our scheme with respect to state-of-the-art algorithms using data duplication are shown empirically with numerical simulations .", "In particular we propose a new optimization procedure for solving the regularized algorithm presented in , where the group lasso penalty is generalized to overlapping groups of variables .", "We deal with the problem of variable selection when variables must be selected group-wise , with possibly overlapping groups defined a priori ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We derive sample complexity bounds in this framework that apply both to the supervised setting and the unsupervised setting .", "Probabilistic grammars are generative statistical models that are useful for compositional and sequential structures .", "We present a framework , reminiscent of structural risk minimization , for empirical risk minimization of the parameters of a fixed probabilistic grammar using the log-loss ."]}
{"orig_sents": ["3", "1", "5", "0", "2", "4"], "shuf_sents": ["The method may be used for an effective screening of potentially interesting genotype-phenotype and biomarker-phenotype associations in genome-wide studies , which may have important implications for validating biomarkers as possible proxy endpoints for early-stage clinical trials .", "The framework builds on sparse linear methods developed for regression and modified here for inferring causal structures of richer networks with latent variables .", "Where the biomarkers are gene transcripts , the method can be used for fine mapping of quantitative trait loci ( QTLs ) detected in genetic linkage studies .", "This paper describes a probabilistic framework for studying associations between multiple genotypes , biomarkers , and phenotypic traits in the presence of noise and unobserved confounders for large genetic studies .", "The method is applied for examining effects of gene transcript levels in the liver on plasma HDL cholesterol levels for a sample of sequenced mice from a heterogeneous stock , with 105 genetic instruments and 47 x 103 gene transcripts .", "The method is motivated by the use of genotypes as `` instruments '' to infer causal associations between phenotypic biomarkers and outcomes , without making the common restrictive assumptions of instrumental variable methods ."]}
{"orig_sents": ["2", "4", "1", "0", "3"], "shuf_sents": ["The techniques reported here lift these restrictions , allowing the learning of a policy for choosing actions given features from historical data where no randomization occurred or was logged .", "Prior solutions here require either control of the actions during the learning process , recorded random exploration , or actions chosen obliviously in a repeated manner .", "We provide a sound and consistent foundation for the use of nonrandom exploration data in `` contextual bandit '' or `` partially labeled '' settings where only the value of a chosen action is learned .", "We empirically verify our solution on two reasonably sized sets of real-world data obtained from Yahoo ! .", "The primary challenge in a variety of settings is that the exploration policy , in which `` offline '' data is logged , is not explicitly known ."]}
{"orig_sents": ["3", "4", "0", "2", "1"], "shuf_sents": ["Afterwards , we show how this bound can be improved for MRFs with specific structures such as bipartite graphs or grids .", "For example , we prove that max-product provides very good results ( at least 90 % optimal ) on MRFs with large variable-disjoint cycles1 .", "Our results provide interesting insight into the behavior of max-product .", "We study worst-case bounds on the quality of any fixed point assignment of the max-product algorithm for Markov Random Fields ( MRF ) .", "We start providing a bound independent of the MRF structure and parameters ."]}
{"orig_sents": ["4", "2", "5", "3", "1", "0"], "shuf_sents": ["We analyze the reasons why the sphere constraint is beneficial in this application , and conjecture that these reasons might apply quite generally to other large-scale tasks .", "Using k-means clustering of the embedded data , our approach efficiently produces state-of-the-art results .", "We use the CODE model of Globerson et al .", "This constraint allows for efficient optimization , even in the case of large datasets and high embedding dimensionality .", "Motivated by an application to unsupervised part-of-speech tagging , we present an algorithm for the Euclidean embedding of large sets of categorical data based on co-occurrence statistics .", "but constrain the embedding to lie on a hig hdimensional unit sphere ."]}
{"orig_sents": ["2", "1", "0", "6", "5", "7", "3", "4"], "shuf_sents": ["Prior work , in the case of gaussian input sequences and linear neuronal networks , shows that the duration of memory traces in a network can not exceed the number of neurons ( in units of the neuronal time constant ) , and that no network can out-perform an equivalent feedforward network .", "Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size , connectivity and signal statistics .", "Recent proposals suggest that large , generic neuronal networks could store memory traces of past input sequences in their instantaneous state .", "We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size , signal sparsity and integration time .", "Alternately , viewed purely from the perspective of CS , this work introduces a new ensemble of measurement matrices derived from dynamical systems , and provides a theoretical analysis of their asymptotic performance .", "In this scenario , we show how linear neural networks can essentially perform compressed sensing ( CS ) of past inputs , thereby attaining a memory capacity that exceeds the number of neurons .", "However a more ethologically relevant scenario is that of sparse input sequences .", "This enhanced capacity is achieved by a class of `` orthogonal '' recurrent networks and not by feedforward networks or generic recurrent networks ."]}
{"orig_sents": ["1", "4", "3", "0", "2"], "shuf_sents": ["Our approach is based on translating the appropriate belief propagation equations to the graph ensemble .", "We study learning curves for Gaussian process regression which characterise performance in terms of the Bayes error averaged over datasets of a given size .", "We demonstrate the accuracy of the predictions for Poisson ( Erdos-Renyi ) and regular random graphs , and discuss when and why previous approximations of the learning curve fail .", "These should in fact become exact for large graphs drawn from a broad range of random graph ensembles with arbitrary degree distributions where each input ( node ) is connected only to a finite number of others .", "Whilst learning curves are in general very difficult to calculate we show that for discrete input domains , where similarity between input points is characterised in terms of a graph , accurate predictions can be obtained ."]}
{"orig_sents": ["1", "4", "0", "7", "5", "3", "6", "2"], "shuf_sents": ["It is then shown that the new measure can be computed with a network that implements the sequence of operations of the standard neurophysiological model of V1 .", "The determination of dominant orientation at a given image location is formulated as a decision-theoretic question .", "This is shown to lead to significant gains for classification tasks , leading to state-of-the-art performance among biologically inspired network models and performance competitive with the best non-biological object recognition systems .", "The connection between SIFT and biological vision provides a justification for the success of SIFT-like features and reinforces the importance of contrast normalization in computer vision .", "This leads to a novel measure for the dominance of a given orientation , which is similar to that used by SIFT .", "The network units are shown to exhibit trademark properties of V1 neurons , such as cross-orientation suppression , sparseness and independence .", "We illustrate this by replacing the Gabor units of an HMAX network with the new bioSIFT units .", "The measure can thus be seen as a biologically plausible version of SIFT , and is denoted as bioSIFT ."]}
{"orig_sents": ["0", "3", "4", "5", "2", "1"], "shuf_sents": ["Recent experimental work has suggested that the neural firing rate can be interpreted as a fractional derivative , at least when signal variation induces neural adaptation .", "As power-law kernels can be accurately approximated using sums or cascades of weighted exponentials , we demonstrate that the corresponding decoding of spiketrains by a receiving neuron allows for natural and transparent temporal signal filtering by tuning the weights of the decoding kernel .", "For such signals , the online power-law kernel approximation typically required less than half the number of spikes for similar SNR as compared to sums of similar but exponentially decaying kernels .", "Here , we show that the actual neural spike-train itself can be considered as the fractional derivative , provided that the neural signal is approximated by a sum of power-law kernels .", "A simple standard thresholding spiking neuron suffices to carry out such an approximation , given a suitable refractory response .", "Empirically , we find that the online approximation of signals with a sum of powerlaw kernels is beneficial for encoding signals with slowly varying components , like long-memory self-similar signals ."]}
{"orig_sents": ["2", "6", "1", "0", "5", "4", "3"], "shuf_sents": ["Under these conditions , our theory guarantees that Nesterov 's first-order method has a globally geometric rate of convergence up to the statistical precision of the model , meaning the typical Euclidean distance between the true unknown parameter and the optimal solution .", "We define appropriately restricted versions of these conditions , and show that they are satisfied with high probability for various statistical models .", "Many statistical M -estimators are based on convex optimization problems formed by the weighted sum of a loss function with a norm-based regularizer .", "Overall , this result reveals an interesting connection between statistical precision and computational efficiency in high-dimensional estimation .", "Our analysis applies to a wide range of M -estimators and statistical models , including sparse linear regression using Lasso ( 1 regularized regression ) , group Lasso , block sparsity , and low-rank matrix recovery using nuclear norm regularization .", "This globally linear rate is substantially faster than previous analyses of global convergence for specific methods that yielded only sublinear rates .", "We analyze the convergence rates of first-order gradient methods for solving such problems within a high-dimensional framework that allows the data dimension d to grow with ( and possibly exceed ) the sample size n. This high-dimensional structure precludes the usual global assumptions -- namely , strong convexity and smoothness conditions -- that underlie classical optimization analysis ."]}
{"orig_sents": ["4", "0", "5", "7", "1", "2", "3", "6"], "shuf_sents": ["The SMO algorithm is simple , easy to implement and adapt , and efficiently scales to large problems .", "Unfortunately , the standard MKL dual is not differentiable , and therefore can not be optimised using SMO style co-ordinate ascent .", "In this paper , we demonstrate that linear MKL regularised with the p-norm squared , or with certain Bregman divergences , can indeed be trained using SMO .", "The resulting algorithm retains both simplicity and efficiency and is significantly faster than state-of-the-art specialised p-norm MKL solvers .", "Our objective is to train p-norm Multiple Kernel Learning ( MKL ) and , more generally , linear MKL regularised by the Bregman divergence , using the Sequential Minimal Optimization ( SMO ) algorithm .", "As a result , it has gained widespread acceptance and SVMs are routinely trained using SMO in diverse real world applications .", "We show that we can train on a hundred thousand kernels in approximately seven minutes and on fifty thousand points in less than half an hour on a single core .", "Training using SMO has been a long standing goal in MKL for the very same reasons ."]}
{"orig_sents": ["0", "1", "2", "4", "3"], "shuf_sents": ["We present a fast online solver for large scale parametric max-flow problems as they occur in portfolio optimization , inventory management , computer vision , and logistics .", "Our algorithm solves an integer linear program in an online fashion .", "It exploits total unimodularity of the constraint matrix and a Lagrangian relaxation to solve the problem as a convex online game .", "We apply the algorithm to optimize tier arrangement of over 84 million web pages on a layered set of caches to serve an incoming query stream optimally .", "The algorithm generates approximate solutions of max-flow problems by performing stochastic gradient descent on a set of flows ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["The computational cost of this algorithm is equal to that of conventional policy gradients whereas previous natural policy gradient methods have a prohibitive computational cost .", "Experimental results show that the proposed method outperforms several policy gradient methods .", "Unlike previous methods based on natural gradients , our algorithm calculates the natural policy gradient using the inverse of the exact Fisher information matrix .", "In this paper , we propose an efficient algorithm for estimating the natural policy gradient using parameter-based exploration ; this algorithm samples directly in the parameter space ."]}
{"orig_sents": ["3", "1", "7", "6", "5", "4", "0", "2"], "shuf_sents": ["Our method has been applied into both genomic and proteomic biomarkers discovery .", "Especially in many bioinformatics tasks , efficient and robust feature selection methods are desired to extract meaningful features and eliminate noisy ones .", "Extensive empirical studies are performed on six data sets to demonstrate the performance of our feature selection method .", "Feature selection is an important component of many machine learning applications .", "Our regression based objective makes the feature selection process more efficient .", "An efficient algorithm is introduced with proved convergence .", "The 2,1 -norm based loss function is robust to outliers in data points and the 2,1 norm regularization selects features across all data points with joint sparsity .", "In this paper , we propose a new robust feature selection method with emphasizing joint 2,1 -norm minimization on both loss function and regularization ."]}
{"orig_sents": ["2", "7", "5", "3", "1", "8", "0", "6", "4", "9"], "shuf_sents": ["( 2 ) The user may want to produce movements at varying speeds .", "position and velocity of the arm , evolves over time - a so-called trajectory model .", "Applications of Brain-Machine-Interfaces typically estimate user intent based on biological signals that are under voluntary control .", "To do so , state of the art approaches typically use a probabilistic model of how the state , e.g .", "Approximate inference on that generative model is implemented using a mixture of extended Kalman filters .", "To solve such problems it is necessary to integrate obtained information over time .", "We thus use a generative model with a trajectory model incorporating these insights .", "For example , we might want to estimate how a patient with a paralyzed arm wants to move based on residual muscle activity .", "We wanted to further develop this approach using two intuitive insights : ( 1 ) At any given point of time there may be a small set of likely movement targets , potentially identified by the location of objects in the workspace or by gaze information from the user .", "We find that the resulting algorithm allows us to decode arm movements dramatically better than when we use a trajectory model with linear dynamics ."]}
{"orig_sents": ["2", "0", "1", "4", "3"], "shuf_sents": ["This is in contrast with existing methods which either assume that the label sets shared by different tasks are the same or that there exists a label mapping oracle .", "Our method directly maximizes the mutual information among the labels , and we show that the resulting objective function can be efficiently optimized using existing algorithms .", "We propose an algorithm to perform multitask learning where each task has potentially distinct label sets and label correspondences are not readily available .", "and DMOZ web directories .", "Our proposed approach has a direct application for data integration with different label spaces , such as integrating Yahoo !"]}
{"orig_sents": ["2", "4", "0", "3", "1"], "shuf_sents": ["In this paper , we theoretically characterize the sample complexity of active learning in the non-realizable case under multi-view setting .", "We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is O ( 1 ) , where the order of 1/ is independent of the parameter in Tsybakov noise , contrasting to previous polynomial bounds where the order of 1/ is related to the parameter in Tsybakov noise .", "The sample complexity of active learning under the realizability assumption has been well-studied .", "We prove that , with unbounded Tsybakov noise , the sample complexity of multi-view active learning can be O ( log 1 ) , contrasting to single-view setting where the polynomial improvement is the best possible achievement .", "The realizability assumption , however , rarely holds in practice ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We introduce priors that bias the agent towards models with both simple representations and simple policies , resulting in improved policy and model learning .", "We consider reinforcement learning in partially observable domains where the agent can query an expert for demonstrations .", "Our nonparametric Bayesian approach combines model knowledge , inferred from expert information and independent exploration , with policy knowledge inferred from expert trajectories ."]}
{"orig_sents": ["5", "4", "2", "1", "0", "3"], "shuf_sents": ["When applied to time-evolving social media content , our models yield a new family of causality-based influence measures that may be seen as an alternative to the classic PageRank algorithm traditionally applied to hyperlink graphs .", "Within this framework , we then formulate the problem of inferring causal relationships over a collection of high-dimensional time series variables .", "This extension accounts for arbitrary sparsity patterns induced by domain-specific groupings over both input and output variables , while also taking advantage of the correlation that may exist between the multiple outputs .", "Theoretical guarantees , extensive simulations and empirical studies confirm the generality and value of our framework .", "To efficiently address such problems , we propose a variable selection method , Multivariate Group Orthogonal Matching Pursuit , which extends the standard Orthogonal Matching Pursuit technique .", "We consider multivariate regression problems involving high-dimensional predictor and response spaces ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["In particular , we study the least-squares temporal difference ( LSTD ) learning algorithm when a space of low dimension is generated with a random projection from a highdimensional space .", "We also show how the error of LSTD with random projections is propagated through the iterations of a policy iteration algorithm and provide a performance bound for the resulting least-squares policy iteration ( LSPI ) algorithm .", "We provide a thorough theoretical analysis of the LSTD with random projections and derive performance bounds for the resulting algorithm .", "We consider the problem of reinforcement learning in high-dimensional spaces when the number of features is bigger than the number of samples ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["As the neuron is dedicated as a universal device for neuroscientific experiments , the focus lays on parameterizability and reproduction of the analytical model .", "Firing patterns of the membrane stimulated by a step current are analyzed in transistor level simulations and in silicon on a prototype chip .", "The neuron is destined to be the hardware neuron of a highly integrated wafer-scale system reaching out for new computational paradigms and opening new experimentation possibilities .", "We describe an accelerated hardware neuron being capable of emulating the adaptive exponential integrate-and-fire neuron model ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["Often , however , we are confronted with `` outliers '' in input space , which are isolated observations in sparsely populated regions .", "We show that heavy-tailed stochastic processes ( which we construct from Gaussian processes via a copula ) , can be used to improve robustness of regression and classification estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions .", "Heavy-tailed distributions are often used to enhance the robustness of regression and classification methods to outliers in output space .", "We carry out a theoretical analysis to show that selective shrinkage occurs when the marginals of the heavy-tailed process have sufficiently heavy tails .", "The analysis is complemented by experiments on biological data which indicate significant improvements of estimates in sparse regions while producing competitive results in dense regions ."]}
{"orig_sents": ["3", "4", "1", "2", "5", "0"], "shuf_sents": ["We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model .", "We show that , due to the conjugacy of the Gamma prior , it is possible to derive efficient inference procedures for both the coefficients and the scale parameter .", "When the scale parameters of a group of coefficients are combined into a single variable , it is possible to describe the dependencies that occur due to common amplitude fluctuations among coefficients , which have been shown to constitute a large fraction of the redundancy in natural images .", "We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture ( LSM ) prior to model dependencies among coefficients .", "Each coefficient is modeled as a Laplacian distribution with a variable scale parameter , with a Gamma distribution prior over the scale parameter .", "We show that , as a consequence of this group sparse coding , the resulting inference of the coefficients follows a divisive normalization rule , and that this may be efficiently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex ."]}
{"orig_sents": ["7", "6", "4", "1", "5", "2", "3", "0"], "shuf_sents": ["Experiments conducted on several benchmark datasets demonstrate the effectiveness of WLDA when compared with some related dimensionality reduction methods .", "This new model adopts the worst-case view which arguably is more suitable for applications such as classification .", "Otherwise , we take a greedy approach by finding one direction of the transformation at a time .", "Moreover , we also analyze a special case of WLDA to show its relationship with conventional LDA .", "Based on this analysis , we then propose a new dimensionality reduction method called worst-case linear discriminant analysis ( WLDA ) by defining new between-class and within-class scatter measures .", "When the number of training data points or the number of features is not very large , we relax the optimization problem involved and formulate it as a metric learning problem .", "In this paper , we first analyze the scatter measures used in the conventional linear discriminant analysis ( LDA ) model and note that the formulation is based on the average-case view .", "Dimensionality reduction is often needed in many applications due to the high dimensionality of the data involved ."]}
{"orig_sents": ["2", "0", "1", "5", "4", "3"], "shuf_sents": ["This problem occurs whenever an estimate can not be obtained from held-out training data ; for instance , when data that have been used to train the model are held back for reasons of privacy or do not reflect the test distribution .", "In this case , new test instances have to be drawn and labeled at a cost .", "We address the problem of estimating the F -measure of a given model as accurately as possible on a fixed labeling budget .", "We explore conditions under which active estimates of F -measures are more accurate than estimates based on instances sampled from the test distribution .", "An analysis of the sources of estimation error leads to an optimal sampling distribution that minimizes estimator variance .", "An active estimation procedure selects instances according to an instrumental sampling distribution ."]}
{"orig_sents": ["1", "4", "6", "5", "8", "7", "2", "0", "3"], "shuf_sents": ["This SGR is essentially different from group lasso in the way of using class or group information , and it outperforms group lasso when there appears group label noise .", "Regularization technique has become a principled tool for statistics and machine learning research and practice .", "Under these sufficient conditions , a large set of consistent regularization terms can be designed .", "We also provide some generalization bounds in a classification setting .", "However , in most situations , these regularization terms are not well interpreted , especially on how they are related to the loss function and data .", "We show that various regularization terms are essentially corresponding to different distortions to the original data matrix .", "In this paper , we propose a robust minimax framework to interpret the relationship between data and regularization terms for a large class of loss functions .", "Within this minimax framework , we further give mathematically exact definition for a novel representation called sparse grouping representation ( SGR ) , and prove a set of sufficient conditions for generating such group level sparsity .", "This minimax framework includes ridge regression , lasso , elastic net , fused lasso , group lasso , local coordinate coding , multiple kernel learning , etc. , as special cases ."]}
{"orig_sents": ["5", "1", "2", "0", "3", "6", "4"], "shuf_sents": ["To deal with discontinuities in the dynamical systems or the latent driving force we introduce an extension of the basic latent force model , that switches between different latent functions and potentially different dynamical systems .", "Each variable to be modeled is represented as the output of a differential equation and each differential equation is driven by a weighted sum of latent functions with uncertainty given by a Gaussian process prior .", "In this paper we consider employing the latent force model framework for the problem of determining robot motor primitives .", "This creates a versatile representation for robot movements that can capture discrete changes and non-linearities in the dynamics .", "Our inspiration is robot motor primitives , but we expect our model to have wide application for dynamical systems including models for human motion capture data and systems biology .", "Latent force models encode the interaction between multiple related dynamical systems in the form of a kernel or covariance function .", "We give illustrative examples on both synthetic data and for striking movements recorded using a Barrett WAM robot as haptic input device ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["Our approach retains the advantages of tractable discriminative models , namely efficient exact inference and arbitrarily accurate parameter learning in polynomial time .", "We present a simple and effective approach to learning tractable conditional random fields with structure that depends on the evidence .", "At the same time , our algorithm does not suffer a large expressive power penalty inherent to fixed tractable structures .", "On real-life relational datasets , our approach matches or exceeds state of the art accuracy of the dense models , and at the same time provides an order of magnitude speedup ."]}
{"orig_sents": ["5", "6", "1", "2", "3", "4", "0"], "shuf_sents": ["We show that our method significantly improves performance in all the sub-tasks in two different domains : ( i ) scene understanding , where we consider depth estimation , scene categorization , event categorization , object detection , geometric labeling and saliency detection , and ( ii ) robotic grasping , where we consider grasp point detection and object classification .", "It is desirable to have an algorithm that can capture such correlation without requiring to make any changes to the inner workings of any classifier .", "We propose Feedback Enabled Cascaded Classification Models ( FE-CCM ) , that maximizes the joint likelihood of the sub-tasks , while requiring only a `black-box ' interface to the original classifier for each sub-task .", "We use a two-layer cascade of classifiers , which are repeated instantiations of the original ones , with the output of the first layer fed into the second layer as input .", "Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about what error modes to focus on .", "In many machine learning domains ( such as scene understanding ) , several related sub-tasks ( such as scene categorization , depth estimation , object detection ) operate on the same raw data and provide correlated outputs .", "Each of these tasks is often notoriously hard , and state-of-the-art classifiers already exist for many subtasks ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["It is shown that both algorithms can be viewed as an application of the perceptron cycling theorem .", "This connection strengthens some herding results and suggests new ( supervised ) herding algorithms that , like CRFs or discriminative RBMs , make predictions by conditioning on the input attributes .", "We develop and investigate variants of conditional herding , and show that conditional herding leads to practical algorithms that perform better than or on par with related classifiers such as the voted perceptron and the discriminative RBM .", "The paper develops a connection between traditional perceptron algorithms and recently introduced herding algorithms ."]}
{"orig_sents": ["1", "0", "5", "2", "4", "3"], "shuf_sents": ["Recent work has considered the setting where each point has a few arbitrarily corrupted components .", "Singular Value Decomposition ( and Principal Component Analysis ) is one of the most widely used techniques for dimensionality reduction : successful and efficiently computable , it is nevertheless plagued by a well-known , well-documented sensitivity to outliers .", "We present an efficient convex optimization-based algorithm we call Outlier Pursuit , that under some mild assumptions on the uncorrupted points ( satisfied , e.g. , by the standard generative assumption in PCA problems ) recovers the exact optimal low-dimensional subspace , and identifies the corrupted points .", "Our techniques involve matrix decomposition using nuclear norm minimization , however , our results , setup , and approach , necessarily differ considerably from the existing line of work in matrix completion and matrix decomposition , since we develop an approach to recover the correct column space of the uncorrupted matrix , rather than the exact matrix itself .", "Such identification of corrupted points that do not conform to the low-dimensional approximation , is of paramount interest in bioinformatics and financial applications , and beyond .", "Yet , in applications of SVD or PCA such as robust collaborative filtering or bioinformatics , malicious agents , defective genes , or simply corrupted or contaminated experiments may effectively yield entire points that are completely corrupted ."]}
{"orig_sents": ["2", "1", "3", "0", "4"], "shuf_sents": ["Our analysis introduces a novel proof technique -- contractive mappings to quantify the speed of convergence of parameter distributions to their asymptotic limits .", "In this paper we present the first parallel stochastic gradient descent algorithm including a detailed analysis and experimental evidence .", "With the increase in available data parallel machine learning has become an increasingly pressing problem .", "Unlike prior work on parallel optimization algorithms our variant comes with parallel acceleration guarantees and it poses no overly tight latency constraints , which might only be available in the multicore setting .", "As a side effect this answers the question of how quickly stochastic gradient descent algorithms reach the asymptotically normal regime ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Modelling camera shake as a space-invariant convolution simplifies the problem of removing camera shake , but often insufficiently models actual motion blur such as those due to camera rotation and movements outside the sensor plane or when objects in the scene have different distances to the camera .", "In an effort to address these limitations , ( i ) we introduce a taxonomy of camera shakes , ( ii ) we build on a recently introduced framework for space-variant filtering by Hirsch et al .", "Finally , we demonstrate that our method is able to deblur images degraded by spatially-varying blur originating from real camera shake , even without using additionally motion sensor information .", "and a fast algorithm for single image blind deconvolution for space-invariant filters by Cho and Lee to construct a method for blind deconvolution in the case of space-variant blur , and ( iii ) , we present an experimental setup for evaluation that allows us to take images with real camera shake while at the same time recording the spacevariant point spread function corresponding to that blur ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["For high level visual tasks , such low-level image representations are potentially not enough .", "Robust low-level image features have been proven to be effective representations for a variety of visual recognition tasks such as object recognition and scene classification ; but pixels , or even local image patches , carry little semantic meanings .", "Sparsity algorithms make our representation more efficient and scalable for large scene datasets , and reveal semantically meaningful feature patterns .", "In this paper , we propose a high-level image representation , called the Object Bank , where an image is represented as a scale-invariant response map of a large number of pre-trained generic object detectors , blind to the testing dataset or visual task .", "Leveraging on the Object Bank representation , superior performances on high level visual recognition tasks can be achieved with simple off-the-shelf classifiers such as logistic regression and linear SVM ."]}
{"orig_sents": ["1", "0", "4", "3", "2"], "shuf_sents": ["Our proposed approach ( EA++ ) builds on the notion of augmented space ( introduced in E ASYA DAPT ( EA ) ) and harnesses unlabeled data in target domain to further assist the transfer of information from source to target .", "This paper presents a co-regularization based approach to semi-supervised domain adaptation .", "Experimental results on sentiment analysis tasks reinforce our theoretical findings and demonstrate the efficacy of the proposed method when compared to EA as well as few other representative baseline approaches .", "Our theoretical analysis ( in terms of Rademacher complexity ) of EA and EA++ show that the hypothesis class of EA++ has lower complexity ( compared to EA ) and hence results in tighter generalization bounds .", "This semi-supervised approach to domain adaptation is extremely simple to implement and can be applied as a pre-processing step to any supervised learner ."]}
{"orig_sents": ["0", "4", "5", "3", "2", "1", "6"], "shuf_sents": ["We present an algorithm for learning high-treewidth Markov networks where inference is still tractable .", "We also propose a greedy version of the algorithm that , while forgoing these guarantees , is much more efficient .", "We provide probabilistic performance guarantees for our algorithm under the assumption that the maximum feature length is bounded by a constant k ( the treewidth can be much larger ) and dependences are of bounded strength .", "Our algorithm searches for a feature that divides the state space into subspaces where the remaining variables decompose into independent subsets ( conditioned on the feature and its negation ) and recurses on each subspace/subset of variables until no useful new features can be found .", "This is made possible by exploiting context-specific independence and determinism in the domain .", "The class of models our algorithm can learn has the same desirable properties as thin junction trees : polynomial inference , closed-form weight learning , etc. , but is much broader .", "Experiments on a variety of domains show that our approach outperforms many state-of-the-art Markov network structure learners ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["In this paper , we introduce the first ever approximate inference methods using ACs , for domains where exact inference remains intractable .", "We propose and evaluate a variety of techniques based on exact compilation , forward sampling , AC structure learning , Markov network parameter learning , variational inference , and Gibbs sampling .", "Arithmetic circuits ( ACs ) exploit context-specific independence and determinism to allow exact inference even in networks with high treewidth .", "In experiments on eight challenging real-world domains , we find that the methods based on sampling and learning work best : one such method ( AC2 -F ) is faster and usually more accurate than loopy belief propagation , mean field , and Gibbs sampling ; another ( AC2 -G ) has a running time similar to Gibbs sampling but is consistently more accurate than all baselines ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["For the first time , compatible function approximators and natural policy gradients are obtained by estimating the cost-to-go function , rather than the ( much larger ) state-action advantage function as is necessary in traditional MDPs .", "We also develop the first compatible function approximators and natural policy gradients for continuous-time stochastic systems .", "We present policy gradient results within the framework of linearly-solvable MDPs ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning , and only hypotheses from this set are ever returned .", "We present and analyze an agnostic active learning algorithm that works without keeping a version space .", "By avoiding this version space approach , our algorithm sheds the computational burden and brittleness associated with maintaining version spaces , yet still allows for substantial improvements over supervised learning for classification ."]}
{"orig_sents": ["5", "1", "6", "4", "2", "3", "0"], "shuf_sents": ["In addition , with a large probability , the proposed method can select the same number of correct features under a milder condition than the Dantzig selector .", "The Dantzig selector has been proposed for sparse signal recovery with strong theoretical guarantees .", "The proposed method improves the estimation bound of the standard Dantzig selector approximately from Cs1/p log m to C ( s - N ) 1/p log m where the value N depends on the number of large entries in .", "When N = s , the proposed algorithm achieves the oracle solution with a high probability .", "We show that if X obeys a certain condition , then with a large probability the difference between the solution estimated by the proposed method and the true solution measured in terms of the lp norm ( p 1 ) is bounded as - p C ( s - N ) 1/p log m + , where C is a constant , s is the number of nonzero entries in , is independent of m and is much smaller than the first term , andN is the number of entries of larger than a certain value in the order of O ( log m ) .", "We consider the following sparse signal recovery ( or feature selection ) problem : given a design matrix X Rnxm ( m n ) and a noisy observation vector y Rn satisfying y = X + where is the noise vector following a Gaussian distribution N ( 0 , 2 I ) , how to recover the signal ( or parameter vector ) when the signal is sparse ?", "In this paper , we propose a multi-stage Dantzig selector method , which iteratively refines the target signal ."]}
{"orig_sents": ["3", "2", "0", "1", "6", "5", "7", "4"], "shuf_sents": ["A very controversial , yet fundamental issue in these studies is how to determine the best functional brain regions or ROIs ( regions of interests ) for individuals .", "Essentially , the computed connectivity patterns and dynamics of brain networks are very sensitive to the locations , sizes , and shapes of the ROIs .", "Studying the connectivity among segregated regions and the dynamics of integrated brain networks has drawn increasing interest .", "Functional segregation and integration are fundamental characteristics of the human brain .", "Our experimental results show that the optimized ROIs have significantly improved consistency in structural and functional profiles across subjects , and have more reasonable localizations and more consistent morphological and anatomic profiles .", "Our strategy is to formulate the individual ROI optimization as a group variance minimization problem , in which group-wise functional and structural connectivity patterns , and anatomic profiles are defined as optimization constraints .", "This paper presents a novel methodology to optimize the locations of an individual 's ROIs in the working memory system .", "The optimization problem is solved via the simulated annealing approach ."]}
{"orig_sents": ["4", "0", "1", "2", "3"], "shuf_sents": ["This framework allows to design and prove relative mistake bounds for any generic loss function .", "The mistake bounds can be specialized for the hinge loss , allowing to recover and improve the bounds of known online classification algorithms .", "By optimizing the general bound we derive a new online classification algorithm , called NAROW , that hybridly uses adaptive- and fixed- second order information .", "We analyze the properties of the algorithm and illustrate its performance using synthetic dataset .", "We propose a general framework to online learning for classification problems with time-varying potential functions in the adversarial setting ."]}
{"orig_sents": ["0", "2", "3", "1", "5", "4", "6"], "shuf_sents": ["Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems .", "Here , we present a methodology that is capable of jointly optimizing the temporal parameters in addition to the control command profiles .", "However , they generally require the temporal parameters ( for e.g .", "the movement duration or the time point of reaching an intermediate goal ) to be specified a priori .", "An approximate EM algorithm is derived that efficiently optimizes both the movement duration and control commands offering , for the first time , a practical approach to tackling generic via point problems in a systematic way under the optimal control framework .", "The presented approach is based on a Bayesian canonical time formulation of the optimal control problem , with the temporal mapping from canonical to real time parametrised by an additional control variable .", "The proposed approach , which is applicable to plants with non-linear dynamics as well as arbitrary state dependent and quadratic control costs , is evaluated on realistic simulations of a redundant robotic plant ."]}
{"orig_sents": ["5", "8", "4", "6", "3", "2", "0", "7", "1"], "shuf_sents": ["However , it is challenging to perform such analysis , because the documents associated with different queries are not identically distributed , and the documents associated with the same query become no longer independent after represented by features extracted from query-document matching .", "The generalization bounds we obtained are quite intuitive and are in accordance with previous empirical studies on the performances of ranking algorithms .", "Such a sampling can better describe the generation mechanism of real data , and the corresponding generalization analysis can better explain the real behaviors of learning to rank algorithms .", "sampling of queries and the conditional i.i.d sampling of documents per query .", "Previous generalization analysis for ranking , however , has not fully considered this structure , and can not explain how the simultaneous change of query number and document number in the training data will affect the performance of the learned ranking model .", "This paper is concerned with the generalization analysis on learning to rank for information retrieval ( IR ) .", "In this paper , we propose performing generalization analysis under the assumption of two-layer sampling , i.e. , the i.i.d .", "To tackle the challenge , we decompose the expected risk according to the two layers , and make use of the new concept of two-layer Rademacher average .", "In IR , data are hierarchically organized , i.e. , consisting of queries and documents ."]}
{"orig_sents": ["4", "1", "0", "2", "3", "5"], "shuf_sents": ["Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus , or a percept .", "Cortical neurons are then connected by a sparse network of lateral synapses .", "We demonstrate that for a family of networks in which the receptive field of each neuron is re-expressed by its outgoing connections , a represented percept can remain constant despite changing activity .", "We term this choice of connectivity REceptive FIeld REcombination ( REFIRE ) networks .", "A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons , an over-complete representation strategy .", "The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit ."]}
{"orig_sents": ["7", "5", "4", "3", "0", "6", "2", "1"], "shuf_sents": ["Our contributions are as follows .", "Finally , we show some relationships between general totally half-integral relaxations and relaxations based on the roof duality .", "Second , we give a new characterization of bisubmodular functions .", "We argue that total half-integrality is a natural requirement for generalizations of roof duality to arbitrary pseudo-boolean functions .", "A well-known example is the roof duality relaxation for quadratic pseudo-boolean functions f .", "We say that the relaxation is totally half-integral if f ( x ) is a polyhedral function with halfintegral extreme points x , and this property is preserved after adding an arbitrary combination of constraints of the form xi = xj , xi = 1 - xj , and xi = where { 0 , 1 , 21 } is a constant .", "First , we provide a complete characterization of totally half-integral relaxations f by establishing a one-to-one correspondence with bisubmodular functions .", "Consider a convex relaxation f of a pseudo-boolean function f ."]}
{"orig_sents": ["1", "2", "5", "3", "0", "4"], "shuf_sents": ["We evaluate these models on the development histories of three large , open-source software systems : Mozilla Firefox , Eclipse Subversive , and Gimp .", "When software developers modify one or more files in a large code base , they must also identify and update other related files .", "Many file dependencies can be detected by mining the development history of the code base : in essence , groups of related files are revealed by the logs of previous workflows .", "We explore different latent variable models ( LVMs ) for this problem , including Bernoulli mixture models , exponential family PCA , restricted Boltzmann machines , and fully Bayesian approaches .", "In all of these applications , we find that LVMs improve the performance of related file prediction over current leading methods .", "From data of this form , we show how to detect dependent files by solving a problem in binary matrix completion ."]}
{"orig_sents": ["2", "4", "0", "1", "3"], "shuf_sents": ["We derive partial differential equations for exact inference and present a very efficient mean field approximation .", "By introducing a novel lower bound on the free energy , we then generalise our approach to Gaussian processes with arbitrary covariance , such as the non-Markovian RBF covariance .", "We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes , where the latent process is a Markovian jump process .", "We present results on both simulated and real data , showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks .", "We first consider the case of jump-diffusion processes , where the drift of a linear stochastic differential equation can jump at arbitrary time points ."]}
{"orig_sents": ["4", "8", "2", "7", "9", "6", "1", "3", "0", "5"], "shuf_sents": ["Experimental results show that the proposed variable margin losses outperform the fixed margin counterparts used by existing algorithms .", "These families are then used to design boosting style algorithms with explicit control of the classification margin .", "It is shown that for a class of risks , denoted canonical risks , asymptotic Bayes consistency is compatible with simple analytical relationships between these functions .", "The new algorithms generalize well established approaches , such as LogitBoost .", "The problem of controlling the margin of a classifier is studied .", "Finally , it is shown that best performance can be achieved by cross-validating the margin parameter .", "Novel families of Bayes consistent loss functions , of variable margin , are derived .", "These enable a precise characterization of the loss for a popular class of link functions .", "A detailed analytical study is presented on how properties of the classification risk , such as its optimal link and minimum risk functions , are related to the shape of the loss , and its margin enforcing properties .", "It is shown that , when the risk is in canonical form and the link is inverse sigmoidal , the margin properties of the loss are determined by a single parameter ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["We model the problem as a Poisson process with a throttling policy that enforces a data-dependent rate limit and reduce the learning problem to a convex optimization problem that can be solved efficiently .", "This problem setting matches applications in which damage caused by an attacker grows as a function of the rate of unsuppressed hostile events .", "The optimization goal is allowed to depend on the rate of decision outcomes ; the rate may depend on a potentially long backlog of events and decisions .", "We report on experiments on abuse detection for an email service .", "We study a setting in which Poisson processes generate sequences of decisionmaking events ."]}
{"orig_sents": ["3", "4", "1", "2", "0", "5"], "shuf_sents": ["Indeed , we present empirical results to this effect for various SDPs encountered in machine learning ; these experiments demonstrate the potential practical usefulness of Random Conic Pursuit .", "Its advantages are realized at the expense of an ability to readily compute highly exact solutions , though useful approximate solutions are easily obtained .", "This property renders Random Conic Pursuit of particular interest for machine learning applications , in which the relevant SDPs are generally based upon random data and so exact minima are often not a priority .", "We present a novel algorithm , Random Conic Pursuit , that solves semidefinite programs ( SDPs ) via repeated optimization over randomly selected two-dimensional subcones of the PSD cone .", "This scheme is simple , easily implemented , applicable to very general SDPs , scalable , and theoretically interesting .", "We also provide a preliminary analysis that yields insight into the theoretical properties and convergence of the algorithm ."]}
{"orig_sents": ["2", "0", "3", "1", "4"], "shuf_sents": ["This problem can be alleviated by imposing ( or learning ) a structure over the set of classes .", "We also propose a method that learns to embed labels in a low dimensional space that is faster than non-embedding approaches and has superior accuracy to existing embedding approaches .", "Multi-class classification becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible .", "We propose an algorithm for learning a treestructure of classifiers which , by optimizing the overall tree loss , provides superior accuracy to existing tree labeling methods .", "Finally we combine the two ideas resulting in the label embedding tree that outperforms alternative methods including One-vs-Rest while being orders of magnitude faster ."]}
{"orig_sents": ["0", "1", "7", "4", "6", "5", "2", "3"], "shuf_sents": ["Many combinatorial problems arising in machine learning can be reduced to the problem of minimizing a submodular function .", "Submodular functions are a natural discrete analog of convex functions , and can be minimized in strongly polynomial time .", "Our algorithm exploits recent results in smoothed convex minimization .", "We apply SLG to synthetic benchmarks and a joint classification-and-segmentation task , and show that it outperforms the state-of-the-art general purpose submodular minimization algorithms by several orders of magnitude .", "In this paper , we introduce a novel subclass of submodular minimization problems that we call decomposable .", "We develop an algorithm , SLG , that can efficiently minimize decomposable submodular functions with tens of thousands of variables .", "Decomposable submodular functions are those that can be represented as sums of concave functions applied to modular functions .", "Unfortunately , state-of-the-art algorithms for general submodular minimization are intractable for larger problems ."]}
{"orig_sents": ["3", "1", "5", "2", "6", "8", "0", "7", "4"], "shuf_sents": ["This is caused by the increasing variance in the input potential due to the diffusion of synaptic weights .", "It is commonly assumed that this ability is achieved by modifications in synaptic weights related to decision making .", "Loewenstein & Seung ( 2006 ) demonstrated that matching behavior is a steady state of learning in neural networks if the synaptic weights change proportionally to the covariance between reward and neural activities .", "When animals repeatedly choose actions from multiple alternatives , they can allocate their choices stochastically depending on past actions and outcomes .", "We suggest that the synaptic diffusion effects provide a robust neural mechanism for stochastic choice behavior .", "Choice behavior has been empirically found to follow Herrnstein 's matching law .", "However , their proof did not take into account the change in entire synaptic distributions .", "This effect causes an undermatching phenomenon , which has been observed in many behavioral experiments .", "In this study , we show that matching behavior is not necessarily a steady state of the covariance-based learning rule when the synaptic strength is sufficiently strong so that the fluctuations in input from individual sensory neurons influence the net input to output neurons ."]}
{"orig_sents": ["1", "2", "6", "0", "4", "3", "5"], "shuf_sents": ["In particular , we define a probabilistic graphical model that explicitly captures : 1 ) occlusions and disocclusions ; 2 ) depth ordering of the layers ; 3 ) temporal consistency of the layer segmentation .", "Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other .", "For image motion estimation , such models have a long history but have not achieved the wide use or accuracy of non-layered methods .", "Finally , a key contribution is the formulation of the layers using an imagedependent hidden field prior based on recent models for static scene segmentation .", "Additionally the optical flow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior ; the resulting model allows roughness in layers .", "The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions .", "We present a new probabilistic model of optical flow in layers that addresses many of the shortcomings of previous approaches ."]}
{"orig_sents": ["9", "7", "1", "10", "0", "5", "6", "4", "8", "2", "3"], "shuf_sents": ["Second , only a black box simulator of the POMDP is required , rather than explicit probability distributions .", "The new algorithm , POMCP , has two important properties .", "Our MonteCarlo planning algorithm achieved a high level of performance with no prior knowledge , and was also able to exploit simple domain knowledge to achieve better results with less search .", "POMCP is the first general purpose planner to achieve high performance in such large and unfactored POMDPs .", "We scale up a well-known benchmark problem , rocksample , by several orders of magnitude .", "These properties enable POMCP to plan effectively in significantly larger POMDPs than has previously been possible .", "We demonstrate its effectiveness in three large POMDPs .", "The algorithm combines a Monte-Carlo update of the agent 's belief state with a Monte-Carlo tree search from the current belief state .", "We also introduce two challenging new POMDPs : 10 x 10 battleship and partially observable PacMan , with approximately 1018 and 1056 states respectively .", "This paper introduces a Monte-Carlo algorithm for online planning in large POMDPs .", "First , MonteCarlo sampling is used to break the curse of dimensionality both during belief state updates and during planning ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classification .", "We obtain a tight distribution-specific characterization of the sample complexity of large-margin classification with L2 regularization : We introduce the -adapted-dimension , which is a simple function of the spectrum of a distribution 's covariance matrix , and show distribution-specific upper and lower bounds on the sample complexity , both governed by the -adapted-dimension of the source distribution .", "The bounds hold for a rich family of sub-Gaussian distributions ."]}
{"orig_sents": ["2", "5", "3", "1", "4", "6", "0"], "shuf_sents": ["Experiments show that the resulting cascades have state-of-the-art performance in various computer vision problems .", "A boosting algorithm , FCBoost , is proposed for fully automated cascade design .", "The problem of optimal and automatic design of a detector cascade is considered .", "This model is analytically tractable , leads to recursive computation , and accounts for both classification and complexity .", "It exploits the new cascade model , minimizes a Lagrangian cost that accounts for both classification risk and complexity .", "A novel mathematical model is introduced for a cascaded detector .", "It searches the space of cascade configurations to automatically determine the optimal number of stages and their predictors , and is compatible with bootstrapping of negative examples and cost sensitive learning ."]}
{"orig_sents": ["2", "3", "1", "0", "5", "4"], "shuf_sents": ["The protocol allows these parties to interact with an untrusted curator to construct additive shares of a perturbed aggregate classifier .", "In this paper , we propose a privacy-preserving protocol for composing a differentially private aggregate classifier using classifiers trained locally by separate mutually untrusting parties .", "As increasing amounts of sensitive personal information finds its way into data repositories , it is important to develop analysis mechanisms that can derive aggregate information from these repositories without revealing information about individual data instances .", "Though the differential privacy model provides a framework to analyze such mechanisms for databases belonging to a single party , this framework has not yet been considered in a multi-party setting .", "We verify the bound with an experimental evaluation on a real dataset .", "We also present a detailed theoretical analysis containing a proof of differential privacy of the perturbed aggregate classifier and a bound on the excess risk introduced by the perturbation ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["We address the problem of semi-supervised learning in an adversarial setting .", "Motivated by the analysis , we formulate a convex optimization problem for parameter estimation , derive an efficient algorithm , and analyze its convergence .", "We present nearly matching upper and lower generalization bounds for learning in this setting under reasonable assumptions about available label information .", "Instead of assuming that labels are missing at random , we analyze a less favorable scenario where the label information can be missing partially and arbitrarily , which is motivated by several practical examples .", "We provide experimental results on several standard data sets showing the robustness of our algorithm to the pattern of missing label information , outperforming several strong baselines ."]}
{"orig_sents": ["3", "6", "4", "7", "0", "2", "5", "1"], "shuf_sents": ["We propose a new framework that extends variational inference to a wide range of combinatorial spaces .", "We also apply the framework to the problem of multiple alignment of protein sequences , obtaining state-of-the-art results on the BAliBASE dataset .", "Our method is based on a simple assumption : the existence of a tractable measure factorization , which we show holds in many examples .", "Since the discovery of sophisticated fully polynomial randomized algorithms for a range of # P problems , theoretical work on approximate inference in combinatorial spaces has focused on Markov chain Monte Carlo methods .", "Because of this , in applications to combinatorial spaces simple exact models are often preferred to more complex models that require approximate inference .", "Simulations on a range of matching models show that the algorithm is more general and empirically faster than a popular fully polynomial randomized algorithm .", "Despite their strong theoretical guarantees , the slow running time of many of these randomized algorithms and the restrictive assumptions on the potentials have hindered the applicability of these algorithms to machine learning .", "Variational inference would appear to provide an appealing alternative , given the success of variational methods for graphical models ; unfortunately , however , it is not obvious how to develop variational approximations for combinatorial objects such as matchings , partial orders , plane partitions and sequence alignments ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["Our result confirms that non-reversible chains are fundamentally better than reversible ones in terms of asymptotic performance , and suggests interesting directions for further improving MCMC .", "We present a new way of converting a reversible finite Markov chain into a nonreversible one , with a theoretical guarantee that the asymptotic variance of the MCMC estimator based on the non-reversible chain is reduced .", "The method is applicable to any reversible chain whose states are not connected through a tree , and can be interpreted graphically as inserting vortices into the state transition graph ."]}
{"orig_sents": ["0", "7", "3", "6", "4", "2", "1", "5"], "shuf_sents": ["To understand the relationship between genomic variations among population and complex diseases , it is essential to detect eQTLs which are associated with phenotypic effects .", "This optimization procedure is efficient since it can be achieved by using a projected gradient descent and a coordinate descent procedure iteratively .", "Then we find the maximum a posteriori ( MAP ) estimation of regression coefficients and estimate weights of covariates jointly .", "Thus , to address the problem , it is desirable to take advantage of the structure of the data and prior information about genomic locations such as conservation scores and transcription factor binding sites .", "We first present a Bayesian network for a multi-task learning problem that includes priors on SNPs , making it possible to estimate the significance of each covariate adaptively .", "Experimental results on simulated and real yeast datasets confirm that our model outperforms previous methods for finding eQTLs .", "In this paper , we propose a novel regularized regression approach for detecting eQTLs which takes into account related traits simultaneously while incorporating many regulatory features .", "However , detecting eQTLs remains a challenge due to complex underlying mechanisms and the very large number of genetic loci involved compared to the number of samples ."]}
{"orig_sents": ["0", "5", "2", "1", "4", "3"], "shuf_sents": ["The Random Projection Tree ( RPT REE ) structures proposed in are space partitioning data structures that automatically adapt to various notions of intrinsic dimensionality of data .", "We also prove a packing lemma for this data structure .", "Our result for RPT REE -M AX gives a nearoptimal bound on the number of levels required by this data structure to reduce the size of its cells by a factor s 2 .", "As a consequence we show that RPT REE -M EAN adapts to manifold dimension as well .", "Our final result shows that low-dimensional manifolds have bounded Local Covariance Dimension .", "We prove new results for both the RPT REE -M AX and the RPT REE -M EAN data structures ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["We consider the problem of learning a local metric to enhance the performance of nearest neighbor classification .", "Empirical experiments show that this learned local metric enhances the discriminative nearest neighbor performance on various datasets using simple class conditional generative models .", "As a byproduct , the asymptotic theoretical analysis in this work relates metric learning with dimensionality reduction , which was not understood from previous discriminative approaches .", "We focus on the bias in the information-theoretic error arising from finite sampling effects , and find an appropriate local metric that maximally reduces the bias based upon knowledge from generative models .", "Conventional metric learning methods attempt to separate data distributions in a purely discriminative manner ; here we show how to take advantage of information from parametric generative models ."]}
{"orig_sents": ["3", "8", "2", "5", "1", "7", "0", "4", "6", "9"], "shuf_sents": ["Each labeling vector encodes the possible labels for the instances in the bag , with only one being fully correct .", "In this paper , we propose a semi-supervised framework to model this kind of problems .", "In general , these problems can be very difficult .", "In many real world applications we do not have access to fully-labeled training data , but only to a list of possible labels .", "The use of the labeling vectors provides a principled way not to exclude any information .", "However most of the time there exist different implicit sources of information , coming from the relations between instances and labels , which are usually dismissed .", "We propose a large margin discriminative formulation , and an efficient algorithm to solve it .", "Each training sample is a bag containing multi-instances , associated with a set of candidate labeling vectors .", "This is the case , e.g. , when learning visual classifiers from images downloaded from the web , using just their text captions or tags as learning oracles .", "Experiments conducted on artificial datasets and a real-world images and captions dataset show that our approach achieves performance comparable to an SVM trained with the ground-truth labels , and outperforms other baselines ."]}
{"orig_sents": ["2", "6", "0", "4", "5", "1", "3"], "shuf_sents": ["In contrast , recent analysis has resulted in the common belief that several extensions of SVM classification to more than two classes are inconsistent .", "Erratum , 20.01.2011 Unfortunately this paper contains a subtle flaw in the proof of Lemma 5 .", "Steinwart was the first to prove universal consistency of support vector machine classification .", "Furthermore it turns out the statement itself is wrong : The multi-class SVM by Crammer & Singer is not universally consistent .", "Countering this belief , we prove the universal consistency of the multi-class support vector machine by Crammer and Singer .", "Our proof extends Steinwart 's techniques to the multi-class case .", "His proof analyzed the `standard ' support vector machine classifier , which is restricted to binary classification problems ."]}
{"orig_sents": ["7", "8", "3", "6", "4", "5", "1", "0", "9", "2"], "shuf_sents": ["The learning can then be posed as a convex quadratic program solvable with cutting-plane optimization .", "We introduce a new loss function , which is well-suited for such learning , and at the same time can be computed efficiently via a maximum subarray algorithm .", "Once trained , our system provides accurate object counts and requires a very small time overhead over the feature extraction step , making it a good candidate for applications involving real-time processing or dealing with huge amount of visual data .", "Our goal is to accurately estimate the count .", "Instead , we cast the problem as that of estimating an image density whose integral over any image region gives the count of objects within that region .", "Learning to infer such density can be formulated as a minimization of a regularized risk quadratic cost function .", "However , we evade the hard task of learning to detect and localize individual object instances .", "We propose a new supervised learning framework for visual object counting tasks , such as estimating the number of cells in a microscopic image or the number of humans in surveillance video frames .", "We focus on the practically-attractive case when the training images are annotated with dots ( one dot per object ) .", "The proposed framework is very flexible as it can accept any domain-specific visual features ."]}
{"orig_sents": ["5", "1", "3", "2", "0", "4"], "shuf_sents": ["This metric is observed to have relatively low variance for certain categories of randomly-generated graphs , and to reveal the presence of an anomalous subgraph with reasonable reliability when the anomaly is not well-correlated with stronger portions of the background graph .", "Nevertheless , it is desirable to determine the detectability of small , anomalous graphs embedded into background networks with known statistical properties .", "Its focus is the detection of anomalies in unweighted , undirected graphs through L1 properties of the eigenvectors of the graph 's so-called modularity matrix .", "Casting the problem of subgraph detection in a signal processing context , this article provides a framework and empirical results that elucidate a `` detection theory '' for graph-valued data .", "An analysis of subgraphs in real network datasets confirms the efficacy of this approach .", "When working with network datasets , the theoretical framework of detection theory for Euclidean vector spaces no longer applies ."]}
{"orig_sents": ["0", "3", "2", "5", "1", "4"], "shuf_sents": ["In this paper , we regard clustering as ensembles of k-ary affinity relations and clusters correspond to subsets of objects with maximal average affinity relations .", "Our method also provides a unified solution to clustering from k-ary affinity relations with k 2 , that is , it applies to both graph-based and hypergraph-based clustering problems .", "We present an efficient procedure to solve this optimization problem , and show that the underlying clusters can be robustly revealed by using priors systematically constructed from the data .", "The average affinity relation of a cluster is relaxed and well approximated by a constrained homogenous function .", "Both theoretical analysis and experimental results show the superiority of our method over classical solutions to the clustering problem , especially when there exists a large number of outliers .", "Our method can automatically select some points to form clusters , leaving other points un-grouped ; thus it is inherently robust to large numbers of outliers , which has seriously limited the applicability of classical methods ."]}
{"orig_sents": ["2", "3", "4", "0", "1", "5"], "shuf_sents": ["Our analysis shows that the Hessian matrix of E tends to be indefinite in the vicinity of ( perturbed ) singular points , suggesting a promising strategy that exploits negative curvature so as to escape from the singularity plateaus .", "For numerical evidence , we limit the scope to small examples ( some of which are found in journal papers ) that allow us to confirm singularities and the eigenvalues of the Hessian matrix , and for which computation using a descent direction of negative curvature encounters no plateau .", "In the neural-network parameter space , an attractive field is likely to be induced by singularities .", "In such a singularity region , first-order gradient learning typically causes a long plateau with very little change in the objective function value E ( hence , a flat region ) .", "Therefore , it may be confused with `` attractive '' local minima .", "Even for those small problems , no efficient methods have been previously developed that avoided plateaus ."]}
{"orig_sents": ["0", "3", "2", "1", "6", "5", "4"], "shuf_sents": ["We present a new learning strategy for classification problems in which train and/or test data suffer from missing features .", "Building onto this framework , we propose a classification strategy for sets .", "In contrast , our method considers instances as sets of ( feature , value ) pairs which naturally handle the missing value case .", "In previous work , instances are represented as vectors from some feature space and one is forced to impute missing values or to consider an instance-specific subspace .", "This simple strategy allows great flexibility in encoding prior knowledge about the features in the embedding step and yields advantageous results compared to alternative solutions over several datasets .", "The embedding and the combination parameters are learned jointly on the final classification objective .", "Our proposal maps ( feature , value ) pairs into an embedding space and then nonlinearly combines the set of embedded vectors ."]}
{"orig_sents": ["4", "5", "2", "1", "0", "3"], "shuf_sents": ["The state of the art result for this setting is a no-regret algorithm .", "The agent is assumed to know the transition probabilities .", "In each time step the agent observes the current state and the reward associated with the last transition , however , the agent does not observe the rewards associated with other state-action pairs .", "In this paper we propose a new learning algorithm and , assuming that stationary policies mix uniformly fast , we show that after T time steps , the expected regret of the new algorithm is O T 2/3 ( ln T ) 1/3 , giving the first rigorously proved regret bound for the problem .", "We consider online learning in finite stochastic Markovian environments where in each time step a new reward function is chosen by an oblivious adversary .", "The goal of the learning agent is to compete with the best stationary policy in terms of the total reward received ."]}
{"orig_sents": ["0", "4", "3", "5", "1", "2"], "shuf_sents": ["Identifying the features of objects becomes a challenge when those features can change in their appearance .", "What transformations can features undergo ?", "We present two new experiments in which we explore how people resolve these questions , showing that the tIBP model demonstrates a similar sensitivity to context to that shown by human learners when determining the invariant aspects of features .", "We show that this model can identify features that are location invariant by modeling a previous experiment on human feature learning .", "We introduce the Transformed Indian Buffet Process ( tIBP ) , and use it to define a nonparametric Bayesian model that infers features that can transform across instantiations .", "However , allowing features to transform adds new kinds of ambiguity : Are two parts of an object the same feature with different transformations or two unique features ?"]}
{"orig_sents": ["0", "3", "2", "1", "4", "5"], "shuf_sents": ["Activity of a neuron , even in the early sensory areas , is not simply a function of its local receptive field or tuning properties , but depends on global context of the stimulus , as well as the neural context .", "We found that the spikes of surrounding neurons indeed provide strong predictions of a neuron 's response , in addition to the neuron 's receptive field transfer function .", "In this paper we implemented an L1 regularized point process model to assess the contribution of multiple factors to the firing rate of many individual units recorded simultaneously from V1 with a 96-electrode `` Utah '' array .", "This suggests the activity of the surrounding neurons and global brain states can exert considerable influence on the activity of a neuron .", "We also found that the same spikes could be accounted for with the local field potentials , a surrogate measure of global network states .", "This work shows that accounting for network fluctuations can improve estimates of single trial firing rate and stimulus-response transfer functions ."]}
{"orig_sents": ["2", "5", "4", "6", "1", "3", "0"], "shuf_sents": ["A variation of this policy is shown to achieve worst-case regret that is logarithmic in the number of goals for any goal distribution .", "We show classes of HAMDPs that are complete for PSPACE and NP along with a polynomial time class .", "We study several classes of interactive assistants from the points of view of decision theory and computational complexity .", "Furthermore , we show that for general HAMDPs a simple myopic policy achieves a regret , compared to an omniscient assistant , that is bounded by the entropy of the initial goal distribution .", "In spite of its restricted nature , we show that optimal action selection in finite horizon HGMDPs is PSPACE-complete even in domains with deterministic dynamics .", "We first introduce a class of POMDPs called hidden-goal MDPs ( HGMDPs ) , which formalize the problem of interactively assisting an agent whose goal is hidden and whose actions are observable .", "We then introduce a more restricted model called helper action MDPs ( HAMDPs ) , where the assistant 's action is accepted by the agent when it is helpful , and can be easily ignored by the agent otherwise ."]}
{"orig_sents": ["2", "0", "3", "1", "4"], "shuf_sents": ["When a collection of experts independently assess events that are structurally interrelated , the resulting assessment may violate fundamental laws of probability .", "In this work we investigate how the problem of incoherence may be affected by allowing experts to specify likelihood models and then update their assessments based on the realization of a globally-observable random sequence .", "Experts ( human or computer ) are often required to assess the probability of uncertain events .", "Such an assessment is termed incoherent .", "Keywords : Bayesian Methods , Information Theory , consistency"]}
{"orig_sents": ["5", "4", "1", "3", "2", "0"], "shuf_sents": ["We show that this significantly improves the performance of sparse coding algorithms on the energy task and illustrate how these disaggregation results can provide useful information about energy usage .", "Thus , developing algorithmic methods for disaggregation presents a key technical challenge in the effort to maximize energy conservation .", "In particular , we develop a method , based upon structured prediction , for discriminatively training sparse coding algorithms specifically to maximize disaggregation performance .", "In this paper , we examine a large scale energy disaggregation task , and apply a novel extension of sparse coding to this problem .", "Studies have shown that having devicelevel energy information can cause users to conserve significant amounts of energy , but current electricity meters only report whole-home data .", "Energy disaggregation is the task of taking a whole-home energy signal and separating it into its component appliances ."]}
{"orig_sents": ["3", "5", "1", "4", "0", "2"], "shuf_sents": ["This result substantiates the notion of a well defined `time complexity ' for the network inference problem .", "We tackle the problem of learning such a network from observation of the system trajectory over a time interval T .", "keywords : Gaussian processes , model selection and structure learning , graphical models , sparsity and feature selection .", "We consider linear models for stochastic dynamics .", "We analyze the 1 -regularized least squares algorithm and , in the setting in which the underlying network is sparse , we prove performance guarantees that are uniform in the sampling rate as long as this is sufficiently high .", "To any such model can be associated a network ( namely a directed graph ) describing which degrees of freedom interact under the dynamics ."]}
{"orig_sents": ["0", "4", "1", "2", "3"], "shuf_sents": ["Automatic speech recognition has gradually improved over the years , but the reliable recognition of unconstrained speech is still not within reach .", "In this paper , it is shown that the recently introduced concept of Reservoir Computing might form the basis of such a methodology .", "In a limited amount of time , a reservoir system that can recognize the elementary sounds of continuous speech has been built .", "The system already achieves a state-of-the-art performance , and there is evidence that the margin for further improvements is still significant .", "In order to achieve a breakthrough , many research groups are now investigating new methodologies that have potential to outperform the Hidden Markov Model technology that is at the core of all present commercial systems ."]}
{"orig_sents": ["1", "3", "5", "4", "0", "2"], "shuf_sents": ["Starting from the definition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information .", "Functional magnetic resonance imaging ( fMRI ) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level .", "We use the infinite relational model ( IRM ) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects .", "Most analyses of functional resting state networks ( RSN ) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain .", "In this paper we take a different view on the analysis of functional resting state networks .", "While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact ."]}
{"orig_sents": ["5", "0", "3", "1", "2", "4"], "shuf_sents": ["Figural assignment ( often referred to as border ownership ) can vary along a contour , suggesting a spatially distributed process whereby local and global cues are combined to yield local estimates of border ownership .", "Our network includes as a nonlocal factor skeletal ( medial axis ) structure , under the hypothesis that medial structure `` draws '' border ownership so that borders are owned by the skeletal hypothesis that best explains them .", "We also briefly present a psychophysical experiment in which we measured local border ownership along a contour at various distances from an inducing cue ( a T-junction ) .", "In this paper we model figure/ground estimation in a Bayesian belief network , attempting to capture the propagation of border ownership across the image as local cues ( contour curvature and T-junctions ) interact with more global cues to yield a figure/ground assignment .", "Both the human subjects and the network show similar patterns of performance , converging rapidly to a similar pattern of spatial variation in border ownership along contours .", "Figure/ground assignment , in which the visual image is divided into nearer ( figural ) and farther ( ground ) surfaces , is an essential step in visual processing , but its underlying computational mechanisms are poorly understood ."]}
{"orig_sents": ["6", "5", "3", "4", "0", "7", "2", "1"], "shuf_sents": ["We first embed each brain into a functional map that reflects connectivity patterns during a fMRI experiment .", "This advantage is pronounced for subjects with tumors that affect the language areas and thus cause spatial reorganization of the functional regions .", "In application to a language fMRI experiment , our preliminary results suggest that the proposed method yields improved functional correspondences across subjects .", "In such cases spatial registration based on anatomical data is only of limited value if the goal is to establish correspondences of functional areas among different individuals , or to localize potentially displaced active regions .", "Rather than rely on spatial alignment , we propose to perform registration in an alternative space whose geometry is governed by the functional interaction patterns in the brain .", "It is particularly difficult , but highly relevant , for patients with pathologies such as brain tumors , which can cause substantial reorganization of functional systems .", "Matching functional brain regions across individuals is a challenging task , largely due to the variability in their location and extent .", "The resulting functional maps are then registered , and the obtained correspondences are propagated back to the two brains ."]}
{"orig_sents": ["1", "0", "3", "2", "4"], "shuf_sents": ["It has been applied to learning natural image statistics but has so-far been limited to simple models due to the difficulty of differentiating the loss with respect to the model parameters .", "Score Matching is a recently-proposed criterion for training high-dimensional density models for which maximum likelihood training is intractable .", "In addition , we introduce a regularization term for the Score Matching loss that enables its use for a broader range of problem by suppressing instabilities that occur with finite training sample sizes and quantized input values .", "We show how this differentiation can be automated with an extended version of the double-backpropagation algorithm .", "Results are reported for image denoising and super-resolution ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["While deep networks outperform local learning machines on some problems , it is still unclear how their nice representation emerges from their complex structure .", "Deep networks can potentially express a learning problem more efficiently than local learning machines .", "We present an analysis based on Gaussian kernels that measures how the representation of the learning problem evolves layer after layer as the deep network builds higher-level abstract representations of the input .", "We use this analysis to show empirically that deep networks build progressively better representations of the learning problem and that the best representations are obtained when the deep network discriminates only in the last layers ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["We propose a new class of regularized spectral estimators based on a new notion of reproducing kernel Hilbert space , which we call `` completely regular '' .", "Numerical experiments show that spectral estimators compare favorably to state of the art machine learning algorithms for density support estimation .", "In particular , they are the key ingredient to prove the universal consistency of the spectral estimators and in this respect they are the analogue of universal kernels for supervised problems .", "In this paper we consider the problem of learning from data the support of a probability distribution when the distribution does not have a density ( with respect to some reference measure ) .", "Completely regular kernels allow to capture the relevant geometric and topological properties of an arbitrary probability space ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["This is highly advantageous over a popular VBMF algorithm based on iterated conditional modes since it can only find a local optimal solution after iterations .", "We further show that the global optimal solution of empirical VBMF ( hyperparameters are also learned from data ) can also be analytically computed .", "Bayesian methods of matrix factorization ( MF ) have been actively explored recently as promising alternatives to classical singular value decomposition .", "In this paper , we show that , despite the fact that the optimization problem is non-convex , the global optimal solution of variational Bayesian ( VB ) MF can be computed analytically by solving a quartic equation .", "We illustrate the usefulness of our results through experiments ."]}
{"orig_sents": ["0", "2", "4", "5", "3", "6", "1"], "shuf_sents": ["Most current image categorization methods require large collections of manually annotated training examples to learn accurate visual recognition models .", "Our experiments demonstrate that , for the same number of strongly-labeled examples , our domain adaptation approach produces significant recognition rate improvements over the best published results ( e.g. , 65 % better when using 5 labeled training examples per class ) and that our classifiers are one order of magnitude faster to learn and to evaluate than the best competing method , despite our use of large weakly-labeled data sets .", "The time-consuming human labeling effort effectively limits these approaches to recognition problems involving a small number of different object classes .", "In this paper we investigate and compare methods that learn image classifiers by combining very few manually annotated examples ( e.g. , 1-10 images per class ) and a large number of weakly-labeled Web photos retrieved using keyword-based image search .", "In order to address this shortcoming , in recent years several authors have proposed to learn object classifiers from weakly-labeled Internet images , such as photos retrieved by keyword-based image search engines .", "While this strategy eliminates the need for human supervision , the recognition accuracies of these methods are considerably lower than those obtained with fully-supervised approaches , because of the noisy nature of the labels associated to Web data .", "We cast this as a domain adaptation problem : given a few stronglylabeled examples in a target domain ( the manually annotated examples ) and many source domain examples ( the weakly-labeled Web photos ) , learn classifiers yielding small generalization error on the target domain ."]}
{"orig_sents": ["1", "4", "7", "2", "3", "6", "5", "0"], "shuf_sents": ["On the other hand , we also observe a previously unreported phenomenon that DN may increase statistical dependencies when the size of pooling is small .", "Divisive normalization ( DN ) has been advocated as an effective nonlinear efficient coding transform for natural sensory signals with applications in biology and engineering .", "The multivariate t model justifies DN as an approximation to the transform that completely eliminates its statistical dependency .", "Furthermore , using the multivariate t model and measuring statistical dependency with multi-information , we can precisely quantify the statistical dependency that is reduced by the DN transform .", "In this work , we aim to establish a connection between the DN transform and the statistical properties of natural sensory signals .", "Our theoretical analysis and quantitative evaluations confirm DN as an effective efficient coding transform for natural sensory signals .", "We compare this with the actual performance of the DN transform in reducing statistical dependencies of natural sensory signals .", "Our analysis is based on the use of multivariate t model to capture some important statistical properties of natural sensory signals ."]}
{"orig_sents": ["0", "6", "7", "4", "5", "1", "3", "8", "2"], "shuf_sents": ["Many studies have explored the impact of response variability on the quality of sensory codes .", "We then compute the Fisher information with respect to binocular disparity , present in the monocular inputs to the standard model of early binocular processing , and thereby obtain an upper bound on how much information a model could theoretically extract from them .", "Furthermore , the largest loss of information is incurred by the standard model for position disparity neurons ( tuned-excitatory ) , that are the most ubiquitous in monkey primary visual cortex , while more information from the inputs is preserved in phase-disparity neurons ( tuned-near or tuned-far ) primarily found in higher cortical regions .", "Then we analyze the information loss incurred by the different ways of combining those inputs to produce a scalar single-neuron response .", "Here we study the impact of such stimulus-induced response variability for the case of binocular disparity inference .", "We characterize the response distribution for the binocular energy model in response to random dot stereograms and find it to be very different from the Poisson-like noise usually assumed .", "The source of this variability is almost always assumed to be intrinsic to the brain .", "However , when inferring a particular stimulus property , variability associated with other stimulus attributes also effectively act as noise .", "We find that in the case of depth inference , monocular stimulus variability places a greater limit on the extractable information than intrinsic neuronal noise for typical spike counts ."]}
{"orig_sents": ["5", "4", "3", "0", "2", "1"], "shuf_sents": ["In this paper , we propose an approach from the other side in that we use techniques from logic for probabilistic inference .", "Our rules yield new tractable classes that could not be solved efficiently by any of the existing techniques .", "In particular , we define a set of rules that look only at the logical representation to identify models for which exact efficient inference is possible .", "and improve its efficiency by exploiting repeated structure in the first-order model .", "All lifted algorithms developed to date are based on the same underlying idea : take a standard probabilistic inference algorithm ( e.g. , variable elimination , belief propagation etc . )", "Lifted Inference algorithms for representations that combine first-order logic and graphical models have been the focus of much recent research ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["For a density f on Rd , a high-density cluster is any connected component of { x : f ( x ) } , for some > 0 .", "We present a procedure for estimating the cluster tree given samples from f .", "We give finite-sample convergence rates for our algorithm , as well as lower bounds on the sample complexity of this estimation problem .", "The set of all high-density clusters form a hierarchy called the cluster tree of f ."]}
{"orig_sents": ["2", "3", "1", "5", "0", "4"], "shuf_sents": ["The main contribution of this paper is a theorem stating that a certain perceptronlike learning rule , involving features vectors derived from loss-adjusted inference , directly corresponds to the gradient of task loss .", "But in structured prediction each task often has its own measure of performance such as the BLEU score in machine translation or the intersection-over-union score in PASCAL segmentation .", "In discriminative machine learning one is interested in training a system to optimize a certain desired measure of performance , or loss .", "In binary classification one typically tries to minimizes the error rate .", "We give empirical results on phonetic alignment of a standard test set from the TIMIT corpus , which surpasses all previously reported results on this problem .", "The most common approaches to structured prediction , structural SVMs and CRFs , do not minimize the task loss : the former minimizes a surrogate loss with no guarantees for task loss and the latter minimizes log loss independent of task loss ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["In system identification both the input and the output of a system are available to an observer and an algorithm is sought to identify parameters of a hypothesized model of that system .", "The output is a time sequence associated with the spike train .", "The input to the circuit is an analog signal that belongs to the space of bandlimited functions .", "Here we present a novel formal methodology for identifying dendritic processing in a neural circuit consisting of a linear dendritic processing filter in cascade with a spiking neuron model .", "We derive an algorithm for identification of the dendritic processing filter and reconstruct its kernel with arbitrary precision ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["We show the usefulness of the model through experiments with synthetic and real-world data sets .", "We propose a new probabilistic model for analyzing dynamic evolutions of relational data , such as additions , deletions and split & merge , of relation clusters like communities in social networks .", "We extend the infinite Hidden Markov model to follow dynamic and time-sensitive changes in the structure of the relational data and to estimate a number of clusters simultaneously .", "Our proposed model abstracts observed timevarying object-object relationships into relationships between object clusters ."]}
{"orig_sents": ["4", "0", "3", "1", "2"], "shuf_sents": ["sample drawn from an unknown , absolutely continuous distribution over Rd .", "For the first time , we prove the almost sure consistency of these estimators and upper bounds on their rates of convergence , the latter of which under the assumption that the density underlying the sample is Lipschitz continuous .", "Experiments demonstrate their usefulness in independent subspace analysis .", "The estimators are calculated as the sum of p-th powers of the Euclidean lengths of the edges of the `generalized nearest-neighbor ' graph of the sample and the empirical copula of the sample respectively .", "We present simple and computationally efficient nonparametric estimators of Renyi entropy and mutual information based on an i.i.d ."]}
{"orig_sents": ["6", "1", "3", "4", "0", "5", "2"], "shuf_sents": ["Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity , generalizing the classical notion of submodular set functions to adaptive policies .", "In the case of noise-free observations , a greedy algorithm called generalized binary search ( GBS ) is known to perform near-optimally .", "We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects , intended to tease apart competing economic theories of how people make decisions under uncertainty .", "We show that if the observations are noisy , perhaps surprisingly , GBS can perform very poorly .", "We develop EC2 , a novel , greedy active learning algorithm and prove that it is competitive with the optimal policy , thus obtaining the first competitiveness guarantees for Bayesian active learning with noisy observations .", "Our results hold even if the tests have non-uniform cost and their noise is correlated .", "We tackle the fundamental problem of Bayesian active learning with noise , where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution ."]}
{"orig_sents": ["6", "8", "4", "2", "0", "3", "1", "5", "7"], "shuf_sents": ["Each image has different characteristics that are represented in an abstract Euclidean space .", "This allows the model to discover and represent groups of annotators that have different sets of skills and knowledge , as well as groups of images that differ qualitatively .", "Our method is based on a model of the image formation and annotation process .", "Each annotator is modeled as a multidimensional entity with variables representing competence , expertise and bias .", "the class ) of each image from ( noisy ) annotations provided by multiple annotators .", "We find that our model predicts ground truth labels on both synthetic and real data more accurately than state of the art methods .", "Distributing labeling tasks among hundreds or thousands of annotators is an increasingly important method for annotating large datasets .", "Experiments also show that our model , starting from a set of binary labels , may discover rich information , such as different `` schools of thought '' amongst the annotators , and can group together images belonging to separate categories .", "We present a method for estimating the underlying value ( e.g ."]}
{"orig_sents": ["1", "5", "4", "2", "3", "0"], "shuf_sents": ["We consider both deterministic and probabilistic network evolution models , and our results indicate that by leveraging the network interaction structure , it is possible to consistently recover high-dimensional patterns even when the noise variance increases with network size .", "We consider the problem of identifying an activation pattern in a complex , largescale network that is embedded in very noisy measurements .", "However , typically there are statistical dependencies in the network activation process that can be leveraged to fuse the measurements of multiple nodes and enable reliable extraction of highdimensional noisy patterns .", "In this paper , we analyze an estimator based on the graph Laplacian eigenbasis , and establish the limits of mean square error recovery of noisy patterns arising from a probabilistic ( Gaussian or Ising ) model based on an arbitrary graph structure .", "Extracting such patterns is a challenging task specially if the network is large ( pattern is very high-dimensional ) and the noise is so excessive that it masks the activity at any single node .", "This problem is relevant to several applications , such as identifying traces of a biochemical spread by a sensor network , expression levels of genes , and anomalous activity or congestion in the Internet ."]}
{"orig_sents": ["7", "2", "0", "4", "8", "5", "3", "1", "9", "6"], "shuf_sents": ["These noise correlations , however , are essentially immeasurable as the number of parameters in a noise correlation matrix grows quadratically with population size .", "We show how this dependency can be used to `` fill the gaps '' in noise correlations matrices using an iterative application of the Wishart distribution over positive definitive matrices .", "Answers to this question are known to strongly depend on the correlation of response variability in neural populations .", "We suggest an explicit parametric dependency between signal and noise correlations .", "Here , we suggest to bypass this problem by imposing a parametric model on a noise correlation matrix .", "On average , noise correlations will therefore reflect signal correlations , which can be measured in neural populations .", "We compare the discrimination thresholds read out from the population of recorded neurons with the discrimination threshold of the monkey and show that our method predicts different results than simpler , average schemes of noise correlations .", "How much information does a neural population convey about a stimulus ?", "Our basic assumption is that noise correlations arise due to common inputs between neurons .", "We apply our method to data from the primary somatosensory cortex of monkeys performing a two-alternativeforced choice task ."]}
{"orig_sents": ["0", "3", "1", "5", "2", "4"], "shuf_sents": ["We prove rates of convergence in the statistical sense for kernel-based least squares regression using a conjugate gradient algorithm , where regularization against overfitting is obtained by early stopping .", "The rates depend on two key quantities : first , on the regularity of the target regression function and second , on the effective dimensionality of the data mapped into the kernel space .", "If this assumption is not fulfilled , we obtain similar convergence rates provided additional unlabeled data are available .", "This method is directly related to Kernel Partial Least Squares , a regression method that combines supervised dimensionality reduction with least squares projection .", "The order of the learning rates match state-of-the-art results that were recently obtained for least squares support vector machines and for linear regularization operators .", "Lower bounds on attainable rates depending on these two quantities were established in earlier literature , and we obtain upper bounds for the considered method that match these lower bounds ( up to a log factor ) if the true regression function belongs to the reproducing kernel Hilbert space ."]}
{"orig_sents": ["1", "2", "9", "10", "6", "3", "4", "8", "0", "7", "5", "11"], "shuf_sents": ["We then show how this measure can be used with each of a one-class SVM , a nearest neighbor classifier , and hierarchical clustering to improve risk stratification .", "Cardiovascular disease is the leading cause of death globally , resulting in 17 million deaths each year .", "Despite the availability of various treatment options , existing techniques based upon conventional medical knowledge often fail to identify patients who might have benefited from more aggressive therapy .", "We describe related approaches that build on these ideas to provide improved medical decision making for patients who have recently suffered coronary attacks .", "We first describe how to compute the symbolic mismatch between pairs of long term electrocardiographic ( ECG ) signals .", "In a univariate analysis , all of the methods provided a statistically significant association with the occurrence of a major adverse cardiac event in the next 90 days .", "We hypothesize that high risk patients can be identified using symbolic mismatch , as individuals in a population with unusual long-term physiological activity .", "We evaluated our methods on a population of 686 cardiac patients with available long-term electrocardiographic data .", "This algorithm maps the original signals into a symbolic domain , and provides a quantitative assessment of the difference between these symbolic representations of the original signals .", "In this paper , we describe and evaluate a novel unsupervised machine learning approach for cardiac risk stratification .", "The key idea of our approach is to avoid specialized medical knowledge , and assess patient risk using symbolic mismatch , a new metric to assess similarity in long-term time-series activity .", "In a multivariate analysis that incorporated the most widely used clinical risk variables , the nearest neighbor and hierarchical clustering approaches were able to statistically significantly distinguish patients with a roughly two-fold risk of suffering a major adverse cardiac event in the next 90 days ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["These network flow problems can further be decomposed in order to solve very large problems .", "We develop efficient methods for each partitioning subproblem through an equivalent representation as a network flow problem , and prove that this sequence of partitions converges to the global solution .", "Success of isotonic regression in prediction and our algorithm 's favorable computational properties are demonstrated through simulated examples as large as 2 x 105 variables and 107 constraints .", "A new algorithm for isotonic regression is presented based on recursively partitioning the solution space ."]}
{"orig_sents": ["4", "1", "5", "6", "0", "2", "7", "3"], "shuf_sents": ["We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data , by imposing a common structure on the graphical model in the population .", "An important view of modern neuroscience is that such large-scale structure of coherent activity reflects modularity properties of brain connectivity graphs .", "We show that individual models learned from functional Magnetic Resonance Imaging ( fMRI ) data using this population prior generalize better to unseen data than models based on alternative regularization schemes .", "Finally , we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the first time that known cognitive networks appear as the integrated communities of functional connectivity graph .", "Spontaneous brain activity , as observed in functional neuroimaging , has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies .", "However , to date , there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data .", "Learning such models entails two main challenges : i ) modeling full brain connectivity is a difficult estimation problem that faces the curse of dimensionality and ii ) variability between subjects , coupled with the variability of functional signals between experimental runs , makes the use of multiple datasets challenging .", "To our knowledge , this is the first report of a cross-validated model of spontaneous brain activity ."]}
{"orig_sents": ["2", "6", "4", "1", "3", "5", "0"], "shuf_sents": ["We also argue that our results may provide test set bounds and particularly interesting empirical racing algorithms for the problem of online learning of scoring functions .", "In addition , it is based on a rather direct argument using two applications of the same ( non-empirical ) Bernstein inequality for U-statistics .", "We present original empirical Bernstein inequalities for U-statistics with bounded symmetric kernels q .", "We discuss potential applications of our new inequalities , especially in the realm of learning ranking/scoring functions .", "Our result subsumes other existing empirical Bernstein inequalities , as it reduces to them when U-statistics of order 1 are considered .", "In the process , we exhibit an efficient procedure to compute the variance estimates for the special case of bipartite ranking that rests on a sorting argument .", "They are expressed with respect to empirical estimates of either the variance of q or the conditional variance that appears in the Bernsteintype inequality for U-statistics derived by Arcones ."]}
{"orig_sents": ["1", "4", "3", "2", "0"], "shuf_sents": ["And unlike GARCH , GCPV can easily handle missing data , incorporate covariates other than time , and model a rich class of covariance structures .", "We define a copula process which describes the dependencies between arbitrarily many random variables independently of their marginal distributions .", "We find our model can outperform GARCH on simulated and financial data .", "To make predictions we use Bayesian inference , with the Laplace approximation , and with Markov chain Monte Carlo as an alternative .", "As an example , we develop a stochastic volatility model , Gaussian Copula Process Volatility ( GCPV ) , to predict the latent standard deviations of a sequence of random variables ."]}
{"orig_sents": ["5", "1", "0", "3", "4", "2"], "shuf_sents": ["In many applications , however , it is desirable to perform multiple evaluations in parallel , which requires selecting batches of multiple inputs to evaluate at once .", "Typically , these methods sequentially select inputs to be evaluated one at a time based on a posterior over the unknown function that is updated after each evaluation .", "Our experimental results on six benchmarks show that the proposed approach significantly outperforms two baselines and can lead to large advantages over a top sequential approach in terms of performance per unit time .", "In this paper , we propose a novel approach to batch Bayesian optimization , providing a policy for selecting batches of inputs with the goal of optimizing the function as efficiently as possible .", "The key idea is to exploit the availability of high-quality and efficient sequential policies , by using Monte-Carlo simulation to select input batches that closely match their expected behavior .", "Bayesian optimization methods are often used to optimize unknown functions that are costly to evaluate ."]}
{"orig_sents": ["1", "2", "3", "6", "4", "0", "5"], "shuf_sents": ["LORETA improves the mean average precision over a passive- aggressive approach in a factorized model , and also improves over a full model trained over pre-selected features using the same memory requirements .", "When learning models that are represented in matrix forms , enforcing a low-rank constraint can dramatically improve the memory and run time complexity , while providing a natural regularization of the model .", "However , naive approaches for minimizing functions over the set of low-rank matrices are either prohibitively time consuming ( repeated singular value decomposition of the matrix ) or numerically unstable ( optimizing a factored representation of the low rank matrix ) .", "We build on recent advances in optimization over manifolds , and describe an iterative online learning procedure , consisting of a gradient step , followed by a second-order retraction back to the manifold .", "We use this algorithm , LORETA , to learn a matrixform similarity measure over pairs of documents represented as high dimensional vectors .", "LORETA also showed consistent improvement over standard methods in a large ( 1600 classes ) multi-label image classification task .", "While the ideal retraction is hard to compute , and so is the projection operator that approximates it , we describe another second-order retraction that can be computed efficiently , with run time and memory complexity of O ( ( n + m ) k ) for a rank-k matrix of dimension m x n , given rank-one gradients ."]}
{"orig_sents": ["3", "0", "4", "1", "2", "5"], "shuf_sents": ["A basic aspect of the observed variation is the fact that some word orders are much more common than others .", "In this paper we offer an informationtheoretic explanation for the observed word-order distribution across languages , based on the concept of Uniform Information Density ( UID ) .", "We suggest that object-first languages are particularly disfavored because they are highly nonoptimal if the goal is to distribute information content approximately evenly throughout a sentence , and that the rest of the observed word-order distribution is at least partially explainable in terms of UID .", "Languages vary widely in many ways , including their canonical word order .", "Although this regularity has been recognized for some time , it has not been well-explained .", "We support our theoretical analysis with data from child-directed speech and experimental work ."]}
{"orig_sents": ["3", "2", "0", "4", "5", "1"], "shuf_sents": ["This formulation offers several advantages over the LARS-inspired formulation , LARS-TD .", "Moreover , warm starts permit a form of modified policy iteration that can be used to approximate a `` greedy '' homotopy path , a generalization of the LARS-TD homotopy path that combines policy evaluation and optimization .", "We propose formulating the L1 regularized linear fixed point problem as a linear complementarity problem ( LCP ) .", "Recent work in reinforcement learning has emphasized the power of L1 regularization to perform feature selection and prevent overfitting .", "The LCP formulation allows the use of efficient off-theshelf solvers , leads to a new uniqueness result , and can be initialized with starting points from similar problems ( warm starts ) .", "We demonstrate that warm starts , as well as the efficiency of LCP solvers , can speed up policy iteration ."]}
{"orig_sents": ["3", "4", "1", "0", "2"], "shuf_sents": ["Compared to earlier work on the regression case , our treatment allows for growth in the number of non-zero parameters in the true model , which is necessary in order to cover connected graphs .", "In this paper we establish the consistency of an extended Bayesian information criterion for Gaussian graphical models in a scenario where both the number of variables p and the sample size n grow .", "We demonstrate the performance of this criterion on simulated data when used in conjunction with the graphical lasso , and verify that the criterion indeed performs better than either cross-validation or the ordinary Bayesian information criterion when p and the number of non-zero parameters q both scale with n .", "Gaussian graphical models with sparsity in the inverse covariance matrix are of significant interest in many modern applications .", "For the problem of recovering the graphical structure , information criteria provide useful optimization objectives for algorithms searching through sets of graphs or for selection of tuning parameters of other methods such as the graphical lasso , which is a likelihood penalization technique ."]}
{"orig_sents": ["7", "2", "6", "4", "5", "3", "0", "1"], "shuf_sents": ["We apply both to pool-based active learning : taking the current hyperplane classifier as a query , our algorithm identifies those points ( approximately ) satisfying the well-known minimal distance-to-hyperplane selection criterion .", "We empirically demonstrate our methods ' tradeoffs , and show that they make it practical to perform active selection with millions of unlabeled points .", "We propose two hashingbased solutions .", "Our first method 's preprocessing stage is more efficient , while the second has stronger accuracy guarantees .", "Our second approach embeds the data into a vector space where the Euclidean norm reflects the desired distance between the original points and hyperplane query .", "Both use hashing to retrieve near points in sub-linear time .", "Our first approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point .", "We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the database ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We evaluate this model on a synthetic dataset and two image classification datasets , showing that it can perform at least as well as a model trained on whole images .", "The model uses a retina that only has enough high resolution pixels to cover a small area of the image , so it must decide on a sequence of fixations and it must combine the `` glimpse '' at each fixation with the location of the fixation before integrating the information with information from other glimpses of the same object .", "We describe a model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several fixations ."]}
{"orig_sents": ["2", "1", "6", "0", "3", "5", "4"], "shuf_sents": ["Samples of valueestimates are dependent , likely non-normally distributed and often limited , particularly in early learning when confidence estimates are pivotal .", "Accurate estimates of an agent 's confidence are useful for many applications , such as biasing exploration and automatically adjusting parameters to reduce dependence on parameter-tuning .", "The reinforcement learning community has explored many approaches to obtaining value estimates and models to guide decision making ; these approaches , however , do not usually provide a measure of confidence in the estimate .", "In this work , we investigate how to compute robust confidences for value estimates in continuous Markov decision processes .", "We demonstrate the applicability of our confidence estimation algorithms with experiments on exploration , parameter estimation and tracking .", "We illustrate how to use bootstrapping to compute confidence intervals online under a changing policy ( previously not possible ) and prove validity under a few reasonable assumptions .", "Computing confidence intervals on reinforcement learning value estimates , however , is challenging because data generated by the agentenvironment interaction rarely satisfies traditional assumptions ."]}
{"orig_sents": ["3", "1", "4", "0", "2"], "shuf_sents": ["When tested on a benchmark database of cardiologist annotated ECG recordings , our method had considerably better performance than other recently proposed methods on the two primary classification tasks recommended by the Association for the Advancement of Medical Instrumentation .", "The problem is made challenging by the variety of tasks , inter- and intra-patient differences , an often severe class imbalance , and the high cost of getting cardiologists to label data for individual patients .", "Additionally , our method required over 90 % less patient-specific training data than the methods to which we compared it .", "While clinicians can accurately identify different types of heartbeats in electrocardiograms ( ECGs ) from different patients , researchers have had limited success in applying supervised machine learning to the same task .", "We address these difficulties using active learning to perform patient-adaptive and task-adaptive heartbeat classification ."]}
{"orig_sents": ["0", "6", "1", "7", "2", "8", "4", "5", "3"], "shuf_sents": ["In order to study the properties of total visual input in humans , a single subject wore a camera for two weeks capturing , on average , an image every 20 seconds .", "Our first goal is to create a visual summary of the subject 's two weeks of life using unsupervised algorithms that would automatically discover recurrent scenes , familiar faces or common actions .", "As a remedy to these problems , we introduce a novel image representation , the `` structural element ( stel ) epitome , '' and an associated efficient learning algorithm .", "As a result , stel epitomes capture structure that is invariant to non-structural changes , such as illumination changes , that tend to uniformly affect pixels belonging to a single scene or object part .", "The limited epitome real-estate forces the mappings of different images to overlap which indicates image similarity .", "However , the image similarity no longer depends on direct pixel-to-pixel intensity/color/feature comparisons as in previous epitome models , but on spatial configuration of scene or object parts , as the model is based on the palette-invariant stel models .", "The resulting new dataset contains a mix of indoor and outdoor scenes as well as numerous foreground objects .", "Direct application of existing algorithms , such as panoramic stitching ( e.g. , Photosynth ) or appearance-based clustering models ( e.g. , the epitome ) , is impractical due to either the large dataset size or the dramatic variations in the lighting conditions .", "In our model , each image or image patch is characterized by a hidden mapping T which , as in previous epitome models , defines a mapping between the image coordinates and the coordinates in the large `` all-I-have-seen '' epitome matrix ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["Further , we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations .", "We verify that the new algorithm performs efficient data compression on par with the recent method of compressive sampling .", "A new algorithm is proposed for a ) unsupervised learning of sparse representations from subsampled measurements and b ) estimating the parameters required for linearly reconstructing signals from the sparse codes .", "The new algorithm can explain how neural populations in the brain that receive subsampled input through fiber bottlenecks are able to form coherent response properties ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["This results in a variety of new capabilities , such as improved estimates for infrequently occurring words , as well as the ability to leverage thesauri and dictionaries in order to boost topic cohesion within and across languages .", "We present experiments on multi-language topic synchronisation where dictionary information is used to bias corresponding words towards similar topics .", "Results indicate that our model substantially improves topic cohesion when compared to the standard LDA model .", "We extend Latent Dirichlet Allocation ( LDA ) by explicitly allowing for the encoding of side information in the distribution over words ."]}
{"orig_sents": ["6", "1", "4", "3", "2", "0", "5"], "shuf_sents": ["We empirically study the proposed method and compare with related models in two real-world problems : detecting landmines in multiple fields and recognizing faces between different subjects .", "Learning multiple ( parametric ) models can be viewed as estimating a matrix of parameters , where rows and columns of the matrix correspond to tasks and features , respectively .", "To address the overfitting issue and select meaningful task and feature structures , we include sparse covariance selection into our matrix-normal regularization via 1 penalties on task and feature inverse covariances .", "Several recently proposed methods are variants of the special cases of this formulation .", "Following the matrix-variate normal density , we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance , which characterizes both task relatedness and feature representation .", "Experimental results show that the proposed framework provides an effective and flexible way to model various different structures of multiple tasks .", "In this paper , we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks ."]}
{"orig_sents": ["3", "1", "2", "4", "6", "5", "0"], "shuf_sents": ["Through simulations on real data matrices ( gene expression data and hospital medical records ) we observe that these results can be relevant in a broad array of practical applications .", "In many contexts ( ranging from model selection to image processing ) it is desirable to construct a sparse estimator x .", "In this case , a popular approach consists in solving an 1 -penalized least squares problem known as the LASSO or Basis Pursuit DeNoising ( BPDN ) .", "We consider the problem of learning a coefficient vector x0 RN from noisy linear observation y = Ax0 + w Rn .", "For sequences of matrices A of increasing dimensions , with independent gaussian entries , we prove that the normalized risk of the LASSO converges to a limit , and we obtain an explicit expression for this limit .", "The proof technique is based on the analysis of AMP , a recently developed efficient algorithm , that is inspired from graphical models ideas .", "Our result is the first rigorous derivation of an explicit formula for the asymptotic mean square error of the LASSO for random instances ."]}
{"orig_sents": ["3", "1", "2", "4", "5", "0"], "shuf_sents": ["Our model might provide new insights into CBS and also demonstrates that generative frameworks are promising as hypothetical models of cortical learning and perception .", "We present a Deep Boltzmann Machine model of CBS , exploring two core hypotheses : First , that the visual cortex learns a generative or predictive model of sensory input , thus explaining its capability to generate internal imagery .", "And second , that homeostatic mechanisms stabilize neuronal activity levels , leading to hallucinations being formed when input is lacking .", "The Charles Bonnet Syndrome ( CBS ) is characterized by complex vivid visual hallucinations in people with , primarily , eye diseases and no other neurological pathology .", "We reproduce a variety of qualitative findings in CBS .", "We also introduce a modification to the DBM that allows us to model a possible role of acetylcholine in CBS as mediating the balance of feed-forward and feed-back processing ."]}
{"orig_sents": ["3", "2", "1", "4", "0", "6", "5"], "shuf_sents": ["We examine two weighting schemes , kernel based weights and Dirichlet process based weights , for use with the solution methods .", "Currently , there is no general purpose algorithm to solve this class of problems .", "There are many stochastic optimization problems whose behavior depends on an exogenous state variable which affects the shape of the objective function .", "In this paper we study convex stochastic optimization problems where a noisy objective function value is observed after a decision is made .", "We use nonparametric density estimation to take observations from the joint state-outcome distribution and use them to infer the optimal decision for a given query state s. We propose two solution methods that depend on the problem characteristics : function-based and gradient-based optimization .", "Our results show that in some cases Dirichlet process weights offer substantial benefits over kernel based weights and more generally that nonparametric estimation methods provide good solutions to otherwise intractable problems .", "The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour ahead wind commitment problem ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["In this paper , we propose a first-order method based on an alternating linearization technique that exploits the problem 's special structure ; in particular , the subproblems solved in each iteration have closed-form solutions .", "Moreover , our algorithm obtains an -optimal solution in O ( 1/ ) iterations .", "Numerical experiments on both synthetic and real data from gene association networks show that a practical version of this algorithm outperforms other competitive algorithms .", "Gaussian graphical models are of great interest in statistical learning .", "Because the conditional independencies between different nodes correspond to zero entries in the inverse covariance matrix of the Gaussian distribution , one can learn the structure of the graph by estimating a sparse inverse covariance matrix from sample data , by solving a convex maximum likelihood problem with an 1 -regularization term ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["The new system , VISA ( Vertically Integrated Seismological Analysis ) , is based on empirically calibrated , generative models of event occurrence , signal propagation , and signal detection .", "We report on the first stage of a project to improve on the current automated software system with a Bayesian inference system that computes the most likely global event history given the record of local sensor data .", "VISA exhibits significantly improved precision and recall compared to the current operational system and is able to detect events that are missed even by the human analysts who post-process the IMS output .", "The International Monitoring System ( IMS ) is a global network of sensors whose purpose is to identify potential violations of the Comprehensive Nuclear-Test-Ban Treaty ( CTBT ) , primarily through detection and localization of seismic events ."]}
{"orig_sents": ["0", "3", "8", "7", "5", "12", "11", "4", "10", "13", "2", "9", "1", "6"], "shuf_sents": ["Clustering is a basic data mining task with a wide variety of applications .", "We also study relationships between the properties , independent of any particular algorithm .", "In this paper , we demonstrate how abstract , intuitive properties of clustering functions can be used to taxonomize a set of popular clustering algorithmic paradigms .", "Not surprisingly , there exist many clustering algorithms .", "In this paper we address the major research challenge of developing tools for helping users make more informed decisions when they come to pick a clustering tool for their data .", "Faced with a concrete clustering task , a user needs to choose an appropriate clustering algorithm .", "In particular , we strengthen Kleinberg 's famous impossibility result , while providing a simpler proof .", "Indeed , different algorithms may yield dramatically different outputs for the same input sets .", "However , clustering is an ill defined problem - given a data set , it is not clear what a `` correct '' clustering for that set is .", "On top of addressing deterministic clustering algorithms , we also propose similar properties for randomized algorithms and use them to highlight functional differences between different common implementations of k-means clustering .", "This is , of course , a very ambitious endeavor , and in this paper , we make some first steps towards this goal .", "Given the crucial effect of the choice of a clustering algorithm on the resulting clustering , this state of affairs is truly regrettable .", "Currently , such decisions are often made in a very ad hoc , if not completely random , manner .", "We propose to address this problem by distilling abstract properties of the input-output behavior of different clustering paradigms ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly , but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling .", "We show that the weighted trace-norm regularization indeed yields significant gains on the highly non-uniformly sampled Netflix dataset ."]}
{"orig_sents": ["2", "1", "5", "4", "0", "3"], "shuf_sents": ["Then , we consider the case where the cost of identifying an object grows exponentially in the number of queries .", "Here , we provide a coding-theoretic interpretation for GBS and show that GBS can be viewed as a top-down algorithm that greedily minimizes the expected number of queries required to identify an object .", "Generalized Binary Search ( GBS ) is a well known greedy algorithm for identifying an unknown object while minimizing the number of `` yes '' or `` no '' questions posed about that object , and arises in problems such as active learning and active diagnosis .", "In each case , we present an exact formula for the objective function involving Shannon or Renyi entropy , and develop a greedy algorithm for minimizing it .", "First , we consider the case where the objects are partitioned into groups , and the objective is to identify only the group to which the object belongs .", "This interpretation is then used to extend GBS in two ways ."]}
{"orig_sents": ["1", "2", "6", "0", "4", "5", "3"], "shuf_sents": ["Our model uses a `` 2.1D '' local feature , which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window .", "Metric constraints are known to be highly discriminative for many objects , but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited .", "In this paper , we show how a crucial aspect of 3-D information-object and feature absolute size-can be added to models learned from commonly available online imagery , without use of any 3-D sensing or reconstruction at training time .", "Experiments on test scenes captured with a traditional stereo rig are shown , exploiting training data from from purely monocular sources with associated EXIF metadata .", "We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata fields specifying camera intrinstics .", "We develop an efficient metric branch-and-bound algorithm for our search task , imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category .", "Such models can be utilized at test time together with explicit 3-D sensing to perform robust search ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["A standard approach to learning object category detectors is to provide strong supervision in the form of a region of interest ( ROI ) specifying each instance of the object in the training images .", "In this work are goal is to learn from heterogeneous labels , in which some images are only weakly supervised , specifying only the presence or absence of the object or a weak indication of object location , whilst others are fully annotated .", "The method is demonstrated on the benchmark INRIA pedestrian detection dataset of Dalal and Triggs and the PASCAL VOC dataset , and it is shown that for a significant proportion of weakly supervised images the performance achieved is very similar to the fully supervised ( state of the art ) results .", "To this end we develop a discriminative learning approach and make two contributions : ( i ) we propose a structured output formulation for weakly annotated images where full annotations are treated as latent variables ; and ( ii ) we propose to optimize a ranking objective function , allowing our method to more effectively use negatively labeled images to improve detection average precision performance ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["In this paper , we introduce the minimum average cost criterion , and show that the theory of intersecting submodular functions can be used for clustering with submodular objective functions .", "The minimum average cost clustering problem is parameterized with a real variable , and surprisingly , we show that all information about optimal clusterings for all parameters can be computed in polynomial time in total .", "A number of objective functions in clustering problems can be described with submodular functions .", "Additionally , we evaluate the performance of the proposed algorithm through computational experiments .", "The proposed algorithm does not require the number of clusters in advance , and it will be determined by the property of a given set of data points ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["Convenient choices of loss functions make it practical to fit graphical models with hidden variables , high treewidth and/or model misspecification .", "Given an arbitrary loss function , defined on marginals , we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice , on slightly perturbed model parameters .", "This method can be used with approximate inference , with a loss function over approximate marginals .", "This paper proposes a simple and efficient finite difference method for implicit differentiation of marginal inference results in discrete graphical models ."]}
{"orig_sents": ["3", "5", "4", "0", "2", "1"], "shuf_sents": ["One can view our model as providing infinite mixtures where the components have a dependency structure corresponding to an evolutionary diffusion down a tree .", "We apply our method to hierarchical clustering of images and topic modeling of text data .", "By using a stick-breaking approach , we can apply Markov chain Monte Carlo methods based on slice sampling to perform Bayesian inference and simulate from the posterior distribution on trees .", "Many data are naturally modeled by an unobserved hierarchical structure .", "The approach uses nested stick-breaking processes to allow for trees of unbounded width and depth , where data can live at any node and are infinitely exchangeable .", "In this paper we propose a flexible nonparametric prior over unknown data hierarchies ."]}
{"orig_sents": ["2", "4", "3", "0", "1"], "shuf_sents": ["Each segment is generated through a noisy transformation of one of a few hidden trajectories representing different types of movement , with possible time re-scaling .", "We analyze three different approximation methods for dealing with model intractability , and demonstrate how the proposed approach can successfully segment table tennis movements recorded using a robot arm as haptic input device .", "Many time-series such as human movement data consist of a sequence of basic actions , e.g. , forehands and backhands in tennis .", "In this paper , we present a probabilistic segmentation approach in which an observed time-series is modeled as a concatenation of segments corresponding to different basic actions .", "Automatically extracting and characterizing such actions is an important problem for a variety of different applications ."]}
{"orig_sents": ["2", "3", "4", "0", "6", "5", "1"], "shuf_sents": ["We derive a generalization of the inverse power method which is guaranteed to converge to a nonlinear eigenvector .", "Moving beyond the standard eigenproblem should be useful also in many other applications and our inverse power method can be easily adapted to new problems .", "Many problems in machine learning and statistics can be formulated as ( generalized ) eigenproblems .", "In terms of the associated optimization problem , computing linear eigenvectors amounts to finding critical points of a quadratic function subject to quadratic constraints .", "In this paper we show that a certain class of constrained optimization problems with nonquadratic objective and constraints can be understood as nonlinear eigenproblems .", "In both applications we achieve state-of-the-art results in terms of solution quality and runtime .", "We apply the inverse power method to 1-spectral clustering and sparse PCA which can naturally be formulated as nonlinear eigenproblems ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["We further demonstrate the effectiveness of the proposed algorithm in solving the affine SfM problem , non-rigid SfM and photometric stereo problems .", "Matrix factorization in the presence of missing data is at the core of many computer vision problems such as structure from motion ( SfM ) , non-rigid SfM and photometric stereo .", "Our empirical evaluations suggest that , under the conditions of matrix completion theory , the proposed algorithm finds the optimal solution , and also requires fewer observations compared to the current state-of-the-art algorithms .", "We formulate the problem of matrix factorization with missing data as a low-rank semidefinite program ( LRSDP ) with the advantage that : 1 ) an efficient quasi-Newton implementation of the LRSDP enables us to solve large-scale factorization problems , and 2 ) additional constraints such as orthonormality , required in orthographic SfM , can be directly incorporated in the new formulation ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["We analyze feature transitions associated with saccadic search and find out that size , color , and orientation are not alike in dynamic attribute processing over time .", "Size , color , and orientation have long been considered elementary features whose attributes are extracted in parallel and available to guide the deployment of attention .", "The Markovian feature transition is attractive for size , repulsive for color , and largely reversible for orientation .", "If each is processed in the same fashion with simply a different set of local detectors , one would expect similar search behaviours on localizing an equivalent flickering change among identically laid out disks ."]}
{"orig_sents": ["6", "5", "1", "7", "4", "0", "2", "3"], "shuf_sents": ["We present a maximum likelihood approach based on convex programming with a l1 -like penalty term that encourages sparsity .", "Here , we formulate the problem of inferring latent social networks based on network diffusion or disease propagation data .", "Experiments on real and synthetic data reveal that our method near-perfectly recovers the underlying network structure as well as the parameters of the contagion propagation model .", "Moreover , our approach scales well as it can infer optimal networks of thousands of nodes in a matter of minutes .", "Given such node infection times , we then identify the optimal network that best explains the observed data .", "In such cases , whole networks must be inferred from underlying observations .", "In many real-world scenarios , it is nearly impossible to collect explicit social network data .", "We consider contagions propagating over the edges of an unobserved social network , where we only observe the times when nodes became infected , but not who infected them ."]}
{"orig_sents": ["3", "0", "5", "2", "1", "4"], "shuf_sents": ["In the Bayesian framework the covariance structure can be specified using unknown hyperparameters .", "However , with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly .", "This integration is often performed using Markov chain Monte Carlo ( MCMC ) sampling .", "The Gaussian process ( GP ) is a popular way to specify dependencies between random variables in a probabilistic model .", "In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes .", "Integrating over these hyperparameters considers different possible explanations for the data when making predictions ."]}
{"orig_sents": ["5", "7", "1", "0", "6", "3", "2", "8", "4"], "shuf_sents": ["Our algorithm is query-efficient in the sense that it involves only a small amount of interaction with the teacher .", "We give an improved generic algorithm to cluster any concept class in that model .", "We eliminate this limitation by proposing a noisy model and give an algorithm for clustering the class of intervals in this noisy model .", "The model assumes that the teacher response to the algorithm is perfect .", "Finally , for datasets satisfying a spectrum of weak to strong properties , we give query bounds , and show that a class of clustering functions containing Single-Linkage will find the target clustering under the strongest property .", "Despite the ubiquity of clustering as a tool in unsupervised learning , there is not yet a consensus on a formal theory , and the vast majority of work in this direction has focused on unsupervised clustering .", "We also present and study two natural generalizations of the model .", "We study a recently proposed framework for supervised clustering where there is access to a teacher .", "We also propose a dynamic model where the teacher sees a random subset of the points ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We develop a theory of online learning by defining several complexity measures .", "We apply these results to various learning problems .", "Among them are analogues of Rademacher complexity , covering numbers and fatshattering dimension from statistical learning theory .", "Relationship among these complexity measures , their connection to online learning , and tools for bounding them are provided .", "We provide a complete characterization of online learnability in the supervised setting ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["We demonstrate how such bounds can be used for model-selection in control problems where prior information is available either on the dynamics of the environment , or on the value of actions .", "These bounds hold regardless of the correctness of the prior distribution .", "Our empirical results confirm that PAC-Bayesian model-selection is able to leverage prior distributions when they are informative and , unlike standard Bayesian RL approaches , ignores them when they are misleading .", "This paper introduces the first set of PAC-Bayesian bounds for the batch reinforcement learning problem in finite state spaces ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["We show that , under standard assumptions of Lambertian reflection and static illumination , the task can be posed as a convex minimization problem .", "Therefore , the solution , computed using efficient algorithms , is guaranteed to be globally optimal , for any number of independently moving objects , and any number of occlusion layers .", "We test the proposed algorithm on benchmark datasets , expanded to enable evaluation of occlusion detection performance .", "We tackle the problem of simultaneously detecting occlusions and estimating optical flow ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We show that augmenting current structured prediction techniques with volumetric reasoning significantly improves the performance of the state-of-the-art .", "There has been a recent push in extraction of 3D spatial layout of scenes .", "However , none of these approaches model the 3D interaction between objects and the spatial layout .", "In this paper , we argue for a parametric representation of objects in 3D , which allows us to incorporate volumetric constraints of the physical world ."]}
{"orig_sents": ["6", "3", "5", "4", "7", "9", "1", "8", "2", "0"], "shuf_sents": ["The results of this study have substantial implications for advancing neuroprosthetic approaches to stroke populations not currently amenable to existing BCI techniques .", "We demonstrate , for the first time , successful finger movement detection using machine learning algorithms .", "We also show that significant accuracies can be achieved with the use of only a fraction of all the features recorded and that these core features are consistent with previous physiological findings .", "Contralateral primary motor cortex is also the region most severely affected by hemispheric stroke .", "The most fundamental functional loss after a hemispheric stroke is the loss of fine motor control of the hand .", "Recent studies have identified ipsilateral cortical activity in planning of motor movements and its potential implications for a stroke relevant BCI .", "Several motor related Brain Computer Interfaces ( BCIs ) have been developed over the years that use activity decoded from the contralateral hemisphere to operate devices .", "Thus , whether ipsilateral cortex encodes finger movements is critical to the potential feasibility of BCI approaches in the future .", "Our results show high decoding accuracies in all cases which are always above chance .", "This study uses ipsilateral cortical signals from humans ( using ECoG ) to decode finger movements ."]}
{"orig_sents": ["0", "1", "2", "4", "3"], "shuf_sents": ["We apply the framework of kernel dimension reduction , originally designed for supervised problems , to unsupervised dimensionality reduction .", "In this framework , kernel-based measures of independence are used to derive low-dimensional representations that maximally capture information in covariates in order to predict responses .", "We extend this idea and develop similarly motivated measures for unsupervised problems where covariates and responses are the same .", "Furthermore , when used in conjunction with supervised learners for classification , our methods lead to lower classification errors than state-of-the-art methods , especially when embedding data in spaces of very few dimensions .", "Our empirical studies show that the resulting compact representation yields meaningful and appealing visualization and clustering of data ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We study repeated zero-sum games against an adversary on a budget .", "We show that , for a general class of normal-form games , the minimax strategy is indeed efficiently computable and relies on a `` random playout '' technique .", "We give three diverse applications of this new algorithmic template : a cost-sensitive `` Hedge '' setting , a particular problem in Metrical Task Systems , and the design of combinatorial prediction markets .", "Given that an adversary has some constraint on the sequence of actions that he plays , we consider what ought to be the player 's best mixed strategy with knowledge of this budget ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["Empirically , the new methods outperform mature techniques from all three areas .", "The max-norm was proposed as a convex matrix regularizer in and was shown to be empirically superior to the trace-norm for collaborative filtering problems .", "The present work uses a factorization technique of Burer and Monteiro to devise scalable first-order algorithms for convex programs involving the max-norm .", "These algorithms are applied to solve huge collaborative filtering , graph cut , and clustering problems .", "Although the max-norm can be computed in polynomial time , there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm ."]}
{"orig_sents": ["1", "2", "4", "10", "8", "9", "11", "6", "0", "7", "5", "3"], "shuf_sents": ["With the explosion of such dirty high-dimensional data in modern settings , it is vital to develop tools - dirty models - to perform biased statistical estimation tailored to such data .", "We consider multi-task learning in the setting of multiple linear regression , and where some relevant features could be shared across the tasks .", "Recent research has studied the use of 1 /q norm block-regularizations with q > 1 for such blocksparse structured problems , establishing strong guarantees on recovery even under high-dimensional scaling where the number of features scale with the number of observations .", "We show both theoretically and empirically , our method strictly and noticeably outperforms both 1 or 1 /q methods , under high-dimensional scaling and over the entire range of possible overlaps ( except at boundary cases , where we match the best method ) .", "However , these papers also caution that the performance of such block-regularized methods are very dependent on the extent to which the features are shared across tasks .", "Our method uses a very simple idea : we estimate a superposition of two sets of parameters and regularize them differently .", "Indeed , this falls under a more general question of whether we can model such dirty data which may not fall into a single neat structural bracket ( all block-sparse , or all low-rank and so on ) .", "Here , we take a first step , focusing on developing a dirty model for the multiple regression problem .", "Since these caveats depend on the unknown true parameters , we might not know when and which method to apply .", "Even otherwise , we are far away from a realistic multi-task setting : not only do the set of relevant features have to be exactly the same across tasks , but their values have to as well .", "Indeed they show that if the extent of overlap is less than a threshold , or even if parameter values in the shared features are highly uneven , then block 1 /q regularization could actually perform worse than simple separate elementwise 1 regularization .", "Here , we ask the question : can we leverage parameter overlap when it exists , but not pay a penalty when it does not ?"]}
{"orig_sents": ["5", "4", "3", "6", "1", "2", "0"], "shuf_sents": ["We demonstrate an application of the proposed divergences as a cost function to find optimally matched point processes .", "A divergence measure compares the full probability structure and , therefore , leads to a more robust test of hypothesis .", "We extend the traditional Kolmogorov-Smirnov and Cramer-von-Mises tests to the space of spike trains via stratification , and show that these statistics can be consistently estimated from data without any free parameter .", "However , these statistics do not fully describe a point process , and therefore , the conclusions drawn by these tests can be misleading .", "Standard tools for hypothesis testing include tests on mean firing rate and time varying rate function .", "Hypothesis testing on point processes has several applications such as model fitting , plasticity detection , and non-stationarity detection .", "In this paper , we introduce a family of non-parametric divergence measures for hypothesis testing ."]}
{"orig_sents": ["0", "4", "1", "2", "5", "3"], "shuf_sents": ["To localise the source of a sound , we use location-specific properties of the signals received at the two ears caused by the asymmetric filtering of the original sound by our head and pinnae , the head-related transfer functions ( HRTFs ) .", "Since HRTFs are not directly accessible from perceptual experience , they can only be inferred from filtered sounds .", "We present a spiking neural network model of sound localisation based on extracting location-specific synchrony patterns , and a simple supervised algorithm to learn the mapping between synchrony patterns and locations from a set of example sounds , with no previous knowledge of HRTFs .", "Keywords : Auditory Perception & Modeling ( Primary ) ; Computational Neural Models , Neuroscience , Supervised Learning ( Secondary )", "These HRTFs change throughout an organism 's lifetime , during development for example , and so the required neural circuitry can not be entirely hardwired .", "After learning , our model was able to accurately localise new sounds in both azimuth and elevation , including the difficult task of distinguishing sounds coming from the front and back ."]}
{"orig_sents": ["4", "2", "1", "3", "0"], "shuf_sents": ["Finally , we demonstrate the advantages of large-margin learning on real video and web image data for discovering predictive latent representations and improving the performance on image classification , annotation and retrieval .", "Our approach is based on an undirected latent space Markov network that fulfills a weak conditional independence assumption that multi-view observations and response variables are independent given a set of latent variables .", "In this paper , we present a large-margin learning framework to discover a predictive latent subspace representation shared by multiple views .", "We provide efficient inference and parameter estimation methods for the latent subspace model .", "Learning from multi-view data is important in many applications , such as image classification and annotation ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["To cope with concept drift , we placed a probability distribution over the location of the most-recent drift point .", "In our experiments , our approach generally yielded improved accuracy and/or speed over these other methods .", "We compare our approach to a non-probabilistic method for drift and a probabilistic method for change-point detection .", "We used Bayesian model comparison to update this distribution from the predictions of models trained on blocks of consecutive observations and pruned potential drift points with low probability ."]}
{"orig_sents": ["3", "4", "0", "8", "6", "7", "5", "2", "1"], "shuf_sents": ["The existing algorithms do not apply if one uses arbitrary losses and often can not handle m > 1 case .", "Experimental results on real world protein data set involving several similarity matrices illustrate the efficacy of the proposed algorithms .", "An alternative to both EMKL and REKL is also suggested which requires only an SVM solver .", "In this paper we consider the problem of learning an n x n kernel matrix from m ( 1 ) similarity matrices under general convex loss .", "Past research have extensively studied the m = 1 case and have derived several algorithms which require sophisticated techniques like ACCP , SOCP , etc .", "By suitably defining a restriction on the objective function , a faster version of EMKL is proposed , called REKL , which avoids the eigen-decomposition .", "One of the major contributions of the paper is to extend the well known Mirror Descent ( MD ) framework to handle Cartesian product of psd matrices .", "This novel extension leads to an algorithm , called EMKL , which solves the problem in 2 n O ( m log ) iterations ; in each iteration one solves an MKL involving m kernels 2 and m eigen-decomposition of n x n matrices .", "We present several provably convergent iterative algorithms , where each iteration requires either an SVM or a Multiple Kernel Learning ( MKL ) solver for m > 1 case ."]}
{"orig_sents": ["3", "10", "2", "6", "9", "1", "8", "7", "4", "0", "11", "5"], "shuf_sents": ["The distribution of basis function shapes reflects properties of simple cell receptive fields that are not reproduced by standard linear approaches .", "Furthermore , we can infer all model parameters including observation noise and the degree of sparseness .", "However , in the place where standard approaches use the sum to combine basis functions we use the maximum .", "We study the application of a strongly non-linear generative model to image patches .", "Quantitatively , the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions .", "The presented algorithm represents the first large-scale application of such an approach .", "To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization .", "Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition .", "In applications to image patches we find that Gabor-like basis functions are obtained .", "The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables .", "As in standard approaches such as Sparse Coding or Independent Component Analysis , the model assumes a sparse prior with independent hidden variables .", "In the study of natural image statistics , the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging ."]}
{"orig_sents": ["2", "6", "0", "1", "3", "4", "5"], "shuf_sents": ["Applying the resulting filters convolutionally results in highly redundant codes because overlapping patches are encoded in isolation .", "By training convolutionally over large image windows , our method reduces the redudancy between feature vectors at neighboring locations and improves the efficiency of the overall representation .", "We propose an unsupervised method for learning multi-stage hierarchies of sparse convolutional features .", "In addition to a linear decoder that reconstructs the image from sparse features , our method trains an efficient feed-forward encoder that predicts quasisparse features from the input .", "While patch-based training rarely produces anything but oriented edge detectors , we show that convolutional training produces highly diverse filters , including center-surround filters , corner detectors , cross detectors , and oriented grating detectors .", "We show that using these filters in multistage convolutional network architecture improves performance on a number of visual recognition and detection tasks .", "While sparse coding has become an increasingly popular method for learning visual features , it is most often trained at the patch level ."]}
{"orig_sents": ["4", "5", "6", "0", "1", "2", "3"], "shuf_sents": ["Unlike other variational methods , our ensembles do not enforce agreement between sub-models , but filter the space of possible outputs by simply adding and thresholding the max-marginals of each constituent model .", "Our framework jointly estimates parameters for all models in the ensemble for each level of the cascade by minimizing a novel , convex loss function , yet requires only a linear increase in computation over learning or inference in a single tractable sub-model .", "We provide a generalization bound on the filtering loss of the ensemble as a theoretical justification of our approach , and we evaluate our method on both synthetic data and the task of estimating articulated human pose from challenging videos .", "We find that our approach significantly outperforms loopy belief propagation on the synthetic data and a state-of-the-art model on the pose estimation/tracking problem .", "For many structured prediction problems , complex models often require adopting approximate inference techniques such as variational methods or sampling , which generally provide no satisfactory accuracy guarantees .", "In this work , we propose sidestepping intractable inference altogether by learning ensembles of tractable sub-models as part of a structured prediction cascade .", "We focus in particular on problems with high-treewidth and large state-spaces , which occur in many computer vision tasks ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Although the case of binary classification is well understood , in the multiclass setting , the `` correct '' requirements on the weak classifier , or the notion of the most efficient boosting algorithms are missing .", "In this paper , we create a broad and general framework , within which we make precise and identify the optimal requirements on the weak-classifier , as well as design the most effective , in a certain sense , boosting algorithms that assume such requirements .", "Boosting combines weak classifiers to form highly accurate predictors ."]}
{"orig_sents": ["0", "6", "4", "1", "5", "3", "2"], "shuf_sents": ["Convolutional neural networks ( CNNs ) have been successfully applied to many tasks such as digit and object recognition .", "We propose tiled convolution neural networks ( Tiled CNNs ) , which use a regular `` tiled '' pattern of tied weights that does not require that adjacent hidden units share identical weights , but instead requires only that hidden units k steps away from each other to have tied weights .", "We provide an efficient learning algorithm for Tiled CNNs based on Topographic ICA , and show that learning complex invariant features allows us to achieve highly competitive results for both the NORB and CIFAR-10 datasets .", "Further , it also enjoys much of CNNs ' advantage of having a relatively small number of learned parameters ( such as ease of learning and greater scalability ) .", "In this paper , we consider the problem of learning invariances , rather than relying on hardcoding .", "By pooling over neighboring units , this architecture is able to learn complex invariances ( such as scale and rotational invariance ) beyond translational invariance .", "Using convolutional ( tied ) weights significantly reduces the number of parameters that have to be learned , and also allows translational invariance to be hard-coded into the architecture ."]}
{"orig_sents": ["2", "5", "0", "3", "1", "4"], "shuf_sents": ["This family subsumes the 1 norm and is flexible enough to include different models of sparsity patterns , which are of practical and theoretical importance .", "Moreover , we present a convergent optimization algorithm for solving regularized least squares with these penalty functions .", "We study the problem of learning a sparse linear regression vector under additional conditions on the structure of its sparsity pattern .", "We establish some important properties of these functions and discuss some examples where they can be computed explicitly .", "Numerical simulations highlight the benefit of structured sparsity and the advantage offered by our approach over the Lasso and other related methods .", "We present a family of convex penalty functions , which encode this prior knowledge by means of a set of constraints on the absolute values of the regression coefficients ."]}
{"orig_sents": ["3", "5", "4", "1", "0", "2"], "shuf_sents": ["The overall model can be interpreted as a gated MRF where both pair-wise dependencies and mean intensities of pixels are modulated by the states of latent variables .", "We investigate the reasons for this failure and we show that by augmenting existing models so that there are two sets of latent variables , one set modelling pixel intensities and the other set modelling image-specific pixel covariances , we are able to generate high-resolution images that look much more realistic than before .", "Finally , we confirm that if we disallow weight-sharing between receptive fields that overlap each other , the gated MRF learns more efficient internal representations , as demonstrated in several recognition tasks .", "Probabilistic models of natural images are usually evaluated by measuring performance on rather indirect tasks , such as denoising and inpainting .", "This method is seldom used with high-resolution images , because current models produce samples that are very different from natural images , as assessed by even simple visual inspection .", "A more direct way to evaluate a generative model is to draw samples from it and to check whether statistical properties of the samples match the statistics of natural images ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["The model is fit to multiple data sets , and provides a parsimonious method for describing how humans learn context specific conceptual representations .", "This paper outlines a hierarchical Bayesian model for human category learning that learns both the organization of objects into categories , and the context in which this knowledge should be applied ."]}
{"orig_sents": ["4", "10", "7", "0", "8", "9", "2", "3", "1", "5", "6"], "shuf_sents": ["Prior work typically resorts to a parametric estimation of these four distributions , and then computes their ratio .", "( RF ) 2 is applied to a challenging task of multiclass object recognition and segmentation over a random field of input image regions .", "We use these class histograms for a nonparametric estimation of the distribution ratios .", "We derive the theoretical error bounds of a two-class ( RF ) 2 .", "We combine random forest ( RF ) and conditional random field ( CRF ) into a new computational framework , called random forest random field ( RF ) 2 .", "In our empirical evaluation , we use only the visual information provided by image regions ( e.g. , color , texture , spatial layout ) , whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene .", "Nevertheless , ( RF ) 2 outperforms the state of the art on benchmark datasets , in terms of accuracy and computation time .", "A jump from one state to another depends on the ratio of the proposal distributions , and on the ratio of the posterior distributions of the two states .", "Our key idea is to instead directly estimate these ratios using RF .", "RF collects in leaf nodes of each decision tree the class histograms of training examples .", "Inference of ( RF ) 2 uses the Swendsen-Wang cut algorithm , characterized by MetropolisHastings jumps ."]}
{"orig_sents": ["0", "4", "2", "1", "3", "5"], "shuf_sents": ["Bayesian approaches to preference elicitation ( PE ) are particularly attractive due to their ability to explicitly model uncertainty in users ' latent utility functions .", "We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user .", "In this paper , we address this deficiency by introducing a Gaussian Process ( GP ) prior over users ' latent utility functions on the joint space of user and item features .", "This approach provides a flexible model of a multi-user utility function , facilitates an efficient value of information ( VOI ) heuristic query selection strategy , and provides a principled way to incorporate the elicitations of multiple users back into the model .", "However , previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users .", "We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types ."]}
{"orig_sents": ["5", "3", "4", "6", "7", "0", "1", "2"], "shuf_sents": [".", "We propose a general , though inefficient , algorithm for general finite concept classes that minimizes the number of don't-know predictions subject to a given bound on the number of allowed mistakes .", "We then present specific polynomial-time algorithms for the concept classes of monotone disjunctions and linear separators with a margin .", "We analyze the trade off between saying `` I do n't know '' and making mistakes .", "If the number of don't-know predictions is required to be zero , the model reduces to the well-known mistake-bound model introduced by Littlestone .", "We discuss an online learning framework in which the agent is allowed to say `` I do n't know '' as well as making incorrect predictions on given examples .", "On the other hand , if no mistakes are allowed , the model reduces to KWIK framework introduced by Li et .", "al ."]}
{"orig_sents": ["1", "5", "0", "2", "4", "3", "6"], "shuf_sents": ["Our method is convolutional , enabling it to scale to realistically-sized images .", "This paper tackles the complex problem of visually matching people in similar pose but with different clothes , background , and other appearance changes .", "By cheaply labeling the head and hands in large video databases through Amazon Mechanical Turk ( a crowd-sourcing service ) , we can use the task of localizing the head and hands as a proxy for determining body pose .", "We evaluate our method quantitatively against other embedding methods .", "We apply our method to challenging real-world data and show that it can generalize beyond hand localization to infer a more general notion of body pose .", "We achieve this with a novel method for learning a nonlinear embedding based on several extensions to the Neighborhood Component Analysis ( NCA ) framework .", "We also demonstrate that realworld performance can be improved through the use of synthetic data ."]}
{"orig_sents": ["7", "6", "3", "0", "1", "4", "2", "5"], "shuf_sents": ["Given the impressive convergence speed of CPM on a number of practical problems , it was conjectured that these rates could be further improved .", "In this paper we disprove this conjecture .", "However , surprisingly , these problems are not inherently hard .", "showed that O ( 1/ ) iterations suffice .", "We present counter examples which are not only applicable for training linear SVMs with hinge loss , but also hold for support vector methods which optimize a multivariate performance score .", "By exploiting the structure of the objective function we can devise an algorithm that converges in O ( 1/ ) iterations .", "By tightening the analysis , Teo et al .", "In a recent paper Joachims presented SVM-Perf , a cutting plane method ( CPM ) for training linear Support Vector Machines ( SVMs ) which converges to an accurate solution in O ( 1/ 2 ) iterations ."]}
{"orig_sents": ["8", "5", "3", "1", "0", "2", "4", "6", "7"], "shuf_sents": ["We propose the SPORE ( Sparse POlynomial REgression ) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs .", "In this paper we study the construction of predictive models for this problem .", "Our two SPORE algorithms are able to build relationships between responses ( e.g. , the execution time of a computer program ) and features , and select a few from hundreds of the retrieved features to construct an explicitly sparse and non-linear model to predict the response variable .", "We recently developed a new system to automatically extract a large number of features from program execution on sample inputs , on which prediction models can be constructed without expert knowledge .", "The compact and explicitly polynomial form of the estimated model could reveal important insights into the computer program ( e.g. , features and their non-linear combinations that dominate the execution time ) , enabling a better understanding of the program 's behavior .", "Existing methods require experts to perform detailed analysis of program code in order to construct predictors or select important features .", "Our evaluation on three widely used computer programs shows that SPORE methods can give accurate prediction with relative error less than 7 % by using a moderate number of training data samples .", "In addition , we compare SPORE algorithms to state-of-the-art sparse regression algorithms , and show that SPORE methods , motivated by real applications , outperform the other methods in terms of both interpretability and prediction accuracy .", "Predicting the execution time of computer programs is an important but challenging problem in the community of computer systems ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["This gives rise to the optimization problem of designing the artificial agent 's goals -- in the RL framework , designing the agent 's reward function .", "Recent work has demonstrated that when artificial agents are limited in their ability to achieve their goals , the agent designer can benefit by making the agent 's goals different from the designer 's .", "Existing attempts at solving this optimal reward problem do not leverage experience gained online during the agent 's lifetime nor do they take advantage of knowledge about the agent 's structure .", "We show that our method generalizes a standard policy gradient approach , and we demonstrate its ability to improve reward functions in agents with various forms of limitations .", "In this work , we develop a gradient ascent approach with formal convergence guarantees for approximately solving the optimal reward problem online during an agent 's lifetime ."]}
{"orig_sents": ["0", "8", "1", "2", "3", "5", "4", "6", "7"], "shuf_sents": ["The design of low-level image features is critical for computer vision algorithms .", "We highlight the kernel view of orientation histograms , and show that they are equivalent to a certain type of match kernels over image patches .", "This novel view allows us to design a family of kernel descriptors which provide a unified and principled framework to turn pixel attributes ( gradient , color , local binary pattern , etc . )", "into compact patch-level features .", "Kernel descriptors are easy to design and can turn any type of pixel attribute into patch-level features .", "In particular , we introduce three types of match kernels to measure similarities between image patches , and construct compact low-dimensional kernel descriptors from these match kernels using kernel principal component analysis ( KPCA ) .", "They outperform carefully tuned and sophisticated features including SIFT and deep belief networks .", "We report superior performance on standard image classification benchmarks : Scene-15 , Caltech-101 , CIFAR10 and CIFAR10-ImageNet .", "Orientation histograms , such as those in SIFT and HOG , are the most successful and popular features for visual object and scene recognition ."]}
{"orig_sents": ["1", "5", "3", "2", "0", "4"], "shuf_sents": ["Such a joint learning allows the individual predictors to focus on a more restricted modeling problem , and improves the performance compared to a standard cascade .", "The standard strategy for efficient object detection consists of building a cascade composed of several binary classifiers .", "From this noisy-AND model , we derive a consistent loss and a Boosting procedure to optimize that global probability on the training set .", "We introduce a novel algorithm to construct jointly the classifiers of such a cascade , which interprets the response of a classifier as the probability of a positive prediction , and the overall response of the cascade as the probability that all the predictions are positive .", "We demonstrate the efficiency of this approach on face and pedestrian detection with standard data-sets and comparisons with reference baselines .", "The detection process takes the form of a lazy evaluation of the conjunction of the responses of these classifiers , and concentrates the computation on difficult parts of the image which can not be trivially rejected ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["The optimization problem is efficiently solved with a variational EM procedure , which iteratively solves an online loss-augmented SVM .", "This paper presents a joint max-margin and max-likelihood learning method for upstream scene understanding models , in which latent topic discovery and prediction model estimation are closely coupled and well-balanced .", "However , existing maximum likelihood estimation ( MLE ) schemes can make the prediction model learning independent of latent topic discovery and result in an imbalanced prediction rule for scene classification .", "Upstream supervised topic models have been widely used for complicated scene understanding .", "We demonstrate the advantages of the large-margin approach on both an 8-category sports dataset and the 67-class MIT indoor scene dataset for scene categorization ."]}
{"orig_sents": ["0", "3", "2", "1", "6", "4", "5"], "shuf_sents": ["Recently , some variants of the 1 norm , particularly matrix norms such as the 1,2 and 1 , norms , have been widely used in multi-task learning , compressed sensing and other related areas to enforce sparsity via joint regularization .", "Based on this probabilistic interpretation , we develop a probabilistic model using the noninformative Jeffreys prior .", "Using the generalized normal distribution , we provide a probabilistic interpretation of the general multi-task feature selection problem using the 1 , norm .", "In this paper , we unify the 1,2 and 1 , norms by considering a family of 1 , norms for 1 < and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection .", "For both versions of the model , we devise expectation-maximization ( EM ) algorithms to learn all model parameters , including , automatically .", "Experiments have been conducted on two cancer classification applications using microarray gene expression data .", "We also extend the model to learn and exploit more general types of pairwise relationships between tasks ."]}
{"orig_sents": ["0", "3", "1", "2", "4"], "shuf_sents": ["We present a novel method for constructing dependent Dirichlet processes .", "The method allows for the creation , removal , and location variation of component models over time while maintaining the property that the random measures are marginally DP distributed .", "Additionally , we derive a Gibbs sampling algorithm for model inference and test it on both synthetic and real data .", "The approach exploits the intrinsic relationship between Dirichlet and Poisson processes in order to create a Markov chain of Dirichlet processes suitable for use as a prior over evolving mixture models .", "Empirical results demonstrate that the approach is effective in estimating dynamically varying mixture models ."]}
{"orig_sents": ["0", "3", "2", "5", "1", "6", "4"], "shuf_sents": ["We consider problems for which one has incomplete binary matrices that evolve with time ( e.g. , the votes of legislators on particular legislation , with each year characterized by a different such matrix ) .", "The research presented here merges two areas of machine-learning that have previously been investigated separately : incomplete-matrix analysis and topic modeling .", "In addition , it is assumed that documents are available for the entities associated with at least one of the matrix axes .", "An objective of such analysis is to infer structure and inter-relationships underlying the matrices , here defined by latent features associated with each axis of the matrix .", "The framework is demonstrated by considering all voting data and available documents ( legislation ) during the 220-year lifetime of the United States Senate and House of Representatives .", "By jointly analyzing the matrices and documents , one may be used to inform the other within the analysis , and the model offers the opportunity to predict matrix values ( e.g. , votes ) based only on an associated document ( e.g. , legislation ) .", "The analysis is performed from a Bayesian perspective , with efficient inference constituted via Gibbs sampling ."]}
{"orig_sents": ["0", "4", "1", "2", "3", "7", "6", "5"], "shuf_sents": ["Recent studies compare gene expression data across species to identify core and species specific genes in biological systems .", "This is a challenging task since the correct matches ( orthologs ) are not known for most genes .", "Previous work in this area used deterministic matchings or reduced multidimensional expression data to binary representation .", "Here we develop a new method that can utilize soft matches ( given as priors ) to infer both , unique and similar expression patterns across species and a matching for the genes in both species .", "To perform such comparisons researchers need to match genes across species .", "Applying our method to immune response data we show that it can accurately identify common and unique response patterns by improving the matchings between human and mouse genes .", "We present learning and inference algorithms based on variational methods for this model .", "Our method uses a Dirichlet process mixture model which includes a latent data matching variable ."]}
{"orig_sents": ["0", "6", "1", "3", "2", "5", "4"], "shuf_sents": ["Is there a principled way to learn a probabilistic discriminative classifier from an unlabeled data set ?", "We call it Regularized Information Maximization ( RIM ) .", "The approach can flexibly incorporate different likelihood functions , express prior assumptions about the relative size of different classes and incorporate partial labels for semi-supervised learning .", "RIM optimizes an intuitive information-theoretic objective function which balances class separation , class balance and classifier complexity .", "Our empirical evaluation indicates that RIM outperforms existing methods on several real data sets , and demonstrates that RIM is an effective model selection method .", "In particular , we instantiate the framework to unsupervised , multi-class kernelized logistic regression .", "We present a framework that simultaneously clusters the data and trains a discriminative classifier ."]}
{"orig_sents": ["0", "2", "3", "5", "1", "4"], "shuf_sents": ["From a functional viewpoint , a spiking neuron is a device that transforms input spike trains on its various synapses into an output spike train on its axon .", "With the kernel we demonstrate how the learning problem can be posed as a Quadratic Program .", "We demonstrate in this paper that the function mapping underlying the device can be tractably learned based on input and output spike train data alone .", "We begin by posing the problem in a classification based framework .", "Experimental results demonstrate the strength of our approach .", "We then derive a novel kernel for an SRM0 model that is based on PSP and AHP like functions ."]}
{"orig_sents": ["5", "2", "0", "4", "1", "3"], "shuf_sents": ["We then give both upper and lower bounds for generalization with bounded importance weights and , more significantly , give learning guarantees for the more common case of unbounded importance weights under the weak assumption that the second moment is bounded , a condition related to the Renyi divergence of the training and test distributions .", "We use these bounds to guide the definition of an alternative reweighting algorithm and report the results of experiments demonstrating its benefits .", "We point out simple cases where importance weighting can fail , which suggests the need for an analysis of the properties of this technique .", "Finally , we analyze the properties of normalized importance weights which are also commonly used .", "These results are based on a series of novel and general bounds we derive for unbounded loss functions , which are of independent interest .", "This paper presents an analysis of importance weighting for learning from finite samples and gives a series of theoretical and algorithmic results ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We present a fast algorithm for the detection of multiple change-points when each is frequently shared by members of a set of co-occurring one-dimensional signals .", "We give conditions on consistency of the method when the number of signals increases , and provide empirical evidence to support the consistency results ."]}
{"orig_sents": ["3", "4", "5", "2", "1", "0"], "shuf_sents": ["Our experimental results demonstrate that by inferring this contextual information together with adaptive structures , the proposed model can significantly improve activity recognition performance .", "a tree structure , we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference .", "Different from most of the previous latent structured models which assume a predefined structure for the hidden layer , e.g .", "We propose a discriminative model for recognizing group activities .", "Our model jointly captures the group activity , the individual person actions , and the interactions among them .", "Two new types of contextual information , group-person interaction and person-person interaction , are explored in a latent variable framework ."]}
{"orig_sents": ["5", "7", "4", "3", "6", "0", "1", "2", "8"], "shuf_sents": ["We also consider the problem of kernelized inductive dimensionality reduction in the semi-supervised setting .", "To this end , we introduce a novel method for this problem by considering a special case of our general kernel learning framework where we select the trace norm function as the regularizer .", "We empirically demonstrate that our framework learns useful kernel functions , improving the k-NN classification accuracy significantly in a variety of domains .", "Furthermore , our result gives a constructive method for kernelizing most existing Mahalanobis metric learning formulations .", "Our result shows that the learned kernel matrices parameterize a linear transformation kernel function and can be applied inductively to new data points .", "In this paper we consider the problem of semi-supervised kernel function learning .", "To make our results practical for large-scale data , we modify our framework to limit the number of parameters in the optimization process .", "We first propose a general regularized framework for learning a kernel matrix , and then demonstrate an equivalence between our proposed kernel matrix learning framework and a general linear transformation learning problem .", "Furthermore , our kernelized dimensionality reduction technique significantly reduces the dimensionality of the feature space while achieving competitive classification accuracies ."]}
{"orig_sents": ["2", "5", "0", "4", "1", "3"], "shuf_sents": ["Most IRL algorithms use a simple Monte Carlo estimation to approximate the expected feature counts under the expert 's policy .", "To reduce this error , we introduce a novel approach for bootstrapping the demonstration by assuming that : ( i ) , the expert is ( near- ) optimal , and ( ii ) , the dynamics of the system is known .", "We consider the problem of apprenticeship learning where the examples , demonstrated by an expert , cover only a small part of a large state space .", "Empirical results on gridworlds and car racing problems show that our approach is able to learn good policies from a small number of demonstrations .", "In this paper , we show that the quality of the learned policies is highly sensitive to the error in estimating the feature counts .", "Inverse Reinforcement Learning ( IRL ) provides an efficient tool for generalizing the demonstration , based on the assumption that the expert is maximizing a utility function that is a linear combination of state-action features ."]}
{"orig_sents": ["4", "3", "0", "1", "2", "5"], "shuf_sents": ["Posterior predictive inference in this model , given a finite training sequence , can be interpreted as averaging over multiple PDFAs of varying structure , where each PDFA is biased towards having few states .", "We suggest that our method for averaging over PDFAs is a novel approach to predictive distribution smoothing .", "We test PDIA inference both on PDFA structure learning and on both natural language and DNA data prediction tasks .", "We define and develop a sampler for a PDFA with an infinite number of states which we call the probabilistic deterministic infinite automata ( PDIA ) .", "We propose a novel Bayesian nonparametric approach to learning with probabilistic deterministic finite automata ( PDFA ) .", "The results suggest that the PDIA presents an attractive compromise between the computational cost of hidden Markov models and the storage requirements of hierarchically smoothed Markov models ."]}
{"orig_sents": ["2", "5", "6", "0", "3", "1", "4", "8", "7"], "shuf_sents": ["Fortunately , the cognitive processes that transform internal states to responses are not simply noisy , but rather are influenced by recent experience in a lawful manner .", "In our formulation , decontamination is fundamentally a problem of inferring latent states ( internal sensations ) which , because of the relativity of judgment , have temporal dependencies .", "For over half a century , psychologists have been struck by how poor people are at expressing their internal sensations , impressions , and evaluations via rating scales .", "We explore techniques to remove sequential dependencies , and thereby decontaminate a series of ratings to obtain more meaningful human judgments .", "We propose a decontamination solution using a conditional random field with constraints motivated by psychological theories of relative judgment .", "When individuals make judgments , they are incapable of using an absolute rating scale , and instead rely on reference points from recent experience .", "This relativity of judgment limits the usefulness of responses provided by individuals to surveys , questionnaires , and evaluation forms .", "Our decontamination techniques yield an over 20 % reduction in the error of human judgments .", "Our exploration of decontamination models is supported by two experiments we conducted to obtain ground-truth rating data on a simple length estimation task ."]}
{"orig_sents": ["5", "0", "3", "6", "4", "2", "1"], "shuf_sents": ["This is the generalization of a common assumption made in the existing literature : task parameters share a common linear subspace .", "We show the efficacy of our method on several datasets .", "An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem , and makes the proposed MTL framework efficient and easy to implement .", "One proposed method uses the projection distance from the manifold to regularize the task parameters .", "When the manifold structure is fixed , our method decomposes across tasks which can be learnt independently .", "We present a novel method for multitask learning ( MTL ) based on manifold regularization : assume that all task parameters lie on a manifold .", "The manifold structure and the task parameters are learned using an alternating optimization framework ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local ( possibly nonsmooth ) convex functions using only local computation and communication .", "We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network .", "We develop and analyze distributed algorithms based on dual averaging of subgradients , and provide sharp bounds on their convergence rates as a function of the network size and topology .", "The sharpness of this prediction is confirmed both by theoretical lower bounds and simulations for various networks .", "Our analysis clearly separates the convergence of the optimization algorithm itself from the effects of communication constraints arising from the network structure ."]}
{"orig_sents": ["3", "2", "1", "5", "4", "6", "0"], "shuf_sents": ["EM also achieves a solution quality within 95 % of optimal for most instances .", "We present an alternative approach , which transforms the MAP problem into that of inference in a mixture of simple Bayes nets .", "Several provably convergent approaches have been successfully developed using linear programming ( LP ) relaxation of the MAP problem .", "Computing a maximum a posteriori ( MAP ) assignment in graphical models is a crucial inference problem for many practical applications .", "The update equations for the EM algorithm are remarkably simple , both conceptually and computationally , and can be implemented using a graph-based message passing paradigm similar to max-product computation .", "We then derive the Expectation Maximization ( EM ) algorithm for this mixture that also monotonically increases a lower bound on the MAP assignment until convergence .", "Experiments on the real-world protein design dataset show that EM 's convergence rate is significantly higher than the previous LP relaxation based approach MPLP ."]}
{"orig_sents": ["0", "4", "2", "6", "3", "7", "1", "5"], "shuf_sents": ["We consider structured multi-armed bandit problems based on the Generalized Linear Model ( GLM ) framework of statistics .", "Keywords : multi-armed bandit , parametric bandits , generalized linear models , UCB , regret minimization .", "We derive finite time , high probability bounds on the regret of the algorithm , extending previous analyses developed for the linear bandits to the non-linear case .", "Moreover , as the actual effectiveness of current parameterized bandit algorithms is often poor in practice , we provide a tuning method based on asymptotic arguments , which leads to significantly better practical performance .", "For these bandits , we propose a new algorithm , called GLM-UCB .", "1", "The analysis highlights a key difficulty in generalizing linear bandit algorithms to the non-linear case , which is solved in GLM-UCB by focusing on the reward space rather than on the parameter space .", "We present two numerical experiments on real-world data that illustrate the potential of the GLM-UCB approach ."]}
{"orig_sents": ["2", "5", "4", "1", "3", "0"], "shuf_sents": ["This theory can account for a plethora of experimental data , including the reward-modulation of sensory receptive fields , GABAergic effects on saccadic movements , and risk aversion in decisions under uncertainty .", "We propose a variational framework for achieving this balance and apply it to the problem of how a neural population code should optimally represent a distribution under resource constraints .", "Optimal control entails combining probabilities and utilities .", "The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility .", "Choosing an approximation requires balancing the benefits of an accurate approximation against the costs of computing it .", "However , for most practical problems , probability densities can be represented only approximately ."]}
{"orig_sents": ["3", "4", "1", "0", "2"], "shuf_sents": ["We close this gap by providing a general technique based on Taylor-type kernels to explicitly construct universal kernels on compact metric spaces which are not subset of Rd .", "Moreover , SVMs are known to be consistent to the Bayes risk , if either the input space is a complete separable metric space and the reproducing kernel Hilbert space ( RKHS ) H Lp ( PX ) is dense , or if the SVM uses a universal kernel k. So far , however , there are no kernels of practical interest known that satisfy these assumptions , if X Rd .", "We apply this technique for the following special cases : universal kernels on the set of probability measures , universal kernels based on Fourier transforms , and universal kernels for signal processing .", "During the last years support vector machines ( SVMs ) have been successfully applied in situations where the input space X is not necessarily a subset of Rd .", "Examples include SVMs for the analysis of histograms or colored images , SVMs for text classification and web mining , and SVMs for applications from computational biology using , e.g. , kernels for trees and graphs ."]}
{"orig_sents": ["0", "3", "4", "1", "5", "2"], "shuf_sents": ["Straightforward application of Deep Belief Nets ( DBNs ) to acoustic modeling produces a rich distributed representation of speech data that is useful for recognition and yields impressive results on the speaker-independent TIMIT phone recognition task .", "Every configuration of the precision units of the mcRBM specifies a different precision matrix for the conditional distribution over the acoustic space .", "The mcRBM features combined with DBNs allow us to achieve a phone error rate of 20.5 % , which is superior to all published results on speaker-independent TIMIT to date .", "However , the first-layer Gaussian-Bernoulli Restricted Boltzmann Machine ( GRBM ) has an important limitation , shared with mixtures of diagonalcovariance Gaussians : GRBMs treat different components of the acoustic input vector as conditionally independent given the hidden state .", "The mean-covariance restricted Boltzmann machine ( mcRBM ) , first introduced for modeling natural images , is a much more representationally efficient and powerful way of modeling the covariance structure of speech data .", "In this work , we use the mcRBM to learn features of speech data that serve as input into a standard DBN ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We propose a new LP relaxation for obtaining the MAP assignment of a binary MRF with pairwise potentials .", "We then propose a combinatorial algorithm to efficiently solve the LP and also provide a lower bound by concurrently solving its dual to within an approximation .", "The algorithm is up to an order of magnitude faster and provides better MAP scores and bounds than the state of the art message passing algorithm of that tightens the local marginal polytope with third-order marginal constraints .", "Our relaxation is derived from reducing the MAP assignment problem to an instance of a recently proposed Bipartite Multi-cut problem where the LP relaxation is guaranteed to provide an O ( log k ) approximation where k is the number of vertices adjacent to non-submodular edges in the MRF ."]}
{"orig_sents": ["3", "4", "0", "1", "2", "5"], "shuf_sents": ["BAGGs can represent arbitrary Bayesian games , and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry , action- and type-specific utility independence , and probabilistic independence of type distributions .", "We provide an algorithm for computing expected utility in BAGGs , and discuss conditions under which the algorithm runs in polynomial time .", "Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm .", "Games of incomplete information , or Bayesian games , are an important gametheoretic model and have many applications in economics .", "We propose Bayesian action-graph games ( BAGGs ) , a novel graphical representation for Bayesian games .", "We show both theoretically and empirically that our approaches improve significantly on the state of the art ."]}
{"orig_sents": ["2", "3", "4", "5", "0", "1"], "shuf_sents": ["The causal direction can then be inferred by using standard Bayesian model selection .", "We evaluate our approach on synthetic data and real-world data and report encouraging results .", "We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y .", "The basic idea is to model the observed data using probabilistic latent variable models , which incorporate the effects of unobserved noise .", "To this end , we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term ( not necessarily additive ) .", "An important novel aspect of our work is that we do not restrict the model class , but instead put general non-parametric priors on this function and on the distribution of the cause ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["Numerical experiments regarding estimation of ARMAX models show that this technique provides a definite advantage over a group LAR algorithm and state-of-the-art parametric identification techniques based on prediction error minimization .", "Sparse solutions are obtained by placing exponential hyperpriors on the scale factors of such kernels .", "We introduce a new Bayesian nonparametric approach to identification of sparse dynamic linear systems .", "The impulse responses are modeled as Gaussian processes whose autocovariances encode the BIBO stability constraint , as defined by the recently introduced `` Stable Spline kernel '' ."]}
{"orig_sents": ["1", "4", "3", "2", "5", "0"], "shuf_sents": ["Empirical results on four real datasets show that the proposed relational learning method can achieve similar prediction quality as the state-of-the-art approaches , but is significantly more efficient in training ; and the induced hidden variables are semantically meaningful and crucial to improve the training speed and prediction qualities of treeRMNs .", "Markov networks ( MNs ) can incorporate arbitrarily complex features in modeling relational data .", "On one hand , the restricted treeRMN only considers simple ( e.g. , unary and pairwise ) features in relational data and thus achieves computational efficiency ; and on the other hand , the CVI algorithm efficiently detects hidden variables which can capture long range dependencies .", "To address this challenge , we propose a novel relational learning approach , which consists of a restricted class of relational MNs ( RMNs ) called relation tree-based RMN ( treeRMN ) , and an efficient Hidden Variable Detection algorithm called Contrastive Variable Induction ( CVI ) .", "However , this flexibility comes at a sharp price of training an exponentially complex model .", "Therefore , the resultant approach is highly efficient yet does not sacrifice its expressive power ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["Most active learning approaches select either informative or representative unlabeled instances to query their labels .", "Extensive experimental results show that the proposed Q UIRE approach outperforms several state-of -the-art active learning approaches .", "The proposed approach provides a systematic way for measuring and combining the informativeness and representativeness of an instance .", "We address this challenge by a principled approach , termed Q UIRE , based on the min-max view of active learning .", "Although several active learning algorithms have been proposed to combine the two criteria for query selection , they are usually ad hoc in finding unlabeled instances that are both informative and representative ."]}
{"orig_sents": ["6", "1", "3", "5", "0", "4", "2"], "shuf_sents": ["We address this computational challenge by developing a framework for ML-MKL that combines the worst-case analysis with stochastic approximation .", "In this work , we develop an efficient algorithm for multi-label multiple kernel learning ( ML-MKL ) .", "Empirical studies with object recognition show that while achieving similar classification accuracy , the proposed method is significantly more efficient than the state-of-the-art algorithms for ML-MKL .", "We assume that all the classes under consideration share the same combination of kernel functions , and the objective is to find the optimal kernel combination that benefits all the classes .", "Our analysis shows that the complexity of our algorithm is O ( m1/3 lnm ) , where m is the number of classes .", "Although several algorithms have been developed for ML-MKL , their computational cost is linear in the number of classes , making them unscalable when the number of classes is large , a challenge frequently encountered in visual object recognition .", "Recent studies have shown that multiple kernel learning is very effective for object recognition , leading to the popularity of kernel learning in computer vision problems ."]}
{"orig_sents": ["3", "5", "4", "2", "1", "0"], "shuf_sents": ["The superior performance of MDRTs are demonstrated on both synthetic and real datasets .", "To make MDRTs applicable for large-scale learning problems , we propose a greedy heuristics .", "Empirically , MDRTs can simultaneously conduct function estimation and variable selection in high dimensions .", "We propose a new nonparametric learning method based on multivariate dyadic regression trees ( MDRTs ) .", "Theoretically , we show that MDRTs can simultaneously adapt to the unknown sparsity and smoothness of the true regression functions , and achieve the nearly optimal rates of convergence ( in a minimax sense ) for the class of ( , C ) -smooth functions .", "Unlike traditional dyadic decision trees ( DDTs ) or classification and regression trees ( CARTs ) , MDRTs are constructed using penalized empirical risk minimization with a novel sparsity-inducing penalty ."]}
{"orig_sents": ["0", "2", "4", "3", "5", "1"], "shuf_sents": ["Estimating 3D pose from monocular images is a highly ambiguous problem .", "As evidenced by the experiments , our method outperforms state-of-the-art approaches on the tasks of rigid and non-rigid pose estimation .", "Physical constraints can be exploited to restrict the space of feasible configurations .", "We first show that the mean prediction of a Gaussian process implicitly satisfies linear constraints if those constraints are satisfied by the training examples .", "In this paper we propose an approach to constraining the prediction of a discriminative predictor .", "We then show how , by performing a change of variables , a GP can be forced to satisfy quadratic constraints ."]}
{"orig_sents": ["4", "3", "0", "5", "1", "2", "6"], "shuf_sents": ["Although this straightforward learning strategy is widely-used in practice , it has been subject to very little formal analysis .", "Further , we prove that this difference is only O ( ) when the expert 's policy is close to optimal .", "This latter result has an important practical consequence : Not only does imitating a near-optimal expert result in a better policy , but far fewer demonstrations are required to successfully imitate such an expert .", "We study a common approach to learning from expert demonstrations : using a classification algorithm to learn to imitate the expert 's behavior .", "We provide new theoretical results for apprenticeship learning , a variant of reinforcement learning in which the true reward function is unknown , and the goal is to perform well relative to an observed expert .", "We prove that , if the learned classifier has error rate , the difference between the value of the apprentice 's policy and the expert 's policy is O ( ) .", "This suggests an opportunity for substantial savings whenever the expert is known to be good , but demonstrations are expensive or difficult to obtain ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["Moreover , we show that the performance loss depends on the expectation of the squared Radon-Nikodym derivative of a certain distribution rather than its supremum - as opposed to what has been suggested by the previous results .", "We quantify the performance loss as the Lp norm of the approximation error/Bellman residual at each iteration .", "Also our results indicate that the contribution of the approximation/Bellman error to the performance loss is more prominent in the later iterations of API/AVI , and the effect of an error term in the earlier iterations decays exponentially fast .", "We address the question of how the approximation error/Bellman residual at each iteration of the Approximate Policy/Value Iteration algorithms influences the quality of the resulted policy ."]}
{"orig_sents": ["3", "2", "4", "5", "0", "1"], "shuf_sents": ["In particular , we show that the same Galerkin method can be used to derive Least-Squares Temporal Difference learning , Kernelized Temporal Difference learning , and a discrete-state Dynamic Programming solution , as well as our proposed method .", "In a numerical evaluation of these algorithms , the proposed approach performed better than the other methods .", "We present a non-parametric approach to policy evaluation , which uses kernel density estimation to represent the system .", "In this paper , we consider the problem of policy evaluation for continuousstate systems .", "The true form of the value function for this model can be determined , and can be computed using Galerkin 's method .", "Furthermore , we also present a unified view of several well-known policy evaluation methods ."]}
{"orig_sents": ["2", "4", "1", "0", "3"], "shuf_sents": ["We advocate for the use of a distance measure based on the likelihood ratio test with appropriate probabilistic models that fit the empirical data distribution .", "In this paper , we show that the statistics of gradient based image descriptors often follow a heavy-tailed distribution , which undermines any principled motivation for the use of Euclidean distances .", "Many applications in computer vision measure the similarity between images or image patches based on some statistics such as oriented gradients .", "We instantiate this similarity measure with the Gammacompound-Laplace distribution , and show significant improvement over existing distance measures in the application of SIFT feature matching , at relatively low computational cost .", "These are often modeled implicitly or explicitly with a Gaussian noise assumption , leading to the use of the Euclidean distance when comparing image descriptors ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["We study multi-label prediction for structured output sets , a problem that occurs , for example , in object detection in images , secondary structure prediction in computational biology , and graph matching with symmetries .", "Relying on techniques originally designed for single-label structured prediction , in particular structured support vector machines , results in reduced prediction accuracy , or leads to infeasible optimization problems .", "It also shares most beneficial properties with single-label maximum-margin approaches , in particular formulation as a convex optimization problem , efficient working set training , and PAC-Bayesian generalization bounds .", "Conventional multilabel classification techniques are typically not applicable in this situation , because they require explicit enumeration of the label set , which is infeasible in case of structured outputs .", "In this work we derive a maximum-margin training formulation for multi-label structured prediction that remains computationally tractable while achieving high prediction accuracy ."]}
{"orig_sents": ["6", "8", "3", "4", "2", "0", "7", "5", "1"], "shuf_sents": ["We prove that an interesting phase transition takes place .", "We also relate our findings to Laplacian regularization and suggest to use q-Laplacians as regularizers , where q satisfies 1/p + 1/q = 1 .", "Secondly , we consider the special case of random geometric graphs ( such as k-nearest neighbor graphs ) when the number n of vertices in the graph tends to infinity .", "We prove that for any fixed graph , for p = 1 the p-resistance coincides with the shortest path distance , for p = 2 it coincides with the standard resistance distance , and for p !", "1 it converges to the inverse of the minimal s-t-cut in the graph .", "We can explicitly compute the critical values : p = 1 + 1/ ( d 1 ) and p = 1 + 1/ ( d 2 ) where d is the dimension of the underlying space ( we believe that the fact that there is a small gap between p and p is an artifact of our proofs ) .", "We study the family of p-resistances on graphs for p 1 .", "There exist two critical thresholds p and p such that if p < p , then the p-resistance depends on meaningful global properties of the graph , whereas if p > p , it only depends on trivial local quantities and does not convey any useful information .", "This family generalizes the standard resistance distance ."]}
{"orig_sents": ["0", "2", "5", "1", "6", "4", "7", "3"], "shuf_sents": ["We propose maximum covariance unfolding ( MCU ) , a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities .", "First we use MCU to analyze EEG-fMRI data , where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces .", "Given high dimensional inputs from two different but naturally aligned sources , MCU computes a common low dimensional embedding that maximizes the cross-modal ( inter-source ) correlations while preserving the local ( intra-source ) distances .", "These ideas transform the original problem for MCU , one of semidefinite programming , into a simpler problem in semidefinite quadratic linear programming .", "Second , we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia .", "In this paper , we explore two applications of MCU .", "To perform this visualization , we augment MCU with an additional step for metric learning in the high dimensional voxel space .", "To manage large applications of MCU , we develop a fast implementation based on ideas from spectral graph theory ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["Amongst the challenges : ( a ) each worker has only a partial view of the data , ( b ) different workers may have different clustering criteria and may produce different numbers of categories , ( c ) the underlying category structure may be hierarchical .", "Is it possible to crowdsource categorization ?", "Our experiments , carried out on large collections of images , suggest that Bayesian crowdclustering works well and may be superior to single-expert annotations .", "We propose a Bayesian model of how workers may approach clustering and show how one may infer clusters / categories , as well as worker parameters , using this model ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["The algorithm , which implements a sophisticated variable elimination procedure , is empirically shown to outperform a state-of-the-art algorithm in randomly generated problems of up to 150 variables and 1064 strategies .", "We do not require the usual assumptions of no forgetting and regularity , which allows us to solve problems with limited information .", "We present a new algorithm for exactly solving decision-making problems represented as an influence diagram ."]}
{"orig_sents": ["2", "1", "4", "0", "3"], "shuf_sents": ["Experiments show that our approach outperforms a discriminative baseline based on multiple kernel learning ( MKL ) which has access to the same image information .", "In particular , we infer the scene topology , geometry as well as traffic activities from a short video sequence acquired with a single camera mounted on a moving car .", "We propose a novel generative model that is able to reason jointly about the 3D scene layout as well as the 3D location and orientation of objects in the scene .", "Furthermore , as we reason about objects in 3D , we are able to significantly increase the performance of state-of-the-art object detectors in their ability to estimate object orientation .", "Our generative model takes advantage of dynamic information in the form of vehicle tracklets as well as static information coming from semantic labels and geometry ( i.e. , vanishing points ) ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We study the problem of active learning in a stream-based setting , allowing the distribution of the examples to change over time .", "We prove upper bounds on the number of prediction mistakes and number of label requests for established disagreement-based active learning algorithms , both in the realizable case and under Tsybakov noise .", "We further prove minimax lower bounds for this problem ."]}
{"orig_sents": ["1", "3", "4", "2", "0"], "shuf_sents": ["We also provide a simulation study comparing our approach to existing methods .", "Most methods for decision-theoretic online learning are based on the Hedge algorithm , which takes a parameter called the learning rate .", "In particular , our adaptive method achieves constant regret in a probabilistic setting , when there exists an action that on average obtains strictly smaller loss than all other actions .", "In most previous analyses the learning rate was carefully tuned to obtain optimal worst-case performance , leading to suboptimal performance on easy instances , for example when there exists an action that is significantly better than all others .", "We propose a new way of setting the learning rate , which adapts to the difficulty of the learning problem : in the worst case our procedure still guarantees optimal performance , but on easy instances it achieves much smaller regret ."]}
{"orig_sents": ["4", "0", "3", "5", "2", "1", "6"], "shuf_sents": ["Much work has focused on the assumption that the data matrix has low rank .", "Using our algorithms as a postprocessing step on an initial reconstruction ( provided by e.g .", "The few user parameters required ( the denoising scale , number of neighbors and local dimensionality ) and the number of iterations can be estimated by cross-validating the reconstruction error .", "We propose a more general assumption based on denoising , so that we expect that the value of a missing entry can be predicted from the values of neighboring points .", "In matrix completion , we are given a matrix where the values of only some of the entries are present , and we want to reconstruct the missing ones .", "We propose a nonparametric version of denoising based on local , iterated averaging with meanshift , possibly constrained to preserve local low-rank manifold structure .", "a low-rank method ) , we show consistent improvements with synthetic , image and motion-capture data ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["However , most current approaches are slow to train , do not model the context of the word , and lack theoretical grounding .", "In this paper , we present a new learning method , Low Rank Multi-View Learning ( LR-MVL ) which uses a fast spectral method to estimate low dimensional context-specific word representations from unlabeled data .", "Recently , there has been substantial interest in using large amounts of unlabeled data to learn word representations which can then be used as features in supervised classifiers for NLP tasks .", "These representation features can then be used with any supervised learner .", "LR-MVL is extremely fast , gives guaranteed convergence to a global optimum , is theoretically elegant , and achieves state-ofthe-art performance on named entity recognition ( NER ) and chunking problems ."]}
{"orig_sents": ["4", "1", "2", "6", "5", "0", "3"], "shuf_sents": ["We demonstrate the performance of our approach in applications from the domain of computational biology addressing the key problem of gene finding .", "Structured output prediction often leads to difficult inference problems and hence requires large amounts of training data to obtain accurate models .", "We propose to use MTL to exploit additional information from related learning tasks by means of hierarchical regularization .", "We show that 1 ) our proposed solver achieves much faster convergence than previous methods and 2 ) that the Hierarchical SO-MTL approach outperforms considered non-MTL methods .", "We present a novel regularization-based Multitask Learning ( MTL ) formulation for Structured Output ( SO ) prediction for the case of hierarchical task relations .", "To be able to solve the optimization problems underlying multitask structured output learning , we propose an efficient algorithm based on bundle-methods .", "Training SO models on the combined set of examples from multiple tasks can easily become infeasible for real world applications ."]}
{"orig_sents": ["2", "4", "0", "5", "1", "7", "3", "8", "6"], "shuf_sents": ["The difference in distributions may be both in marginal and conditional probabilities .", "However in many real world applications , conditional probability distribution differences are as commonplace as marginal probability differences .", "Discriminative learning when training and test data belong to different distributions is a challenging and complex task .", "The weights for minimizing the marginal probability differences are estimated independently , while the weights for minimizing conditional probability differences are computed simultaneously by exploiting the potential interaction among multiple sources .", "Often times we have very few or no labeled data from the test or target distribution but may have plenty of labeled data from multiple related sources with different distributions .", "Most of the existing domain adaptation work focuses on the marginal probability distribution difference between the domains , assuming that the conditional probabilities are similar .", "Empirical comparisons with existing state-of-the-art domain adaptation methods using three real-world datasets demonstrate the effectiveness of the proposed approach .", "In this paper we propose a two-stage domain adaptation methodology which combines weighted data from multiple sources based on marginal probability differences ( first stage ) as well as conditional probability differences ( second stage ) , with the target domain data .", "We also provide a theoretical analysis on the generalization performance of the proposed multi-source domain adaptation formulation using the weighted Rademacher complexity measure ."]}
{"orig_sents": ["3", "0", "1", "2", "5", "4"], "shuf_sents": ["Given a matrix X Rnxd , whose rows represent n data points with respect to d features , the top k right singular vectors of X ( the so-called eigenfeatures ) , are arbitrary linear combinations of all available features .", "The eigenfeatures are very useful in data analysis , including the regularization of linear regression .", "Enforcing sparsity on the eigenfeatures , i.e. , forcing them to be linear combinations of only a small number of actual features ( as opposed to all available features ) , can promote better generalization error and improve the interpretability of the eigenfeatures .", "Principal Components Analysis ( PCA ) is often used as a feature extraction procedure .", "Our algorithms are relatively simple and practically efficient , and we demonstrate their performance on several data sets .", "We present deterministic and randomized algorithms that construct such sparse eigenfeatures while provably achieving in-sample performance comparable to regularized linear regression ."]}
{"orig_sents": ["5", "7", "1", "10", "8", "4", "3", "6", "2", "9", "0"], "shuf_sents": ["Experiments also show that the method out-performs the standard EM approach that assumes mentions are missing at random .", "Consequently , the texts tend to be concise and mention the minimum information necessary for the reader to draw the correct conclusions .", "We accomplish this via an application of Expectation Maximization within a Markov Logic framework .", "This paper introduces a mention model that models the probability of facts being mentioned in the text based on what other facts have already been mentioned and domain knowledge in the form of Horn clause rules .", "Hence , we can explicitly model this `` missingness '' process and invert it via probabilistic inference to learn the underlying domain knowledge .", "We consider the problem of learning rules from natural language text sources .", "Learning must simultaneously search the space of rules and learn the parameters of the mention model .", "These sources , such as news articles and web texts , are created by a writer to communicate information to a reader , where the writer and reader share substantial domain knowledge .", "However , unlike standard approaches to missing data , in this setting we know that facts are more likely to be missing from the text in cases where the reader can infer them from the facts that are mentioned combined with the domain knowledge .", "An experimental evaluation on synthetic and natural text data shows that the method can learn accurate rules and apply them to new texts to make correct inferences .", "We study the problem of learning domain knowledge from such concise texts , which is an instance of the general problem of learning in the presence of missing data ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We present the algorithm and its analysis alongside with some theoretical lower bounds and an improved algorithm for the special problem of supervised learning of a distance metric .", "In this work we present the first sublinear time approximation algorithm for semidefinite programs which we believe may be useful for such problems in which the size of data may cause even linear time algorithms to have prohibitive running times in practice .", "In many of these problems the amount of data in practice is so large that there is a constant need for faster algorithms .", "In recent years semidefinite optimization has become a tool of major importance in various optimization and machine learning problems ."]}
{"orig_sents": ["3", "2", "4", "1", "0", "5"], "shuf_sents": ["The proposed model contains bilinear constraints , and is solved using two iterative approaches : successive linear programming and a constrained concave-convex approach .", "The proposed approach is particularly effective for knowledge discovery in domains with few labeled examples .", "A major limitation that has not been fully addressed occurs when the expert advice is imperfect , which can lead to poorer models .", "Knowledge-based support vector machines ( KBSVMs ) incorporate advice from domain experts , which can improve generalization significantly .", "We propose a model that extends KBSVMs and is able to not only learn from data and advice , but also simultaneously improves the advice .", "Experimental results demonstrate that these algorithms yield useful refinements to expert advice , as well as improve the performance of the learning algorithm overall ."]}
{"orig_sents": ["4", "1", "2", "5", "6", "3", "0"], "shuf_sents": ["Finally , we show that , when the complexities of candidate reproducing kernel Hilbert spaces are inhomogeneous , dense type regularization shows better learning rate compared with sparse 1 regularization .", "Our main target in this paper is dense type regularizations including p -MKL that imposes p -mixed-norm regularization instead of 1 -mixed-norm regularization .", "According to the recent numerical experiments , the sparse regularization does not necessarily show a good performance compared with dense type regularizations .", "We also show that our general learning rate achieves the minimax lower bound .", "In this paper , we give a new generalization error bound of Multiple Kernel Learning ( MKL ) for a general class of regularizations .", "Motivated by this fact , this paper gives a general theoretical tool to derive fast learning rates that is applicable to arbitrary mixed-norm-type regularizations in a unifying manner .", "As a by-product of our general result , we show a fast learning rate of p -MKL that is tightest among existing bounds ."]}
{"orig_sents": ["4", "6", "5", "3", "1", "2", "0"], "shuf_sents": ["Overall , the proposed system has superior segmentation accuracy on several datasets ( Graz-02 , Stanford background ) compared to previously suggested approaches .", "We apply this formulation , which we call the pylon model , to the task of semantic segmentation where the goal is to separate an image into areas belonging to different semantic classes .", "The experiments highlight the advantage of inference on a segmentation tree ( over a flat partitioning ) and demonstrate that the optimization in the pylon model is able to flexibly choose the level of segmentation across the image .", "As a result of such inference , the image gets partitioned into a set of segments that may come from different layers of the tree .", "Graph cut optimization is one of the standard workhorses of image segmentation since for binary random field representations of the image , it gives globally optimal results and there are efficient polynomial time implementations .", "In the paper we show that if , instead of a flat partitioning , the image is represented by a hierarchical segmentation tree , then the resulting energy combining unary and boundary terms can still be optimized using graph cut ( with all the corresponding benefits of global optimality and efficiency ) .", "Often , the random field is applied over a flat partitioning of the image into non-intersecting elements , such as pixels or super-pixels ."]}
{"orig_sents": ["2", "4", "5", "3", "1", "0"], "shuf_sents": ["Model selection issues , related to the number of clusters forming the data partition in particular , are also considered .", "Based on recent results related to the tail behavior of degenerate U -processes , it is also shown how to establish tighter rate bounds .", "Many clustering techniques aim at optimizing empirical criteria that are of the form of a U -statistic of degree two .", "In this setup , under adequate assumptions on the complexity of the subsets forming the partition candidates , the excess of clustering risk is proved to be of the order OP ( 1/ n ) .", "Given a measure of dissimilarity between pairs of observations , the goal is to minimize the within cluster point scatter over a class of partitions of the feature space .", "It is the purpose of this paper to define a general statistical framework , relying on the theory of U -processes , for studying the performance of such clustering methods ."]}
{"orig_sents": ["6", "3", "5", "0", "1", "4", "2"], "shuf_sents": ["In the literature , the most important and widely studied model averaging method that achieves the optimal O ( 1/n ) average regret is the exponential weighted model averaging ( EWMA ) algorithm .", "However this method suffers from several limitations .", "We prove strong theoretical guarantees for the new procedure and illustrate our theoretical results with empirical examples .", "It is known that if the models are mis-specified , model averaging is superior to model selection .", "The purpose of this paper is to present a new greedy model averaging procedure that improves EWMA .", "Specifically , let n be the sample size , then the worst case regret of the former decays at the rate of O ( 1/n ) while the worst case regret of the latter decays at the rate of O ( 1/ n ) .", "This paper considers the problem of combining multiple models to achieve a prediction accuracy not much worse than that of the best single model for least squares regression ."]}
{"orig_sents": ["5", "8", "2", "4", "3", "6", "7", "0", "1"], "shuf_sents": ["The pooled representation is then used as input to a classifier .", "Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus .", "We introduce a method for paraphrase detection based on recursive autoencoders ( RAE ) .", "These features are used to measure the word- and phrase-wise similarity between two sentences .", "Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees .", "Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning .", "Since sentences may be of arbitrary length , the resulting matrix of similarity measures is of variable size .", "We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices .", "In order to obtain high accuracy on this task , thorough syntactic and semantic analysis of the two statements is needed ."]}
{"orig_sents": ["7", "3", "4", "1", "8", "6", "5", "0", "2"], "shuf_sents": ["The -model avoids biophysical problems associated with implementing exp ( * ) , implements the multiplicative operation of via divisive inhibition , and explains why activity peaks could occur after ttc .", "The -function predicts that the LGMD activity is a product between an exponential function of angular size exp ( - ) and angular velocity , and that peak activity is reached before time-to-contact ( ttc ) .", "It consistently predicts response features of the LGMD , and provides excellent fits to published experimental data , with goodness of fit measures comparable to corresponding fits with the -function .", "In locusts , the corresponding escape behavior correlates with the activity of the lobula giant movement detector ( LGMD ) neuron .", "During an object approach , its firing rate was reported to gradually increase until a peak is reached , and then it declines quickly .", "Here we address to these issues with a new model ( -model ) , which explicitly connects and biophysical quantities .", "Several inconsistencies remain unresolved , though .", "Many species show avoidance reactions in response to looming object approaches .", "The -function has become the prevailing LGMD model because it reproduces many experimental observations , and even experimental evidence for the multiplicative operation was reported ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["This is especially true for samples stemming from patients with longer treatment history and samples associated with rare therapies .", "Furthermore , our approach is at least as powerful for the remaining samples .", "This paper presents an approach that predicts the effectiveness of HIV combination therapies by simultaneously addressing several problems affecting the available HIV clinical data sets : the different treatment backgrounds of the samples , the uneven representation of the levels of therapy experience , the missing treatment history information , the uneven therapy representation and the unbalanced therapy outcome representation .", "The computational validation on clinical data shows that , compared to the most commonly used approach that does not account for the issues mentioned above , our model has significantly higher predictive power ."]}
{"orig_sents": ["0", "4", "1", "2", "3", "5"], "shuf_sents": ["This paper proposes a novel boosting algorithm called VadaBoost which is motivated by recent empirical Bernstein bounds .", "Each step of the proposed algorithm minimizes the cost efficiently by providing weighted data to a weak learner rather than requiring a brute force evaluation of all possible weak learners .", "Thus , the proposed algorithm solves a key limitation of previous empirical Bernstein boosting methods which required brute force enumeration of all possible weak learners .", "Experimental results confirm that the new algorithm achieves the performance improvements of EBBoost yet goes beyond decision stumps to handle any weak learner .", "VadaBoost iteratively minimizes a cost function that balances the sample mean and the sample variance of the exponential loss .", "Significant performance gains are obtained over AdaBoost for arbitrary weak learners including decision trees ( CART ) ."]}
{"orig_sents": ["1", "4", "3", "2", "0", "5"], "shuf_sents": ["Furthermore , our sample complexity guarantees have no explicit dependence on the dimensionality of the observed variables , making the algorithm applicable to many high-dimensional settings .", "This work considers the problem of learning the structure of multivariate linear tree models , which include a variety of directed tree graphical models with continuous , discrete , and mixed latent variables such as linear-Gaussian models , hidden Markov models , Gaussian mixture models , and Markov evolutionary trees .", "Our finite sample size bounds for exact recovery of the tree structure reveal certain natural dependencies on underlying statistical and structural properties of the underlying joint distribution .", "We propose the Spectral Recursive Grouping algorithm , an efficient and simple bottom-up procedure for recovering the tree structure from independent samples of the observed variables .", "The setting is one where we only have samples from certain observed variables in the tree , and our goal is to estimate the tree structure ( i.e. , the graph of how the underlying hidden variables are connected to each other and to the observed variables ) .", "At the heart of our algorithm is a spectral quartet test for determining the relative topology of a quartet of variables from second-order statistics ."]}
{"orig_sents": ["9", "7", "4", "3", "8", "6", "2", "0", "5", "1"], "shuf_sents": ["Additionally , we impose a Structure Lasso ( SLasso ) penalty on groups of functions to learn the graph structure .", "In this way , we are able to shrink higher order interactions to obtain a sparse graph structure .", "The functional spaces can be flexibly determined by kernels .", "The main contribution of this paper is to learn the graph structure and the functions conditioned on X at the same time .", "observed features ) such that the distribution P ( Y | X ) is determined by functions of X that characterize the ( higher-order ) interactions among the Y 's .", "These groups with overlaps are designed to enforce hierarchical function selection .", "The reparameterization of the potential functions in graphical models by conditional log odds ratios of the latter offers advantages in representation of the conditional independence structure .", "We study the case where there is another input random vector X ( e.g .", "We prove that discrete undirected graphical models with feature X are equivalent to multivariate discrete models .", "In discrete undirected graphical models , the conditional independence of node labels Y is specified by the graph structure ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["The common practice of providing survival time estimates based only on population averages for the site and stage of cancer ignores many important individual differences among patients .", "When tested on a cohort of more than 2000 cancer patients , our method gives survival time predictions that are much more accurate than popular survival analysis models such as the Cox and Aalen regression models .", "An accurate model of patient survival time can help in the treatment and care of cancer patients .", "Our results also show that using patient-specific attributes can reduce the prediction error on survival time by as much as 20 % when compared to using cancer site and stage only .", "In this paper , we propose a local regression method for learning patient-specific survival time distribution based on patient attributes such as blood tests and clinical assessments ."]}
{"orig_sents": ["1", "5", "0", "3", "4", "2"], "shuf_sents": ["An FCP is exchangeable , projective , stationary and reversible , and its equilibrium distributions are given by the Chinese restaurant process .", "We propose a novel class of Bayesian nonparametric models for sequential data called fragmentation-coagulation processes ( FCPs ) .", "Our development of FCPs is motivated by applications in population genetics , and we demonstrate the utility of FCPs on problems of genotype imputation with phased and unphased SNP data .", "As opposed to hidden Markov models , FCPs allow for flexible modelling of the number of clusters , and they avoid label switching non-identifiability problems .", "We develop an efficient Gibbs sampler for FCPs which uses uniformization and the forward-backward algorithm .", "FCPs model a set of sequences using a partition-valued Markov process which evolves by splitting and merging clusters ."]}
{"orig_sents": ["1", "0", "3", "2", "4"], "shuf_sents": ["The key contribution of the approach is a technique to simultaneously determine the structure of the tree and learn the classifiers for each node in the tree .", "We present a novel approach to efficiently learn a label tree for large scale classification with many classes .", "Experiments are performed on large scale image classification with 10184 classes and 9 million images .", "This approach also allows fine grained control over the efficiency vs accuracy trade-off in designing a label tree , leading to more balanced trees .", "We demonstrate significant improvements in test accuracy and efficiency with less training time and more balanced trees compared to the previous state of the art by Bengio et al ."]}
{"orig_sents": ["0", "2", "3", "6", "1", "5", "4"], "shuf_sents": ["Multiclass prediction is the problem of classifying an object into a relevant target class .", "We prove that ShareBoost efficiently finds a predictor that uses few shared features ( if such a predictor exists ) and that it has a small generalization error .", "We consider the problem of learning a multiclass predictor that uses only few features , and in particular , the number of used features should increase sublinearly with the number of possible classes .", "This implies that features should be shared by several classes .", "In a series of experiments with natural data sets we demonstrate the benefits of ShareBoost and evaluate its success relatively to other state-of-the-art approaches .", "We also describe how to use ShareBoost for learning a non-linear predictor that has a fast evaluation time .", "We describe and analyze the ShareBoost algorithm for learning a multiclass predictor that uses few shared features ."]}
{"orig_sents": ["2", "4", "0", "3", "1"], "shuf_sents": ["An estimation problem may be formulated on the basis of the state-space model with prior distributions that penalize large fluctuations in these parameters .", "The proposed method is tested not only on the simulated data from the Hodgkin-Huxley type models but also on experimental data obtained from a cortical slice in vitro .", "State-of-the-art statistical methods in neuroscience have enabled us to fit mathematical models to experimental data and subsequently to infer the dynamics of hidden parameters underlying the observable phenomena .", "After optimizing the hyperparameters by maximizing the marginal likelihood , the state-space model provides the time-varying parameters of the input signals and the ion channel states .", "Here , we develop a Bayesian method for inferring the time-varying mean and variance of the synaptic input , along with the dynamics of each ion channel from a single voltage trace of a neuron ."]}
{"orig_sents": ["0", "8", "2", "4", "1", "6", "3", "5", "7"], "shuf_sents": ["In many experiments , the data points collected live in high-dimensional observation spaces , yet can be assigned a set of labels or parameters .", "Here , we start with the assumption that a particularly informative description is one that reveals the dependency of the high-dimensional data on the individual parameters .", "The heterogeneity and diversity of these parameter dependencies can make visualization and interpretation of such data extremely difficult .", "We call this method demixed principal component analysis ( dPCA ) as the principal components here segregate the parameter dependencies .", "Standard dimensionality reduction techniques such as principal component analysis ( PCA ) can provide a succinct and complete description of the data , but the description is constructed independent of the relevant task variables and is often hard to interpret .", "We phrase the problem as a probabilistic graphical model , and present a fast Expectation-Maximization ( EM ) algorithm .", "We show how to modify the loss function of PCA so that the principal components seek to capture both the maximum amount of variance about the data , while also depending on a minimum number of parameters .", "We demonstrate the use of this algorithm for electrophysiological data and show that it serves to demix the parameter-dependence of a neural population response .", "In electrophysiological recordings , for instance , the responses of populations of neurons generally depend on mixtures of experimentally controlled parameters ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["To this end , we apply the modulus of smoothness .", "Finally , it turns out that our learning rates are asymptotically optimal for regression functions satisfying certain standard smoothness conditions .", "We prove a new oracle inequality for support vector machines with Gaussian RBF kernels solving the regularized least squares regression problem .", "With the help of the new oracle inequality we then derive learning rates that can also be achieved by a simple data-dependent parameter selection method ."]}
{"orig_sents": ["8", "2", "6", "0", "3", "4", "7", "1", "5"], "shuf_sents": ["We resort to a special decomposition of a transition matrix , called stochastic factorization , to fix the size of the approximator while at the same time incorporating all the information contained in the data .", "We empirically demonstrate that the proposed approach is able to compress the information contained in KBRL 's model .", "However , the size of the approximator grows with the number of transitions , which makes the approach impractical for large problems .", "The resulting algorithm , kernel-based stochastic factorization ( KBSF ) , is much faster but still converges to a unique solution .", "We derive a theoretical upper bound for the distance between the value functions computed by KBRL and KBSF .", "Also , on the tasks studied , KBSF outperforms two of the most prominent reinforcement-learning algorithms , namely least-squares policy iteration and fitted Q-iteration .", "In this paper we introduce a novel algorithm to improve the scalability of KBRL .", "The effectiveness of our method is illustrated with computational experiments on four reinforcement-learning problems , including a difficult task in which the goal is to learn a neurostimulation policy to suppress the occurrence of seizures in epileptic rat brains .", "Kernel-based reinforcement-learning ( KBRL ) is a method for learning a decision policy from a set of sample transitions which stands out for its strong theoretical guarantees ."]}
{"orig_sents": ["9", "0", "8", "2", "7", "1", "5", "3", "4", "6"], "shuf_sents": ["This problem of identifying groups from a collection of bipartite variables such as proteins and drugs , biological species and gene sequences , malware and signatures , etc is commonly referred to as biclustering or co-clustering .", "We prove lower bounds on the minimum signal strength needed for successful recovery of a bicluster as a function of the noise variance , size of the matrix and bicluster of interest .", "The problem we consider is also closely related to structured multiple hypothesis testing , an area of statistics that has recently witnessed a flurry of activity .", "We show that a combinatorial procedure based on the scan statistic achieves this optimal limit .", "3 .", "2 .", "We characterize the SNR required by several computationally tractable procedures for biclustering including element-wise thresholding , column/row average thresholding and a convex relaxation approach to sparse singular vector decomposition .", "We make the following contributions 1 .", "Despite its great practical relevance , and although several ad-hoc methods are available for biclustering , theoretical analysis of the problem is largely non-existent .", "We consider the problem of identifying a sparse set of relevant columns and rows in a large data matrix with highly corrupted entries ."]}
{"orig_sents": ["4", "1", "0", "3", "2", "5"], "shuf_sents": ["We demonstrate that consistency with an expert 's test selection leads to non-convex constraints on the model parameters .", "At each step , the expert executes an evidence gathering test , which suggests the test 's relative diagnostic value .", "Gibbs sampling , stochastic hill climbing and greedy search algorithms are proposed to find a MAP estimate that takes into account test ordering constraints and any data available .", "We incorporate these constraints by augmenting the network with nodes that represent the constraint likelihoods .", "In this paper , we derive a method to refine a Bayes network diagnostic model by exploiting constraints implied by expert decisions on test ordering .", "We demonstrate our approach on diagnostic sessions from a manufacturing scenario ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We derive a highlyefficient Gibbs sampling algorithm for sampling from the posterior distribution of the sufficient statistics conditioned on noisy aggregate observations , prove its correctness , and demonstrate its effectiveness experimentally .", "This paper introduces Collective Graphical Models -- a framework for modeling and probabilistic inference that operates directly on the sufficient statistics of the individual model .", "There are many settings in which we wish to fit a model of the behavior of individuals but where our data consist only of aggregate information ( counts or low-dimensional contingency tables ) ."]}
{"orig_sents": ["5", "0", "3", "1", "2", "4"], "shuf_sents": ["An additive function is one which decomposes into a sum of low-dimensional functions , each depending on only a subset of the input variables .", "Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning ( HKL ) .", "We introduce an expressive but tractable parameterization of the kernel function , which allows efficient evaluation of all input interaction terms , whose number is exponential in the input dimension .", "Additive GPs generalize both Generalized Additive Models , and the standard GP models which use squared-exponential kernels .", "The additional structure discoverable by this model results in increased interpretability , as well as state-of-the-art predictive power in regression tasks .", "We introduce a Gaussian process model of functions which are additive ."]}
{"orig_sents": ["2", "5", "0", "4", "1", "3"], "shuf_sents": ["We show that almost all sets of O ( rd log6 d ) Pauli measurements satisfy the rankr restricted isometry property ( RIP ) .", "A similar result holds for any class of measurements that use an orthonormal operator basis whose elements have small operator norm .", "We study the problem of reconstructing an unknown matrix M of rank r and dimension d using O ( rd poly log d ) Pauli measurements .", "Our proof uses Dudley 's inequality for Gaussian processes , together with bounds on covering numbers obtained via entropy duality .", "This implies that M can be recovered from a fixed ( `` universal '' ) set of Pauli measurements , using nuclear-norm minimization ( e.g. , the matrix Lasso ) , with nearly-optimal bounds on the error .", "This has applications in quantum state tomography , and is a non-commutative analogue of a well-known problem in compressed sensing : recovering a sparse vector from a few of its Fourier coefficients ."]}
{"orig_sents": ["4", "0", "1", "2", "5", "3"], "shuf_sents": ["The first phase is an experimentation phase where the decision maker is free to explore multiple options .", "In the second phase the decision maker has to commit to one of the arms and stick with it .", "Cost is incurred during both phases with a higher cost during the experimentation phase .", "Our analysis reveals that if given the choice , it is optimal to experiment ( ln T ) steps and then commit , where T is the time horizon .", "We consider a multi-armed bandit problem where there are two phases .", "We analyze the regret in this setup , and both propose algorithms and provide upper and lower bounds that depend on the ratio of the duration of the experimentation phase to the duration of the commitment phase ."]}
{"orig_sents": ["5", "0", "7", "2", "1", "4", "6", "3"], "shuf_sents": ["We build on the locally order-less spatial pyramid bag-of-features model , which was shown to perform extremely well on a range of object , scene and human action recognition tasks .", "Second , we introduce new person-object interaction features based on spatial co-occurrences of individual body parts and objects .", "First , we replace the standard quantized local HOG/SIFT features with stronger discriminatively trained body part and object detectors .", "Benefits of the proposed model are shown on human action recognition in consumer photographs , outperforming the strong bag-of-features baseline .", "Third , we address the combinatorial problem of a large number of possible interaction pairs and propose a discriminative selection procedure using a linear support vector machine ( SVM ) with a sparsity inducing regularizer .", "We investigate a discriminatively trained model of person-object interactions for recognizing common human actions in still images .", "Learning of action-specific body part and object interactions bypasses the difficult problem of estimating the complete human body pose configuration .", "We introduce three principal contributions ."]}
{"orig_sents": ["1", "4", "0", "2", "3"], "shuf_sents": ["We propose a strategy that samples the arms according to an upper bound on their standard deviations and compare its estimation quality to an ideal allocation that would know the standard deviations of the strata .", "We consider the problem of stratified sampling for Monte-Carlo integration .", "We provide two regret analyses : a distribution -3/2 ) that depends on a measure of the disparity of dependent bound O ( n -4/3 ) that does not .", "the strata , and a distribution-free bound O ( n", "We model this problem in a multi-armed bandit setting , where the arms represent the strata , and the goal is to estimate a weighted average of the mean values of the arms ."]}
{"orig_sents": ["0", "6", "5", "3", "2", "1", "4"], "shuf_sents": ["Inexpensive RGB-D cameras that give an RGB image together with depth data have become widely available .", "In our experiments over a total of 52 3D scenes of homes and offices ( composed from about 550 views , having 2495 segments labeled with 27 object classes ) , we get a performance of 84.06 % in labeling 17 object classes for offices , and 73.38 % in labeling 17 object classes for home scenes .", "The model admits efficient approximate inference , and we train it using a maximum-margin learning approach .", "With a large number of object classes and relations , the model 's parsimony becomes important and we address that by using multiple types of edge potentials .", "Finally , we applied these algorithms successfully on a mobile robot for the task of finding objects in large cluttered rooms.1", "We propose a graphical model that captures various features and contextual relations , including the local visual appearance and shape cues , object co-occurence relationships and geometric relationships .", "In this paper , we use this data to build 3D point clouds of full indoor scenes such as an office and address the task of semantic labeling of these 3D point clouds ."]}
{"orig_sents": ["0", "5", "2", "1", "4", "3"], "shuf_sents": ["We derive an instantaneous ( per-round ) data-dependent regret bound for stochastic multiarmed bandits with side information ( also known as contextual bandits ) .", "In the extreme case , when It ( S ; A ) = 0 , the dependence on the number of states reduces from linear to logarithmic .", "However , if the side information It ( S ; A ) is not fully used , the regret bound is significantly tighter .", "We also present an algorithm for multiarmed bandits with side information with O ( K ) computational complexity per game round .", "Our analysis allows to provide the algorithm large amount of side information , let the algorithm to decide which side information is relevant for the task , and penalize the algorithm only for the side information that it is using de facto .", "The scaling of our regret bound with the number of states ( contexts ) N goes as p N It ( S ; A ) , where It ( S ; A ) is the mutual information between states and actions ( the side information ) used by the algorithm at round p t. If the algorithm uses all the side information , the regret bound scales as N ln K , where K is the number of actions ( arms ) ."]}
{"orig_sents": ["1", "2", "4", "3", "0"], "shuf_sents": ["We show that the proposed methodology matches the current state of the art in the Stanford dataset , as well as in VOC2010 , where 41.7 % accuracy on the test set is achieved .", "We present a joint image segmentation and labeling model ( JSL ) which , given a bag of figure-ground segment hypotheses extracted at multiple image locations and scales , constructs a joint probability distribution over both the compatible image interpretations ( tilings or image segmentations ) composed from those segments , and over their labeling into categories .", "The process of drawing samples from the joint distribution can be interpreted as first sampling tilings , modeled as maximal cliques , from a graph connecting spatially non-overlapping segments in the bag , followed by sampling labels for those segments , conditioned on the choice of a particular tiling .", "The partition function over tilings and labelings is increasingly more accurately approximated by including incorrect configurations that a not-yet-competent model rates probable during learning .", "We learn the segmentation and labeling parameters jointly , based on Maximum Likelihood with a novel Incremental Saddle Point estimation procedure ."]}
{"orig_sents": ["1", "2", "3", "5", "0", "6", "4"], "shuf_sents": ["We then propose efficient algorithms to optimize the cost function using a novel annealing-based iterative alternation algorithm .", "In this paper , we consider the Precis problem of sampling K representative yet diverse data points from a large dataset .", "This problem arises frequently in applications such as video and document summarization , exploratory data analysis , and pre-filtering .", "We formulate a general theory which encompasses not just traditional techniques devised for vector spaces , but also non-Euclidean manifolds , thereby enabling these techniques to shapes , human activities , textures and many other image and video based datasets .", "Experimental results show the strength and generality of the proposed approach .", "We propose intrinsic manifold measures for measuring the quality of a selection of points with respect to their representative power , and their diversity .", "The proposed formulation is applicable to manifolds of known geometry as well as to manifolds whose geometry needs to be estimated from samples ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["Latent variable models are frequently used to identify structure in dichotomous network data , in part because they give rise to a Bernoulli product likelihood that is both well understood and consistent with the notion of exchangeable random graphs .", "In this article we propose conservative confidence sets that hold with respect to these underlying Bernoulli parameters as a function of any given partition of network nodes , enabling us to assess estimates of residual network structure , that is , structure that can not be explained by known covariates and thus can not be easily verified by manual inspection .", "We demonstrate the proposed methodology by analyzing student friendship networks from the National Longitudinal Survey of Adolescent Health that include race , gender , and school year as covariates .", "We employ a stochastic expectation-maximization algorithm to fit a logistic regression model that includes these explanatory variables as well as a latent stochastic blockmodel component and additional node-specific effects .", "Although maximumlikelihood estimates do not appear consistent in this context , we are able to evaluate confidence sets as a function of different blockmodel partitions , which enables us to qualitatively assess the significance of estimated residual network structure relative to a baseline , which models covariates but lacks block structure ."]}
{"orig_sents": ["0", "4", "3", "1", "2"], "shuf_sents": ["Non-negative data are commonly encountered in numerous fields , making nonnegative least squares regression ( NNLS ) a frequently used tool .", "Even in this setting - unlike first intuition may suggest - we show that for a broad class of designs , NNLS is resistant to overfitting and works excellently for sparse recovery when combined with thresholding , experimentally even outperforming 1 regularization .", "Since NNLS also circumvents the delicate choice of a regularization parameter , our findings suggest that NNLS may be the method of choice .", "Serious doubts about its usefulness arise for modern high-dimensional linear models .", "At least relative to its simplicity , it often performs rather well in practice ."]}
{"orig_sents": ["6", "3", "0", "1", "5", "2", "4"], "shuf_sents": ["We show that , when the eective number of topics per document is small , exact inference takes polynomial time .", "In contrast , we show that , when a document has a large number of topics , finding the MAP assignment of topics to words in LDA is NP-hard .", "We show that this problem is also NP-hard .", "First , we study the problem of finding the maximum a posteriori ( MAP ) assignment of topics to words , where the document 's topic distribution is integrated out .", "Finally , we briefly discuss the problem of sampling from the posterior , showing that this is NP-hard in one restricted setting , but leaving open the general question .", "Next , we consider the problem of finding the MAP topic distribution for a document , where the topic-word assignments are integrated out .", "We consider the computational complexity of probabilistic inference in Latent Dirichlet Allocation ( LDA ) ."]}
{"orig_sents": ["3", "5", "2", "1", "0", "4"], "shuf_sents": ["We demonstrate our framework on four datasets , including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk .", "We implement a constrained tracker and compute the expected change for putative annotations with efficient dynamic programming algorithms .", "We cast this problem as one of active learning , and show that we can obtain excellent performance by querying frames that , if annotated , would produce a large expected change in the estimated object track .", "We introduce a novel active learning framework for video annotation .", "Our results indicate that we could obtain equivalent labels for a small fraction of the original cost .", "By judiciously choosing which frames a user should annotate , we can obtain highly accurate tracks with minimal user effort ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["In particular , two results are obtained : the first one shows that , using the unlabeled samples , the confidence term of the conventional bound can be reduced by a factor of three ; the second one shows that the unlabeled samples can be used to obtain much tighter bounds , by building localized versions of the hypothesis class containing the optimal classifier .", "We derive here new generalization bounds , based on Rademacher Complexity theory , for model selection and error estimation of linear ( kernel ) classifiers , which exploit the availability of unlabeled samples ."]}
{"orig_sents": ["6", "3", "4", "1", "2", "5", "0"], "shuf_sents": ["The computational results demonstrate that our methods generally outperform the existing methods in terms of solution quality and/or speed .", "Using this result , we then propose penalty decomposition methods for general rank minimization problems .", "The convergence results of the PD methods have been shown in the longer version of the paper .", "We first show that a class of matrix optimization problems can be solved as lower dimensional vector optimization problems .", "As a consequence , we establish that a class of rank minimization problems have closed form solutions .", "Finally , we test the performance of our methods by applying them to matrix completion and nearest low-rank correlation matrix problems .", "In this paper we consider general rank minimization problems with rank appearing in either objective function or constraint ."]}
{"orig_sents": ["3", "4", "8", "7", "5", "6", "12", "0", "10", "2", "11", "9", "1"], "shuf_sents": ["Contextual relations : ( i ) Cooperative `` + '' relations represent positive links between binding entities , such as hinged faces of a object or aligned boxes ; ( ii ) Competitive `` - '' relations represents negative links between competing entities , such as mutually exclusive boxes .", "In addition , our approach achieves richer structures in the parse tree .", "The algorithm has two stages : ( i ) Clustering : It forms all possible higher-level structures ( clusters ) from lower-level entities by production rules and contextual relations .", "This paper proposes a parsing algorithm for scene understanding which includes four aspects : computing 3D scene layout , detecting 3D objects ( e.g .", "furniture ) , detecting 2D faces ( windows , doors etc .", "This grammar represents the compositional structures of visual entities from scene categories , 3D foreground/background , 2D faces , to 1D lines .", "The grammar includes three types of production rules and two types of contextual relations .", "In contrast to previous scene labeling work that applied discriminative classifiers to pixels ( or super-pixels ) , we use a generative Stochastic Scene Grammar ( SSG ) .", ") , and segmenting background .", "In our experiment , we demonstrate the superiority of our algorithm over existing methods on public dataset .", "We design an efficient MCMC inference algorithm , namely Hierarchical cluster sampling , to search in the large solution space of scene configurations .", "( ii ) Sampling : It jumps between alternative structures ( clusters ) in each layer of the hierarchy to find the most probable configuration ( represented by a parse tree ) .", "Production rules : ( i ) AND rules represent the decomposition of an entity into sub-parts ; ( ii ) OR rules represent the switching among sub-types of an entity ; ( iii ) SET rules represent an ensemble of visual entities ."]}
{"orig_sents": ["5", "0", "4", "2", "3", "1"], "shuf_sents": ["However , in many real-world applications the user 's interests are focused on a subset of the variables , specified by a query .", "We demonstrate the success of our approach with positive experimental results on a wide range of graphical models .", "In this paper we propose a query-specific approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efficiency .", "Surprisingly there has been almost no previous work on query-aware MCMC .", "In this case it would be wasteful to uniformly sample , say , one million variables when the query concerns only ten .", "Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model ."]}
{"orig_sents": ["2", "3", "5", "4", "1", "0"], "shuf_sents": ["Clustering via a Dirichlet process mixture model is used to discover a minimal , sufficient collection of portable skills .", "We show that these problems can be overcome by clustering subgoal data defined in an agent-space and using the resulting clusters as templates for skill termination conditions .", "Skill discovery algorithms in reinforcement learning typically identify single states or regions in state space that correspond to task-specific subgoals .", "However , such methods do not directly address the question of how many distinct skills are appropriate for solving the tasks that the agent faces .", "Furthermore , skills created in this manner are often only transferable to tasks that share identical state spaces , since corresponding subgoals across tasks are not merged into a single skill goal .", "This can be highly inefficient when many identified subgoals correspond to the same underlying skill , but are all used individually as skill goals ."]}
{"orig_sents": ["6", "7", "0", "5", "3", "2", "4", "1"], "shuf_sents": ["Prediction in this model consists of minimising a particular submodular set function , what can be accomplished exactly and efficiently via graph-cuts .", "We also make available source code that enables the reproduction of our experiments .", "We also present a nontrivial test of a sufficient condition for our algorithm to have found an optimal solution .", "We present an approximate algorithm for this problem and prove that it is sound in the sense that it never predicts incorrect labels .", "We present experiments on benchmark multi-label datasets , which attest the value of the proposed technique .", "Learning however is substantially more involved and requires the solution of an intractable combinatorial optimisation problem .", "In this paper we present an algorithm to learn a multi-label classifier which attempts at directly optimising the F -score .", "The key novelty of our formulation is that we explicitly allow for assortative ( submodular ) pairwise label interactions , i.e. , we can leverage the co-ocurrence of pairs of labels in order to improve the quality of prediction ."]}
{"orig_sents": ["3", "4", "2", "0", "1"], "shuf_sents": ["The second change is introducing a communication of expected utility from the student to the teacher .", "The resulting system only uses teacher traces when the agent needs to learn concepts it can not efficiently learn on its own .", "The first change is replacing previously used Mistake Bound model learners with a recently proposed framework that melds the KWIK and Mistake Bound supervised learning protocols .", "We present theoretical and empirical results for a framework that combines the benefits of apprenticeship and autonomous reinforcement learning .", "Our approach modifies an existing apprenticeship learning framework that relies on teacher demonstrations and does not necessarily explore the environment ."]}
{"orig_sents": ["0", "4", "3", "5", "2", "6", "1"], "shuf_sents": ["Multi-class Gaussian Process Classifiers ( MGPCs ) are often affected by overfitting problems when labeling errors occur far from the decision boundaries .", "Finally , we show how RMGPC can be used for successfully identifying data instances which are difficult to classify correctly in practice .", "This method performs better than other Gaussian process alternatives based on considering latent Gaussian noise or heavy-tailed processes .", "Expectation propagation is used for approximate inference .", "To prevent this , we investigate a robust MGPC ( RMGPC ) which considers labeling errors independently of their distance to the decision boundaries .", "Experiments with several datasets in which noise is injected in the labels illustrate the benefits of RMGPC .", "When no noise is injected in the labels , RMGPC still performs equal or better than the other methods ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["We introduce a general family of group sparsity inducing priors based on matrix-variate Gaussian scale mixtures .", "The model is able to capture correlations between tasks , or more specifically a low-rank approximation of the covariance matrix , while being sparse in the features .", "Empirical evaluations on data sets from biology and vision demonstrate the applicability of the model , where on both regression and classification tasks it achieves competitive predictive performance compared to previously proposed methods .", "We propose a new sparse Bayesian model for multi-task regression and classification .", "We show the amount of sparsity can be learnt from the data by combining an approximate inference approach with type II maximum likelihood estimation of the hyperparameters ."]}
{"orig_sents": ["0", "3", "4", "2", "5", "1"], "shuf_sents": ["There is much evidence that humans and other animals utilize a combination of model-based and model-free RL methods .", "The statistical circumstances favoring model-based RL are also those that promote a high learning rate , which helps explain why , in psychology , the distinction between these strategies is traditionally conceived in terms of rulebased vs. incremental learning .", "Using theory and simulation , we show that model-free TD learning is relatively most disadvantaged in cases of high volatility and low noise .", "Although it has been proposed that these systems may dominate according to their relative statistical efficiency in different circumstances , there is little specific evidence -- especially in humans -- as to the details of this trade-off .", "Accordingly , we examine the relative performance of different RL approaches under situations in which the statistics of reward are differentially noisy and volatile .", "We present data from a decision-making experiment manipulating these parameters , showing that humans shift learning strategies in accord with these predictions ."]}
{"orig_sents": ["2", "0", "5", "1", "3", "4"], "shuf_sents": ["It has remained an open question , however , whether anything can be said a priori about the quality of the TD solution when off-policy sampling is employed with function approximation .", "In this paper we propose a novel approach to address this problem : we show that by considering a certain convex subset of off-policy distributions we can indeed provide guarantees as to the solution quality similar to the on-policy case .", "Off-policy learning , the ability for an agent to learn about a policy other than the one it is following , is a key element of Reinforcement Learning , and in recent years there has been much work on developing Temporal Different ( TD ) algorithms that are guaranteed to converge under off-policy sampling .", "Furthermore , we show that we can efficiently project on to this convex set using only samples generated from the system .", "The end result is a novel TD algorithm that has approximation guarantees even in the case of off-policy sampling and which empirically outperforms existing TD methods .", "In general the answer is no : for arbitrary off-policy sampling the error of the TD solution can be unboundedly large , even when the approximator can represent the true value function well ."]}
{"orig_sents": ["5", "1", "2", "3", "4", "0"], "shuf_sents": ["We test our algorithm and show it to perform well in experiments , even when is a small constant .", "We measure its regret with respect to the log-loss defined in , which is parameterized by a scalar .", "We prove that the regret of N EWTRON is O ( log T ) when is a constant that does not vary with horizon T , and at most O ( T 2/3 ) if is allowed to increase to infinity with T .", "For = O ( log T ) , the regret is bounded by O ( T ) , thus solving the open problem of .", "Our algorithm is based on a novel application of the online Newton method .", "We present an efficient algorithm for the problem of online multiclass prediction with bandit feedback in the fully adversarial setting ."]}
{"orig_sents": ["1", "3", "4", "0", "6", "2", "5"], "shuf_sents": ["This is done by solving a sparse optimization problem , which encourages selecting nearby points that lie in the same manifold and approximately span a low-dimensional affine subspace .", "We propose an algorithm called Sparse Manifold Clustering and Embedding ( SMCE ) for simultaneous clustering and dimensionality reduction of data lying in multiple nonlinear manifolds .", "Moreover , the size of the optimal neighborhood of a data point , which can be different for different points , provides an estimate of the dimension of the manifold to which the point belongs .", "Similar to most dimensionality reduction methods , SMCE finds a small neighborhood around each data point and connects each point to its neighbors with appropriate weights .", "The key difference is that SMCE finds both the neighbors and the weights automatically .", "Experiments demonstrate that our method can effectively handle multiple manifolds that are very close to each other , manifolds with non-uniform sampling and holes , as well as estimate the intrinsic dimensions of the manifolds .", "The optimal solution encodes information that can be used for clustering and dimensionality reduction using spectral clustering and embedding ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["In application to distributed optimization , we show n-node architectures whose optimization error in stochastic problems -- in spite of asynchronous delays -- scales asymptotically as O ( 1/ nT ) , which is known to be optimal even in the absence of delays .", "The main application of our results is to the development of distributed minimization algorithms where a master node performs parameter updates while worker nodes compute stochastic gradients based on local information in parallel , which may give rise to delays due to asynchrony .", "We analyze the convergence of gradient-based optimization algorithms whose updates depend on delayed stochastic gradient information .", "Our main contribution is to show that for smooth stochastic problems , the delays are asymptotically negligible ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["We consider loss functions for multiclass prediction problems .", "We subsume existing results on `` classification calibration '' by relating it to properness and show that the simple integral representation for binary proper losses can not be extended to multiclass losses .", "We determine the stationarity condition , Bregman representation , order-sensitivity , existence and uniqueness of the composite representation for multiclass losses .", "We show when a multiclass loss can be expressed as a `` proper composite loss '' , which is the composition of a proper loss and a link function .", "We extend existing results for binary losses to multiclass losses ."]}
{"orig_sents": ["3", "2", "4", "1", "0", "5"], "shuf_sents": ["When applied to a challenging dataset of brain images from serial electron microscopy , LASH dramatically improved segmentation accuracy when clustering supervoxels generated by state of the boundary detection algorithms .", "We apply this general method to segment images by clustering superpixels , an application that we call Learning to Agglomerate Superpixel Hierarchies ( LASH ) .", "The function that evaluates similarity is traditionally handdesigned , but there has been recent interest in supervised or semisupervised settings in which ground-truth clustered data is available for training .", "An agglomerative clustering algorithm merges the most similar pair of clusters at every iteration .", "Here we show how to train a similarity function by regarding it as the action-value function of a reinforcement learning problem .", "The naive strategy of directly training only supervoxel similarities and applying single linkage clustering produced less improvement ."]}
{"orig_sents": ["4", "0", "2", "1", "5", "6", "3"], "shuf_sents": ["Given a hierarchical taxonomy that captures semantic similarity between the objects , we learn a corresponding tree of metrics ( ToM ) .", "Specifically , a Mahalanobis metric learned for a given node must satisfy the appropriate ( dis ) similarity constraints generated only among its subtree members ' training instances .", "In this tree , we have one metric for each non-leaf node of the object hierarchy , and each metric is responsible for discriminating among its immediate subcategory children .", "We validate our approach with multiple image datasets using the WordNet taxonomy , show its advantages over alternative metric learning approaches , and analyze the meaning of attribute features selected by our algorithm .", "We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships .", "To further exploit the semantics , we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor ( supercategory ) nodes ' metrics .", "Intuitively , this reflects that visual cues most useful to distinguish the generic classes ( e.g. , feline vs. canine ) should be different than those cues most useful to distinguish their component fine-grained classes ( e.g. , Persian cat vs. Siamese cat ) ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["Our bound is also superior to the existing results for both modelfree and model-based instances of batch Q-value iteration that are considered to be more efficient than the incremental methods like Q-learning .", "This bound has a better dependency on 1/ and 1/ ( 1 - ) , and thus , is tighter than the best available result for Q-learning .", "We introduce a new convergent variant of Q-learning , called speedy Q-learning ( SQL ) , to address the problem of slow convergence in the standard form of the Q-learning algorithm .", "We prove a PAC bound on the performance of SQL , which shows that for an MDP with n state-action pairs and the discount factor only T = O log ( n ) / ( 2 ( 1 - ) 4 ) steps are required for the SQL algorithm to converge to an -optimal action-value function with high probability ."]}
{"orig_sents": ["4", "6", "2", "0", "5", "1", "3"], "shuf_sents": ["The D.S .", "In fact , this generalizes any set-function optimization .", "The developed algorithm is a branch-and-bound-based algorithm which responds to the structure of this problem through the relationship between submodularity and convexity .", "We empirically investigate the performance of our algorithm , and illustrate the difference between exact and approximate solutions respectively obtained by the proposed and existing algorithms in feature selection and discriminative structure learning .", "In this paper , we propose the first exact algorithm for minimizing the difference of two submodular functions ( D.S .", "programming problem covers a broad range of applications in machine learning .", ") , i.e. , the discrete version of the D.C. programming problem ."]}
{"orig_sents": ["5", "2", "4", "6", "7", "3", "0", "1"], "shuf_sents": ["Here we demonstrate only ( 1 ) and ( 2 ) : Given signals are temporally aligned using nonlinear warpings and , thus , separated into their phase and amplitude components .", "The proposed method for signal alignment is shown to have state of the art performance using Berkeley growth , handwritten signatures , and neuroscience spike train data .", "We present a novel framework for estimating the unknown signal that utilizes the action of the warping group to form an equivalence relation between signals .", "This estimation algorithm has many applications : ( 1 ) registration/alignment of functional data , ( 2 ) separation of phase/amplitude components of functional data , ( 3 ) joint demodulation and carrier estimation , and ( 4 ) sparse modeling of functional data .", "First , we derive an estimator for the equivalence class of the unknown signal using the notion of Karcher mean on the quotient space of equivalence classes .", "While signal estimation under random amplitudes , phase shifts , and additive noise is studied frequently , the problem of estimating a deterministic signal under random time-warpings has been relatively unexplored .", "This step requires the use of Fisher-Rao Riemannian metric and a square-root representation of signals to enable computations of distances and means under this metric .", "Then , we define a notion of the center of a class and show that the center of the estimated class is a consistent estimator of the underlying unknown signal ."]}
{"orig_sents": ["0", "4", "5", "1", "3", "2"], "shuf_sents": ["Divergence estimators based on direct approximation of density-ratios without going through separate approximation of numerator and denominator densities have been successfully applied to machine learning tasks that involve distribution comparison such as outlier detection , transfer learning , and two-sample homogeneity test .", "Since relative density-ratios are always smoother than corresponding ordinary density-ratios , our proposed method is favorable in terms of the non-parametric convergence speed .", "Through experiments , we demonstrate the usefulness of the proposed approach .", "Furthermore , we show that the proposed divergence estimator has asymptotic variance independent of the model complexity under a parametric setup , implying that the proposed estimator hardly overfits even with complex models .", "However , since density-ratio functions often possess high fluctuation , divergence estimation is still a challenging task in practice .", "In this paper , we propose to use relative divergences for distribution comparison , which involves approximation of relative density-ratios ."]}
{"orig_sents": ["1", "2", "4", "5", "3", "0"], "shuf_sents": ["An efficient Gibbs sampler is developed for computations , and state-of-the-art results are presented for image processing and music analysis tasks .", "A new Levy process prior is proposed for an uncountable collection of covariatedependent feature-learning measures ; the model is called the kernel beta process ( KBP ) .", "Available covariates are handled efficiently via the kernel construction , with covariates assumed observed with each data sample ( `` customer '' ) , and latent covariates learned for each feature ( `` dish '' ) .", "The beta process is recovered as a limiting case of the KBP .", "Each customer selects dishes from an infinite buffet , in a manner analogous to the beta process , with the added constraint that a customer first decides probabilistically whether to `` consider '' a dish , based on the distance in covariate space between the customer and dish .", "If a customer does consider a particular dish , that dish is then selected probabilistically as in the beta process ."]}
{"orig_sents": ["0", "4", "5", "1", "2", "6", "3"], "shuf_sents": ["We address the challenging task of decoupling material properties from lighting properties given a single image .", "This results in a Random Field model with global , latent variables ( basis colors ) and pixel-accurate output reflectance values .", "We show that without edge information high-quality results can be achieved , that are on par with methods exploiting this source of information .", "We believe that our new approach is an excellent starting point for future developments in this field .", "In the last two decades virtually all works have concentrated on exploiting edge information to address this problem .", "We take a different route by introducing a new prior on reflectance , that models reflectance values as being drawn from a sparse set of basis colors .", "Finally , we are able to improve on state-of-the-art results by integrating edge information into our model ."]}
{"orig_sents": ["4", "1", "5", "2", "0", "3"], "shuf_sents": ["The HSLDS model also performs better than recent comparable models in predicting the firing rate of an isolated neuron based on the firing rates of others , suggesting that it captures more of the `` shared variance '' of the data .", "In principle , these dynamics might be identified by purely unsupervised , statistical means .", "The regimes are identified without reference to behavioural or experimental epochs , but nonetheless transitions between them correlate strongly with external events whose timing may vary from trial to trial .", "Thus , the method is able to trace the dynamical processes underlying the coordinated evolution of network activity in a way that appears to reflect its computational role .", "Simultaneous recordings of many neurons embedded within a recurrentlyconnected cortical network may provide concurrent views into the dynamical processes of that network , and thus its computational function .", "Here , we show that a Hidden Switching Linear Dynamical Systems ( HSLDS ) model -- in which multiple linear dynamical laws approximate a nonlinear and potentially non-stationary dynamical process -- is able to distinguish different dynamical regimes within single-trial motor cortical activity associated with the preparation and initiation of hand movements ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["Desirable traits include the ability to incorporate annotations or metadata associated with documents ; the discovery of correlated patterns of topic usage ; and the avoidance of parametric assumptions , such as manual specification of the number of topics .", "Topic models are learned via a statistical model of variation within document collections , but designed to extract meaningful semantic structure .", "We validate the semantic structure and predictive performance of the DCNT using a corpus of NIPS documents annotated by various metadata .", "We propose a doubly correlated nonparametric topic ( DCNT ) model , the first model to simultaneously capture all three of these properties .", "The DCNT models metadata via a flexible , Gaussian regression on arbitrary input features ; correlations via a scalable square-root covariance representation ; and nonparametric selection from an unbounded series of potential topics via a stick-breaking construction ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We derive an upper bound on the local Rademacher complexity of p -norm multiple kernel learning , which yields a tighter excess risk bound than global approaches .", "Previous local approaches analyzed the case p = 1 only while our analysis covers all cases 1 p , assuming the different feature mappings corresponding to the different kernels to be uncorrelated .", "We also show a lower bound that shows that the bound is tight , and derive consequences regarding ex cess loss , namely fast convergence rates of the order O ( n- 1+ ) , where is the minimum eigenvalue decay rate of the individual kernels ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We consider the hypothesis testing problem of detecting a shift between the means of two multivariate normal distributions in the high-dimensional setting , allowing for the data dimension p to exceed the sample size n. Our contribution is a new test statistic for the two-sample test of means that integrates a random projection with the classical Hotelling T 2 statistic .", "Working within a high-dimensional framework that allows ( p , n ) , we first derive an asymptotic power function for our test , and then provide sufficient conditions for it to achieve greater power than other state-of-the-art tests .", "Lastly , we illustrate an advantage of our procedure with comparisons on a high-dimensional gene expression dataset involving the discrimination of different types of cancer .", "Using ROC curves generated from simulated data , we demonstrate superior performance against competing tests in the parameter regimes anticipated by our theoretical results ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["While the spectral relaxation is known to be loose , it has been shown recently that a non-linear eigenproblem yields a tight relaxation of the Cheeger cut .", "Spectral clustering is based on the spectral relaxation of the normalized/ratio graph cut criterion .", "In this paper , we extend this result considerably by providing a characterization of all balanced graph cuts which allow for a tight relaxation .", "Moreover , our approach comes with the quality guarantee that given any partition as initialization the algorithm either outputs a better partition or it stops immediately .", "Although the resulting optimization problems are non-convex and non-smooth , we provide an efficient first-order scheme which scales to large graphs ."]}
{"orig_sents": ["0", "2", "4", "3", "5", "6", "7", "1"], "shuf_sents": ["Learning theory has largely focused on two main learning scenarios : the classical statistical setting where instances are drawn i.i.d .", "We study a smoothed online learning scenario and show that exponentially small amount of noise can make function classes with infinite Littlestone dimension learnable .", "from a fixed distribution , and the adversarial scenario wherein , at every time step , an adversarially chosen instance is revealed to the player .", "We define the minimax value of a game where the adversary is restricted in his moves , capturing stochastic and non-stochastic assumptions on data .", "It can be argued that in the real world neither of these assumptions is reasonable .", "Building on the sequential symmetrization approach , we define a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i.i.d .", "to worst-case .", "The bounds let us immediately deduce variation-type bounds ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["Here we extend the Indian Buffet Process ( IBP ) , a nonparametric Bayesian model , to integrate noisy interaction scores with properties of individual entities for inferring interaction networks and clustering nodes within these networks .", "Analysis of synthetic and real data indicates that the method improves upon prior methods , correctly recovers interactions and clusters , and provides accurate biological predictions .", "Determining interactions between entities and the overall organization and clustering of nodes in networks is a major challenge when analyzing biological and social network data .", "We present an application of this method to study how microRNAs regulate mRNAs in cells ."]}
{"orig_sents": ["4", "2", "5", "1", "3", "0"], "shuf_sents": ["Finally , we demonstrate the usefulness of the improved PGPE method through experiments .", "We then derive the optimal baseline for PGPE , which contributes to further reducing the variance .", "In this paper , we analyze and improve the stability of policy gradient methods .", "We also theoretically show that PGPE with the optimal baseline is more preferable than REINFORCE with the optimal baseline in terms of the variance of gradient estimates .", "Policy gradient is a useful model-free reinforcement learning approach , but it tends to suffer from instability of gradient estimates .", "We first prove that the variance of gradient estimates in the PGPE ( policy gradients with parameter-based exploration ) method is smaller than that of the classical REINFORCE method under a mild assumption ."]}
{"orig_sents": ["2", "3", "5", "1", "4", "0"], "shuf_sents": ["The algorithmic development and empirical studies are complemented by theoretical analyses in terms of Rademacher generalization bounds and sparse recovery conditions analogous to those for OMP and Group-OMP .", "In this paper , we close this gap by proposing a Group-OMP based framework for sparse MKL .", "We consider regularized risk minimization in a large dictionary of Reproducing kernel Hilbert Spaces ( RKHSs ) over which the target function has a sparse representation .", "This setting , commonly referred to as Sparse Multiple Kernel Learning ( MKL ) , may be viewed as the non-parametric extension of group sparsity in linear models .", "Unlike l1 -MKL , our approach decouples the sparsity regularizer ( via a direct l0 constraint ) from the smoothness regularizer ( via RKHS norms ) , which leads to better empirical performance and a simpler optimization procedure that only requires a black-box single-kernel solver .", "While the two dominant algorithmic strands of sparse learning , namely convex relaxations using l1 norm ( e.g. , Lasso ) and greedy methods ( e.g. , OMP ) , have both been rigorously extended for group sparsity , the sparse MKL literature has so far mainly adopted the former with mild empirical success ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We show that our method is superlinearly convergent , and also present experimental results using synthetic and real application data that demonstrate the considerable improvements in performance of our method when compared to other state-of-the-art methods .", "In contrast to other state-of-the-art methods that largely use first order gradient information , our algorithm is based on Newton 's method and employs a quadratic approximation , but with some modifications that leverage the structure of the sparse Gaussian MLE problem .", "The 1 regularized Gaussian maximum likelihood estimator has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix , or alternatively the underlying graph structure of a Gaussian Markov Random Field , from very limited samples .", "We propose a novel algorithm for solving the resulting optimization problem which is a regularized log-determinant program ."]}
{"orig_sents": ["1", "0", "2", "3", "4"], "shuf_sents": ["In the mistake-bounded planning framework , the learner has access to a planner for the given model representation , a simulator , and a planning problem generator , and aims to learn a model with at most a polynomial number of faulty plans .", "This paper introduces two new frameworks for learning action models for planning .", "In the planned exploration framework , the learner does not have access to a problem generator and must instead design its own problems , plan for them , and converge with at most a polynomial number of planning attempts .", "The paper reduces learning in these frameworks to concept learning with one-sided error and provides algorithms for successful learning in both frameworks .", "A specific family of hypothesis spaces is shown to be efficiently learnable in both the frameworks ."]}
{"orig_sents": ["2", "0", "3", "1", "4"], "shuf_sents": ["We show that these surrogate loss functions are consistent in the strong sense that for any feature map ( finite or infinite dimensional ) they yield predictors approaching the infimum task loss achievable by any linear predictor over the given features .", "These bounds suggest that probit loss converges more rapidly .", "We consider latent structural versions of probit loss and ramp loss .", "We also give finite sample generalization bounds ( convergence rates ) for these loss functions .", "However , ramp loss is more easily optimized on a given sample ."]}
{"orig_sents": ["4", "0", "1", "2", "5", "3"], "shuf_sents": ["We extend an existing Bayesian measure of representativeness , which indicates the representativeness of a sample from a distribution , to define a measure of the representativeness of an item to a set .", "We show that this measure is formally related to a machine learning method known as Bayesian Sets .", "Building on this connection , we derive an analytic expression for the representativeness of objects described by a sparse vector of binary features .", "Comparing the resulting predictions to human judgments of representativeness provides a test of this measure with naturalistic stimuli , and illustrates how databases that are more commonly used in computer vision and machine learning can be used to evaluate psychological theories .", "How do people determine which elements of a set are most representative of that set ?", "We then apply this measure to a large database of images , using it to determine which images are the most representative members of different sets ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["We justify the proposed approach with an oracle inequality which links the properties of the recovery algorithms and the best estimation performance .", "We discuss new methods for the recovery of signals with block-sparse structure , based on 1 -minimization .", "We optimize these bounds with respect to the method parameters to construct the estimators with improved statistical properties .", "Our emphasis is on the efficiently computable error bounds for the recovery routines ."]}
{"orig_sents": ["4", "3", "2", "1", "0"], "shuf_sents": ["Finally , we show that our framework allows us to learn the values of the interactions from the data , rather than having them pre-specified .", "We show that interesting dictionaries can be learned for interactions that encode tree structures or locally connected structures .", "We describe modifications of standard sparse coding algorithms for inference in this setting , and describe experiments showing that these algorithms are efficient .", "Supposing a dictionary with K atoms , we introduce a structure as a set of penalties or interactions between every pair of atoms .", "This work describes a conceptually simple method for structured sparse coding and dictionary design ."]}
{"orig_sents": ["2", "4", "0", "5", "3", "1"], "shuf_sents": ["Our interpretation will be analogous to the manner in which 2 -regularized or 1 -regularized 2 -regression ( often called Ridge regression and Lasso regression , respectively ) can be interpreted in terms of a Gaussian prior or a Laplace prior , respectively , on the coefficient vector of the regression problem .", "Empirical results are also provided to illustrate the manner in which approximate eigenvector computation implicitly performs statistical regularization , relative to running the corresponding exact algorithm .", "Recently , Mahoney and Orecchia demonstrated that popular diffusion-based procedures to compute a quick approximation to the first nontrivial eigenvector of a data graph Laplacian exactly solve certain regularized Semi-Definite Programs ( SDPs ) .", "Conversely , it will imply that the solution to this regularized estimation problem can be computed very quickly by running , e.g. , the fast diffusion-based PageRank procedure for computing an approximation to the first nontrivial eigenvector of the graph Laplacian .", "In this paper , we extend that result by providing a statistical interpretation of their approximation procedure .", "Our framework will imply that the solutions to the MahoneyOrecchia regularized SDP can be interpreted as regularized estimates of the pseudoinverse of the graph Laplacian ."]}
{"orig_sents": ["1", "2", "3", "6", "4", "5", "0"], "shuf_sents": ["The MMLE approach is shown to embed automatic model order selection , akin to automatic relevance determination .", "In this paper we describe a maximum likelihood approach for dictionary learning in the multiplicative exponential noise model .", "This model is prevalent in audio signal processing where it underlies a generative composite model of the power spectrogram .", "Maximum joint likelihood estimation of the dictionary and expansion coefficients leads to a nonnegative matrix factorization problem where the Itakura-Saito divergence is used .", "In this paper we describe a variational procedure for optimization of the marginal likelihood , i.e. , the likelihood of the dictionary where the activation coefficients have been integrated out ( given a specific prior ) .", "We compare the output of both maximum joint likelihood estimation ( i.e. , standard Itakura-Saito NMF ) and maximum marginal likelihood estimation ( MMLE ) on real and synthetical datasets .", "The optimality of this approach is in question because the number of parameters ( which include the expansion coefficients ) grows with the number of observations ."]}
{"orig_sents": ["0", "2", "5", "4", "6", "1", "3", "7"], "shuf_sents": ["A majority of approximate dynamic programming approaches to the reinforcement learning problem can be categorized into greedy value function methods and value-based policy gradient methods .", "In addition , it has been suggested in the literature that the oscillation phenomenon might be subtly connected to the grossly suboptimal performance in the Tetris benchmark problem of all attempted approximate dynamic programming methods .", "The former approach , although fast , is well known to be susceptible to the policy oscillation phenomenon .", "We report empirical evidence against such a connection and in favor of an alternative explanation .", "We explain the phenomenon in terms of this view and illustrate the underlying mechanism with artificial examples .", "We take a fresh view to this phenomenon by casting a considerable subset of the former approach as a limiting special case of the latter .", "We also use it to derive the constrained natural actor-critic algorithm that can interpolate between the aforementioned approaches .", "Finally , we report scores in the Tetris problem that improve on existing dynamic programming based results ."]}
{"orig_sents": ["2", "7", "6", "4", "5", "1", "3", "0"], "shuf_sents": ["Experimental results show that the proposed algorithm is more efficient than existing state-of-the-art algorithms .", "We reveal several key properties of the proximal operator associated with the overlapping group Lasso , and compute the proximal operator by solving the smooth and convex dual problem , which allows the use of the gradient descent type of algorithms for the optimization .", "The group Lasso is an extension of the Lasso for feature selection on ( predefined ) non-overlapping groups of features .", "We have performed empirical evaluations using both synthetic and the breast cancer gene expression data set , which consists of 8,141 genes organized into ( overlapping ) gene sets .", "The resulting optimization is , however , much more challenging to solve due to the group overlaps .", "In this paper , we consider the efficient optimization of the overlapping group Lasso penalized problem .", "There have been several recent attempts to study a more general formulation , where groups of features are given , potentially with overlaps between the groups .", "The non-overlapping group structure limits its applicability in practice ."]}
{"orig_sents": ["4", "1", "5", "6", "3", "0", "2"], "shuf_sents": ["A 2,000-neuron embedded Matlab SNN implementation runs in real-time and its closed-loop performance is quite comparable to that of the standard Kalman filter .", "Despite compelling proof of concept systems , barriers to clinical translation remain .", "The success of this closed-loop decoder holds promise for hardware SNN implementations of statistical signal processing algorithms on neuromorphic chips , which may offer power savings necessary to overcome a major obstacle to the successful clinical translation of neural motor prostheses .", "The Kalman filter was trained to predict the arm 's velocity and mapped on to the SNN using the Neural Engineering Framework ( NEF ) .", "Motor prostheses aim to restore function to disabled patients .", "One challenge is to develop a low-power , fully-implantable system that dissipates only minimal power so as not to damage tissue .", "To this end , we implemented a Kalman-filter based decoder via a spiking neural network ( SNN ) and tested it in brain-machine interface ( BMI ) experiments with a rhesus monkey ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["In this paper , we introduce a new penalty function which takes into account the correlation of the design matrix to stabilize the estimation .", "This norm , called the trace Lasso , uses the trace norm of the selected covariates , which is a convex surrogate of their rank , as the criterion of model complexity .", "Using the 1 -norm to regularize the estimation of the parameter vector of a linear model leads to an unstable estimator when covariates are highly correlated .", "We analyze the properties of our norm , describe an optimization algorithm based on reweighted least-squares , and illustrate the behavior of this norm on synthetic data , showing that it is more adapted to strong correlations than competing methods such as the elastic net ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We show that while this generalization yields richer distance measures on probabilities compared to its Hilbert space counterpart , it however suffers from serious computational drawback limiting its practical applicability , which therefore demonstrates the need for developing efficient learning algorithms in Banach spaces .", "While many works have been carried out in generalizing Hilbert methods to Banach spaces , in this paper , we consider the simple problem of learning a Parzen window classifier in a reproducing kernel Banach space ( RKBS ) -- which is closely related to the notion of embedding probability measures into an RKBS -- in order to carefully understand its pros and cons over the Hilbert space classifier .", "The goal of this paper is to investigate the advantages and disadvantages of learning in Banach spaces over Hilbert spaces ."]}
{"orig_sents": ["9", "4", "0", "1", "5", "6", "7", "3", "2", "8"], "shuf_sents": ["Recent results have shown that electrocorticographic ( ECoG ) recordings from the surface of the brain in humans can give information about kinematic parameters ( e.g. , hand velocity or finger flexion ) .", "The decoding approaches in these demonstrations usually employed classical classification/regression algorithms that derive a linear mapping between brain signals and outputs .", "Our results show that the application of the proposed model , which incorporates anatomical constraints , improves decoding performance compared to the results in the previous work .", "We then apply the resulting SNDS decoder to infer the flexion of individual fingers from the same ECoG dataset used in a recent study .", "Some BCI approaches begin by decoding kinematic parameters of movements from brain signals , and then proceed to using these signals , in absence of movements , to allow a user to control an output .", "However , they typically only incorporate little prior information about the target kinematic parameter .", "In this paper , we show that different types of anatomical constraints that govern finger flexion can be exploited in this context .", "Specifically , we incorporate these constraints in the construction , structure , and the probabilistic functions of a switched non-parametric dynamic system ( SNDS ) model .", "Thus , the results presented in this paper may ultimately lead to neurally controlled hand prostheses with full fine-grained finger articulation .", "Brain-computer interfaces ( BCIs ) use brain signals to convey a user 's intent ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["These approximations are typically used over graphs with short-range cycles .", "We demonstrate that these approximations also help in sparse graphs with long-range loops , as the ones used in coding theory to approach channel capacity .", "Furthermore , we propose a new method for constructing the tree structure on the fly that might be more amenable for sparse graphs with general factors .", "We show an application of a tree structure for approximate inference in graphical models using the expectation propagation algorithm .", "For asymptotically large sparse graph , the expectation propagation algorithm together with the tree structure yields a completely disconnected approximation to the graphical model but , for for finite-length practical sparse graphs , the tree structure approximation to the code graph provides accurate estimates for the marginal of each variable ."]}
{"orig_sents": ["5", "2", "4", "0", "3", "1"], "shuf_sents": ["Using this framework , we show how to generalize the Graphical Lasso in order to learn a sparse inverse covariance between features while accounting for a low-rank confounding covariance between samples .", "We find greater accuracy in recovering biological network structures and are able to better reconstruct the confounders .", "Here , we discuss an approach for efficient inference in such models that explicitly account for iid observation noise .", "We show practical utility on applications to biology , where we model covariances with more than 100,000 dimensions .", "Computational tractability can be retained by exploiting the Kronecker product between row and column covariance matrices .", "Inference in matrix-variate Gaussian models has major applications for multioutput prediction and joint learning of row and column covariances from matrixvariate data ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We illustrate the recovery algorithm on both artificially constructed and real data .", "This paper considers the problem of embedding directed graphs in Euclidean space while retaining directional information .", "We model the observed graph as a sample from a manifold endowed with a vector field , and we design an algorithm that separates and recovers the features of this process : the geometry of the manifold , the data density and the vector field .", "The algorithm is motivated by our analysis of Laplacian-type operators and their continuous limit as generators of diffusions on a manifold ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["We illustrate our approach on the Bayes Point Machine with a Student 's t-prior .", "We extend the idea of approximate inference to the t-exponential family by defining a new t-divergence .", "Approximate inference is an important technique for dealing with large , intractable graphical models based on the exponential family of distributions .", "This divergence measure is obtained via convex duality between the log-partition function of the t-exponential family and a new t-entropy ."]}
{"orig_sents": ["4", "2", "3", "5", "0", "1"], "shuf_sents": ["A novel form of expectation propagation is used for inference .", "We demonstrate that although PAFD is computationally demanding , it outperforms previous approaches on synthetic and real signals in clean , noisy and missing data settings .", "Although signal processing provides algorithms for so-called amplitude- and frequencydemodulation ( AFD ) , there are well known problems with all of the existing methods .", "Motivated by the fact that AFD is ill-posed , we approach the problem using probabilistic inference .", "A number of recent scientific and engineering problems require signals to be decomposed into a product of a slowly varying positive envelope and a quickly varying carrier whose instantaneous frequency also varies slowly over time .", "The new approach , called probabilistic amplitude and frequency demodulation ( PAFD ) , models instantaneous frequency using an auto-regressive generalization of the von Mises distribution , and the envelopes using Gaussian auto-regressive dynamics with a positivity constraint ."]}
{"orig_sents": ["5", "3", "2", "0", "4", "1"], "shuf_sents": ["We derive our algorithm by showing that it falls out as the solution of a particular relaxation of a variational framework .", "Experimental results on synthetic and real-world datasets , against several baselines , demonstrate the efficacy of our proposed algorithm .", "The hybrid algorithm passes a mix of sum and max messages depending on the type of source node ( sum or max ) .", "We present a hybrid message-passing algorithm to accomplish this .", "We further show that the Expectation Maximization algorithm can be seen as an approximation to our algorithm .", "We consider a general inference setting for discrete probabilistic graphical models where we seek maximum a posteriori ( MAP ) estimates for a subset of the random variables ( max nodes ) , marginalizing over the rest ( sum nodes ) ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["Our experimental results show that the approach leads to valid inferences and non-trivial insights .", "We consider the problem of Bayesian inference for continuous-time multi-stable stochastic systems which can change both their diffusion and drift parameters at discrete times .", "We propose exact inference and sampling methodologies for two specific cases where the discontinuous dynamics is given by a Poisson process and a two-state Markovian switch .", "We test the methodology on simulated data , and apply it to two real data sets in finance and systems biology ."]}
{"orig_sents": ["4", "2", "5", "1", "3", "0", "6"], "shuf_sents": ["We show that BP-kNNG is asymptotically consistent in recovering the p-value of each test point .", "In this paper , we propose a novel bipartite k-nearest neighbor graph ( BPkNNG ) anomaly detection scheme for estimating minimum volume sets .", "Several approaches to learning minimum volume sets have been proposed in the literature , including the K-point nearest neighbor graph ( K-kNNG ) algorithm based on the geometric entropy minimization ( GEM ) principle .", "Our bipartite estimator retains all the desirable theoretical properties of the K-kNNG , while being computationally simpler than the K-kNNG and the surrogate L1OkNNG detectors .", "Learning minimum volume sets of an underlying nominal distribution is a very effective approach to anomaly detection .", "The K-kNNG detector , while possessing several desirable characteristics , suffers from high computation complexity , and in a simpler heuristic approximation , the leave-one-out kNNG ( L1O-kNNG ) was proposed .", "Experimental results are given that illustrate the superior performance of BP-kNNG as compared to the L1O-kNNG and other state of the art anomaly detection schemes ."]}
{"orig_sents": ["5", "3", "1", "2", "0", "4"], "shuf_sents": ["In this paper , we examine the application of some standard techniques for variance reduction in MCTS , including common random numbers , antithetic variates and control variates .", "Whilst reducing bias ( typically through the addition of domain knowledge ) has been studied in the MCTS literature , comparatively little effort has focused on reducing variance .", "This is somewhat surprising , since variance reduction techniques are a well-studied area in classical statistics .", "The stochastic nature of the Monte-Carlo simulations introduces errors in the value estimates , both in terms of bias and variance .", "We demonstrate how these techniques can be applied to MCTS and explore their efficacy on three different stochastic , single-agent settings : Pig , Ca n't Stop and Dominion .", "Monte-Carlo Tree Search ( MCTS ) has proven to be a powerful , generic planning technique for decision-making in single-agent and adversarial environments ."]}
{"orig_sents": ["5", "4", "1", "2", "3", "0", "6"], "shuf_sents": ["We find that the latent dynamical approach outperforms the GLM in terms of goodness-offit , and reproduces the temporal correlations in the data more accurately .", "What statistical structure best describes the concurrent spiking of cells within a local network ?", "We argue that in the cortex , where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population , the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics , rather than by putative direct coupling .", "We test this claim by comparing a latent dynamical model with realistic spiking observations to coupled generalised linear spike-response models ( GLMs ) using cortical recordings .", "Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data .", "Neurons in the neocortex code and compute as part of a locally interconnected population .", "We also compare models whose observations models are either derived from a Gaussian or point-process models , finding that the non-Gaussian model provides slightly better goodness-of-fit and more realistic population spike counts ."]}
{"orig_sents": ["0", "3", "6", "2", "5", "4", "1"], "shuf_sents": ["In this paper , we address the problem of learning the structure of a pairwise graphical model from samples in a high-dimensional setting .", "We corroborate these results using numerical simulations at the end .", "As a corollary of our general result , we derive sufficient conditions on the number of samples n , the maximum nodedegree d and the problem size p , as well as other conditions on the model parameters , so that the algorithm recovers all the edges with high probability .", "Our first main result studies the sparsistency , or consistency in sparsity pattern recovery , properties of a forward-backward greedy algorithm as applied to general statistical models .", "Further , the greedy algorithm only requires a restricted strong convexity condition which is typically milder than irrepresentability assumptions .", "Our result guarantees graph selection for samples scaling as n = ( d2 log ( p ) ) , in contrast to existing convex-optimization based algorithms that require a sample complexity of ( d3 log ( p ) ) .", "As a special case , we then apply this algorithm to learn the structure of a discrete graphical model via neighborhood estimation ."]}
{"orig_sents": ["6", "7", "4", "3", "1", "0", "5", "2"], "shuf_sents": ["Our regularizers work by creating a structured prior over words that reflect broad patterns in the external data .", "To overcome this , we propose two methods to regularize the learning of topic models .", "Overall , this work makes topic models more useful across a broader range of text data .", "web search result snippets or blog posts ) , learned topics can be less coherent , less interpretable , and less useful .", "However , when dealing with small collections or noisy text ( e.g .", "Using thirteen datasets we show that both regularizers improve topic coherence and interpretability while learning a faithful representation of the collection of interest .", "Topic models have the potential to improve search and browsing by extracting useful semantic themes from web pages and other text documents .", "When learned topics are coherent and interpretable , they can be valuable for faceted browsing , results set diversity analysis , and document retrieval ."]}
{"orig_sents": ["4", "9", "5", "1", "7", "6", "0", "3", "2", "8"], "shuf_sents": ["The CMTL formulation is non-convex , and we adopt a convex relaxation to the CMTL formulation .", "As an alternative MTL approach , clustered multi-task learning ( CMTL ) assumes that multiple tasks follow a clustered structure , i.e. , tasks are partitioned into a set of groups where tasks in the same group are similar to each other , and that such a clustered structure is unknown a priori .", "In addition , we present three algorithms for solving the convex CMTL formulation .", "We further establish the equivalence relationship between the proposed convex relaxation of CMTL and an existing convex relaxation of ASO , and show that the proposed convex CMTL formulation is significantly more efficient especially for high-dimensional data .", "Multi-task learning ( MTL ) learns multiple related tasks simultaneously to improve generalization performance .", "It has been applied successfully in many real world applications .", "Interestingly , we show in this paper the equivalence relationship between ASO and CMTL , providing significant new insights into ASO and CMTL as well as their inherent relationship .", "The objectives in ASO and CMTL differ in how multiple tasks are related .", "We report experimental results on benchmark datasets to demonstrate the efficiency of the proposed algorithms .", "Alternating structure optimization ( ASO ) is a popular MTL method that learns a shared low-dimensional predictive structure on hypothesis spaces from multiple related tasks ."]}
{"orig_sents": ["4", "2", "5", "1", "0", "3"], "shuf_sents": ["This approach allows us to harness the advantages of local receptive fields ( such as improved scalability , and reduced data requirements ) when we do not know how to specify such receptive fields by hand or where our unsupervised training algorithm has no obvious generalization to a topographic setting .", "Specifically , we choose local receptive fields that group together those low-level features that are most similar to each other according to a pairwise similarity metric .", "Unfortunately , for such large architectures the number of parameters can grow quadratically in the width of the network , thus necessitating hand-coded `` local receptive fields '' that limit the number of connections from lower level features to higher ones ( e.g. , based on spatial locality ) .", "We produce results showing how this method allows us to use even simple unsupervised training algorithms to train successful multi-layered networks that achieve state-of-the-art results on CIFAR and STL datasets : 82.0 % and 60.1 % accuracy , respectively .", "Recent deep learning and unsupervised feature learning systems that learn from unlabeled data have achieved high performance in benchmarks by using extremely large architectures with many features ( hidden units ) at each layer .", "In this paper we propose a fast method to choose these connections that may be incorporated into a wide variety of unsupervised training methods ."]}
{"orig_sents": ["0", "7", "5", "3", "4", "6", "2", "1"], "shuf_sents": ["Multi-instance learning ( MIL ) considers input as bags of instances , in which labels are assigned to the bags .", "Extensive experiments have demonstrated promising results that validate the proposed method .", "We apply our new approach to the automatic image categorization tasks on three ( one single-label and two multilabel ) benchmark data sets .", "Existing MIL methods typically build their models using the Bag-to-Bag ( B2B ) distance , which are often computationally expensive and may not truly reflect the semantic similarities .", "To tackle this , in this paper we approach MIL problems from a new perspective using the Class-to-Bag ( C2B ) distance , which directly assesses the relationships between the classes and the bags .", "For example , in image categorization semantic meanings ( labels ) of an image mostly arise from its regions ( instances ) instead of the entire image ( bag ) .", "Taking into account the two major challenges in MIL , high heterogeneity on data and weak label association , we propose a novel Maximum Margin Multi-Instance Learning ( M3 I ) approach to parameterize the C2B distance by introducing the class specific distance metrics and the locally adaptive significance coefficients .", "MIL is useful in many real-world applications ."]}
{"orig_sents": ["9", "8", "1", "6", "7", "4", "0", "5", "3", "2"], "shuf_sents": ["They are trained alongside other hyperparameters by the usual method of maximisation of the marginal likelihood .", "Gaussian noise .", "We compare our model to others over a range of different regression problems and show that it improves over current methods .", "Analytic predictive moments can then be found for Gaussian distributed test points .", "The input noise variances are inferred from the data as extra hyperparameters .", "Training uses an iterative scheme , which alternates between optimising the hyperparameters and calculating the posterior gradient .", "To make computations tractable we use a local linear expansion about each input point .", "This allows the input noise to be recast as output noise proportional to the squared gradient of the GP posterior mean .", "We present a simple yet effective GP model for training on input points corrupted by i.i.d .", "In standard Gaussian Process regression input locations are assumed to be noise free ."]}
{"orig_sents": ["1", "4", "3", "5", "2", "0"], "shuf_sents": ["Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy .", "Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions .", "Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels .", "In this paper , we consider fully connected CRF models defined on the complete set of pixels in an image .", "While regionlevel models often feature dense pairwise connectivity , pixel-level models are considerably larger and have only permitted sparse graph structures .", "The resulting graphs have billions of edges , making traditional inference algorithms impractical ."]}
{"orig_sents": ["6", "2", "0", "3", "5", "1", "4"], "shuf_sents": ["The policy in infinite-horizon POMDP and DEC-POMDP problems has been represented as finite state controllers ( FSCs ) .", "This policy is optimized by a new infinite-horizon algorithm to yield deterministic periodic policies , and by a new expectation maximization algorithm to yield stochastic periodic policies .", "Partially observable Markov decision processes ( POMDPs ) plan policies for single agents under uncertainty and their decentralized versions ( DEC-POMDPs ) find a policy for multiple agents .", "We introduce a novel class of periodic FSCs , composed of layers connected only to the previous and next layer .", "Our method yields better results than earlier planning methods and can compute larger solutions than with regular FSCs .", "Our periodic FSC method finds a deterministic finite-horizon policy and converts it to an initial periodic infinitehorizon policy .", "Applications such as robot control and wireless communication require planning under uncertainty ."]}
{"orig_sents": ["2", "0", "3", "1", "4"], "shuf_sents": ["We present a new method , `` Expansion-Constrained Ordinary Least Squares '' ( ECOLS ) , that produces a linear approximation but also guarantees convergence when used with FVI .", "We show that the space of function approximators that satisfy this constraint is more rich than the space of `` averagers , '' we prove a minimax property of the ECOLS residual error , and we give an efficient algorithm for computing the coefficients of ECOLS based on constraint generation .", "Fitted value iteration ( FVI ) with ordinary least squares regression is known to diverge .", "To ensure convergence , we constrain the least squares regression operator to be a non-expansion in the -norm .", "We illustrate the algorithmic convergence of FVI with ECOLS in a suite of experiments , and discuss its properties ."]}
{"orig_sents": ["5", "4", "3", "1", "2", "0"], "shuf_sents": ["We evaluate the effectiveness of FGM on both synthetic and real data sets including images and turbulence data , and show that it is superior to existing approaches in detecting group anomalies .", "For this purpose , we propose the Flexible Genre Model ( FGM ) .", "FGM is designed to characterize data groups at both the point level and the group level so as to detect various types of group anomalies .", "Unlike traditional anomaly detection research that focuses on data points , our goal is to discover anomalous aggregated behaviors of groups of points .", "In this paper , we study the group anomaly detection problem .", "An important task in exploring and analyzing real-world data sets is to detect unusual and interesting phenomena ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["Typical problem formulations assume that experiments are selected one at a time with a limited total number of experiments , which fail to capture important aspects of many real-world problems .", "The results show that our algorithms produce highly effective schedules compared to natural baselines .", "We develop both offline and online algorithms for selecting concurrent experiments in this new setting and provide experimental results on a number of optimization benchmarks .", "Budgeted optimization involves optimizing an unknown function that is costly to evaluate by requesting a limited number of function evaluations at intelligently selected inputs .", "This paper defines a novel problem formulation with the following important extensions : 1 ) allowing for concurrent experiments ; 2 ) allowing for stochastic experiment durations ; and 3 ) placing constraints on both the total number of experiments and the total experimental time ."]}
{"orig_sents": ["4", "2", "7", "0", "3", "5", "6", "1"], "shuf_sents": ["The second is a specialized mechanism for HMMs that identifies low quality HMM states and abstain from prediction in those states .", "Our results indicate that both methods are effective , and that the sHMM model is superior .", "We examine two types of selective mechanisms for HMM predictors .", "We call this model selective HMM ( sHMM ) .", "Focusing on short term trend prediction in a financial context , we consider the problem of selective prediction whereby the predictor can abstain from prediction in order to improve performance .", "In both approaches we can trade-off prediction coverage to gain better accuracy in a controlled manner .", "We compare performance of the ambiguity-based rejection technique with that of the sHMM approach .", "The first is a rejection in the spirit of Chow 's well-known ambiguity principle ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["Motivated by applications in electronic games as well as teaching systems , we investigate the problem of dynamic difficulty adjustment .", "The contributions of this paper are ( i ) the formulation of difficulty adjustment as an online learning problem on partially ordered sets , ( ii ) an exponential update algorithm for dynamic difficulty adjustment , ( iii ) a bound on the number of wrong difficulty settings relative to the best static setting chosen in hindsight , and ( iv ) an empirical investigation of the algorithm when playing against adversaries .", "The task here is to repeatedly find a game difficulty setting that is neither `too easy ' and bores the player , nor `too difficult ' and overburdens the player ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["We show that the standard weighted-trace norm might fail when the sampling distribution is not a product distribution ( i.e .", "We provide guarantees when weighting by either the true or empirical sampling distribution , and suggest that even if the true distribution is known ( or is uniform ) , weighting by the empirical distribution may be beneficial .", "when row and column indexes are not selected independently ) , present a corrected variant for which we establish strong learning guarantees , and demonstrate that it works better in practice .", "We provide rigorous guarantees on learning with the weighted trace-norm under arbitrary sampling distributions ."]}
{"orig_sents": ["2", "5", "3", "4", "1", "0"], "shuf_sents": ["We then define a second algorithm , SOO , which does not require the knowledge of the semimetric under which f is smooth , and whose performance is almost as good as DOO optimally-fitted .", "We report a finite-sample performance bound in terms of a measure of the quantity of near-optimal states .", "We consider a global optimization problem of a deterministic function f in a semimetric space , given a finite budget of n evaluations .", "We describe two algorithms based on optimistic exploration that use a hierarchical partitioning of the space at all scales .", "A first contribution is an algorithm , DOO , that requires the knowledge of .", "The function f is assumed to be locally smooth ( around one of its global maxima ) with respect to a semi-metric ."]}
{"orig_sents": ["1", "2", "0", "3", "4"], "shuf_sents": ["We apply the method to a general multi-task and multiple kernel learning model in which a common set of Gaussian process functions is linearly combined with task-specific sparse weights , thus inducing relation between tasks .", "We introduce a variational Bayesian inference algorithm which can be widely applied to sparse linear models .", "The algorithm is based on the spike and slab prior which , from a Bayesian perspective , is the golden standard for sparse inference .", "This model unifies several sparse linear models , such as generalized linear models , sparse factor analysis and matrix factorization with missing values , so that the variational algorithm can be applied to all these cases .", "We demonstrate our approach in multioutput Gaussian process regression , multi-class classification , image processing applications and collaborative filtering ."]}
{"orig_sents": ["2", "0", "1", "5", "3", "7", "6", "4"], "shuf_sents": ["Specifically , we propose a framework for defining the goodness of a ( dis ) similarity function with respect to a given learning task and propose algorithms that have guaranteed generalization properties when working with such good functions .", "Our framework unifies and generalizes the frameworks proposed by and .", "We consider the problem of classification using similarity/distance functions over data .", "We show , by giving theoretical guarantees that the goodness criterion best suited to a problem can itself be learned which makes our approach applicable to a variety of domains and problems .", "We demonstrate the effectiveness of our goodness criteria learning method as well as the landmark selection heuristic on a variety of similarity-based learning datasets and benchmark UCI datasets on which our method consistently outperforms existing approaches by a significant margin .", "An attractive feature of our framework is its adaptability to data - we do not promote a fixed notion of goodness but rather let data dictate it .", "We then provide a novel diversity based heuristic to perform task-driven selection of landmark points instead of random selection .", "We propose a landmarking-based approach to obtaining a classifier from such learned goodness criteria ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects .", "To train the model , we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data .", "While such models are appealing from a theoretical point of view , it has been difficult to demonstrate that they lead to performance advantages on challenging datasets .", "Our model represents people using a hierarchy of deformable parts , variable structure and an explicit model of occlusion for partially visible objects .", "Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark ."]}
{"orig_sents": ["3", "0", "5", "4", "2", "7", "6", "1"], "shuf_sents": ["We argue that this view ignores the fact that the loss function depends on stochastically generated data which in turn determines an intrinsic scale of precision for statistical estimation .", "In this paper , we illustrate these ideas on three L1 regularized coordinate descent algorithms : L1 -regularized L2 -loss SVMs , L1 -regularized logistic regression , and the Lasso , but we emphasize that the underlying methods are much more generally applicable .", "We utilize subsets of the data for computing updates , and use the hypothesis tests for determining when the batch-size needs to be increased .", "Learning problems , such as logistic regression , are typically formulated as pure optimization problems defined on some loss function .", "gradients ) , we can construct frequentist hypothesis tests to determine the reliability of these updates .", "By considering the statistical properties of the update variables used during the optimization ( e.g .", "Moreover , the proposed algorithms depend on a single interpretable parameter - the probability for an update to be in the wrong direction - which is set to a single value across all algorithms and datasets .", "This provides computational benefits and avoids overfitting by stopping when the batch-size has become equal to size of the full dataset ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["These interpretations can be easily coded using special-purpose objects and operator overloading .", "We show how nonstandard interpretations of probabilistic programs can be used to craft efficient inference algorithms : information about the structure of a distribution ( such as gradients or dependencies ) is generated as a monad-like side computation while executing the program .", "We implement two examples of nonstandard interpretations in two different languages , and use them as building blocks to construct inference algorithms : automatic differentiation , which enables gradient based methods , and provenance tracking , which enables efficient construction of global proposals .", "Because the program is in machine-readable format , a variety of techniques from compiler design and program analysis can be used to examine the structure of the distribution represented by the probabilistic program .", "Probabilistic programming languages allow modelers to specify a stochastic process using syntax that resembles modern programming languages ."]}
{"orig_sents": ["7", "3", "2", "5", "8", "0", "4", "6", "1"], "shuf_sents": ["This paper aims at shading some light on this problem , i.e .", "Experiments in object recognition with two standard computer vision data-sets show that the adaptive methods we propose outperform basic sampling and state-of-the-art bandit methods .", "In such contexts , the training time may become prohibitive .", "Some applications , in particular in computer vision , may involve up to millions of training examples and features .", "given a fixed amount of time , for a particular problem , which strategy is optimal in order to reduce the training loss the most .", "Several methods exist to accelerate training , typically either by sampling the features , or the examples , used to train the weak learners .", "We apply this analysis to the design of new algorithms which estimate on the fly at every iteration the optimal trade-off between the number of samples and the number of features to look at in order to maximize the expected loss reduction .", "Classical Boosting algorithms , such as AdaBoost , build a strong classifier without concern about the computational cost .", "Even if those methods can precisely quantify the speed improvement they deliver , they offer no guarantee of being more efficient than any other , given the same amount of time ."]}
{"orig_sents": ["2", "1", "8", "3", "9", "0", "5", "7", "6", "4"], "shuf_sents": ["Our model captures the sources of bias by describing labelers as influenced by shared random effects .", "A typical crowdsourcing application can be divided into three steps : data collection , data curation , and learning .", "Biased labelers are a systemic problem in crowdsourcing , and a comprehensive toolbox for handling their responses is still being developed .", "We present Bayesian Bias Mitigation for Crowdsourcing ( BBMC ) , a Bayesian model to unify all three .", "Experiments show BBMC to outperform many common heuristics .", "This approach can account for more complex bias patterns that arise in ambiguous or hard labeling tasks and allows us to merge data curation and learning into a single computation .", "We propose a general approximation strategy for Markov chains to efficiently quantify the effect of a perturbation on the stationary distribution and specialize this approach to active learning .", "Active learning integrates data collection with learning , but is commonly considered infeasible with Gibbs sampling inference .", "At present these steps are often treated separately .", "Most data curation methods account for the effects of labeler bias by modeling all labels as coming from a single latent truth ."]}
{"orig_sents": ["5", "1", "2", "4", "3", "0"], "shuf_sents": ["Experimental results on flow cytometry data are presented .", "This problem arises in several applications where data distributions fluctuate because of biological , technical , or other sources of variation .", "We develop a distributionfree , kernel-based approach to the problem .", "We present generalization error analysis , describe universal kernels , and establish universal consistency of the proposed methodology .", "This approach involves identifying an appropriate reproducing kernel Hilbert space and optimizing a regularized empirical risk over the space .", "We consider the problem of assigning class labels to an unlabeled test data set , given several labeled training data sets drawn from similar distributions ."]}
{"orig_sents": ["1", "0", "2", "4", "3"], "shuf_sents": ["Examples of such data include web pages and their placement in directories , product descriptions and associated categories from product hierarchies , and free-text clinical records and their assigned diagnosis codes .", "We introduce hierarchically supervised latent Dirichlet allocation ( HSLDA ) , a model for hierarchically and multiply labeled bag-of-word data .", "Out-of-sample label prediction is the primary goal of this work , but improved lower-dimensional representations of the bagof-word data are also of interest .", "We show that leveraging the structure from hierarchical labels improves out-of-sample label prediction substantially when compared to models that do not .", "We demonstrate HSLDA on large-scale data from clinical document labeling and retail product categorization tasks ."]}
{"orig_sents": ["2", "5", "1", "4", "6", "0", "3"], "shuf_sents": ["With LDC benchmark corpora and a Chinese speech corpus , we demonstrate that a resultant speaker-specific representation is insensitive to text/languages spoken and environmental mismatches and hence outperforms MFCCs and other state-of-the-art techniques in speaker recognition .", "Thus , the use of the same representation in both speech and speaker recognition hinders a system from producing better performance due to interference of irrelevant information .", "Speech conveys different yet mixed information ranging from linguistic to speaker-specific components , and each of them should be exclusively used in a specific task .", "We discuss relevant issues and relate our approach to previous work .", "In this paper , we present a deep neural architecture to extract speaker-specific information from MFCCs .", "However , it is extremely difficult to extract a specific information component given the fact that nearly all existing acoustic representations carry all types of speech information .", "As a result , a multi-objective loss function is proposed for learning speaker-specific characteristics and regularization via normalizing interference of non-speaker related information and avoiding information loss ."]}
{"orig_sents": ["3", "2", "4", "1", "0"], "shuf_sents": ["This approach suggests normative roles for some puzzling forms of nonlinear dendritic dynamics and plasticity .", "Our theory predicts a matching of dendritic nonlinearities and synaptic weight distributions to the joint statistics of presynaptic inputs .", "Conversely , circuit computations with spiking neurons are usually formalized without regard to the rich nonlinear nature of dendritic processing .", "Computational analyses of dendritic computations often assume stationary inputs to neurons , ignoring the pulsatile nature of spike-based communication between neurons and the moment-to-moment fluctuations caused by such spiking inputs .", "Here we address the computational challenge faced by neurons that compute and represent analogue quantities but communicate with digital spikes , and show that reliable computation of even purely linear functions of inputs can require the interplay of strongly nonlinear subunits within the postsynaptic dendritic tree ."]}
{"orig_sents": ["3", "5", "7", "1", "6", "2", "0", "4"], "shuf_sents": ["This situation is remedied when using slower decays together with averaging , robustly leading to the optimal rate of convergence .", "Robbins-Monro algorithm ) as well as a simple modification where iterates are averaged ( a.k.a .", "Our analysis suggests that a learning rate proportional to the inverse of the number of iterations , while leading to the optimal convergence rate in the strongly convex case , is not robust to the lack of strong convexity or the setting of the proportionality constant .", "We consider the minimization of a convex objective function defined on a Hilbert space , which is only available through unbiased estimates of its gradients .", "We illustrate our theoretical results with simulations on synthetic and standard datasets .", "This problem includes standard machine learning algorithms such as kernel logistic regression and least-squares regression , and is commonly referred to as a stochastic approximation problem in the operations research community .", "Polyak-Ruppert averaging ) .", "We provide a non-asymptotic analysis of the convergence of two well-known algorithms , stochastic gradient descent ( a.k.a ."]}
{"orig_sents": ["3", "5", "6", "4", "1", "2", "0"], "shuf_sents": ["The method is validated on estimation of linear nonlinear Poisson ( LNP ) cascade models for receptive fields of salamander retinal ganglion cells .", "In the neural connectivity problem , the GAMP-based method is shown to be computational efficient , provides a more exact modeling of the sparsity , can incorporate nonlinearities in the output and significantly outperforms previous compressed-sensing methods .", "For the receptive field estimation , the GAMP method can also exploit inherent structured sparsity in the linear weights .", "Many functional descriptions of spiking neurons assume a cascade structure where inputs are passed through an initial linear filtering stage that produces a lowdimensional signal that drives subsequent nonlinear stages .", "The GAMP method is based on Gaussian approximations of loopy belief propagation .", "This paper presents a novel and systematic parameter estimation procedure for such models and applies the method to two neural estimation problems : ( i ) compressed-sensing based neural mapping from multi-neuron excitation , and ( ii ) estimation of neural receptive fields in sensory neurons .", "The proposed estimation algorithm models the neurons via a graphical model and then estimates the parameters in the model using a recently-developed generalized approximate message passing ( GAMP ) method ."]}
{"orig_sents": ["5", "6", "7", "4", "0", "2", "1", "3"], "shuf_sents": ["However , within the class of faces , knowledge of the image transformation evoked by 3D rotation can be reliably transferred from previously viewed faces to help identify a novel face at a new viewpoint .", "We argue here that in order to accomplish viewpoint-invariant face identification from a single example view , visual cortex must separate the circuitry involved in discounting 3D rotations of faces from the generic circuitry involved in processing other objects .", "We show , through computational simulations , that an architecture which applies this method of gaining invariance to class-specific transformations is effective when restricted to faces and fails spectacularly when applied to other object classes .", "The resulting model of the ventral stream of visual cortex is consistent with the recent physiology results showing the hierarchical organization of the face processing network .", "In particular , the 2D images evoked by a face undergoing a 3D rotation are not produced by the same image transformation ( 2D ) that would produce the images evoked by an object of another class undergoing the same 3D rotation .", "Many studies have uncovered evidence that visual cortex contains specialized regions involved in processing faces but not other object classes .", "Recent electrophysiology studies of cells in several of these specialized regions revealed that at least some of these regions are organized in a hierarchical manner with viewpointspecific cells projecting to downstream viewpoint-invariant identity-specific cells .", "A separate computational line of reasoning leads to the claim that some transformations of visual inputs that preserve viewed object identity are class-specific ."]}
{"orig_sents": ["5", "3", "6", "7", "2", "1", "4", "0"], "shuf_sents": ["P I C O D ES of 256 bytes match the accuracy of the current best known classifier for the Caltech256 benchmark , but they decrease the database storage size by a factor of 100 and speed-up the training and testing of novel classes by orders of magnitude .", "In contrast to previous approaches to learn compact codes , we optimize explicitly for ( an upper bound on ) classification performance .", "In contrast to previous work in the domain of object recognition , we do not choose an arbitrary intermediate representation , but explicitly learn short codes .", "In particular , we address novel-category recognition : the task of defining indexing structures and image representations which enable a large collection of images to be searched for an object category that was not known when the index was built .", "Optimization directly for binary features is difficult and nonconvex , but we present an alternation scheme and convex upper bound which demonstrate excellent performance in practice .", "We introduce P I C O D ES : a very compact image descriptor which nevertheless allows high performance on object category recognition .", "Instead , the training images defining the category are supplied at query time .", "We explicitly learn descriptors of a given length ( from as small as 16 bytes per image ) which have good object-recognition performance ."]}
{"orig_sents": ["0", "4", "5", "1", "3", "2"], "shuf_sents": ["Extensive evidence suggests that items are not encoded independently in visual short-term memory ( VSTM ) .", "We report the results of an experiment designed to determine the specific form of the stimulus-dependence of the mean and the covariance matrix .", "We further show that this type of covariance function can be explained as a natural consequence of encoding multiple stimuli in a population of neurons with correlated responses .", "We find that the magnitude of the covariance between the representations of two items is a monotonically decreasing function of the difference between the items ' feature values , similar to a Gaussian process with a distance-dependent , stationary kernel function .", "However , previous research has not quantitatively considered how the encoding of an item influences the encoding of other items .", "Here , we model the dependencies among VSTM representations using a multivariate Gaussian distribution with a stimulus-dependent mean and covariance matrix ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We present here some empirical results using Thompson sampling on simulated and real data , and show that it is highly competitive .", "Thompson sampling is one of oldest heuristic to address the exploration / exploitation trade-off , but it is surprisingly unpopular in the literature .", "And since this heuristic is very easy to implement , we argue that it should be part of the standard baselines to compare against ."]}
{"orig_sents": ["6", "1", "2", "5", "3", "4", "9", "0", "8", "7"], "shuf_sents": ["We apply these methods to neural data from a color-tuned simple cell in macaque V1 , characterizing its nonlinear response function in the 3D space of cone contrasts .", "However , comparatively little work has addressed the problem of estimating the nonlinear function from feature space to spike rate .", "Here , we use a Gaussian process ( GP ) prior over the infinitedimensional space of nonlinear functions to obtain Bayesian estimates of the `` nonlinearity '' in the linear-nonlinear-Poisson ( LNP ) encoding model .", "We then develop a framework for optimal experimental design under the GP-Poisson model using uncertainty sampling .", "This involves adaptively selecting stimuli according to an information-theoretic criterion , with the goal of characterizing the nonlinearity with as little experimental data as possible .", "This approach offers increased flexibility , robustness , and computational tractability compared to traditional methods ( e.g. , parametric forms , histograms , cubic splines ) .", "A sizeable literature has focused on the problem of estimating a low-dimensional feature space for a neuron 's stimulus sensitivity .", "With simulated experiments , we show that optimal design substantially reduces the amount of data required to estimate these nonlinear combination rules .", "We find that it combines cone inputs in a highly nonlinear manner .", "Our framework relies on a method for rapidly updating hyperparameters under a Gaussian approximation to the posterior ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["We describe a simple algorithm that runs in time poly ( n , 1/ , 1/ ) and learns an unknown n-dimensional -margin halfspace to accuracy 1 - in the presence of malicious noise , when the noise rate is allowed to be as high as ( log ( 1/ ) ) .", "Our algorithm does not work by optimizing a convex loss function .", "Previous efficient algorithms could only learn to accuracy in the presence of malicious noise of rate at most ( ) .", "We show that no algorithm for learning -margin halfspaces that minimizes a convex proxy for misclassification error can tolerate malicious noise at a rate greater than ( ) ; this may partially explain why previous algorithms could not achieve the higher noise tolerance of our new algorithm ."]}
{"orig_sents": ["3", "5", "4", "1", "2", "0"], "shuf_sents": ["We illustrate our approach on visual tracking problems whereby the object of interest ( target ) moves and evolves as a result of occlusions and deformations , and partial knowledge of the target is given in the form of a bounding box ( training set ) .", "Our approach can be thought of as a combination of standard finite-dimensional filtering ( Extended Kalman Filter , or Unscented Filter ) with multiple instance learning , whereby the initial condition comes with a putative set of inlier measurements .", "We show how both the state ( regression ) and the inlier set ( classification ) can be estimated iteratively and causally by processing only the current measurement .", "We propose a robust filtering approach based on semi-supervised and multiple instance learning ( MIL ) .", "Therefore , we seek for a point estimate at the outset , rather than a generic approximation of the entire posterior .", "We assume that the posterior density would be unimodal if not for the effect of outliers that we do not wish to explicitly model ."]}
{"orig_sents": ["0", "4", "1", "3", "2"], "shuf_sents": ["We develop unified information-theoretic machinery for deriving lower bounds for passive and active learning schemes .", "The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of `` disagreement coefficient . ''", "For active learning , we provide first known lower bounds based on the capacity function rather than the disagreement coefficient .", "For passive learning , our lower bounds match the upper bounds of Gine and Koltchinskii up to constants and generalize analogous results of Massart and Nedelec .", "Our bounds involve the so-called Alexander 's capacity function ."]}
{"orig_sents": ["4", "2", "0", "5", "1", "3"], "shuf_sents": ["In this paper we propose encoding data using orthogonal anchor planes , rather than anchor points .", "In practice , the orthogonal coordinate system can be easily learned by minimizing this upper bound using singular value decomposition ( SVD ) .", "It provides a set of anchor points which form a local coordinate system , such that each data point on the manifold can be approximated by a linear combination of its anchor points , and the linear weights become the local coordinate coding .", "We apply our method to model the coordinates locally in linear SVMs for classification tasks , and our experiment on MNIST shows that using only 50 anchor planes our method achieves 1.72 % error rate , while LCC achieves 1.90 % error rate using 4096 anchor points .", "Local Coordinate Coding ( LCC ) is a method for modeling functions of data lying on non-linear manifolds .", "Our method needs only a few orthogonal anchor planes for coding , and it can linearize any ( , , p ) -Lipschitz smooth nonlinear function with a fixed expected value of the upper-bound approximation error on any high dimensional data ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["We derive the shape of the neuronal action potential from first principles , by postulating that action potential generation is strongly constrained by the brain 's need to minimize energy expenditure .", "Energy optimality predicts features in the biophysics that are not per se required for producing the characteristic neuronal action potential : sodium currents should be extraordinarily powerful and inactivate with voltage ; both potassium and sodium currents should have kinetics that have a bell-shaped voltage-dependence ; and the cooperative action of multiple `gates ' should start the flow of current .", "For a given height of an action potential , the least energy is consumed when the underlying currents obey the bang-bang principle : the currents giving rise to the spike should be intense , yet short-lived , yielding spikes with sharp onsets and offsets .", "Most action potentials in the nervous system take on the form of strong , rapid , and brief voltage deflections known as spikes , in stark contrast to other action potentials , such as in the heart , that are characterized by broad voltage plateaus ."]}
{"orig_sents": ["1", "2", "0", "3", "5", "4"], "shuf_sents": ["The proposed approach aims to maximize the correlation between the so derived latent variables and is shown to be suitable for the prediction of multidimensional dependent data from multidimensional independent data , where for the estimation of the latent variables we introduce an algorithm based on Multilinear Singular Value Decomposition ( MSVD ) on a specially defined cross-covariance tensor .", "A multilinear subspace regression model based on so called latent variable decomposition is introduced .", "Unlike standard regression methods which typically employ matrix ( 2D ) data representations followed by vector subspace transformations , the proposed approach uses tensor subspace transformations to model common latent variables across both the independent and dependent data .", "It is next shown that in this way we are also able to unify the existing Partial Least Squares ( PLS ) and N-way PLS regression algorithms within the same framework .", "The potential of the proposed technique is further illustrated on a real world task of the decoding of human intracranial electrocorticogram ( ECoG ) from a simultaneously recorded scalp electroencephalograph ( EEG ) .", "Simulations on benchmark synthetic data confirm the advantages of the proposed approach , in terms of its predictive ability and robustness , especially for small sample sizes ."]}
{"orig_sents": ["3", "1", "0", "4", "2", "5"], "shuf_sents": ["This paper introduces an easy-to-implement stochastic variational method ( or equivalently , minimum description length loss function ) that can be applied to most neural networks .", "However the approaches proposed so far have only been applicable to a few simple network architectures .", "It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation .", "Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks .", "Along the way it revisits several common regularisers from a variational perspective .", "Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus ."]}
{"orig_sents": ["3", "4", "2", "1", "0", "5"], "shuf_sents": ["The approach also allows for the appropriate dimensionality of the latent space to be automatically determined .", "Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space .", "In this paper we introduce the variational Gaussian process dynamical system .", "High dimensional time series are endemic in applications of machine learning such as robotics ( sensor data ) , computational biology ( gene expression data ) , vision ( video sequences ) and graphics ( motion capture data ) .", "Practical nonlinear probabilistic approaches to this data are required .", "We demonstrate the model on a human motion capture data set and a series of high resolution video sequences ."]}
{"orig_sents": ["2", "3", "4", "0", "1"], "shuf_sents": ["Based on these modeling results we propose these models as phenomenological models of receptive field plasticity during an organism 's lifetime .", "Finally , due to the success of the same models in multiple sensory areas , we suggest that these algorithms may provide a constructive realization of the theory , first proposed by Mountcastle , that a qualitatively similar learning algorithm acts throughout primary sensory cortices .", "The efficient coding hypothesis holds that neural receptive fields are adapted to the statistics of the environment , but is agnostic to the timescale of this adaptation , which occurs on both evolutionary and developmental timescales .", "In this work we focus on that component of adaptation which occurs during an organism 's lifetime , and show that a number of unsupervised feature learning algorithms can account for features of normal receptive field properties across multiple primary sensory cortices .", "Furthermore , we show that the same algorithms account for altered receptive field properties in response to experimentally altered environmental statistics ."]}
{"orig_sents": ["0", "5", "2", "7", "1", "3", "6", "4"], "shuf_sents": ["The multi-armed bandit ( MAB ) setting is a useful abstraction of many online learning tasks which focuses on the trade-off between exploration and exploitation .", "In this paper we consider the more realistic scenario in which the metric space is implicit - it is defined by the available structure but not revealed to the algorithm directly .", "While the case of small number of arms is by now well-understood , a lot of recent work has focused on multi-armed bandits with ( infinitely ) many arms , where one needs to assume extra structure in order to make the problem tractable .", "Specifically , we assume that an algorithm is given a tree-based classification of arms .", "We provide an algorithm for this setting , whose performance guarantees ( almost ) match the best known guarantees for the corresponding instance of the Lipschitz MAB problem .", "In this setting , an online algorithm has a fixed set of alternatives ( `` arms '' ) , and in each round it selects one arm and then observes the corresponding reward .", "For any given problem instance such a classification implicitly defines a similarity metric space , but the numerical similarity information is not available to the algorithm .", "In particular , in the Lipschitz MAB problem there is an underlying similarity metric space , known to the algorithm , such that any two arms that are close in this metric space have similar payoffs ."]}
{"orig_sents": ["3", "4", "1", "0", "5", "6", "2"], "shuf_sents": ["For this particular model the ML objective function is continuously degenerate .", "We develop an analytical framework based on a generating function formalism and illustrate it on an exactly solvable model of HMM with one unambiguous symbol .", "For more general scenario VT can be worse compared to ML but still capable of correctly recovering most of the parameters .", "We present an asymptotic analysis of Viterbi Training ( VT ) and contrast it with a more conventional Maximum Likelihood ( ML ) approach to parameter estimation in Hidden Markov Models .", "While ML estimator works by ( locally ) maximizing the likelihood of the observed data , VT seeks to maximize the probability of the most likely hidden state sequence .", "VT objective , in contrast , is shown to have only finite degeneracy .", "Furthermore , VT converges faster and results in sparser ( simpler ) models , thus realizing an automatic Occam 's razor for HMM learning ."]}
{"orig_sents": ["3", "2", "6", "4", "5", "1", "0"], "shuf_sents": ["We evaluate sparse filtering on natural images , object classification ( STL-10 ) , and phone classification ( TIMIT ) , and show that our method works well on a range of different modalities .", "Sparse filtering scales gracefully to handle high-dimensional inputs , and can also be used to learn meaningful features in additional layers with greedy layer-wise stacking .", "However , many existing feature learning algorithms are hard to use and require extensive hyperparameter tuning .", "Unsupervised feature learning has been shown to be effective at learning representations that perform well on image , video and audio classification .", "In contrast to most other feature learning methods , sparse filtering does not explicitly attempt to construct a model of the data distribution .", "Instead , it optimizes a simple cost function - the sparsity of 2 -normalized features - which can easily be implemented in a few lines of MATLAB code .", "In this work , we present sparse filtering , a simple new algorithm which is efficient and only has one hyperparameter , the number of features to learn ."]}
{"orig_sents": ["2", "1", "0", "5", "4", "3"], "shuf_sents": ["In contrast , herein sparse estimation is considered in the context of structured dictionaries possibly exhibiting high coherence between arbitrary groups of columns and/or rows .", "But in reality , these types of dictionaries represent only a subset of the dictionaries that are actually used in practice ( largely restricted to idealized compressive sensing applications ) .", "In the vast majority of recent work on sparse estimation algorithms , performance has been evaluated using ideal or quasi-ideal dictionaries ( e.g. , random Gaussian or Fourier ) characterized by unit 2 norm , incoherent columns or features .", "This can translate into improved performance in applications such as model selection with correlated features , source localization , and compressive sensing with constrained measurement directions .", "In particular , a Type II Bayesian estimator with a dictionarydependent sparsity penalty is shown to have a number of desirable invariance properties leading to provable advantages over more conventional penalties such as the 1 norm , especially in areas where existing theoretical recovery guarantees no longer hold .", "Sparse penalized regression models are analyzed with the purpose of finding , to the extent possible , regimes of dictionary invariant performance ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["Our experiments using facial images , texture patches , and images of object categories suggest that the approach can improve our ability to recover meaningful structure in many classes of signals .", "We derive solutions to the problem , present nonlinear extensions , and discuss relations to compressed sensing .", "We formulate an optimization problem for learning a linear projection from the original signal domain to a lower-dimensional one in a way that approximately preserves , in expectation , pairwise inner products in the sparse domain .", "We propose an approach for linear unsupervised dimensionality reduction , based on the sparse linear model that has been used to probabilistically interpret sparse coding ."]}
{"orig_sents": ["3", "5", "4", "1", "6", "2", "0"], "shuf_sents": ["These results illustrate how Sparse PCA can help organize a large corpus of text data in a user-interpretable way , providing an attractive alternative approach to topic models .", "This comes from a rigorous feature elimination pre-processing result , coupled with the favorable fact that features in real-life data typically have exponentially decreasing variances , which allows for many features to be eliminated .", "We provide experimental results obtained on text corpora involving millions of documents and hundreds of thousands of features .", "Sparse PCA provides a linear combination of small number of features that maximizes variance across data .", "In this paper , we demonstrate the surprising fact that sparse PCA can be easier than PCA in practice , and that it can be reliably applied to very large data sets .", "Although Sparse PCA has apparent advantages compared to PCA , such as better interpretability , it is generally thought to be computationally much more expensive .", "We introduce a fast block coordinate ascent algorithm with much better computational complexity than the existing first-order ones ."]}
{"orig_sents": ["4", "1", "5", "3", "2", "0", "6"], "shuf_sents": ["We also develop a multiple-object detection variation of the system , where hypotheses for 20 categories are inserted in a common priority queue .", "Instead of evaluating the classifier score exhaustively over image locations and scales , we use BB to focus on promising image locations .", "We obtain exactly the same results but are 10-20 times faster on average .", "We evaluate our approach using Mixture-of-Deformable Part Models .", "In this work we use Branch-and-Bound ( BB ) to efficiently detect objects with deformable part models .", "The core problem is to compute bounds that accommodate part deformations ; for this we adapt the Dual Trees data structure to our problem .", "For the problem of finding the strongest category in an image this results in a 100-fold speedup ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["We show empirically that the resulting algorithm consistently outperforms the traditional rejection mechanism based on distance from decision boundary .", "For a learning problem whose associated excess loss class is ( , B ) -Bernstein , we show that it is theoretically possible to track the same classification performance of the best ( unknown ) hypothesis in our class , provided that we are free to abstain from prediction in some region of our choice .", "The strategy achieving this performance has computational barriers because it requires empirical error minimization in an agnostic setting .", "The ( probabilistic ) volume of this rejected region of the domain is shown to be diminishing at rate O ( B ( 1/m ) ) , where is Hanneke 's disagreement coefficient .", "Nevertheless , we heuristically approximate this strategy and develop a novel selective classification algorithm using constrained SVMs ."]}
{"orig_sents": ["6", "1", "5", "4", "2", "0", "3"], "shuf_sents": ["This active classification process is applied at test time for each individual test instance , resulting in an efficient instance-specific decision path .", "Many of these tasks are tackled by constructing a set of classifiers , which are then applied at test time and then pieced together in a fixed procedure determined in advance or at training time .", "The expected classification gain is computed using a probabilistic model that uses the outcome from previous observations .", "We demonstrate the benefit of the active scheme on various real-world datasets , and show that it can achieve comparable or even higher classification accuracy at a fraction of the computational costs of traditional methods .", "Observations are then selected dynamically based on previous observations , using a value-theoretic computation that balances an estimate of the expected classification gain from each observation as well as its computational cost .", "We present an active classification process at the test time , where each classifier in a large ensemble is viewed as a potential observation that might inform our classification process .", "Modern classification tasks usually involve many class labels and can be informed by a broad range of features ."]}
{"orig_sents": ["4", "0", "3", "5", "2", "1"], "shuf_sents": ["It is inspired by the Translation-invariant Wishart-Dirichlet process ( TIWD ) in and shares a number of advantageous properties like the fully probabilistic nature of the inference model , automatic selection of the number of clusters and applicability in semi-supervised settings .", "With this new method it is now possible to `mine ' large relational datasets with a probabilistic model , thereby automatically detecting new and potentially interesting clusters .", "Our experiments show that the cost reduction does not compromise the quality of the inferred partitions .", "In addition , our method ( which we call fastTIWD ) overcomes the main shortcoming of the original TIWD , namely its high computational costs .", "A Bayesian approach to partitioning distance matrices is presented .", "The fastTIWD reduces the workload in each iteration of a Gibbs sampler from O ( n3 ) in the TIWD to O ( n2 ) ."]}
{"orig_sents": ["1", "4", "0", "3", "2"], "shuf_sents": ["We additionally improve upon previous results for k-way spectral clustering to derive conditions under which spectral clustering makes no mistakes .", "Although spectral clustering has enjoyed considerable empirical success in machine learning , its theoretical properties are not yet fully developed .", "We also present experiments on simulated and real world data illustrating our results .", "Further , using minimax analysis , we derive tight upper and lower bounds for the clustering problem and compare the performance of spectral clustering to these information theoretic limits .", "We analyze the performance of a spectral algorithm for hierarchical clustering and show that on a class of hierarchically structured similarity matrices , this algorithm can tolerate noise that grows with the number of data points while still perfectly recovering the hierarchical clusters with high probability ."]}
{"orig_sents": ["2", "1", "3", "0", "4"], "shuf_sents": ["Finally , it is established that any instance can be decomposed into two smaller instances resembling the two preceding special cases , yielding a rate O ( 1/ ) , with a matching lower bound for the logistic loss .", "First , it is established that the setting of weak learnability aids the entire class , granting a rate O ( ln ( 1/ ) ) .", "This manuscript considers the convergence rate of boosting under a large class of losses , including the exponential and logistic losses , where the best previous rate of convergence was O ( exp ( 1/2 ) ) .", "Next , the ( disjoint ) conditions under which the infimal empirical risk is attainable are characterized in terms of the sample and weak learning class , and a new proof is given for the known rate O ( ln ( 1/ ) ) .", "The principal technical hurdle throughout this work is the potential unattainability of the infimal empirical risk ; the technique for overcoming this barrier may be of general interest ."]}
{"orig_sents": ["2", "1", "5", "0", "4", "3"], "shuf_sents": ["In this paper , we prove that the global solution under matrix-wise independence is actually column-wise independent , implying that the column-wise independence assumption is harmless .", "A recent study on fully-observed VBMF showed that , under a stronger assumption that the two factorized matrices are column-wise independent , the global optimal solution can be analytically computed .", "Variational Bayesian matrix factorization ( VBMF ) efficiently approximates the posterior distribution of factorized matrices by assuming matrix-wise independence of the two factors .", "We experimentally illustrate advantages of using our analytic solution in probabilistic principal component analysis .", "A practical consequence of our theoretical finding is that the global solution under matrix-wise independence ( which is a standard setup ) can be obtained analytically in a computationally very efficient way without any iterative algorithms .", "However , it was not clear how restrictive the column-wise independence assumption is ."]}
{"orig_sents": ["3", "0", "4", "1", "5", "2"], "shuf_sents": ["The solutions of these are subsequently combined with message passing algorithms .", "To develop these methods , we introduce a notion of coupling between variables of optimization .", "Despite its generality , this notion of coupling is easier to verify empirically , making structure estimation easy , while allowing us to migrate well-established inference methods on graphical models to the setting of global optimization .", "We describe a family of global optimization procedures that automatically decompose optimization problems into smaller loosely coupled problems .", "We show empirically that these methods produce better solutions with fewer function evaluations than existing global optimization methods .", "This notion of coupling generalizes the notion of independence between random variables in statistics , sparseness of the Hessian in nonlinear optimization , and the generalized distributive law ."]}
{"orig_sents": ["8", "5", "2", "7", "4", "3", "0", "1", "6"], "shuf_sents": ["In numerical experiments on artificial data and image patches , we compare the performance of the algorithms to that of exact EM , variational state space selection alone , MCMC alone , and the combined select and sample approach .", "The select and sample approach integrates the advantages of the sampling and variational approximations , and forms a robust , neurally plausible , and very efficient model of processing and learning in cortical networks .", "Two influential proposals of efficient posterior representation by neural populations are : 1 ) neural activity represents samples of the underlying distribution , or 2 ) they represent a parametric representation of a variational approximation of the posterior .", "We demonstrate the effectiveness and efficiency of this approach on a sparse coding model .", "Neurally , the combined method can be interpreted as a feed-forward preselection of the relevant state space , followed by a neural dynamics implementation of Markov Chain Monte Carlo ( MCMC ) to approximate the posterior over the relevant states .", "One outstanding difficulty with this hypothesis is that the exact posterior will in general be too complex to be represented directly , and thus neurons will have to represent an approximation of this distribution .", "For sparse coding we show applications easily exceeding a thousand observed and a thousand hidden dimensions .", "We show that these approaches can be combined for an inference scheme that retains the advantages of both : it is able to represent multiple modes and arbitrary correlations , a feature of sampling methods , and it reduces the represented space to regions of high probability mass , a strength of variational approximations .", "An increasing number of experimental studies indicate that perception encodes a posterior probability distribution over possible causes of sensory stimuli , which is used to act close to optimally in the environment ."]}
{"orig_sents": ["6", "5", "3", "1", "4", "2", "0"], "shuf_sents": ["Experimental results on a subset of ImageNet containing 1.2 million images from 1000 categories demonstrate the effectiveness and promise of our proposed approach .", "In this paper , we employ such semantic relatedness among image categories for large-scale image categorization .", "An efficient optimization method based on proximal approximation and accelerated parallel gradient method is introduced .", "As human cognition of complex visual world benefits from underlying semantic relationships between object classes , we believe a machine learning system can and should leverage such information as well for better performance .", "Specifically , a category hierarchy is utilized to properly define loss function and select common set of features for related categories .", "With the emergence of structured large-scale dataset such as the ImageNet , rich information about the conceptual relationships between images , such as a tree hierarchy among various image categories , become available .", "Most previous research on image categorization has focused on medium-scale data sets , while large-scale image categorization with millions of images from thousands of categories remains a challenge ."]}
{"orig_sents": ["0", "5", "4", "3", "2", "1"], "shuf_sents": ["We are motivated by an application to extract a representative subset of machine learning training data and by the poor empirical performance we observe of the popular minimum norm algorithm .", "We show theoretical properties , and empirical results suggest significant speedups over minimum norm while retaining higher accuracies .", "Other submodular functions are iteratively approximated by tight submodular upper bounds , and then repeatedly optimized .", "For a large sub-class of submodular functions , the algorithm is exact .", "We therefore propose a fast approximate method to minimize arbitrary submodular functions .", "In fact , for our application , minimum norm can have a running time of about O ( n7 ) ( O ( n5 ) oracle calls ) ."]}
{"orig_sents": ["3", "2", "5", "4", "1", "0"], "shuf_sents": ["We report numerical experiments illustrating our method .", "The method uses a set of sampling points uniformly distributed along a one-dimensional curve selected according to the features .", "the number of non-zero entries of is small compared to the number K of features ) given noisy evaluations of f at a set of well-chosen sampling points .", "We consider the problem of recovering the parameter RK of a sparse function f ( i.e .", "Under the assumption that f is Holder continuous with exponent at least 1/2 , we provide an estimate of the parameter such that - 2 = O ( 2 / N ) , where is the observation noise .", "We introduce an additional randomization process , called Brownian sensing , based on the computation of stochastic integrals , which produces a Gaussian sensing matrix , for which good recovery properties are proven , independently on the number of sampling points N , even when the features are arbitrarily non-orthogonal ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We investigate the representational power of sum-product networks ( computation networks analogous to neural networks , but whose individual units compute either products or weighted sums ) , through a theoretical analysis that compares deep ( multiple hidden layers ) vs. shallow ( one hidden layer ) architectures .", "with substantially fewer hidden units .", "Such results were not available until now , and contribute to motivate recent research involving learning of deep sum-product networks , and more generally motivate research in Deep Learning .", "We prove there exist families of functions that can be represented much more efficiently with a deep network than with a shallow one , i.e ."]}
{"orig_sents": ["6", "7", "4", "3", "5", "1", "2", "0"], "shuf_sents": ["In contrast to AIS , our method provides this estimate at each time-step , at a computational cost similar to that required for training alone .", "Learning MRFs through Tempered Stochastic Maximum Likelihood , we can estimate Z using no more temperatures than are required for learning .", "Comparing to both exact values and estimates using annealed importance sampling ( AIS ) , we show on several datasets that our method is able to accurately track the log partition function .", "Our method relies on two distinct sources of information : ( 1 ) estimating the change Z incurred by each gradient update , ( 2 ) estimating the difference in Z over a small set of tempered distributions using bridge sampling .", "In this paper , we exploit the gradient descent training procedure of restricted Boltzmann machines ( a type of MRF ) to track the log partition function during learning .", "The two sources of information are then combined using an inference procedure similar to Kalman filtering .", "Markov Random Fields ( MRFs ) have proven very powerful both as density estimators and feature extractors for classification .", "However , their use is often limited by an inability to estimate the partition function Z ."]}
{"orig_sents": ["1", "4", "0", "3", "2"], "shuf_sents": ["In this paper , we present an efficient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities .", "A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data .", "We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art .", "Furthermore , we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning .", "Existing approaches however , are either too simplistic ( linear ) , too complex to learn , or can only learn latent spaces from `` simple data '' , i.e. , single activities such as walking or running ."]}
{"orig_sents": ["2", "5", "4", "3", "6", "1", "0"], "shuf_sents": ["We provide experimental results on the nearest and the farthest neighbor searches .", "The MS-distance can be used to various applications where the Euclidean distance is used to measure the proximity or similarity between objects .", "Given a set V of n vectors in d-dimensional space , we provide an efficient method for computing quality upper and lower bounds of the Euclidean distances between a pair of vectors in V .", "Furthermore , these bounds can be refined further in such a way to converge monotonically to the exact Euclidean distance within d refinement steps .", "Once we compute the mean and the standard deviation values of vectors in V in O ( dn ) time , the MS-distance provides upper and lower bounds of Euclidean distance between any pair of vectors in V in constant time .", "For this purpose , we define a distance measure , called the MS-distance , by using the mean and the standard deviation values of vectors in V .", "An analysis on a random sequence of refinement steps shows that the MS-distance provides very tight bounds in only a few refinement steps ."]}
{"orig_sents": ["2", "5", "4", "3", "0", "1"], "shuf_sents": ["When an ambiguous image could be assigned to two conflicting reference frames , the model predicts two factors should influence the reference frame inferred for the image : The image should be more likely to share the reference frame of the closer object ( proximity ) and it should be more likely to share the reference frame containing the most objects ( alignment ) .", "We confirm people use both cues using a novel methodology that allows for easy testing of human reference frame inference .", "The object people perceive in an image can depend on its orientation relative to the scene it is in ( its reference frame ) .", "We propose an ideal observer model based on nonparametric Bayesian statistics for inferring the number of reference frames in a scene and their parameters .", "Although real scenes have multiple images and reference frames , psychologists have focused on scenes with only one reference frame .", "For example , the images of the symbols x and + differ by a 45 degree rotation ."]}
{"orig_sents": ["3", "2", "4", "6", "1", "5", "0"], "shuf_sents": ["These results help to understand the relationship between the different approaches to stochastic neuron models .", "We find a mathematical expression for this link-function and test the ability of the GLM to predict the firing probability of a neuron receiving complex stimulation .", "We use analytical and numerical methods to relate state-of-theart models from both schools of thought .", "Variability in single neuron models is typically implemented either by a stochastic Leaky-Integrate-and-Fire model or by a model of the Generalized Linear Model ( GLM ) family .", "First we find the analytical expressions relating the subthreshold voltage from the Adaptive Exponential Integrate-andFire model ( AdEx ) to the Spike-Response Model with escape noise ( SRM as an example of a GLM ) .", "Comparing the prediction performance of various link-functions , we find that a GLM with an exponential link-function provides an excellent approximation to the Adaptive Exponential Integrate-and-Fire with colored-noise input .", "Then we calculate numerically the link-function that provides the firing probability given a deterministic membrane potential ."]}
{"orig_sents": ["1", "0", "2", "9", "3", "5", "8", "7", "6", "4"], "shuf_sents": ["Previous approaches are not highthroughput , are not generalizable or scalable , or lack sufficient data to be effective .", "Being able to predict the course of arbitrary chemical reactions is essential to the theory and applications of organic chemistry .", "We describe single mechanistic reactions as concerted electron movements from an electron orbital source to an electron orbital sink .", "We then pose identifying productive mechanistic steps as a ranking problem : rank potential orbital interactions such that the top ranked interactions yield the major products .", "Furthermore , it is generalizable , making reasonable predictions over reactants and conditions which the rule-based expert system does not handle .", "The machine learning implementation follows a two-stage approach , in which we first train atom level reactivity filters to prune 94.0 % of non-productive reactions with less than a 0.1 % false negative rate .", "The final system allows multi-step reaction prediction .", "Without the use of explicit transformation patterns , the ensemble perfectly ranks the productive mechanisms at the top 89.1 % of the time , rising to 99.9 % of the time when top ranked lists with at most four nonproductive reactions are considered .", "Then , we train an ensemble of ranking models on pairs of interacting orbitals to learn a relative productivity function over single mechanistic reactions in a given system .", "We use an existing rule-based expert system to derive a dataset consisting of 2,989 productive mechanistic steps and 6.14 million non-productive mechanistic steps ."]}
{"orig_sents": ["1", "0", "3", "5", "2", "4", "6", "7"], "shuf_sents": ["However , maximum entropy models fit to small data sets can be subject to sampling bias ; i.e .", "Maximum entropy models have become popular statistical models in neuroscience and other areas in biology , and can be useful tools for obtaining estimates of mutual information in biological systems .", "We show that if the data is generated by a distribution that lies in the model class , the bias is equal to the number of parameters divided by twice the number of observations .", "the true entropy of the data can be severely underestimated .", "However , in practice , the true distribution is usually outside the model class , and we show here that this misspecification can lead to much larger bias .", "Here we study the sampling properties of estimates of the entropy obtained from maximum entropy models .", "We provide a perturbative approximation of the maximally expected bias when the true model is out of model class , and we illustrate our results using numerical simulations of an Ising model ; i.e .", "the second-order maximum entropy distribution on binary data ."]}
{"orig_sents": ["1", "2", "3", "6", "5", "0", "4"], "shuf_sents": ["We develop a novel and efficient MCMC sampler for posterior inference .", "Renewal processes are generalizations of the Poisson process on the real line whose intervals are drawn i.i.d .", "from some distribution .", "Modulated renewal processes allow these interevent distributions to vary with time , allowing the introduction of nonstationarity .", "In our experiments , we test these on a number of synthetic and real datasets .", "Our approach is based on the idea of uniformization , which allows us to draw exact samples from an otherwise intractable distribution .", "In this work , we take a nonparametric Bayesian approach , modelling this nonstationarity with a Gaussian process ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We present an optimization approach for linear SVMs based on a stochastic primal-dual approach , where the primal step is akin to an importance-weighted SGD , and the dual step is a stochastic update on the importance weights .", "This yields an optimization method with a sublinear dependence on the training set size , and the first method for learning linear SVMs with runtime less then the size of the training set required for learning !"]}
{"orig_sents": ["3", "4", "0", "2", "1"], "shuf_sents": ["Often these different views admit same underlying clustering of the data , so we can approach this problem by looking for clusterings that are consistent across the views , i.e. , corresponding data points in each view should have same cluster membership .", "Experimental comparisons with a number of baselines on two synthetic and three real-world datasets establish the efficacy of our proposed approaches .", "We propose a spectral clustering framework that achieves this goal by co-regularizing the clustering hypotheses , and propose two co-regularization schemes to accomplish this .", "In many clustering problems , we have access to multiple views of the data each of which could be individually used for clustering .", "Exploiting information from multiple views , one can hope to find a clustering that is more accurate than the ones obtained using the individual views ."]}
{"orig_sents": ["1", "2", "4", "5", "3", "0"], "shuf_sents": ["On unsupervised image segmentation , we demonstrate that similar performance to existing nonparametric Bayesian models is possible with substantially simpler models and algorithms .", "The distance dependent Chinese restaurant process ( ddCRP ) was recently introduced to accommodate random partitions of non-exchangeable data .", "The ddCRP clusters data in a biased way : each data point is more likely to be clustered with other data that are near it in an external sense .", "We then study the sensitivity of the models to various distance and appearance hyperparameters , and provide the first rigorous comparison of nonparametric Bayesian models in the image segmentation domain .", "This paper examines the ddCRP in a spatial setting with the goal of natural image segmentation .", "We explore the biases of the spatial ddCRP model and propose a novel hierarchical extension better suited for producing `` human-like '' segmentations ."]}
{"orig_sents": ["4", "1", "0", "5", "2", "3"], "shuf_sents": ["Our algorithm is based on recent theoretical results , with significant improvements to make it practical .", "We consider the k-means problem in the situation where the data is too large to be stored in main memory and must be accessed sequentially , such as from a disk , and where we must use as little memory as possible .", "We then incorporate approximate nearest neighbor search to compute k-means in o ( nk ) ( where n is the number of data points ; note that computing the cost , given a solution , takes 8 ( nk ) time ) .", "We show that our algorithm compares favorably to existing algorithms - both theoretically and experimentally , thus providing state-of-the-art performance in both theory and practice .", "Clustering is a popular problem with many applications .", "Our approach greatly simplifies a recently developed algorithm , both in design and in analysis , and eliminates large constant factors in the approximation guarantee , the memory requirements , and the running time ."]}
{"orig_sents": ["5", "1", "7", "4", "0", "2", "6", "3"], "shuf_sents": ["More precisely , we prove that a weighted set of O ( dk3 /2 ) data points suffices for computing a ( 1 + ) -approximation for the optimal model on the original n data points .", "In this paper , we show how to construct coresets for mixtures of Gaussians and natural generalizations .", "Moreover , such coresets can be efficiently constructed in a map-reduce style computation , as well as in a streaming setting .", "We empirically evaluate our algorithms on several real data sets , including a density estimation problem in the context of earthquake detection using accelerometers in mobile phones .", "We show that , perhaps surprisingly , Gaussian mixtures admit coresets of size independent of the size of the data set .", "How can we train a statistical mixture model on a massive data set ?", "Our results rely on a novel reduction of statistical estimation to problems in computational geometry , as well as new complexity results about mixtures of Gaussians .", "A coreset is a weighted subset of the data , which guarantees that models fitting the coreset will also provide a good fit for the original data set ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["Using a normative model of autoassociative memory , we show that a dual memory system , consisting of two interacting modules for familiarity and recollection , has best performance for both recollection and recognition .", "Knowing the age of a pattern thus becomes critical for recalling it faithfully .", "This finding provides a new window onto actively contentious psychological and neural aspects of recognition memory .", "This implies that there should be a tight coupling between estimates of age , as a form of familiarity , and the neural dynamics of recollection , something which current theories omit .", "Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["We particularly focus on developing infinite latent support vector machines ( iLSVM ) and multi-task infinite latent support vector machines ( MT-iLSVM ) , which explore the largemargin idea in combination with a nonparametric Bayesian model for discovering predictive latent features for classification and multi-task learning , respectively .", "We present efficient inference methods and report empirical studies on several benchmark datasets .", "Our results appear to demonstrate the merits inherited from both large-margin learning and Bayesian nonparametrics .", "Unlike existing nonparametric Bayesian models , which rely solely on specially conceived priors to incorporate domain knowledge for discovering improved latent representations , we study nonparametric Bayesian inference with regularization on the desired posterior distributions .", "While priors can indirectly affect posterior distributions through Bayes ' theorem , imposing posterior regularization is arguably more direct and in some cases can be much easier ."]}
{"orig_sents": ["0", "2", "1", "4", "3", "5"], "shuf_sents": ["We consider an adversarial online learning setting where a decision maker can choose an action in every stage of the game .", "The observation structure is encoded as a graph , where node i is linked to node j if sampling i provides information on the reward of j .", "In addition to observing the reward of the chosen action , the decision maker gets side observations on the reward he would have obtained had he chosen some of the other actions .", "We develop practical algorithms with provable regret guarantees , which depend on non-trivial graph-theoretic properties of the information feedback structure .", "This setting naturally interpolates between the well-known `` experts '' setting , where the decision maker can view all rewards , and the multi-armed bandits setting , where the decision maker can only view the reward of the chosen action .", "We also provide partially-matching lower bounds ."]}
{"orig_sents": ["5", "1", "2", "0", "3", "4"], "shuf_sents": ["We provide a general framework for creating static experts , an approach that generalizes some previous strategy stitching efforts .", "Typically , strategies from abstract games perform better in the real game as the granularity of abstraction is increased .", "This paper investigates two techniques for stitching a base strategy in a coarse abstraction of the full game tree , to expert strategies in fine abstractions of smaller subtrees .", "In addition , we show that static experts can create strong agents for both 2-player and 3-player Leduc and Limit Texas Hold'em poker , and that a specific class of static experts can be preferred among a number of alternatives .", "Furthermore , we describe a poker agent that used static experts and won the 3-player events of the 2010 Annual Computer Poker Competition .", "Computing a good strategy in a large extensive form game often demands an extraordinary amount of computer memory , necessitating the use of abstraction to reduce the game size ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["It shares the desirable properties of RBMs : efficient exact inference , an exponentially more expressive latent state than HMMs , and the ability to model nonlinear structure and dynamics .", "We present a type of Temporal Restricted Boltzmann Machine that defines a probability distribution over an output sequence conditional on an input sequence .", "Our results demonstrate improved performance over several baselines modeling high-dimensional 2D and 3D data .", "We apply our model to a challenging real-world graphics problem : facial expression transfer ."]}
{"orig_sents": ["5", "1", "8", "4", "3", "2", "7", "6", "0"], "shuf_sents": ["We demonstrate significant objective improvements in the quality of the recovered impressions .", "Instead of using an absolute scale , individuals rely on reference points from recent experience .", "In our formulation , the problem is to infer latent ( subjective ) impressions from a sequence of stimulus labels ( e.g. , movie names ) and responses .", "We explore techniques to remove sequential dependencies , and thereby decontaminate a series of ratings to obtain more meaningful human judgments .", "Fortunately , the cognitive processes that map stimuli to responses are not simply noisy , but rather are influenced by recent experience in a lawful manner .", "Psychologists have long been struck by individuals ' limitations in expressing their internal sensations , impressions , and evaluations via rating scales .", "We test our iterated impression inference , or I3 , algorithm in three domains : rating the gap between dots , the desirability of a movie based on an advertisement , and the morality of an action .", "We describe an unsupervised approach that simultaneously recovers the impressions and parameters of a contamination model that predicts how recent judgments affect the current response .", "This relativity of judgment limits the informativeness of responses on surveys , questionnaires , and evaluation forms ."]}
{"orig_sents": ["6", "3", "2", "5", "4", "0", "1", "7"], "shuf_sents": ["Under some transparent assumptions , we establish that the proposed algorithm is -4 structurally consistent ( or sparsistent ) when the number of samples scales as n = ( Jmin log p ) , where p is the number of nodes and Jmin is the minimum edge potential .", "We also develop novel non-asymptotic techniques for obtaining necessary conditions for graphical model selection .", "We propose an efficient threshold-based algorithm for structure estimation based on conditional mutual information thresholding .", "samples from the model .", "We identify graph families for which the proposed algorithm has low sample and computational complexities .", "This simple local algorithm requires only loworder statistics of the data and decides whether two nodes are neighbors in the unknown graph .", "We consider the problem of Ising and Gaussian graphical model selection given n i.i.d .", "Keywords : Graphical model selection , high-dimensional learning , local-separation property , necessary conditions , typical sets , Fano 's inequality ."]}
{"orig_sents": ["3", "1", "4", "0", "5", "2"], "shuf_sents": ["The Gaussian form of this asymptotic sufficient statistic allows us in certain cases to perform optimal Bayesian decoding by simple linear transformations , and to obtain closed-form expressions of the Shannon information carried by the network .", "In this paper , we apply methods from the asymptotic theory of statistical inference to obtain a clearer analytical understanding of these quantities .", "We argue that our findings help to clarify some results from the recent literature on neural decoding and neuroprosthetic design .", "Many fundamental questions in theoretical neuroscience involve optimal decoding and the computation of Shannon information rates in populations of spiking neurons .", "We find that for large neural populations carrying a finite total amount of information , the full spiking population response is asymptotically as informative as a single observation from a Gaussian process whose mean and covariance can be characterized explicitly in terms of network and single neuron properties .", "One technical advantage of the theory is that it may be applied easily even to non-Poisson point process network models ; for example , we find that under some conditions , neural populations with strong history-dependent ( non-Poisson ) effects carry exactly the same information as do simpler equivalent populations of non-interacting Poisson neurons with matched firing rates ."]}
{"orig_sents": ["4", "3", "1", "2", "0"], "shuf_sents": ["Our data support the inverse decision-making approach to preference learning .", "Existing data sets , however , do not provide sufficient resolution to thoroughly evaluate this approach .", "We introduce a new preference learning task that provides a benchmark for evaluating computational accounts and use it to compare the inverse decision-making approach to a feature-based approach , which relies on a discriminative combination of decision features .", "The inverse decision-making approach proposes that people infer preferences by inverting a generative model of decision-making .", "Psychologists have recently begun to develop computational accounts of how people infer others ' preferences from their behavior ."]}
{"orig_sents": ["6", "5", "1", "4", "0", "3", "2"], "shuf_sents": ["To the best of our knowledge , this is the first algorithm that guarantees the consistency between target neighbors and the feature space metric .", "This issue , called the target neighbor change , was not properly addressed in the existing feature weighting and metric learning literature .", "We demonstrate the effectiveness of the proposed algorithm through experiments .", "We further show that the proposed algorithm can be naturally combined with regularization path tracking , allowing computationally efficient selection of the regularization parameter .", "In this paper , we propose a novel feature weighting algorithm that can exactly and efficiently keep track of the correct target neighbors via sequential quadratic programming .", "A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process .", "We consider feature selection and weighting for nearest neighbor classifiers ."]}
{"orig_sents": ["0", "1", "2", "5", "3", "4"], "shuf_sents": ["Probabilistic logics are receiving a lot of attention today because of their expressive power for knowledge representation and learning .", "However , this expressivity is detrimental to the tractability of inference , when done at the propositional level .", "To solve this problem , various lifted inference algorithms have been proposed that reason at the first-order level , about groups of objects as a whole .", "The key contribution of this paper is that we introduce a formal definition of lifted inference that allows us to reason about the completeness of lifted inference algorithms relative to a particular class of probabilistic models .", "We then show how to obtain a completeness result using a first-order knowledge compilation approach for theories of formulae containing up to two logical variables .", "Despite the existence of various lifted inference approaches , there are currently no completeness results about these algorithms ."]}
{"orig_sents": ["6", "4", "5", "2", "3", "8", "1", "7", "0"], "shuf_sents": ["We believe that the simplicity and practicality of our algorithm will help to promote skeleton graphs as a data analysis tool for a broad range of applications .", "We also give theoretical results to justify our method .", "In this paper , we develop a framework to extract , as well as to simplify , a one-dimensional `` skeleton '' from unorganized data using the Reeb graph .", "Our algorithm is very simple , does not require complex optimizations and can be easily applied to unorganized high-dimensional data such as point clouds or proximity graphs .", "While such data is often high-dimensional , it is of interest to approximate it with a lowdimensional or even one-dimensional space , since many important aspects of data are often intrinsically low-dimensional .", "Furthermore , there are many scenarios where the underlying structure is graph-like , e.g , river/road networks or various trajectories .", "Recovering hidden structure from complex and noisy non-linear data is one of the most fundamental problems in machine learning and statistical inference .", "We provide a number of experiments to demonstrate the effectiveness and generality of our algorithm , including comparisons to existing methods , such as principal curves .", "It can also represent arbitrary graph structures in the data ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["The proposed approach allows the release of a wide class of M-estimators with both differential privacy and statistical utility without knowing a priori the particular inference procedure .", "A practical algorithm is given and applied on a real world data set containing both continuous and categorical variables .", "The performance of the proposed method is demonstrated through a careful study of the convergence rates .", "This paper studies privacy preserving M-estimators using perturbed histograms ."]}
{"orig_sents": ["10", "6", "9", "2", "8", "1", "3", "7", "5", "4", "0"], "shuf_sents": ["So these matrix algorithms learn the eigenvectors without any regret .", "We show how popular online algorithms for learning a multinomial distribution can be extended to learn density matrices .", "Whereas in the classical case the goal is to learn ( i.e .", "Intuitively , learning the n2 parameters of a density matrix is much harder than learning the n parameters of a multinomial distribution .", "the worst case regret is achieved in the classical case .", "The reason is that the worst-case sequence of dyads share a common eigensystem , i.e .", "In this extension , the alphabet of n outcomes is replaced by the set of all dyads , i.e .", "Completely surprisingly , we prove that the worst-case regrets of certain classical algorithms and their matrix generalizations are identical .", "sequentially predict as well as ) the best multinomial distribution , in the matrix case we desire to learn the density matrix that best explains the observed sequence of dyads .", "outer products uu where u is a vector in Rn of unit length .", "We extend the classical problem of predicting a sequence of outcomes from a finite alphabet to the matrix domain ."]}
{"orig_sents": ["6", "3", "4", "1", "0", "7", "5", "2"], "shuf_sents": ["To overcome this limitation , we present a novel hybrid model , EigenNet , that uses the eigenstructures of data to guide variable selection .", "Despite its great success , the elastic net does not exploit the correlation information embedded in the data to select correlated variables .", "Experimental results on synthetic data and imaging genetics data demonstrate the superior predictive performance of the EigenNet over the lasso , the elastic net , and the automatic relevance determination .", "The correlation between variables presents a challenge to classical variable selection methods .", "To address this challenge , the elastic net has been developed and successfully applied to many applications .", "We develop an efficient active-set algorithm to estimate the model via evidence maximization .", "For many real-world applications , we often need to select correlated variables -- such as genetic variations and imaging features associated with Alzheimer 's disease -- in a high dimensional space .", "Specifically , it integrates a sparse conditional classification model with a generative model capturing variable correlations in a principled Bayesian framework ."]}
{"orig_sents": ["2", "5", "1", "0", "3", "4"], "shuf_sents": ["What can we conclude about the properties of the tree we observe from these revealed paths , and can we use the structure of the observed tree to estimate the size of the full unobserved tree T ?", "In the case of a petition , the list of names on each public copy of the petition also reveals a path leading back to the root of the tree .", "Motivated by the spread of on-line information in general and on-line petitions in particular , recent research has raised the following combinatorial estimation problem .", "Here we provide the first algorithm for this size estimation task , together with provable guarantees on its performance .", "We also establish structural properties of the observed tree , providing the first rigorous explanation for some of the unusual structural phenomena present in the spread of real chain-letter petitions on the Internet .", "There is a tree T that we can not observe directly ( representing the structure along which the information has spread ) , and certain nodes randomly decide to make their copy of the information public ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["In this way we can specify the number of hidden units that guarantees a sufficiently rich model containing different classes of distributions and respecting a given error tolerance .", "We present explicit classes of probability distributions that can be learned by Restricted Boltzmann Machines ( RBMs ) depending on the number of units that they contain , and which are representative for the expressive power of the model .", "We use this to show that the maximal Kullback-Leibler divergence to the RBM model with n visible and m hidden units is bounded from above by ( n-1 ) -log ( m+1 ) ."]}
{"orig_sents": ["2", "6", "0", "5", "1", "3", "7", "4"], "shuf_sents": ["The main problem we study is how to search the database for the nearest neighbor ( NN ) of a query , while minimizing the questions .", "We show the importance of a characterization : combinatorial disorder D which defines approximate triangle n inequalities on ranks .", "This paper addresses the problem of finding the nearest neighbor ( or one of the R-nearest neighbors ) of a query object q in a database of n objects , when we can only use a comparison oracle .", "We present a lower bound of ( D log D + D2 ) average number of questions in the search phase for any randomized algorithm , which demonstrates the fundamental role of D for worst case behavior .", "The learning requires asking O ( nD3 log2 n + D log2 n log log nD ) questions and O ( n log2 n/ log ( 2D ) ) bits to store .", "The difficulty of this problem depends on properties of the underlying database .", "The comparison oracle , given two reference objects and a query object , returns the reference object most similar to the query object .", "We develop 3 a randomized scheme for NN retrieval in O ( D3 log2 n + D log2 n log log nD ) 3 questions ."]}
{"orig_sents": ["5", "2", "4", "0", "1", "3"], "shuf_sents": ["The approach draws heavily from the concept of a prediction market , where traders bet on the likelihood of a future event .", "In our framework , the mechanism continues to publish the current hypothesis , and participants can modify this hypothesis by wagering on an update .", "But these competitions have a number of weaknesses , particularly in the incentive structure they create for the participants .", "The critical incentive property is that a participant will profit an amount that scales according to how much her update improves performance on a released test set .", "We propose a new approach , called a Crowdsourced Learning Mechanism , in which participants collaboratively `` learn '' a hypothesis for a given prediction task .", "Machine Learning competitions such as the Netflix Prize have proven reasonably successful as a method of `` crowdsourcing '' prediction tasks ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["Furthermore , we derive an approximate online learning rule and show that our learning rule is consistent with Spike-Timing Dependent Plasticity in that if a presynaptic spike shortly precedes a postynaptic spike , potentiation is induced and otherwise depression is elicited .", "We consider a statistical framework in which recurrent networks of spiking neurons learn to generate spatio-temporal spike patterns .", "We show that learning synaptic weights towards hidden neurons significantly improves the storing capacity of the network .", "Given biologically realistic stochastic neuronal dynamics we derive a tractable learning rule for the synaptic weights towards hidden and visible neurons that leads to optimal recall of the training sequences ."]}
{"orig_sents": ["6", "4", "3", "7", "2", "1", "0", "5"], "shuf_sents": ["As observed in the primate retina , the Off-center neurons are more numerous and have filters with smaller spatial extent .", "The filters are organized into two populations , with On- and Off-centers , which independently tile the visual space .", "When applied to an ensemble of natural images , the method yields filters that are center-surround and nonlinearities that are rectifying .", "Here we show that an efficient coding model that incorporates biologically realistic ingredients - input and output noise , nonlinear response functions , and a metabolic cost on the firing rate - predicts receptive fields and response nonlinearities similar to those observed in the retina .", "Most attempts to test this principle have been limited to linear , noiseless models , and when applied to natural images , have yielded oriented filters consistent with responses in primary visual cortex .", "In the absence of noise , our method reduces to a generalized version of independent components analysis , with an adapted nonlinear `` contrast '' function ; in this case , the optimal filters are localized and oriented .", "Efficient coding provides a powerful principle for explaining early sensory coding .", "Specifically , we develop numerical methods for simultaneously learning the linear filters and response nonlinearities of a population of model neurons , so as to maximize information transmission subject to metabolic costs ."]}
{"orig_sents": ["2", "0", "3", "4", "1"], "shuf_sents": ["In this paper we allow inter-agent communication which turns the problem in a centralized Multiagent POMDP ( MPOMDP ) .", "We formalize these notions by casting the problem into convex optimization form , and present experimental results illustrating the savings in communication that we can obtain .", "Factored Decentralized Partially Observable Markov Decision Processes ( DecPOMDPs ) form a powerful framework for multiagent planning under uncertainty , but optimal solutions require a rigid history-based policy representation .", "We map belief distributions over state factors to an agent 's local actions by exploiting structure in the joint MPOMDP policy .", "The key point is that when sparse dependencies between the agents ' decisions exist , often the belief over its local state factors is sufficient for an agent to unequivocally identify the optimal action , and communication can be avoided ."]}
{"orig_sents": ["3", "0", "2", "5", "1", "4"], "shuf_sents": ["We propose a so-called extended Lasso optimization which takes into consideration sparse prior information of both and e .", "Our second set of results applies to a general class of Gaussian design matrix X with i.i.d rows N ( 0 , ) , for which we provide a surprising phenomenon : the extended Lasso can recover exact signed supports of both and e from only ( k log p log n ) observations , even the fraction of corruption is arbitrarily close to one .", "Our first result shows that the extended Lasso can faithfully recover both the regression and the corruption vectors .", "This paper studies the problem of accurately recovering a sparse vector from highly corrupted linear measurements y = X + e + w where e is a sparse error vector whose nonzero entries may be unbounded and w is a bounded noise .", "Our analysis also shows that this amount of observations required to achieve exact signed support is optimal .", "Our analysis is relied on a notion of extended restricted eigenvalue for the design matrix X ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["A simulation confirms the method 's applicability to learning both stationary and temporal spike patterns .", "We derive a plausible learning rule for feedforward , feedback and lateral connections in a recurrent network of spiking neurons .", "Operating in the context of a generative model for distributions of spike sequences , the learning mechanism is derived from variational inference principles .", "The synaptic plasticity rules found are interesting in that they are strongly reminiscent of experimental Spike Time Dependent Plasticity , and in that they differ for excitatory and inhibitory neurons ."]}
{"orig_sents": ["10", "4", "6", "2", "5", "0", "8", "9", "3", "12", "1", "7", "11"], "shuf_sents": ["We show that the tradeoff between loss and regret is optimal up to constant factors .", "First , we obtain a parameter free algorithm for the experts problem that has optimal regret bounds with respect to k-shifting optima , i.e .", "In this paper we are interested in algorithms that have essentially zero ( expected ) loss over any string at any point in time and yet have small regret with respect to always predicting 0 or always predicting 1 .", "We obtain essentially zero loss with respect to the special expert and optimal loss/regret tradeoff , improving upon the results of Even-Dar et al and settling the main question left open in their paper .", "Assume we are allowed to say `predict 0 ' or `predict 1 ' , and our payoff is +1 if the prediction is correct and -1 otherwise .", "For a sequence of length T our algorithm has regret 14 T and loss 2 2 T e- T in expectation for all strings .", "We will say that at each point in time the loss of an algorithm is the number of wrong predictions minus the number of right predictions so far .", "bounds with respect to the optimum that is allowed to change arms multiple times .", "Our techniques extend to the general setting of N experts , where the related problem of trading off regret to the best expert for regret to the 'special ' expert has been studied by Even-Dar et al .", "( COLT'07 ) .", "Consider a sequence of bits where we are trying to predict the next bit from the previous bits .", "Moreover , for any window of size n the regret of our algorithm to any expert never exceeds O ( n ( log N + log T ) ) , where N is the number of experts and T is the time horizon , while maintaining the essentially zero loss property .", "The strong loss bounds of the algorithm have some surprising consequences ."]}
{"orig_sents": ["2", "0", "1", "5", "4", "3"], "shuf_sents": ["Optimizing this measure remains a statistically and computationally challenging problem , since no closed-form maximizer exists .", "Current algorithms are approximate and typically rely on additional assumptions regarding the statistical distribution of the binary response variables .", "The F-measure , originally introduced in information retrieval , is nowadays routinely used as a performance metric for problems such as binary classification , multi-label classification , and structured output prediction .", "We illustrate its practical performance by means of experimental results for multi-label classification .", "The algorithm requires only a quadratic number of parameters of the joint distribution ( with respect to the number of binary responses ) .", "In this paper , we present an algorithm which is not only computationally efficient but also exact , regardless of the underlying distribution ."]}
{"orig_sents": ["1", "6", "4", "3", "2", "0", "5", "7", "8"], "shuf_sents": ["We show that when the associated optimization problem is sparse , meaning most gradient updates only modify small parts of the decision variable , then H OGWILD !", "Stochastic Gradient Descent ( SGD ) is a popular algorithm that can achieve stateof-the-art performance on a variety of machine learning tasks .", "which allows processors access to shared memory with the possibility of overwriting each other 's work .", "We present an update scheme called H OGWILD !", "This work aims to show using novel theoretical analysis , algorithms , and implementation that SGD can be implemented without any locking .", "achieves a nearly optimal rate of convergence .", "Several researchers have recently proposed schemes to parallelize SGD , but all require performancedestroying memory locking and synchronization .", "We demonstrate experimentally that H OGWILD !", "outperforms alternative schemes that use locking by an order of magnitude ."]}
{"orig_sents": ["5", "2", "4", "3", "6", "0", "7", "1"], "shuf_sents": ["This problem occurs whenever the Hessian of the Bethe free energy is not positive-definite at the target marginals .", "We then show that averaging inaccurate beliefs , each obtained from belief propagation using model parameters perturbed about some learned mean values , can achieve the unbelievable marginals .", "One might hope to compensate for the approximation by adjusting model parameters .", "On the contrary , here we show that many probability distributions have marginals that can not be reached by belief propagation using any set of model parameters or any learning algorithm .", "Learning algorithms for this purpose have been explored previously , and the claim has been made that every set of locally consistent marginals can arise from belief propagation run on a graphical model .", "Loopy belief propagation performs approximate inference on graphical models with loops .", "We call such marginals ' unbelievable . '", "All learning algorithms for belief propagation necessarily fail in these cases , producing beliefs or sets of beliefs that may even be worse than the pre-learning approximation ."]}
{"orig_sents": ["2", "1", "3", "0", "4"], "shuf_sents": ["We show a variety of synthetic and real-world experiments where SPML predicts link patterns from node features more accurately than standard techniques .", "To better model and understand these networks , we present structure preserving metric learning ( SPML ) , an algorithm for learning a Mahalanobis distance metric from a network such that the learned distances are tied to the inherent connectivity structure of the network .", "Many real-world networks are described by both connectivity information and features for every node .", "Like the graph embedding algorithm structure preserving embedding , SPML learns a metric which is structure preserving , meaning a connectivity algorithm such as k-nearest neighbors will yield the correct connectivity when applied using the distances from the learned metric .", "We further demonstrate a method for optimizing SPML based on stochastic gradient descent which removes the running-time dependency on the size of the network and allows the method to easily scale to networks of thousands of nodes and millions of edges ."]}
{"orig_sents": ["0", "3", "4", "1", "6", "5", "2"], "shuf_sents": ["A model of human visual search is proposed .", "The ratio is computed on the firing pattern of V1/V2 neurons , modeled by Poisson distributions .", "A psychophyisics experiment is proposed that may discriminate between which mechanism is used in the human brain .", "It predicts both response time ( RT ) and error rates ( RT ) as a function of image parameters such as target contrast and clutter .", "The model is an ideal observer , in that it optimizes the Bayes ratio of target present vs target absent .", "An approximation of the optimal Bayesian observer , based on integrating local decisions , rather than diffusions , is also derived ; it is shown experimentally to produce very similar predictions to the optimal observer in common psychophysics conditions .", "The optimal mechanism for integrating information over time is shown to be a `soft max ' of diffusions , computed over the visual field by `hypercolumns ' of neurons that share the same receptive field and have different response properties to image features ."]}
{"orig_sents": ["4", "2", "3", "0", "1"], "shuf_sents": ["Our method can recover the latent tree structures with provable guarantees and perform local-minimum free parameter learning and efficient inference .", "Experiments on simulated and real data show the advantage of our proposed approach .", "However , existing models are largely restricted to discrete and Gaussian variables due to computational constraints ; furthermore , algorithms for estimating the latent tree structure and learning the model parameters are largely restricted to heuristic local search .", "We present a method based on kernel embeddings of distributions for latent tree graphical models with continuous and non-Gaussian variables .", "Latent tree graphical models are natural tools for expressing long range and hierarchical dependencies among many variables which are common in computer vision , bioinformatics and natural language processing problems ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["We describe a closed-form Bayesian approach to learning these models , and describe an importance sampling algorithm for forecasting future events using these models , using a proposal distribution based on Poisson superposition .", "We introduce the Piecewise-Constant Conditional Intensity Model , a model for learning temporal dependencies in event streams .", "We then use synthetic data , supercomputer event logs , and web search query logs to illustrate that our learning algorithm can efficiently learn nonlinear temporal dependencies , and that our importance sampling algorithm can effectively forecast future events ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["Crowdsourcing systems , in which tasks are electronically distributed to numerous `` information piece-workers '' , have emerged as an effective paradigm for humanpowered solving of large scale problems in domains such as image classification , data entry , optical character recognition , recommendation , and proofreading .", "We give a new algorithm for deciding which tasks to assign to which workers and for inferring correct answers from the workers ' answers .", "In this paper , we consider a general model of such crowdsourcing tasks , and pose the problem of minimizing the total price ( i.e. , number of task assignments ) that must be paid to achieve a target overall reliability .", "Because these low-paid workers can be unreliable , nearly all crowdsourcers must devise schemes to increase confidence in their answers , typically by assigning each task multiple times and combining the answers in some way such as majority voting .", "We show that our algorithm significantly outperforms majority voting and , in fact , is asymptotically optimal through comparison to an oracle that knows the reliability of every worker ."]}
{"orig_sents": ["3", "6", "0", "8", "9", "1", "2", "7", "10", "5", "4"], "shuf_sents": ["Since then , several attempts have been made at obtaining mathematical models of cancer progression , devising learning algorithms , and applying these to cross-sectional data .", "Given the small size of current and future data sets , it is important to minimize the number of parameters of a model .", "For this reason , we too focus on tree-based models and introduce Hidden-variable Oncogenetic Trees ( HOTs ) .", "Cancer has complex patterns of progression that include converging as well as diverging progressional pathways .", "The algorithm for single HOTs performs very well on reasonable-sized data sets , while that for HOT-mixtures requires data sets of sizes obtainable only with tomorrow 's more cost-efficient technologies .", "The algorithms are global in the sense that , during the M-step , they find a structure that yields a global maximum of the expected complete log-likelihood rather than merely one that improves it .", "Vogelstein 's path model of colon cancer was a pioneering contribution to cancer research .", "In contrast to OTs , HOTs allow for errors in the data and thereby provide more realistic modeling .", "Beerenwinkel et al .", "provided , what they coined , EM-like algorithms for Oncogenetic Trees ( OTs ) and mixtures of such .", "We also design global structural EM algorithms for learning HOTs and mixtures of HOTs ( HOT-mixtures ) ."]}
{"orig_sents": ["4", "7", "0", "1", "6", "5", "2", "3"], "shuf_sents": ["However , beyond smoothness , it is suggested by recent theoretical work that we should ensure second order smoothness for achieving faster rates of convergence for semisupervised regression problems .", "To achieve this goal , we show that the second order smoothness measures the linearity of the function , and the gradient field of a linear function has to be a parallel vector field .", "The discretized optimization problem turns out to be a sparse linear system which can be solved very efficiently .", "The experimental results have demonstrated the effectiveness of our proposed approach .", "This paper studies the problem of semi-supervised learning from the vector field perspective .", "We give a continuous objective function on the manifold and discuss how to discretize it by using random points .", "Consequently , we propose to find a function which minimizes the empirical error , and simultaneously requires its gradient field to be as parallel as possible .", "Many of the existing work use the graph Laplacian to ensure the smoothness of the prediction function on the data manifold ."]}
{"orig_sents": ["7", "1", "6", "2", "0", "5", "3", "8", "4"], "shuf_sents": ["Multiple kernel learning addresses this limitation by learning a linear combination of a number of predefined kernels ; this approach can be also readily used in the context of multiple-source learning to fuse different data sources .", "The most popular representative-Mahalanobis metric learning-can be seen as learning a linear transformation and then computing the Euclidean metric in the transformed space .", "However , the problem then becomes finding the appropriate kernel function .", "In this paper we fill this gap and present a general approach for metric learning with multiple kernel learning .", "Experimental evidence suggests that our approach outperforms metric learning with an unweighted kernel combination and metric learning with cross-validation based kernel selection .", "Surprisingly , and despite the extensive work on multiple kernel learning for SVMs , there has been no work in the area of metric learning with multiple kernel learning .", "Since a linear transformation might not always be appropriate for a given learning problem , kernelized versions of various metric learning algorithms exist .", "Metric learning has become a very active research field .", "Our approach can be instantiated with different metric learning algorithms provided that they satisfy some constraints ."]}
{"orig_sents": ["4", "6", "5", "1", "2", "3", "0"], "shuf_sents": ["Empirical results show that our framework can learn informative hierarchical sparse representations more efficiently .", "First , we derive new , greatly improved screening tests that quickly identify codewords that are guaranteed to have zero weights .", "Second , we study the properties of random projections in the context of learning sparse representations .", "Finally , we develop a hierarchical framework that uses incremental random projections and screening to learn , in small stages , a hierarchically structured dictionary for sparse representations .", "Learning sparse representations on data adaptive dictionaries is a state-of-the-art method for modeling data .", "We explore three aspects of the problem .", "But when the dictionary is large and the data dimension is high , it is a computationally challenging problem ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["Nonparametric Bayesian methods are developed for analysis of multi-channel spike-train data , with the feature learning and spike sorting performed jointly .", "The dHDP is augmented to eliminate refractoryperiod violations , it allows the `` appearance '' and `` disappearance '' of neurons over time , and it models smooth variation in the spike statistics .", "Dictionary learning is implemented via the beta-Bernoulli process , with spike sorting performed via the dynamic hierarchical Dirichlet process ( dHDP ) , with these two models coupled .", "The feature learning and sorting are performed simultaneously across all channels ."]}
{"orig_sents": ["1", "8", "5", "2", "10", "4", "9", "7", "0", "3", "6"], "shuf_sents": ["We then apply first- and second-order Riemannian trust-region methods to solve it .", "We consider large matrices of low rank .", "In this setting , the rows of the matrix may correspond to items and the columns may correspond to users .", "The cost of each iteration is linear in the number of known entries .", "The aim is to predict the unobserved ratings .", "Matrix completion finds applications in recommender systems .", "Our methods , RTRMC 1 and 2 , outperform state-of-the-art algorithms on a wide range of problem instances .", "We follow an approach that exploits the geometry of the low-rank constraint to recast the problem as an unconstrained optimization problem on the Grassmann manifold .", "We address the problem of recovering such matrices when most of the entries are unknown .", "This problem is commonly stated in a constrained optimization framework .", "The known entries are the ratings given by users to some items ."]}
{"orig_sents": ["2", "6", "0", "1", "4", "3", "5"], "shuf_sents": ["We employ a Deep Boltzmann Machine ( DBM ) model of cortical processing to demonstrate that these two different approaches can be combined in the same framework .", "Based on recent developments in machine learning , we show how neuronal adaptation can be understood as a mechanism that improves probabilistic , sampling-based inference .", "It has been argued that perceptual multistability reflects probabilistic inference performed by the brain when sensory input is ambiguous .", "We also examine the influence of spatial attention , and explore how binocular rivalry can be modeled with the same approach .", "Using the ambiguous Necker cube image , we analyze the perceptual switching exhibited by the model .", "Our work joins earlier studies in demonstrating how the principles underlying DBMs relate to cortical processing , and offers novel perspectives on the neural implementation of approximate probabilistic inference in the brain .", "Alternatively , more traditional explanations of multistability refer to low-level mechanisms such as neuronal adaptation ."]}
{"orig_sents": ["2", "4", "1", "0", "5", "7", "3", "6"], "shuf_sents": ["In this paper , we cast the problem of refining existing models for questionnaire data as follows : solve a constrained optimization problem of preserving the maximum amount of information found in a latent variable model using only a subset of existing questions .", "While comprehensive surveys help to better estimate the latent variables of interest , aiming at a high number of questions comes at a price : refusal to participate in surveys can go up , as well as the rate of missing data ; quality of answers can decline ; costs associated with applying such questionnaires can also increase .", "Inferring key unobservable features of individuals is an important task in the applied sciences .", "Three different approximate inference methods are introduced to solve this problem .", "In particular , an important source of data in fields such as marketing , social sciences and medicine is questionnaires : answers in such questionnaires are noisy measures of target unobserved features .", "The goal is to find an optimal subset of a given size .", "Comparisons against a simple but powerful heuristic are presented .", "For that , we first define an information theoretical measure for quantifying the quality of a reduced questionnaire ."]}
{"orig_sents": ["2", "4", "6", "7", "3", "1", "5", "0"], "shuf_sents": ["Experimental results on various datasets show that the proposed higher-order correlation clustering outperforms other state-of-the-art image segmentation algorithms .", "We first apply the pairwise correlation clustering to image segmentation over a pairwise superpixel graph and then develop higher-order correlation clustering over a hypergraph that considers higher-order relations among superpixels .", "For many of the state-of-the-art computer vision algorithms , image segmentation is an important preprocessing step .", "This improves clustering in the presence of local boundary ambiguities .", "As such , several image segmentation algorithms have been proposed , however , with certain reservation due to high computational load and many hand-tuning parameters .", "Fast inference is possible by linear programming relaxation , and also effective parameter learning framework by structured support vector machine is possible .", "Correlation clustering , a graphpartitioning algorithm often used in natural language processing and document clustering , has the potential to perform better than previously proposed image segmentation algorithms .", "We improve the basic correlation clustering formulation by taking into account higher-order cluster relationships ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["Variational Message Passing ( VMP ) is an algorithmic implementation of the Variational Bayes ( VB ) method which applies only in the special case of conjugate exponential family models .", "In the multinomial case we introduce a novel variational bound for the softmax factor which is tighter than other commonly used bounds whilst maintaining computational tractability .", "We propose an extension to VMP , which we refer to as Non-conjugate Variational Message Passing ( NCVMP ) which aims to alleviate this restriction while maintaining modularity , allowing choice in how expectations are calculated , and integrating into an existing message-passing framework : Infer.NET .", "We demonstrate NCVMP on logistic binary and multinomial regression ."]}
{"orig_sents": ["4", "6", "2", "1", "0", "9", "3", "7", "10", "8", "5"], "shuf_sents": ["Consequently such an embedding has to be used with linear scan or another search algorithm .", "While supervised learning algorithms have been applied to related problems , those proposed in the literature mainly focused on learning hash codes optimized for compact embedding of the data rather than search efficiency .", "Traditional approaches relied on algorithmic constructions that are often data independent ( such as Locality Sensitive Hashing ) or weakly dependent ( such as kd-trees , k-means trees ) .", "This paper considers a new framework that applies supervised learning to directly optimize a data structure that supports efficient large scale search .", "High dimensional similarity search in large scale databases becomes an important challenge due to the advent of Internet .", "Experimental results show that our approach significantly outperforms the start-of-the-art learning to hash methods ( such as spectral hashing ) , as well as state-of-the-art high dimensional search algorithms ( such as LSH and k-means trees ) .", "For such applications , specialized data structures are required to achieve computational efficiency .", "Our approach takes both search quality and computational cost into consideration .", "The output of this search forest can be efficiently converted into an inverted indexing data structure , which can leverage modern text search infrastructure to achieve both scalability and efficiency .", "Hence learning to hash does not directly address the search efficiency issue .", "Specifically , we learn a boosted search forest that is optimized using pair-wise similarity labeled examples ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["This representation learning algorithm can be stacked to yield a deep architecture , and we combine it with a domain knowledge-free version of the TangentProp algorithm to encourage the classifier to be insensitive to local directions changes along the manifold .", "Record-breaking classification results are obtained .", "We combine three important ideas present in previous work for building classifiers : the semi-supervised hypothesis ( the input distribution contains information about the classifier ) , the unsupervised manifold hypothesis ( data density concentrates near low-dimensional manifolds ) , and the manifold hypothesis for classification ( different classes correspond to disjoint manifolds separated by low density ) .", "We exploit a novel algorithm for capturing manifold structure ( high-order contractive auto-encoders ) and we show how it builds a topological atlas of charts , each chart being characterized by the principal singular vectors of the Jacobian of a representation mapping ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["This paper studies to what extent analytic statements about optimal learning are possible if all beliefs are Gaussian processes .", "A first order approximation of learning of both loss and dynamics , for nonlinear , time-varying systems in continuous time and space , subject to a relatively weak restriction on the dynamics , is described by an infinite-dimensional partial differential equation .", "The optimal Bayesian solution is intractable in general .", "The exploration-exploitation trade-off is among the central challenges of reinforcement learning .", "An approximate finitedimensional projection gives an impression for how this result may be helpful ."]}
{"orig_sents": ["1", "4", "2", "6", "5", "0", "3"], "shuf_sents": ["We describe an empirical Bayes method for selecting the number of features , and extend the model to accommodate an arbitrary elliptical nonlinear response function , which results in a more powerful and more flexible model for feature space inference .", "Neurons typically respond to a restricted number of stimulus features within the high-dimensional space of natural stimuli .", "First , we show that traditional estimators based on the spike-triggered average ( STA ) and spike-triggered covariance ( STC ) can be formalized in terms of the `` expected log-likelihood '' of a Linear-Nonlinear-Poisson ( LNP ) model with Gaussian stimuli .", "We validate these methods using neural data recorded extracellularly from macaque primary visual cortex .", "Here we describe an explicit modelbased interpretation of traditional estimators for a neuron 's multi-dimensional feature space , which allows for several important generalizations and extensions .", "It also allows us to employ Bayesian methods for regularization , smoothing , sparsification , and model comparison , and provides Bayesian confidence intervals on model parameters .", "This model-based formulation allows us to define maximum-likelihood and Bayesian estimators that are statistically consistent and efficient in a wider variety of settings , such as with naturalistic ( non-Gaussian ) stimuli ."]}
{"orig_sents": ["4", "2", "0", "1", "3", "5"], "shuf_sents": ["Efforts are now underway to distill this valuable experience by proposing general unified frameworks that can achieve the twio goals of summarizing previous analyses and enabling their application to notions of structure hitherto unexplored .", "Inspired by these developments , we propose and analyze a general computational scheme based on a greedy strategy to solve convex optimization problems that arise when dealing with structurally constrained high-dimensional problems .", "A deep understanding of the capabilities and limits of high dimensional learning methods under specific assumptions such as sparsity , group sparsity , and low rank has been attsined .", "Our framework not only unifies existing greedy algorithms by recovering them as special cases but also yields novel ones .", "A hallmark of modern machine learning is its ability to deal with high dimensional problems by exploiting structural assumptions that limit the degrees of freedom in the underlying model .", "Finally , we extend our results to infinite dimensional settings by using interesting connections between smoothness of norms and behavior of martingales in Banach spaces ."]}
{"orig_sents": ["0"], "shuf_sents": ["We show that for a general class of convex online learning problems , Mirror Descent can always achieve a ( nearly ) optimal regret guarantee ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["A nonparametric kernel-based method for realizing Bayes ' rule is proposed , based on kernel representations of probabilities in reproducing kernel Hilbert spaces .", "A consistency rate for the posterior estimate is established .", "The prior and conditional probabilities are expressed as empirical kernel mean and covariance operators , respectively , and the kernel mean of the posterior distribution is computed in the form of a weighted sample .", "The kernel Bayes ' rule can be applied to a wide variety of Bayesian inference problems : we demonstrate Bayesian computation without likelihood , and filtering with a nonparametric statespace model ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["Without knowing neither which of the models is the correct one , nor what are the probabilistic characteristics of the resulting MDP , it is required to obtain as much reward as the optimal policy for the correct model ( or for the best of the correct models , if there are several ) .", "Several models ( functions mapping past observations to a finite set ) of the observations are given , and it is known that for at least one of these models the resulting state dynamics are indeed Markovian .", "We propose an algorithm that achieves that , with a regret of order T 2/3 where T is the horizon time .", "The problem of selecting the right state-representation in a reinforcement learning problem is considered ."]}
{"orig_sents": ["7", "1", "2", "3", "6", "4", "0", "5"], "shuf_sents": ["In both cases , our method substantially reduces the number of missed spikes and false positives when compared to a standard clustering algorithm , primarily by recovering overlapping spikes .", "Most current methods are based on clustering , which requires substantial human supervision and systematically mishandles temporally overlapping spikes .", "We formulate the problem as one of statistical inference , in which the recorded voltage is a noisy sum of the spike trains of each neuron convolved with its associated spike waveform .", "Joint maximum-a-posteriori ( MAP ) estimation of the waveforms and spikes is then a blind deconvolution problem in which the coefficients are sparse .", "We validate our method on simulated data as well as real data for which ground truth is available via simultaneous intracellular recordings .", "The method offers a fully automated alternative to clustering methods that is less susceptible to systematic errors .", "We develop a block-coordinate descent procedure to approximate the MAP solution , based on our recently developed continuous basis pursuit method .", "We consider the problem of estimating neural spikes from extracellular voltage recordings ."]}
{"orig_sents": ["2", "0", "6", "5", "3", "1", "7", "4"], "shuf_sents": ["In particular , we show that a simple modification of Auer 's UCB algorithm ( Auer , 2002 ) achieves with high probability constant regret .", "Our modification improves the regret bound by a logarithmic factor , though experiments show a vast improvement .", "We improve the theoretical analysis and empirical performance of algorithms for the stochastic multi-armed bandit problem and the linear stochastic multi-armed bandit problem .", "( 2010 ) .", "For their construction we use a novel tail inequality for vector-valued martingales .", "( 2008 ) , Rusmevichientong and Tsitsiklis ( 2010 ) , Li et al .", "More importantly , we modify and , consequently , improve the analysis of the algorithm for the for linear stochastic bandit problem studied by Auer ( 2002 ) , Dani et al .", "In both cases , the improvement stems from the construction of smaller confidence sets ."]}
{"orig_sents": ["7", "1", "3", "6", "5", "0", "4", "2"], "shuf_sents": ["In particular , two sets of parameters are encouraged to have similar values if they are spatially close or semantically close .", "We can capture such contextual information by taking as input the features/attributes from all the regions in the image .", "In extensive evaluation over two different settings , of multi-class object detection and of multiple scene understanding tasks ( scene categorization , depth estimation , geometric labeling ) , our method beats the state-of-the-art methods in all the four tasks .", "However , this contextual dependence also varies with the spatial location of the region of interest , and we therefore need a different set of parameters for each spatial location .", "Our method is , in principle , complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead .", "In this work , we model the independence properties between the parameters for each location and for each task , by defining a Markov Random Field ( MRF ) over the parameters .", "This results in a very large number of parameters .", "For most scene understanding tasks ( such as object detection or depth estimation ) , the classifiers need to consider contextual information in addition to the local features ."]}
{"orig_sents": ["0", "1", "5", "4", "2", "6", "3"], "shuf_sents": ["Recently , image categorization has been an active research topic due to the urgent need to retrieve and browse digital images via semantic keywords .", "This paper formulates image categorization as a multi-label classification problem using recent advances in matrix completion .", "A major advantage of our approach w.r.t .", "Experimental validation on several datasets shows how our method outperforms state-of-the-art algorithms , while effectively capturing semantic concepts of classes .", "We propose two convex algorithms for matrix completion based on a Rank Minimization criterion specifically tailored to visual data , and prove its convergence properties .", "Under this setting , classification of testing data is posed as a problem of completing unknown label entries on a data matrix that concatenates training and testing features with training labels .", "standard discriminative classification methods for image categorization is its robustness to outliers , background noise and partial occlusions both in the feature and label space ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["Our probabilistic algorithm allows complex behaviors to be captured from suboptimal stochastic demonstrations , while automatically balancing the simplicity of the learned reward structure against its consistency with the observed actions .", "We present a probabilistic algorithm for nonlinear inverse reinforcement learning .", "While most prior inverse reinforcement learning algorithms represent the reward as a linear combination of a set of features , we use Gaussian processes to learn the reward as a nonlinear function , while also determining the relevance of each feature to the expert 's policy .", "The goal of inverse reinforcement learning is to learn the reward function in a Markov decision process from expert demonstrations ."]}
{"orig_sents": ["5", "3", "6", "2", "0", "1", "7", "4"], "shuf_sents": ["Different optimization algorithms have been evaluated empirically in many papers .", "In this work , we analyze the optimization problem analytically and show that the training of log-linear models can be highly ill-conditioned .", "The optimization of log-linear model parameters is costly and therefore an important topic , in particular for large-scale applications .", "Typically , log-linear models are trained according to a convex criterion .", "By making use of our convergence analysis , we obtain good results on a large-scale continuous handwriting recognition task with a simple and generic approach .", "Log-linear models are widely used probability models for statistical pattern recognition .", "In recent years , the interest in log-linear models has greatly increased .", "We verify our findings on two handwriting tasks ."]}
{"orig_sents": ["5", "4", "2", "0", "1", "3"], "shuf_sents": ["In all previous works , uniqueness is guaranteed only in the situations where the strength of the interactions are `` sufficiently '' small in certain senses .", "In contrast , our condition covers arbitrary strong interactions on the specified class of signed graphs .", "In this paper , we develop a novel approach to the uniqueness problem of the LBP fixed point ; our new `` necessary and sufficient '' condition is stated in terms of graphs and signs , where the sign denotes the types ( attractive/repulsive ) of the interaction ( i.e. , compatibility function ) on the edge .", "The result of this paper is based on the recent theoretical advance in the LBP algorithm ; the connection with the graph zeta function .", "Especially , if the interactions of random variables in a graphical model are strong , the behaviors of the algorithm can be difficult to analyze due to underlying phase transitions .", "While loopy Belief Propagation ( LBP ) has been utilized in a wide variety of applications with empirical success , it comes with few theoretical guarantees ."]}
{"orig_sents": ["2", "5", "6", "0", "4", "1", "3"], "shuf_sents": ["The first approach proposes that humans rely on abstract representations of dependency relationships between features , and is formalized here as a graphical model .", "We evaluate these models using a task where participants reason about chimeras , or animals with pairs of features that have not previously been observed to co-occur .", "Given one feature of a novel animal , humans readily make inferences about other features of the animal .", "The results support the hypothesis that humans rely on explicit representations of relationships between features .", "The second approach proposes that humans rely on specific knowledge of previously encountered animals , and is formalized here as a family of exemplar models .", "For example , winged creatures often fly , and creatures that eat fish often live in the water .", "We explore the knowledge that supports these inferences and compare two approaches ."]}
{"orig_sents": ["1", "3", "4", "2", "0"], "shuf_sents": ["We illustrate the proposed method on synthetic data .", "We study a particular class of cyclic causal models , where each variable is a ( possibly nonlinear ) function of its parents and additive noise .", "In the acyclic case , the method reduces to ordinary regression , but in the more challenging cyclic case , an additional term arises in the loss function , which makes it a special case of nonlinear independent component analysis .", "We prove that the causal graph of such models is generically identifiable in the bivariate , Gaussian-noise case .", "We also propose a method to learn such models from observational data ."]}
{"orig_sents": ["1", "5", "9", "6", "0", "4", "3", "8", "2", "7"], "shuf_sents": ["In particular , we investigate the greedy coordinate descent algorithm , and note that performing the greedy step efficiently weakens the costly dependence on the problem size provided the solution is sparse .", "Increasingly , optimization problems in machine learning , especially those arising from bigh-dimensional statistical estimation , bave a large number of variables .", "Without tuning the latter data structore , we are not only able to significantly speed up the vanilla greedy method , hot also outperform cyclic descent when the problem size becomes large .", "We also devise a more amenable form of greedy descent for composite non-smooth objectives ; as well as several approximate variants of such greedy descent .", "We then propose a snite of methods that perform these greedy steps efficiently by a reduction to nearest neighbor search .", "Modem statistical estimators developed over the past decade have statistical or sample complexity that depends only weakly on the number of parameters when there is some structore to the problem , such as sparsity .", "In this paper , we propose strategies that indicate that such advances can indeed be made .", "Our resnlts indicate the effectiveness of our nearest neighbor strategies , and also point to many open questions regarding the development of computational geometric techniques tailored towards first-order optimization methods .", "We develop a practical implementation of our algorithm that combines greedy coordinate descent with locality sensitive hashing .", "A central question is whether similar advances can be made in their computational complexity as well ."]}
{"orig_sents": ["7", "5", "6", "3", "2", "4", "1", "0"], "shuf_sents": ["We demonstrate the applicability of our method with synthetic dataset , natural images and brain signals .", "Our new twostage model enables estimation of both the linear mixing and the interactions related to energy-correlations , without resorting to approximations of the likelihood function or other non-principled approaches .", "The main new feature is a model of the energy-correlations based on the structural equation model ( SEM ) , in particular , a Linear Non-Gaussian SEM .", "Our two-stage model includes a linear mixing of latent signals into the observed ones like in ICA .", "The SEM is closely related to divisive normalization which effectively reduces energy correlation .", "A very common form of nonlinear dependency between the components is correlations in their variances or energies .", "Here , we propose a principled probabilistic model to model the energycorrelations between the latent variables .", "Components estimated by independent component analysis and related methods are typically not independent in real data ."]}
{"orig_sents": ["1", "2", "0", "7", "3", "4", "6", "5"], "shuf_sents": ["We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons .", "This paper examines the problem of ranking a collection of objects using pairwise comparisons ( rankings of two objects ) .", "In general , the ranking of n objects can be identified by standard sorting methods using n log2 n pairwise comparisons .", "We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons , on average .", "If instead the comparisons are chosen at random , then almost all pairwise comparisons must be made in order to identify any ranking .", "Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis .", "In addition , we propose a robust , error-tolerant algorithm that only requires that the pairwise comparisons are probably correct .", "Specifically , we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reflect their relative distances from a common reference point in Rd ."]}
{"orig_sents": ["4", "3", "2", "5", "0", "1"], "shuf_sents": ["This is strictly better , and often significantly better than what non-adaptive sampling could achieve .", "Our main result helps settle an open problem posed by learning-to-rank ( from pairwise information ) theoreticians and practitioners : What is a provably correct way to sample preference labels ?", "Our performance is measured by two parameters : The number of disagreements ( loss ) and the query complexity ( number of pairwise preference labels ) .", "The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible .", "Given a set V of n elements we wish to linearly order them using pairwise preference labels which may be non-transitive ( due to irrationality or arbitrary noise ) .", "Our algorithm adaptively queries at most O ( n poly ( log n , -1 ) ) preference labels for a regret of times the optimal loss ."]}
{"orig_sents": ["2", "3", "6", "7", "0", "5", "4", "1"], "shuf_sents": ["However , to obtain provable performance , the method requires a fresh sample every iteration .", "We provide a brief empirical study , demonstrating the feasibility of our algorithms in practice .", "Generalized Linear Models ( GLMs ) and Single Index Models ( SIMs ) provide powerful generalizations of linear regression , where the target variable is assumed to be a ( possibly unknown ) 1-dimensional function of a linear predictor .", "In general , these problems entail non-convex estimation procedures , and , in practice , iterative local search heuristics are often used .", "We modify the isotonic regression step in Isotron to fit a Lipschitz monotonic function , and also provide an efficient O ( n log ( n ) ) algorithm for this step , improving upon the previous O ( n2 ) algorithm .", "In this paper , we provide algorithms for learning GLMs and SIMs , which are both computationally and statistically efficient .", "Kalai and Sastry ( 2009 ) provided the first provably efficient method , the Isotron algorithm , for learning SIMs and GLMs , under the assumption that the data is in fact generated under a GLM and under certain monotonicity and Lipschitz ( bounded slope ) constraints .", "The Isotron algorithm interleaves steps of perceptron-like updates with isotonic regression ( fitting a one-dimensional non-decreasing function ) ."]}
{"orig_sents": ["0", "2", "3", "6", "5", "1", "4"], "shuf_sents": ["Latent variable mixture models are a powerful tool for exploring the structure in large datasets .", "We also develop a correspondence between logarithmic regularization and what we term the pseudo-Dirichlet distribution , a generalization of the ordinary Dirichlet distribution well-suited for inducing sparsity .", "A common challenge for interpreting such models is a desire to impose sparsity , the natural assumption that each data point only contains few latent features .", "Since mixture distributions are constrained in their L1 norm , typical sparsity techniques based on L1 regularization become toothless , and concave regularization becomes necessary .", "We demonstrate our approach on a text corpus , inferring a sparse topic mixture model for 2,406 weblogs .", "In this work , we introduce a technique for circumventing this difficulty , using the so-called Mountain Pass Theorem to provide easily verifiable conditions under which the M-step is well-behaved despite the lacking concavity .", "Unfortunately concave regularization typically results in EM algorithms that must perform problematic non-concave M-step maximizations ."]}
{"orig_sents": ["4", "1", "3", "5", "2", "0"], "shuf_sents": ["As a demonstration of this concept , we analyze real data on course selections of undergraduate students at Duke University , with the goal of uncovering and concisely representing structure in the curriculum and in the characteristics of the student body .", "Each tree path corresponds to a type of person , and each node ( topic ) has a corresponding probability vector over items that may be selected .", "To share topics across the tree nodes , topic distributions are drawn from a Dirichlet process .", "The observed data are assumed to have associated temporal covariates ( corresponding to the time at which choices are made ) , and we wish to impose that with increasing time it is more probable that topics deeper in the tree are utilized .", "The nested Chinese restaurant process is extended to design a nonparametric topic-model tree for representation of human choices .", "This structure is imposed by developing a new `` change point '' stick-breaking model that is coupled with a Poisson and productof-gammas construction ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We provide a novel analysis , which shows how standard gradient methods may sometimes be insufficient to obtain a significant speed-up and propose a novel accelerated gradient algorithm , which deals with this deficiency , enjoys a uniformly superior guarantee and works well in practice .", "We study how such algorithms can be improved using accelerated gradient methods .", "Mini-batch algorithms have been proposed as a way to speed-up stochastic convex optimization problems ."]}
{"orig_sents": ["8", "1", "4", "6", "3", "0", "7", "5", "2"], "shuf_sents": ["Instead , for each iteration of cotraining , we formulate a single optimization problem which simultaneously learns a target predictor , a split of the feature space into views , and a subset of source and target features to include in the predictor .", "In many practical cases , the source and target distributions can differ substantially , and in some cases crucial target features may not have support in the source domain .", "Indeed , over a wide range ( 65 of 84 comparisons ) of target supervision CODA achieves the best performance .", "Unlike the original co-training work , we do not assume a particular feature split .", "In this paper we introduce an algorithm that bridges the gap between source and target domains by slowly adding to the training set both the target features and instances in which the current algorithm is the most confident .", ".", "Our algorithm is a variant of co-training , and we name it CODA ( Co-training for domain adaptation ) .", "CODA significantly out-performs the state-of-the-art on the 12-domain benchmark data set of Blitzer et al .", "Domain adaptation algorithms seek to generalize a model trained in a source domain to a new target domain ."]}
{"orig_sents": ["0", "4", "3", "6", "5", "1", "7", "2"], "shuf_sents": ["Many machine learning and signal processing problems can be formulated as linearly constrained convex programs , which could be efficiently solved by the alternating direction method ( ADM ) .", "As an example , we apply LADMAP to solve lowrank representation ( LRR ) , which is an important subspace clustering technique yet suffers from high computation cost .", "Numerical experiments verify that for LRR our LADMAP based methods are much faster than state-of-the-art algorithms .", "To address this issue , we propose a linearized ADM ( LADM ) method by linearizing the quadratic penalty term and adding a proximal term when solving the subproblems .", "However , usually the subproblems in ADM are easily solvable only when the linear mappings in the constraints are identities .", "We prove the global convergence of LADM with adaptive penalty ( LADMAP ) .", "For fast convergence , we also allow the penalty to change adaptively according a novel update rule .", "By combining LADMAP with a skinny SVD representation technique , we are able to reduce the complexity O ( n3 ) of the original ADM based method to O ( rn2 ) , where r and n are the rank and size of the representation matrix , respectively , hence making LRR possible for large scale applications ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["In this paper , we investigate the theoretical properties of this transfer method and we introduce novel algorithms adapting the transfer process on the basis of the similarity between source and target tasks .", "Transfer reinforcement learning ( RL ) methods leverage on the experience collected on a set of source tasks to speed-up RL algorithms .", "Finally , we report illustrative experimental results in a continuous chain problem .", "A simple and effective approach is to transfer samples from source tasks and include them in the training set used to solve a target task ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["We also develop an efficient inference scheme that allows our approach to scale to large networks .", "On synthetic and real-world data , empirical results demonstrate that the proposed inference approach can accurately estimate the coefficients of the regression model , which is useful for interpreting the evolution of the network ; furthermore , the learned model has systematically better predictive performance compared to standard baseline methods .", "The development of statistical models for continuous-time longitudinal network data is of increasing interest in machine learning and social science .", "Leveraging ideas from survival and event history analysis , we introduce a continuous-time regression modeling framework for network event data that can incorporate both time-dependent network statistics and time-varying regression coefficients ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["Negative-feedback models of homeostatic regulation , on the other hand , are concerned with behavioral adaptation in response to the `` internal '' state of the animal , and assume that animals ' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints .", "Building upon the drive-reduction theory of reward , we propose a new analytical framework that integrates learning and regulatory systems , such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identical .", "We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism , anticipatory responses , interaction among competing motivational systems , and risk aversion .", "Reinforcement learning models address animal 's behavioral adaptation to its changing `` external '' environment , and are based on the assumption that Pavlovian , habitual and goal-directed responses seek to maximize reward acquisition .", "The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["This model subsumes three important classes of signal recovery problems : compressive sensing , affine rank minimization , and robust principal component analysis .", "Empirically , SpaRCS inherits a number of desirable properties from the state-of-the-art CoSaMP and ADMiRA algorithms , including exponential convergence and efficient implementation .", "We consider the problem of recovering a matrix M that is the sum of a low-rank matrix L and a sparse matrix S from a small set of linear measurements of the form y = A ( M ) = A ( L + S ) .", "Simulation results with video compressive sensing , hyperspectral imaging , and robust matrix completion data sets demonstrate both the accuracy and efficacy of the algorithm .", "We propose a natural optimization problem for signal recovery under this model and develop a new greedy algorithm called SpaRCS to solve it ."]}
{"orig_sents": ["2", "0", "4", "1", "3"], "shuf_sents": ["In general , these new priors can be expressed as scale mixtures of normals , but have more complex forms and better properties than traditional Cauchy and double exponential priors .", "This encompassing framework should prove useful in comparing competing priors , considering properties and revealing close connections .", "In recent years , a rich variety of shrinkage priors have been proposed that have great promise in addressing massive regression problems .", "We then develop a class of variational Bayes approximations through the new hierarchy presented that will scale more efficiently to the types of truly massive data sets that are now encountered routinely .", "We first propose a new class of normal scale mixtures through a novel generalized beta distribution that encompasses many interesting priors as special cases ."]}
{"orig_sents": ["8", "12", "1", "3", "10", "6", "9", "0", "7", "11", "5", "2", "4"], "shuf_sents": ["SCLDA uses a novel formulation that decomposes each LDA parameter into a product of a common parameter shared by all the modalities and a parameter specific to each modality , which enables joint analysis of all the modalities and borrowing strength from one another .", "The fast growing neuroimaging techniques hold great promise .", "We apply SCLDA to the Magnetic Resonance Imaging ( MRI ) and Positron Emission Tomography ( PET ) images of 49 AD patients and 67 normal controls ( NC ) .", "Research so far has focused on single neuroimaging modality .", "Our study identifies disease-related brain regions consistent with findings in the AD literature .", "We perform extensive simulations to show that SCLDA outperforms existing competing algorithms on feature selection , especially on the ability for identifying weak-effect features .", "This is especially true for early AD , at which stage the disease-related regions are most likely to be weakeffect regions that are difficult to be detected from a single modality alone .", "We prove that this formulation is equivalent to a penalized likelihood with non-convex regularization , which can be solved by the DC ( difference of convex functions ) programming .", "Diagnosis of Alzheimer 's disease ( AD ) at the early stage of the disease development is of great clinical importance .", "We propose a sparse composite linear discriminant analysis model ( SCLDA ) for identification of disease-related brain regions of early AD from multi-modality data .", "However , as different modalities provide complementary measures for the same disease pathology , fusion of multi-modality data may increase the statistical power in identification of disease-related brain regions .", "We show that in using the DC programming , the property of the nonconvex regularization in terms of preserving weak-effect features can be nicely revealed .", "Current clinical assessment that relies primarily on cognitive measures proves low sensitivity and specificity ."]}
{"orig_sents": ["3", "2", "5", "4", "1", "0", "6"], "shuf_sents": ["We also propose an efficient post-refinement procedure to perform mutual inhibition between bases which is essential for an overcomplete setting .", "By representing the distribution of sparse coefficients with slice transform , we fit a piece-wise linear mapping function with the generalized lasso .", "For visual object category recognition , 1 regularized sparse coding is combined with the spatial pyramid representation to obtain state-of-the-art performance .", "Sparse coding , a method of explaining sensory data with as few dictionary bases as possible , has attracted much attention in computer vision .", "To overcome this computational challenge , this paper presents `` Generalized Lasso based Approximation of Sparse coding '' ( GLAS ) .", "However , because of its iterative optimization , applying sparse coding onto every local feature descriptor extracted from an image database can become a major bottleneck .", "The experiments show that GLAS obtains a comparable performance to 1 regularized sparse coding , yet achieves a significant speed up demonstrating its effectiveness for large-scale visual recognition problems ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["However , these models have focused on explaining inferences from discrete data of the kind that can be summarized in a 2x 2 contingency table .", "We develop a new rational model of causal induction using continuous dimensions , which aims to diminish the gap between empirical and theoretical approaches and real-world causal induction .", "This severely limits the scope of these models , since the world often provides non-binary data .", "This model successfully predicts human judgments from previous studies better than models of discrete causal inference , and outperforms several other plausible models of causal induction with continuous causes in accounting for people 's inferences in a new experiment .", "Rational models of causal induction have been successful in accounting for people 's judgments about causal relationships ."]}
{"orig_sents": ["2", "5", "0", "7", "3", "1", "4", "6"], "shuf_sents": ["Presently , computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results .", "Random search has been shown to be sufficiently efficient for learning neural networks for several datasets , but we show it is unreliable for training DBNs .", "Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning .", "We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion .", "The sequential algorithms are applied to the most difficult DBN learning problems from and find significantly better results than the best previously reported .", "Traditionally , hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible .", "This work contributes novel techniques for making response surface models P ( y|x ) in which many elements of hyper-parameter assignment ( x ) are known to be irrelevant given particular values of other elements .", "We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks ( DBNs ) ."]}
{"orig_sents": ["0", "5", "4", "3", "2", "1"], "shuf_sents": ["We study the fundamental problem of learning an unknown large-margin halfspace in the context of parallel computation .", "We give an information-theoretic proof that in the original PAC framework , in which a weak learning algorithm is provided as an oracle that is called by the booster , boosting can not be parallelized : the ability to call the weak learner multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required .", "Our main negative result deals with boosting , which is a standard approach to learning large-margin halfspaces .", "In contrast , naive parallel algorithms that learn a -margin halfspace in time that depends polylogarithmically on n have ( 1/ 2 ) runtime dependence on .", "We show that this algorithm learns an unknown -margin halfspace over n dimensions using poly ( n , 1/ ) processors and runs in time O ( 1/ ) + O ( log n ) .", "Our main positive result is a parallel algorithm for learning a large-margin halfspace that is based on interior point methods from convex optimization and fast parallel algorithms for matrix computations ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["We present an algorithm , called LSBG REEDY , and prove that it efficiently converges to a near-optimal model .", "In this paper , we propose the linear submodular bandits problem , which is an online learning setting for optimizing a general class of feature-rich submodular utility models for diversified retrieval .", "In a live user study , we found that LSBG REEDY significantly outperforms existing online learning approaches .", "Diversified retrieval and online learning are two core research areas in the design of modern information retrieval systems .", "As a case study , we applied our approach to the setting of personalized news recommendation , where the system must recommend small sets of news articles selected from tens of thousands of available articles each day ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["Most online algorithms used in machine learning today are based on variants of mirror descent or follow-the-leader .", "As an application of our approach , we provide the first computationally efficient online algorithm for collaborative filtering with trace-norm constrained matrices .", "In this paper , we present an online algorithm based on a completely different approach , which combines `` random playout '' and randomized rounding of loss subgradients .", "As a second application , we solve an open question linking batch learning and transductive online learning ."]}
{"orig_sents": ["5", "0", "3", "2", "4", "1"], "shuf_sents": ["The method exploits the relation between appearance distance and spatial overlap .", "For example , our algorithm finds the most similar pair of windows between two images while computing only 1 % of all distances on average .", "We propose algorithms that build on these basic operations to efficiently solve tasks relevant to many computer vision applications , such as finding all pairs of windows between two images with distance smaller than a threshold , or finding the single pair with the smallest distance .", "We derive an upper bound on appearance distance given the spatial overlap of two windows in an image , and use it to bound the distances of many pairs between two images .", "In experiments on the PASCAL VOC 07 dataset , our algorithms accurately solve these problems while greatly reducing the number of appearance distances computed , and achieve larger speedups than approximate nearest neighbour algorithms based on trees and on hashing .", "We present a computationally efficient technique to compute the distance of highdimensional appearance descriptor vectors between image windows ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["Our experiments show that our method converges quickly to highly accurate solutions on a range of benchmark instances , outperforming other state-of-the-art methods such as IJGP , TRW , and Gibbs sampling both in run-time and accuracy .", "In particular , we show how to accelerate a flat histogram sampling technique by significantly reducing the number of `` null moves '' in the chain , while maintaining asymptotic convergence properties .", "We also show how obtaining a so-called density of states distribution allows for efficient weight learning in Markov Logic theories .", "We propose a novel Adaptive Markov Chain Monte Carlo algorithm to compute the partition function ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We present a novel class of actor-critic algorithms for actors consisting of sets of interacting modules .", "Such updates are necessary when computation of compatible features becomes prohibitively difficult and are also desirable to increase the biological plausibility of reinforcement learning methods .", "We present , analyze theoretically , and empirically evaluate an update rule for each module , which requires only local information : the module 's input , output , and the TD error broadcast by a critic ."]}
{"orig_sents": ["1", "0", "4", "7", "5", "3", "2", "6"], "shuf_sents": ["A new framework , based on multi-dimensional codewords and predictors is introduced .", "The problem of multi-class boosting is considered .", "They also reduce to AdaBoost when there are only two classes .", "The algorithms differ in the weak learners that they support but are both shown to be 1 ) Bayes consistent , 2 ) margin enforcing , and 3 ) convergent to the global minimum of the risk .", "The optimal set of codewords is derived , and a margin enforcing loss proposed .", "Two algorithms are proposed : 1 ) CD-MCBoost , based on coordinate descent , updates one predictor component at a time , 2 ) GD-MCBoost , based on gradient descent , updates all components jointly .", "Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets .", "The resulting risk is minimized by gradient descent on a multidimensional functional space ."]}
{"orig_sents": ["0", "1", "7", "4", "5", "6", "3", "2"], "shuf_sents": ["Artists , advertisers , and photographers are routinely presented with the task of creating an image that a viewer will remember .", "While it may seem like image memorability is purely subjective , recent work shows that it is not an inexplicable phenomenon : variation in memorability of images is consistent across subjects , suggesting that some images are intrinsically more memorable than others , independent of a subjects ' contexts and biases .", "This work represents one of the first attempts at understanding intrinsic image memorability , and opens a new domain of investigation at the interface between human cognition and computer vision .", "Contrary to popular belief , unusual or aesthetically pleasing scenes do not tend to be highly memorable .", ", and augmented the object and scene annotations with interpretable spatial , content , and aesthetic image properties .", "We used a feature-selection scheme with desirable explaining-away properties to determine a compact set of attributes that characterizes the memorability of any individual image .", "We find that images of enclosed spaces containing people with visible faces are memorable , while images of vistas and peaceful scenes are not .", "In this paper , we used the publicly available memorability dataset of Isola et al ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["Using these rates , we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems .", "We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case , provided that the errors decrease at appropriate rates .", "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods , where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term ."]}
{"orig_sents": ["1", "2", "4", "0", "3"], "shuf_sents": ["The current analysis naturally extends the analysis of convex low-rank matrix estimation to tensors .", "We analyze the statistical performance of a recently proposed convex tensor decomposition algorithm .", "Conventionally tensor decomposition has been formulated as non-convex optimization problems , which hindered the analysis of their performance .", "Furthermore , we show through numerical experiments that our theory can precisely predict the scaling behaviour in practice .", "We show under some conditions that the mean squared error of the convex method scales linearly with the quantity we call the normalized rank of the true tensor ."]}
{"orig_sents": ["1", "6", "2", "0", "5", "3", "4", "7"], "shuf_sents": ["Many standard approaches to noisy or missing data , such as those using the EM algorithm , lead to optimization problems that are inherently non-convex , and it is difficult to establish theoretical guarantees on practical algorithms .", "Although the standard formulations of prediction problems involve fully-observed and noiseless data drawn in an i.i.d .", "We study these issues in the context of high-dimensional sparse linear regression , and propose novel estimators for the cases of noisy , missing , and/or dependent data .", "On the statistical side , we provide non-asymptotic bounds that hold with high probability for the cases of noisy , missing , and/or dependent data .", "On the computational side , we prove that under the same types of conditions required for statistical consistency , the projected gradient descent algorithm will converge at geometric rates to a near-global minimizer .", "While our approach also involves optimizing non-convex programs , we are able to both analyze the statistical error associated with any global optimum , and prove that a simple projected gradient descent algorithm will converge in polynomial time to a small neighborhood of the set of global minimizers .", "manner , many applications involve noisy and/or missing data , possibly involving dependencies .", "We illustrate these theoretical predictions with simulations , showing agreement with the predicted scalings ."]}
{"orig_sents": ["1", "3", "0", "5", "4", "2", "6"], "shuf_sents": ["a manifold ) .", "Many nonparametric regressors were recently shown to converge at rates that depend only on the intrinsic dimension of data .", "Furthermore , we show a simple way to choose k = k ( x ) locally at any x so as to nearly achieve the minimax rate at x in terms of the unknown intrinsic dimension in the vicinity of x .", "These regressors thus escape the curse of dimension when high-dimensional data has low intrinsic dimension ( e.g .", "In particular our rates are local to a query x and depend only on the way masses of balls centered at x vary with radius .", "We show that k-NN regression is also adaptive to intrinsic dimension .", "We also establish that the minimax rate does not depend on a particular choice of metric space or distribution , but rather that this minimax rate holds for any metric space and doubling measure ."]}
{"orig_sents": ["3", "0", "1", "2"], "shuf_sents": ["Yet , because of their divergent motivations and forms , the objective functions of many non-ML learning methods are seemingly unrelated , and there lacks a unified framework to understand them .", "In this work , based on an information geometric view of parametric learning , we introduce a general non-ML learning principle termed as minimum KL contraction , where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator .", "We then show that the objective functions of several important or recently developed non-ML learning methods , including contrastive divergence , noise-contrastive estimation , partial likelihood , non-local contrastive objectives , score matching , pseudo-likelihood , maximum conditional likelihood , maximum mutual information , maximum marginal likelihood , and conditional and marginal composite likelihood , can be unified under the minimum KL contraction framework with different choices of the KL contraction operators .", "When used to learn high dimensional parametric probabilistic models , the classical maximum likelihood ( ML ) learning often suffers from computational intractability , which motivates the active developments of non-ML learning methods ."]}
{"orig_sents": ["3", "2", "0", "4", "1"], "shuf_sents": ["We show that the Lovasz extension may be seen as the convex envelope of a function that depends on level sets ( i.e. , the set of indices whose corresponding components of the underlying predictor are greater than a given constant ) : this leads to a class of convex structured regularization terms that impose prior knowledge on the level sets , and not only on the supports of the underlying predictors .", "By selecting specific submodular functions , we give a new interpretation to known norms , such as the total variation ; we also define new norms , in particular ones that are based on order statistics with application to clustering and outlier detection , and on noisy cuts in graphs with application to change point detection in the presence of outliers .", "While previous work has focused on non-decreasing functions , we explore symmetric submodular functions and their Lovasz extensions .", "We consider a class of sparsity-inducing regularization terms based on submodular functions .", "We provide unified optimization algorithms , such as proximal operators , and theoretical guarantees ( allowed level sets and recovery conditions ) ."]}
{"orig_sents": ["4", "5", "1", "0", "2", "3"], "shuf_sents": ["Instrumental in raising the effectiveness of our method is an adaptive hypothesis generator , whose proposal distribution is learned incrementally and online .", "To overcome this weakness we propose a new multi-structure fitting approach based on Reversible Jump MCMC .", "We prove that this adaptive proposal satisfies the diminishing adaptation property crucial for ensuring ergodicity in MCMC .", "Our method effectively conducts hypothesis sampling and optimisation simultaneously , and yields superior computational efficiency over previous two-stage methods .", "Multi-structure model fitting has traditionally taken a two-stage approach : First , sample a ( large ) number of model hypotheses , then select the subset of hypotheses that optimise a joint fitting and model selection criterion .", "This disjoint two-stage approach is arguably suboptimal and inefficient -- if the random sampling did not retrieve a good set of hypotheses , the optimised outcome will not represent a good fit ."]}
{"orig_sents": ["8", "3", "0", "4", "5", "7", "6", "2", "1"], "shuf_sents": ["Such a constraint is desirable when the features follow an ordered tree structure , that is , a given feature is selected for the given regression/classification task only if its parent node is selected .", "Empirical results show that the proposed algorithm has an expected linear time complexity for many special cases including a sequential list , a full binary tree , and a tree with depth 1 .", "We report simulation results showing the effectiveness of the max-heap for regression with an ordered tree structure .", "This Euclidean projection plays a building block role in the optimization problem with a non-negative maxheap constraint .", "In this paper , we show that such Euclidean projection problem admits an analytical solution and we develop a top-down algorithm where the key operation is to find the so-called maximal root-tree of the subtree rooted at each node .", "A naive approach for finding the maximal root-tree is to enumerate all the possible root-trees , which , however , does not scale well .", "The proposed algorithm has a ( worst-case ) linear time complexity for a sequential list , and O ( p2 ) for a general tree .", "We reveal several important properties of the maximal root-tree , based on which we design a bottom-up algorithm with merge for efficiently finding the maximal roottree .", "We consider the problem of computing the Euclidean projection of a vector of length p onto a non-negative max-heap -- an ordered tree where the values of the nodes are all nonnegative and the value of any parent node is no less than the value ( s ) of its child node ( s ) ."]}
{"orig_sents": ["0", "4", "3", "2", "1", "5"], "shuf_sents": ["We propose a novel inference framework for finding maximal cliques in a weighted graph that satisfy hard constraints .", "Two core problems in the learning framework , matching of image patches and finding salient parts , are formulated as two instances of the problem of finding maximal cliques with hard constraints .", "We apply the inference framework to a challenging problem of learning part-based , deformable object models .", "The proposed inference is based on a novel particle filter algorithm with state permeations .", "The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes , i.e. , sets of nodes that can not belong to the same solution .", "Our learning framework yields discriminative part based object models that achieve very good detection rate , and outperform other methods on object classes with large deformation ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Despite the recent trend of increasingly large datasets for object detection , there still exist many classes with few training examples .", "To overcome this lack of training data for certain classes , we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes .", "Our experimental results demonstrate that our new object detector , with borrowed and transformed examples , improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset .", "Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class ."]}
{"orig_sents": ["8", "10", "7", "4", "9", "1", "0", "3", "6", "2", "5"], "shuf_sents": ["In contrast , OMP is known to have very weak performance guarantees under RIP .", "This simple change allows us to prove that OMPR has the best known guarantees for sparse recovery in terms of the Restricted Isometry Property ( a condition on the measurement matrix ) .", "We provide experimental results on large problems providing recovery for vectors of size up to million dimensions .", "Given its simple structore , we are able to extend OMPR using locality sensitive hashing to get OMPR-Hasb , the first provably sub-linear ( in dimensionality ) algorithm for sparse recovery .", "OMPR , like the classic greedy algorithm OMP , adds exactly one coordinate to the support at each iteration , based on the correlation with the current residnal .", "We demonstrste that for large-scale problems our proposed methods are more robust and faster than existing methods .", "Our proof techniques are novel and flexible enough to also permit the tightest known analysis of popular iterative algorithms such as CoSaMP and Subspace Pursnit .", "While one extreme of the family yields well known hard thresholding algorithms like ITI and HTP , the other end of the spectrum leads to a novel algorithm that we call Orthogonal Matching Pursnit with Replacement ( OMPR ) .", "In this paper , we consider the problem of compressed sensing where the goal is to recover all sparse vectors using a small number offixed linear measurements .", "However , unlike OMP , OMPR also removes one coordinate from the support .", "For this problem , we propose a novel partial hard-thresholding operator that leads to a general family of iterative algorithms ."]}
{"orig_sents": ["5", "6", "4", "0", "1", "3", "2"], "shuf_sents": ["After establishing these properties , we show how posterior inference can be carried efficiently using Particle MCMC methods .", "This yields a MCMC algorithm that can resample entire sequences atomically while avoiding the complications of introducing slice and stick auxiliary variables of the beam sampler .", "In both domains , we found that our model outperformed the standard rate matrix estimation approach .", "We applied our model to the problem of estimating the disease progression in multiple sclerosis , and to RNA evolutionary modeling .", "Models based on HGEPs display many attractive properties : conjugacy , exchangeability and closed-form predictive distribution for the waiting times , and exact Gibbs updates for the time scale parameters .", "We introduce the Gamma-Exponential Process ( GEP ) , a prior over a large family of continuous time stochastic processes .", "A hierarchical version of this prior ( HGEP ; the Hierarchical GEP ) yields a useful model for analyzing complex time series ."]}
{"orig_sents": ["0", "5", "3", "2", "1", "4"], "shuf_sents": ["The performance of Markov chain Monte Carlo methods is often sensitive to the scaling and correlations between the random variables of interest .", "We address this problem by using limited memory quasi-Newton methods , which depend only on a fixed window of previous samples .", "A key issue is that MCMC samplers that depend on the history of previous states are in general not valid .", "In this paper we propose MCMC samplers that make use of quasiNewton approximations , which approximate the Hessian of the target distribution from previous samples and gradients generated by the sampler .", "On several real world datasets , we show that the quasi-Newton sampler is more effective than standard Hamiltonian Monte Carlo at a fraction of the cost of MCMC methods that require higher-order derivatives .", "An important source of information about the local correlation and scale is given by the Hessian matrix of the target distribution , but this is often either computationally expensive or infeasible ."]}
{"orig_sents": ["2", "0", "1", "3", "4"], "shuf_sents": ["In each round , the learning algorithm chooses a sequence of items .", "The algorithm then receives a monotone submodular function and suffers loss equal to the cover time of the function : the number of items needed , when items are selected in order of the chosen sequence , to achieve a coverage constraint .", "We propose an online prediction version of submodular set cover with connections to ranking and repeated active learning .", "We develop an online learning algorithm whose loss converges to approximately that of the best sequence in hindsight .", "Our proposed algorithm is readily extended to a setting where multiple functions are revealed at each round and to bandit and contextual bandit settings ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["We show through behavioral studies that humans employ three distinct teaching strategies , one of which is consistent with the curriculum learning principle , and propose a novel theoretical framework as a potential explanation for this strategy .", "This framework , which assumes a teaching goal of minimizing the learner 's expected generalization error at each iteration , extends the standard teaching dimension model and offers a theoretical justification for curriculum learning .", "We study the empirical strategies that humans follow as they teach a target concept with a simple 1D threshold to a robot.1 Previous studies of computational teaching , particularly the teaching dimension model and the curriculum learning principle , offer contradictory predictions on what optimal strategy the teacher should follow in this teaching task ."]}
{"orig_sents": ["1", "0", "3", "6", "9", "2", "5", "8", "7", "4"], "shuf_sents": ["However , standard ICA requires an orthonoramlity constraint to be enforced , which makes it difficult to learn overcomplete features .", "Independent Components Analysis ( ICA ) and its variants have been successfully used for unsupervised feature learning .", "Our formulation reveals formal connections between ICA and sparse autoencoders , which have previously been observed only empirically .", "In addition , ICA is sensitive to whitening .", "We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets .", "Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers .", "These properties make it challenging to scale ICA to high dimensional data .", "Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks , we obtain competitive performances on a wide variety of object recognition tasks .", "We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks .", "In this paper , we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data ."]}
{"orig_sents": ["3", "2", "6", "0", "5", "4", "1", "7"], "shuf_sents": ["First , using a generalized bilinear model with Poisson output we estimate time-varying coupling assuming that all changes are spike-timing-dependent .", "Using simulations of neurons undergoing spike-timing dependent modification , we show that the true modification function can be recovered .", "However , it is often difficult to detect changes in synaptic strength in vivo , since intracellular recordings are experimentally challenging .", "Synaptic plasticity underlies learning and is thus central for development , memory , and recovery from injury .", "Then , using recursive point-process adaptive filtering methods we estimate more general variation in coupling strength over time .", "This approach allows model-based estimation of STDP modification functions from pairs of spike trains .", "Here we present two methods aimed at inferring changes in the coupling between pairs of neurons from extracellularly recorded spike trains .", "Using multi-electrode data from motor cortex we then illustrate the use of this technique on in vivo data ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["With the advent of crowdsourcing services it has become quite cheap and reasonably effective to get a dataset labeled by multiple annotators in a short amount of time .", "Spammers can make the cost of acquiring labels very expensive and can potentially degrade the quality of the consensus labels .", "Various methods have been proposed to estimate the consensus labels by correcting for the bias of annotators with different kinds of expertise .", "In this paper we formalize the notion of a spammer and define a score which can be used to rank the annotators -- with the spammers having a score close to zero and the good annotators having a high score close to one .", "Often we have low quality annotators or spammers-annotators who assign labels randomly ( e.g. , without actually looking at the instance ) ."]}
{"orig_sents": ["1", "2", "4", "3", "0"], "shuf_sents": ["Finally we introduce a new objective performance measure for image captioning .", "We develop and demonstrate automatic image description methods using a large captioned photo collection .", "One contribution is our technique for the automatic collection of this new dataset - performing a huge number of Flickr queries and then filtering the noisy results down to 1 million images with associated visually relevant captions .", "We also develop methods incorporating many state of the art , but fairly noisy , estimates of image content to produce even more pleasing results .", "Such a collection allows us to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results ."]}
{"orig_sents": ["3", "2", "0", "7", "5", "4", "6", "1"], "shuf_sents": ["There have been no exact results for the error in the biologically plausible setting of inference on point process , however .", "This leads to a characterization of the optimal encoding for the setting as a function of the statistics of the stimulus , providing a mathematically sound primer for an ecological theory of sensory processing .", "It has been applied to describe the way in which biological systems dynamically represent and make decisions about the environment .", "Bayesian filtering of stochastic stimuli has received a great deal of attention recently .", "This is done for Markovian and a class of non-Markovian Gaussian processes .", "This allows us to study the dynamics of the error of an optimal Bayesian decoder , providing insights into the limits obtainable in this task .", "We find that there is an optimal tuning width for which the error is minimized .", "We present an exact analysis of the evolution of the meansquared error in a state estimation task using Gaussian-tuned point processes as sensors ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We derive TD , the -return equivalent of the original TD ( ) algorithm , which eliminates the parameter but can only perform updates at the end of an episode and requires time and space proportional to the episode length .", "We show that the -return target used in the TD ( ) family of algorithms is the maximum likelihood estimator for a specific model of how the variance of an nstep return estimate increases with n. We introduce the -return estimator , an alternative target based on a more accurate model of variance , which defines the TD family of complex-backup temporal difference learning algorithms .", "We show that TD outperforms TD ( ) for any setting of on 4 out of 5 benchmark domains , and that TD ( C ) performs as well as or better than TD for intermediate settings of C .", "We then derive a second algorithm , TD ( C ) , with a capacity parameter C. TD ( C ) requires C times more time and memory than TD ( ) and is incremental and online ."]}
{"orig_sents": ["7", "8", "4", "2", "1", "5", "3", "6", "0"], "shuf_sents": ["HMP consistently yields superior accuracy on three types of image classification problems : object recognition ( Caltech-101 ) , scene recognition ( MIT-Scene ) , and static event recognition ( UIUC-Sports ) .", "To speed up the orthogonal matching pursuit , we propose a batch tree orthogonal matching pursuit that is particularly suitable to encode a large number of observations that share the same large dictionary .", "We investigate the architecture of HMP , and show that all three components are critical for good performance .", "In addition , HMP enables linear support vector machines ( SVM ) to match the performance of nonlinear SVM while being scalable to large datasets .", "It includes three modules : batch ( tree ) orthogonal matching pursuit , spatial pyramid max pooling , and contrast normalization .", "HMP is scalable and can efficiently handle full-size images .", "We compare HMP with many state-of-the-art algorithms including convolutional deep belief networks , SIFT based single layer sparse coding , and kernel based feature learning .", "Extracting good representations from images is essential for many computer vision tasks .", "In this paper , we propose hierarchical matching pursuit ( HMP ) , which builds a feature hierarchy layer-by-layer using an efficient matching pursuit encoder ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["We introduce HD ( or `` Hierarchical-Deep '' ) models , a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian models .", "We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition , handwritten character recognition , and human motion capture datasets .", "This compound HDP-DBM model learns to learn novel concepts from very few training examples , by learning low-level generic features , high-level features that capture correlations among low-level features , and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts .", "Specifically we show how we can learn a hierarchical Dirichlet process ( HDP ) prior over the activities of the top-level features in a Deep Boltzmann Machine ( DBM ) ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["In this model , the algorithm is allowed to observe noisy realizations of the function value f ( x ) at any query point x X .", "We demonstrate a generalization of the ellipsoid algorithm that incurs O ( poly ( d ) T ) regret .", "This paper addresses the problem of minimizing a convex , Lipschitz function f over a convex , compact set X under a stochastic bandit feedback model .", "Since any algorithm has regret at least ( T ) on this problem , our algorithm is optimal in terms of the scaling with T ."]}
{"orig_sents": ["5", "4", "3", "0", "2", "1"], "shuf_sents": ["We fill this hole and introduce an efficient node predictor , S HAZOO , which is nearly optimal on any weighted tree .", "Experiments on real-world datasets confirm that S HAZOO performs well in that it fully exploits the structure of the input tree , and gets very close to ( and sometimes better than ) less scalable energy minimization methods .", "Moreover , we show that S HAZOO can be viewed as a common nontrivial generalization of both previous approaches for unweighted trees and weighted lines .", "Although it is known how to predict the nodes of an unweighted tree in a nearly optimal way , in the weighted case a fully satisfactory algorithm is not available yet .", "Since graph sparsification via spanning trees retains enough information while making the task much easier , trees are an important special case of this problem .", "Predicting the nodes of a given graph is a fascinating theoretical problem with applications in several domains ."]}
{"orig_sents": ["3", "1", "5", "2", "4", "0"], "shuf_sents": ["Experiments show that Macro-MCVI substantially improves the performance of MCVI with suitable macro-actions .", "The recently introduced Monte Carlo Value Iteration ( MCVI ) can tackle POMDPs with very large discrete state spaces or continuous state spaces , but its performance degrades when faced with long planning horizons .", "We provide sufficient conditions for Macro-MCVI to inherit the good theoretical properties of MCVI .", "POMDP planning faces two major computational challenges : large state spaces and long planning horizons .", "Macro-MCVI does not require explicit construction of probabilistic models for macro-actions and is thus easy to apply in practice .", "This paper presents Macro-MCVI , which extends MCVI by exploiting macro-actions for temporal abstraction ."]}
{"orig_sents": ["4", "2", "3", "1", "0", "5"], "shuf_sents": ["Since GapE and GapE-V need to tune an exploration parameter that depends on the complexity of the problem , which is often unknown in advance , we also introduce variations of these algorithms that estimate this complexity online .", "We prove an upper-bound on the probability of error for both algorithms .", "We first propose an algorithm called Gap-based Exploration ( GapE ) that focuses on the arms whose mean is close to the mean of the best arm in the same bandit ( i.e. , small gap ) .", "We then introduce an algorithm , called GapE-V , which takes into account the variance of the arms in addition to their gap .", "We study the problem of identifying the best arm in each of the bandits in a multibandit multi-armed setting .", "Finally , we evaluate the performance of these algorithms and compare them to other allocation strategies on a number of synthetic problems ."]}
{"orig_sents": ["0", "2", "3", "1"], "shuf_sents": ["The difficulty in inverse reinforcement learning ( IRL ) arises in choosing the best reward function since there are typically an infinite number of reward functions that yield the given behaviour data as optimal .", "We show the effectiveness of our approach by comparing the performance of the proposed method to those of the previous algorithms .", "Using a Bayesian framework , we address this challenge by using the maximum a posteriori ( MAP ) estimation for the reward function , and show that most of the previous IRL algorithms can be modeled into our framework .", "We also present a gradient method for the MAP estimation based on the ( sub ) differentiability of the posterior distribution ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["We illustrate our coupled factorisation approach on synthetic data as well as on a musical audio restoration problem .", "We derive algorithms for generalised tensor factorisation ( GTF ) by building upon the well-established theory of Generalised Linear Models .", "By bounding the step size of the Fisher Scoring iteration of the GLM , we obtain general updates for real data and multiplicative updates for non-negative data .", "Our algorithms are general in the sense that we can compute arbitrary factorisations in a message passing framework , derived for a broad class of exponential family distributions including special cases such as Tweedie 's distributions corresponding to divergences .", "The GTF framework is , then extended easily to address the problems when multiple observed tensors are factorised simultaneously ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["Our main observation is that modeling joint-cue distributions independently is more statistically robust for typical classification problems than attempting to empirically estimate the dependent , joint-cue distribution directly .", "We use Information theoretic vocabulary compression to find discriminative combinations of cues and the resulting vocabulary of portmanteau1 words is compact , has the cue binding property , and supports individual weighting of cues in the final image representation .", "Our approach builds discriminative compound words from primitive cues learned independently from training images .", "We describe a novel technique for feature combination in the bag-of-words model of image classification .", "State-of-theart results on both the Oxford Flower-102 and Caltech-UCSD Bird-200 datasets demonstrate the effectiveness of our technique compared to other , significantly more complex approaches to multi-cue image representation ."]}
{"orig_sents": ["4", "2", "0", "1", "3", "5"], "shuf_sents": ["In those situations , however , we observe that it is often easier to collect a large amount of non-sequence samples , or snapshots of the dynamic process of interest .", "In this work , we assume a small amount of time series data are available , and propose methods to incorporate non-sequence data into penalized least-square estimation of VAR models .", "In quite a few modern time series modelling tasks , the collection of reliable time series turns out to be a major challenge , either due to the slow progression of the dynamic process of interest , or inaccessibility of repetitive measurements of the same dynamic process over time .", "We consider non-sequence data as samples drawn from the stationary distribution of the underlying VAR model , and devise a novel penalization scheme based on the Lyapunov equation concerning the covariance of the stationary distribution .", "Vector Auto-regressive models ( VAR ) are useful tools for analyzing time series data .", "Experiments on synthetic and video data demonstrate the effectiveness of the proposed methods ."]}
{"orig_sents": ["0", "6", "1", "5", "2", "3", "4"], "shuf_sents": ["Most existing Multiple-Instance Learning ( MIL ) algorithms assume data instances and/or data bags are independently and identically distributed .", "Ignoring this structure information limits the performance of existing MIL algorithms .", "In particular , an effective and efficient optimization algorithm has been proposed to solve the original non-convex optimization problem by using a combination of ConcaveConvex Constraint Programming ( CCCP ) method and an adapted Cutting Plane method , which deals with two sets of constraints caused by learning on instances within individual bags and learning on structured data .", "Our method has the nice convergence property , with specified precision on each set of constraints .", "Experimental results on three different applications , i.e. , webpage classification , market targeting , and protein fold identification , clearly demonstrate the advantages of the proposed method over state-of-the-art methods .", "This paper explores the research problem as multiple instance learning on structured data ( MILSD ) and formulates a novel framework that considers additional structure information .", "But there often exists rich additional dependency/structure information between instances/bags within many applications of MIL ."]}
{"orig_sents": ["1", "0", "3", "2", "4"], "shuf_sents": ["Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research .", "We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology .", "We propose a structured learning approach that allows to learn optimum parameters automatically from a training set .", "Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search .", "This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["As a typical result , we prove that for an the agent following the greedy policy with respect to an action-value function Q , - Q 1+ performance loss E V ( X ) - V ( X ) is upper bounded by O ( Q ) , in which 0 is the parameter quantifying the action-gap regularity .", "The goal of this paper is to explain and formalize this phenomenon by introducing the concept of the action-gap regularity .", "Finally , we show how this regularity affects the performance of the family of approximate value iteration algorithms .", "Many practitioners of reinforcement learning problems have observed that oftentimes the performance of the agent reaches very close to the optimal performance even though the estimated ( action- ) value function is still far from the optimal one .", "For > 0 , our results indicate smaller performance loss compared to what previous analyses had suggested ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["DFC divides a large-scale matrix factorization task into smaller subproblems , solves each subproblem in parallel using an arbitrary base matrix factorization algorithm , and combines the subproblem solutions using techniques from randomized matrix approximation .", "Moreover , our analysis shows that DFC enjoys high-probability recovery guarantees comparable to those of its base algorithm .", "This work introduces Divide-Factor-Combine ( DFC ) , a parallel divide-andconquer framework for noisy matrix factorization .", "Our experiments with collaborative filtering , video background modeling , and simulated data demonstrate the near-linear to super-linear speed-ups attainable with this approach ."]}
{"orig_sents": ["1", "7", "3", "8", "6", "5", "4", "0", "2"], "shuf_sents": ["Lastly , we evaluate our algorithm on two case studies , in the context of automated vaccine design and sensor management .", "How should we design experiments to maximize performance of a complex system , taking into account uncontrollable environmental conditions ?", "We show that context-sensitive optimization outperforms no or naive use of context .", "These tasks can be formalized as contextual bandit problems , where at each round , we receive context ( about the experimental conditions , the query ) , and have to choose an action ( parameters , documents ) .", "We further provide generic tools for deriving regret bounds when using such composite kernel functions .", "We show that by mixing and matching kernels for contexts and actions , CGP-UCB can handle a variety of practical applications .", "We model the payoff function as a sample from a Gaussian process defined over the joint context-action space , and develop CGP-UCB , an intuitive upper-confidence style algorithm .", "How should we select relevant documents ( ads ) to display , given information about the user ?", "The key challenge is to trade off exploration by gathering data for estimating the mean payoff function over the context-action space , and to exploit by choosing an action deemed optimal based on the gathered data ."]}
{"orig_sents": ["5", "2", "4", "0", "1", "3"], "shuf_sents": ["Second , in combination of a sparse penalty , the method is extended to variable selection , following the approach by Chen et al .", ".", "First , a method of linear feature extraction is proposed using the gradient of regression function , based on the recent development of the kernel method .", "Experimental results show that the proposed methods successfully find effective features and variables without parametric models .", "In comparison with other existing methods , the proposed one has wide applicability without strong assumptions on the regressor or type of variables , and uses computationally simple eigendecomposition , thus applicable to large data sets .", "We propose a novel kernel approach to dimension reduction for supervised learning : feature extraction and variable selection ; the former constructs a small number of features from predictors , and the latter finds a subset of predictors ."]}
{"orig_sents": ["1", "0", "2", "5", "4", "3"], "shuf_sents": ["Here we argue that a neural system that emulates Bayesian inference is naturally constrained by the way it represents sensory information in populations of neurons .", "A common challenge for Bayesian models of perception is the fact that the two fundamental Bayesian components , the prior distribution and the likelihood function , are formally unconstrained .", "More specifically , we show that an efficient coding principle creates a direct link between prior and likelihood based on the underlying stimulus distribution .", "Our results suggest that efficient coding is a promising hypothesis in constraining Bayesian models of perceptual inference .", "We demonstrate that our framework correctly accounts for the repulsive biases previously reported for the perception of visual orientation , and show that the predicted tuning characteristics of the model neurons match the reported orientation tuning properties of neurons in primary visual cortex .", "The resulting Bayesian estimates can show biases away from the peaks of the prior distribution , a behavior seemingly at odds with the traditional view of Bayesian estimation , yet one that has been reported in human perception ."]}
{"orig_sents": ["0", "6", "4", "2", "1", "3", "5"], "shuf_sents": ["An important way to make large training sets is to gather noisy labels from crowds of nonexperts .", "We infer the ground truth by minimizing the entropy of this distribution , which we show minimizes the Kullback-Leibler ( KL ) divergence between the probability distribution and the unknown truth .", "By maximizing the entropy of this distribution , the method naturally infers item confusability and worker expertise .", "We show that a simple coordinate descent scheme can optimize minimax entropy .", "Our method assumes that labels are generated by a probability distribution over workers , items , and labels .", "Empirically , our results are substantially better than previously published methods for the same problem .", "We propose a minimax entropy principle to improve the quality of these labels ."]}
{"orig_sents": ["4", "0", "2", "3", "1"], "shuf_sents": ["Exact inference in realworld applications of these problems is intractable , making efficient approximation methods essential for learning and inference .", "We present experimental results with bipartite matching problems -- ranking and image correspondence -- which show that the sequential matching sampler efficiently approximates the target distribution , significantly outperforming other sampling approaches .", "In this paper we propose a novel sequential matching sampler based on a generalization of the PlackettLuce model , which can effectively make large moves in the space of matchings .", "This allows the sampler to match the difficult target distributions common in these problems : highly multimodal distributions with well separated modes .", "Bipartite matching problems characterize many situations , ranging from ranking in information retrieval to correspondence in vision ."]}
{"orig_sents": ["6", "0", "5", "7", "4", "1", "3", "2"], "shuf_sents": ["For = 1/ , polynomial time and sample complexity is achievable using the hinge-loss .", "We derive positive results interpolating between the polynomial time for = 1/ and the exponential time for = 0 .", "Our results naturally extend to the adversarial online learning model and to the PAC learning with malicious noise model .", "In particular , we show that there are cases in which = o ( 1/ ) but the problem is still solvable in polynomial time .", "An immediate question , which this paper tackles , is what is achievable if ( 0 , 1/ ) .", "For = 0 , Shalev-Shwartz et al .", "Given , , we study the time complexity required to improperly learn a halfspace with misclassification error rate of at most ( 1 + ) L + , where L is the optimal -margin error rate .", "showed that poly ( 1/ ) time is impossible , while learning is possible in time exp ( O ( 1/ ) ) ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["At its heart lies a novel proposal distribution using random projections to achieve high throughput in generating proposals , which is crucial for clustering models with large numbers of clusters .", "Clustering is a key component in any data analysis toolbox .", "Despite its importance , scalable algorithms often eschew rich statistical models in favor of simpler descriptions such as k-means clustering .", "In this paper we present a sampler , capable of estimating mixtures of exponential families ."]}
{"orig_sents": ["3", "4", "0", "2", "1", "5"], "shuf_sents": ["In order to learn its parameters , maximum likelihood was used .", "The resulting Bayesian WGP is then able to work in scenarios in which the maximum likelihood WGP failed : Low data regime , data with censored values , classification , etc .", "In this work we show that it is possible to use a non-parametric nonlinear transformation in WGP and variationally integrate it out .", "Warped Gaussian processes ( WGP ) model output observations in regression tasks as a parametric nonlinear transformation of a Gaussian process ( GP ) .", "The use of this nonlinear transformation , which is included as part of the probabilistic model , was shown to enhance performance by providing a better prior model on several data sets .", "We demonstrate the superior performance of Bayesian warped GPs on several real data sets ."]}
{"orig_sents": ["2", "0", "5", "3", "1", "4"], "shuf_sents": ["This problem occurs whenever models can not be compared on held-out training data , possibly because the training data are unavailable or do not reflect the desired test distribution .", "We derive the sampling distribution that maximizes the power of a statistical test applied to the observed empirical risks , and thereby minimizes the likelihood of choosing the inferior model .", "We address the problem of comparing the risks of two given predictive models -- for instance , a baseline model and a challenger -- as confidently as possible on a fixed labeling budget .", "We devise an active comparison method that selects instances according to an instrumental sampling distribution .", "Empirically , we investigate model selection problems on several classification and regression tasks and study the accuracy of the resulting p-values .", "In this case , new test instances have to be drawn and labeled at a cost ."]}
{"orig_sents": ["0", "1", "4", "2", "3"], "shuf_sents": ["In this work we consider a setting where we have a very large number of related tasks with few examples from each individual task .", "Rather than either learning each task individually ( and having a large generalization error ) or learning all the tasks together using a single hypothesis ( and suffering a potentially large inherent error ) , we consider learning a small pool of shared hypotheses .", "We derive VC dimension generalization bounds for our model , based on the number of tasks , shared hypothesis and the VC dimension of the hypotheses class .", "We conducted experiments with both synthetic problems and sentiment of reviews , which strongly support our approach .", "Each task is then mapped to a single hypothesis in the pool ( hard association ) ."]}
{"orig_sents": ["0", "3", "2", "1", "6", "4", "5"], "shuf_sents": ["Recent work in unsupervised feature learning has focused on the goal of discovering high-level features from unlabeled images .", "Though a handful of prior results suggest that this is possible when each object class accounts for a large fraction of the data ( as in many labeled datasets ) , it is unclear whether something similar can be accomplished when dealing with completely unlabeled data .", "In this paper , we aim to test the hypothesis that unsupervised feature learning methods , provided with only unlabeled data , can learn high-level , invariant features that are sensitive to commonly-occurring objects .", "Much progress has been made in this direction , but in most cases it is still standard to use a large amount of labeled data in order to construct detectors sensitive to object classes or other complex patterns in the data .", "Here , we propose a large-scale feature learning system that enables us to carry out this experiment , learning 150,000 features from tens of millions of unlabeled images .", "Based on two scalable clustering algorithms ( K-means and agglomerative clustering ) , we find that our simple system can discover features sensitive to a commonly occurring object class ( human faces ) and can also combine these into detectors invariant to significant global distortions like large translations and scale .", "A major obstacle to this test , however , is scale : we can not expect to succeed with small datasets or with small numbers of learned features ."]}
{"orig_sents": ["4", "7", "2", "5", "0", "3", "6", "1"], "shuf_sents": ["We prove that for large i.i.d .", "The adaptive GAMP methodology thus provides a systematic , general and computationally efficient method applicable to a large range of complex linear-nonlinear models with provable guarantees .", "We present a method , called adaptive generalized approximate message passing ( Adaptive GAMP ) , that enables joint learning of the statistics of the prior and measurement channel along with estimation of the unknown vector x .", "Gaussian transform matrices the asymptotic componentwise behavior of the adaptive GAMP algorithm is predicted by a simple set of scalar state evolution equations .", "We consider the estimation of an i.i.d .", "Our method can be applied to a large class of learning problems including the learning of sparse priors in compressed sensing or identification of linear-nonlinear cascade models in dynamical systems and neural spiking processes .", "This analysis shows that the adaptive GAMP method can yield asymptotically consistent parameter estimates , which implies that the algorithm achieves a reconstruction quality equivalent to the oracle algorithm that knows the correct parameter values .", "vector x Rn from measurements y Rm obtained by a general cascade model consisting of a known linear transform followed by a probabilistic componentwise ( possibly nonlinear ) measurement channel ."]}
{"orig_sents": ["5", "6", "0", "1", "4", "3", "2"], "shuf_sents": ["Specifically , the network differences are generated from node perturbations : a few nodes are perturbed across networks , and most or all edges stemming from such nodes differ between networks .", "This corresponds to a simple model for the mechanism underlying many cancers , in which the gene regulatory network is disrupted due to the aberrant activity of a few specific genes .", "Our proposal is illustrated on synthetic data and on an application to brain cancer gene expression data .", "We then solve the convex problem using an alternating directions method of multipliers algorithm .", "We propose to solve this problem using the perturbed-node joint graphical lasso , a convex optimization problem that is based upon the use of a row-column overlap norm penalty .", "We consider estimation of multiple high-dimensional Gaussian graphical models corresponding to a single set of nodes under several distinct conditions .", "We assume that most aspects of the networks are shared , but that there are some structured differences between them ."]}
{"orig_sents": ["1", "8", "2", "4", "5", "6", "3", "0", "7"], "shuf_sents": ["In addition , we show that the VC bound for linear classifiers can be recovered from our bound under mild conditions .", "Margin is one of the most important concepts in machine learning .", "A major advantage of this dimensionality independency is that it can explain the excellent performance of SVM whose feature spaces are often of high or infinite dimension .", "We show that our bound is strictly sharper than a previously well-known PAC-Bayes margin bound if the feature space is of finite dimension ; and the two bounds tend to be equivalent as the dimension goes to infinity .", "In this paper we address the problem whether such dimensionality independency is intrinsic for the margin bounds .", "We prove a dimensionality dependent PAC-Bayes margin bound .", "The bound is monotone increasing with respect to the dimension when keeping all other factors fixed .", "We conduct extensive experiments on benchmark datasets and find that the new bound is useful for model selection and is usually significantly sharper than the dimensionality independent PAC-Bayes margin bound as well as the VC bound for linear classifiers .", "Previous margin bounds , both for SVM and for boosting , are dimensionality independent ."]}
{"orig_sents": ["5", "6", "3", "7", "1", "0", "2", "4"], "shuf_sents": ["Several previously proposed structural regularization based multiple-output regression models turn out to be special cases of our model .", "More importantly , unlike some of the other existing methods , none of these structures need be known a priori in our model , and are learned from the data .", "Moreover , in addition to being a rich model for multiple-output regression , our model can also be used in estimating the graphical model structure of a set of variables ( multivariate outputs ) conditioned on another set of variables ( inputs ) .", "In this paper , we present a multiple-output regression model that leverages the covariance structure of the latent model parameters as well as the conditional covariance structure of the observed outputs .", "Experimental results on both synthetic and real datasets demonstrate the effectiveness of our method .", "Multiple-output regression models require estimating multiple parameters , one for each output .", "Structural regularization is usually employed to improve parameter estimation in such models .", "This is in contrast with existing methods that usually take into account only one of these structures ."]}
{"orig_sents": ["2", "6", "0", "5", "3", "1", "4"], "shuf_sents": ["However , whether these measures have further predictive power to infer a trajectory of cognitive performance over time is still an under-explored but important topic in AD research .", "The sparsity of the model enables the selection of a small number of imaging measures while maintaining high prediction accuracy .", "Alzheimer 's disease ( AD ) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions .", "The proposed model explores the temporal correlations existing in imaging and cognitive data by structured sparsity-inducing norms .", "The empirical studies , using the longitudinal imaging and cognitive data of the ADNI cohort , have yielded promising results .", "We propose a novel high-order multi-task learning model to address this issue .", "Regression analysis has been studied to relate neuroimaging measures to cognitive status ."]}
{"orig_sents": ["7", "1", "0", "6", "2", "9", "3", "10", "11", "5", "8", "4"], "shuf_sents": ["This interesting connection opens up many opportunities bridging graph theoretic algorithms and machine learning .", "In this paper we establish that the Lovasz function is equivalent to a kernel learning problem related to one class SVM .", "This leads to novel use of SVM techniques for solving algorithmic problems in large graphs e.g .", "A classic approach for this problem involves computing the function , however it is not scalable due to SDP computation .", "The proposed algorithm achieves an order of magnitude scalability compared to state of the art methods .", "We introduce the notion of common orthogonal labelling and show that it can be computed by solving a Multiple Kernel learning problem .", "We show that there exist graphs , which we call SVM - graphs , on which the Lovasz function can be approximated well by a one-class SVM .", "The Lovasz function of a graph , a fundamental tool in combinatorial optimization and approximation algorithms , is computed by solving a SDP .", "It is further shown that such a labelling is extremely useful in identifying a large common dense subgraph in multiple graphs , which is known to be a computationally difficult problem .", "identifying a planted clique of size ( n ) in a random graph G ( n , 21 ) .", "We show that the random graph with a planted clique is an example of SVM - graph .", "As a consequence a SVM based approach easily identifies the clique in large graphs and is competitive with the state-of-the-art ."]}
{"orig_sents": ["5", "7", "6", "1", "3", "0", "2", "4"], "shuf_sents": ["We then develop a penalized version for the noisy setting which can be solved using second order cone programs .", "As a first application we consider recovering a sparse probability measure given moment constraints , in which our formulation becomes linear programming , hence can be solved very efficiently .", "The proposed method outperforms known rescaling heuristics based on 1 norm .", "A sufficient condition for exact recovery of the minimum cardinality solution is derived for arbitrary affine constraints .", "As a second application we consider convex clustering using a sparse Gaussian mixture and compare our results with the well known soft k-means algorithm .", "We consider the problem of cardinality penalized optimization of a convex function over the probability simplex with additional convex constraints .", "We propose a direct relaxation of the minimum cardinality problem and show that it can be efficiently solved using convex programming .", "The classical 1 regularizer fails to promote sparsity on the probability simplex since 1 norm on the probability simplex is trivially constant ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["As a consequence , we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility , measured by convergence rate , of any statistical estimator .", "We study statistical risk minimization problems under a version of privacy in which the data is kept confidential even from the learner .", "In this local privacy framework , we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["Using a multiplicative assumption we show how to update the forest likelihood in closed form , producing efficient model updates .", "Continuous-time Bayesian networks effectively model such processes but are limited by the number of conditional intensity matrices , which grows exponentially in the number of parents per variable .", "Our results show multiplicative forests can be learned from few temporal trajectories with large gains in performance and scalability .", "We develop a partition-based representation using regression trees and forests whose parameter spaces grow linearly in the number of node splits .", "Learning temporal dependencies between variables over continuous time is an important and challenging task ."]}
{"orig_sents": ["6", "3", "8", "5", "9", "0", "7", "2", "4", "1"], "shuf_sents": ["Herein we consider the estimation of a trade-off parameter balancing sparsity and data fit .", "It also facilitates the analysis of Type II when non-Gaussian likelihood models lead to intractable integrations .", "In contrast , for analyses of update rules and sparsity properties of local and global solutions , as well as extensions to more general likelihood models , we can leverage coefficient-space techniques developed for Type I and apply them to Type II .", "These priors can conveniently be expressed as a maximization over zero-mean Gaussians with different variance hyperparameters .", "For example , this allows us to prove that Type II-inspired techniques can be successful recovering sparse coefficients when unfavorable restricted isometry properties ( RIP ) lead to failure of popular 1 reconstructions .", "The underlying cost functions can be related via a dual-space framework from , which allows both the Type I or Type II objectives to be expressed in either coefficient or hyperparmeter space .", "Sparse linear ( or generalized linear ) models combine a standard likelihood function with a sparse prior on the unknown coefficients .", "As this parameter is effectively a variance , natural estimators exist by assessing the problem in hyperparameter ( variance ) space , transitioning natural ideas from Type II to solve what is much less intuitive for Type I .", "Standard MAP estimation ( Type I ) involves maximizing over both the hyperparameters and coefficients , while an empirical Bayesian alternative ( Type II ) first marginalizes the coefficients and then maximizes over the hyperparameters , leading to a tractable posterior approximation .", "This perspective is useful because some analyses or extensions are more conducive to development in one space or the other ."]}
{"orig_sents": ["6", "2", "0", "1", "7", "3", "5", "4"], "shuf_sents": ["We propose a model that is generic enough to handle any supervised learning task and also subsumes the model previously proposed for classification .", "We give a `` goodness '' criterion for similarity functions w.r.t .", "Existing work on learning with indefinite kernels has concentrated solely on binary/multiclass classification problems .", "We demonstrate the effectiveness of our model on three important supervised learning problems : a ) real-valued regression , b ) ordinal regression and c ) ranking where we show that our method guarantees bounded generalization error .", "Finally , we report results of our learning algorithms on regression and ordinal regression tasks using non-PSD similarity functions and demonstrate the effectiveness of our algorithms , especially that of the sparse landmark selection algorithm that achieves significantly higher accuracies than the baseline methods while offering reduced computational costs .", "Furthermore , for the case of real-valued regression , we give a natural goodness definition that , when used in conjunction with a recent result in sparse vector recovery , guarantees a sparse predictor with bounded generalization error .", "We address the problem of general supervised learning when data can only be accessed through an ( indefinite ) similarity function between data points .", "a given supervised learning task and then adapt a well-known landmarking technique to provide efficient algorithms for supervised learning using `` good '' similarity functions ."]}
{"orig_sents": ["0", "2", "1", "3", "4"], "shuf_sents": ["This paper provides lower bounds on the convergence rate of Derivative Free Optimization ( DFO ) with noisy function evaluations , exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations .", "A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons , rather than function evaluations .", "However , there are situations in which DFO is unavoidable , and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions .", "This makes the algorithm useful in an even wider range of applications , such as optimization based on paired comparisons from human subjects , for example .", "We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons , the convergence rate is the same ."]}
{"orig_sents": ["0", "1", "3", "5", "4", "2"], "shuf_sents": ["We show how binary classification methods developed to work on i.i.d .", "data can be used for solving statistical problems that are seemingly unrelated to classification and concern highly-dependent time series .", "The theoretical results are illustrated with experiments on synthetic and real-world data .", "Specifically , the problems of time-series clustering , homogeneity testing and the three-sample problem are addressed .", "Universal consistency of the proposed algorithms is proven under most general assumptions .", "The algorithms that we construct for solving these problems are based on a new metric between time-series distributions , which can be evaluated using binary classification methods ."]}
{"orig_sents": ["3", "2", "0", "4", "6", "1", "5"], "shuf_sents": ["The main idea in these algorithms is to improve the accuracy and scalability of existing graphical models ' inference algorithms by exploiting symmetry in the first-order representation .", "We propose an approach for constructing the clusters and show how it can be used to trade accuracy with computational complexity in a principled manner .", "Lifted probabilistic inference algorithms for them have been the subject of much recent research .", "First-order probabilistic models combine the power of first-order logic , the de facto tool for handling relational structure , with probabilistic graphical models , the de facto tool for handling uncertainty .", "In this paper , we consider blocked Gibbs sampling , an advanced MCMC scheme , and lift it to the first-order level .", "Our experimental evaluation shows that lifted Gibbs sampling is superior to the propositional algorithm in terms of accuracy , scalability and convergence .", "We propose to achieve this by partitioning the first-order atoms in the model into a set of disjoint clusters such that exact lifted inference is polynomial in each cluster given an assignment to all other atoms not in the cluster ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["This extends the known class of tractable variational approximations and enables the fitting for example of skew variational densities to the target density .", "We consider inference in a broad class of non-conjugate probabilistic models based on minimising the Kullback-Leibler divergence between the given target density and an approximating `variational ' density .", "In particular , for generalised linear models we describe approximating densities formed from an affine transformation of independently distributed latent variables , this class including many well known densities as special cases .", "We show how all relevant quantities can be efficiently computed using the fast Fourier transform ."]}
{"orig_sents": ["5", "4", "9", "2", "3", "6", "0", "10", "1", "7", "8"], "shuf_sents": ["We found that combined low-frequency ( 0.1-5 Hz ) LFP signals from 10 electrodes were predictive of the intended left-/right-hand movements before the onset of the go signal .", "Based on these results , we constructed an ORT system that tracked up to 30 electrodes simultaneously , and tested it on retrospective data from 7 patients .", "In each trial , subjects were given a 5 s countdown , after which they had to raise their left or right hand immediately as the `` go '' signal appeared on a computer screen .", "They won a fixed amount of money if they raised a different hand than their opponent and lost that amount otherwise .", "On-line real-time ( ORT ) prediction is important for understanding the relation between neural correlates of decision-making and conscious , voluntary action as well as for brain-machine interfaces .", "The ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making , agency and volition .", "The question we here studied was the extent to which neural precursors of the subjects ' decisions can be detected in intracranial local field potentials ( LFP ) prior to the onset of the action .", "On average , we could predict the correct hand choice in 83 % of the trials , which rose to 92 % if we let the system drop 3/10 of the trials on which it was less confident .", "Our system demonstrates -- for the first time -- the feasibility of accurately predicting a binary action on single trials in real time for patients with intracranial recordings , well before the action occurs .", "Here , epilepsy patients , implanted with intracranial depth microelectrodes or subdural grid electrodes for clinical purposes , participated in a `` matching-pennies '' game against an opponent .", "Our ORT system predicted which hand the patient would raise 0.5 s before the go signal with 683 % accuracy in two patients ."]}
{"orig_sents": ["6", "7", "1", "0", "4", "3", "5", "2"], "shuf_sents": ["We propose a new optimization objective for risk-aware planning and show that it has desirable theoretical properties .", "In risk-aware settings , however , the expected return is often not an appropriate objective to optimize .", "Synthetic and real-world experiments illustrate the effectiveness of our method , at scale .", "Our method applies to an extended class of Markov decision processes : we allow costs to be stochastic as long as they are bounded .", "We also draw connections to previously proposed objectives for risk-aware planing : minmax , exponential utility , percentile and mean minus variance .", "Additionally , we present an efficient algorithm for optimizing the proposed objective .", "The expected return is a widely used objective in decision making under uncertainty .", "Many algorithms , such as value iteration , have been proposed to optimize it ."]}
{"orig_sents": ["3", "5", "7", "8", "4", "0", "1", "2", "6"], "shuf_sents": ["The optimal decision policy is formally equivalent to a DDM with a timevarying threshold that initially rises after stimulus onset , and collapses again just before the response deadline .", "The initial rise in the threshold is due to the diminishing temporal advantage of choosing the fast Go response compared to the fixeddelay NoGo response .", "We also show that fitting a simpler , fixed-threshold DDM to the optimal model reproduces the counterintuitive result of a higher threshold in GNG than 2AFC decision-making , previously observed in direct DDM fit to behavioral data , although such fixed-threshold approximations can not reproduce the Go bias .", "Two-alternative forced choice ( 2AFC ) and Go/NoGo ( GNG ) tasks are behavioral choice paradigms commonly used to study sensory and cognitive processing in choice behavior .", "We show that a Bayes-risk minimizing decision policy that minimizes not only error rate but also average decision delay naturally exhibits the experimentally observed Go bias .", "While GNG is thought to isolate the sensory/decisional component by eliminating the need for response selection as in 2AFC , a consistent tendency for subjects to make more Go responses ( both higher hits and false alarm rates ) in the GNG task raises the concern that there may be fundamental differences in the sensory or cognitive processes engaged in the two tasks .", "Our results suggest that observed discrepancies between GNG and 2AFC decision-making may arise from rational strategic adjustments to the cost structure , and thus need not imply any other difference in the underlying sensory and cognitive processes .", "Existing mechanistic models of these choice tasks , mostly variants of the drift-diffusion model ( DDM ; ) and the related leaky competing accumulator models , capture various aspects of behavioral performance , but do not clarify the provenance of the Go bias in GNG .", "We postulate that this `` impatience '' to go is a strategic adjustment in response to the implicit asymmetry in the cost structure of the 2AFC and GNG tasks : the NoGo response requires waiting until the response deadline , while a Go response immediately terminates the current trial ."]}
{"orig_sents": ["1", "2", "8", "3", "6", "0", "4", "7", "5"], "shuf_sents": ["The resulting updates have a simple and intuitive form .", "Sum-product networks are a new deep architecture that can perform fast , exact inference on high-treewidth models .", "Only generative methods for training SPNs have been proposed to date .", "We show that the class of tractable discriminative SPNs is broader than the class of tractable generative ones , and propose an efficient backpropagation-style algorithm for computing the gradient of the conditional log likelihood .", "We test discriminative SPNs on standard image classification tasks .", "We also report the highest published test accuracy on STL-10 even though we only use the labeled portion of the dataset .", "Standard gradient descent suffers from the diffusion problem , but networks with many layers can be learned reliably using `` hard '' gradient descent , where marginal inference is replaced by MPE inference ( i.e. , inferring the most probable state of the non-evidence variables ) .", "We obtain the best results to date on the CIFAR-10 dataset , using fewer features than prior methods with an SPN architecture that learns local image structure discriminatively .", "In this paper , we present the first discriminative training algorithms for SPNs , combining the high accuracy of the former with the representational power and tractability of the latter ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Focusing on the Gaussian copula we extend the analytical IB solution available for the multivariate Gaussian case to distributions with a Gaussian dependence structure but arbitrary marginal densities , also called meta-Gaussian distributions .", "We present a reformulation of the information bottleneck ( IB ) problem in terms of copula , using the equivalence between mutual information and negative copula entropy .", "This opens new possibles applications of IB to continuous data and provides a solution more robust to outliers ."]}
{"orig_sents": ["4", "8", "0", "6", "3", "2", "5", "1", "7"], "shuf_sents": ["More precisely , given a data matrix X , the algorithm identifies a matrix C that satisfies X CX and some linear constraints .", "Experiments with synthetic and real datasets provide evidence that the new approach is also superior in practice .", "( 2012 ) .", "A theoretical analysis demonstrates that this approach has guarantees similar to those of the recent NMF algorithm of Arora et al .", "This paper describes a new approach , based on linear programming , for computing nonnegative matrix factorizations ( NMFs ) .", "In contrast with this earlier work , the proposed method extends to more general noise models and leads to efficient , scalable algorithms .", "The constraints are chosen to ensure that the matrix C selects features ; these features can then be used to find a low-rank NMF of X .", "An optimized C++ implementation can factor a multigigabyte matrix in a matter of minutes .", "The key idea is a data-driven model for the factorization where the most salient features in the data are used to express the remaining features ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We prove that the estimate returned by the algorithm is almost similarly accurate as the estimate that an optimal oracle strategy ( that would know the variations of the function everywhere ) would return , and provide a finite-sample analysis .", "We consider the problem of adaptive stratified sampling for Monte Carlo integration of a differentiable function given a finite number of evaluations to the function .", "We construct a sampling scheme that samples more often in regions where the function oscillates more , while allocating the samples such that they are well spread on the domain ( this notion shares similitude with low discrepancy ) ."]}
{"orig_sents": ["4", "2", "1", "0", "5", "3", "6", "7"], "shuf_sents": ["In this paper , we propose a novel MLNP algorithm that ( i ) considers the global hierarchy structure ; and ( ii ) can be used on hierarchies of both trees and DAGs .", "However , while there have been a lot of MLNP methods in hierarchical multiclass classification , performing MLNP in hierarchical multilabel classification is much more difficult .", "This is called mandatory leaf node prediction ( MLNP ) and is particularly useful when the leaf nodes have much stronger semantic meaning than the internal nodes .", "Moreover , this can be further extended to the minimization of the expected symmetric loss .", "In hierarchical classification , the prediction paths may be required to always end at leaf nodes .", "We show that one can efficiently maximize the joint posterior probability of all the node labels by a simple greedy algorithm .", "Experiments are performed on a number of real-world data sets with tree- and DAG-structured label hierarchies .", "The proposed method consistently outperforms other hierarchical and flat multilabel classification methods ."]}
{"orig_sents": ["3", "4", "0", "2", "1"], "shuf_sents": ["Here we show that they provide natural priors for Bayesian entropy estimation , due to the analytic tractability of the moments of the induced posterior distribution over entropy H. We derive formulas for the posterior mean and variance of H given data .", "We therefore define a family of continuous mixing measures such that the resulting mixture of Dirichlet or Pitman-Yor processes produces an approximately flat prior over H. We explore the theoretical properties of the resulting estimators and show that they perform well on data sampled from both exponential and power-law tailed distributions .", "However , we show that a fixed Dirichlet or Pitman-Yor process prior implies a narrow prior on H , meaning the prior strongly determines the estimate in the under-sampled regime .", "We consider the problem of estimating Shannon 's entropy H in the under-sampled regime , where the number of possible symbols may be unknown or countably infinite .", "Dirichlet and Pitman-Yor processes provide tractable prior distributions over the space of countably infinite discrete distributions , and have found major applications in Bayesian non-parametric statistics and machine learning ."]}
{"orig_sents": ["6", "4", "5", "1", "3", "0", "2"], "shuf_sents": ["We describe new algorithms that take into account the variable cost ( duration ) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation .", "In this work , we consider this problem through the framework of Bayesian optimization , in which a learning algorithm 's generalization performance is modeled as a sample from a Gaussian process ( GP ) .", "We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation , structured SVMs and convolutional neural networks .", "We show that certain choices for the nature of the GP , such as the type of kernel and the treatment of its hyperparameters , can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance .", "Unfortunately , this tuning is often a `` black art '' requiring expert experience , rules of thumb , or sometimes bruteforce search .", "There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand .", "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters ."]}
{"orig_sents": ["2", "4", "1", "3", "0"], "shuf_sents": ["The algorithm has extensive applications including signal processing , sparse recovery and machine learning and classification .", "The second part of the paper applies the previous result to acceleration of convex minimization problems , and leads to an elegant quasi-Newton method .", "A new result in convex analysis on the calculation of proximity operators in certain scaled norms is derived .", "The optimization method compares favorably against state-of-the-art alternatives .", "We describe efficient implementations of the proximity calculation for a useful class of functions ; the implementations exploit the piece-wise linear nature of the dual problem ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["This is in contrast to general linear programming , for which no sub-polynomial pivot rule is known .", "The paramount complexity parameter in linear classification problems is called the margin .", "We present a simplex algorithm for linear programming in a linear classification formulation .", "We prove that for margin values of practical interest our simplex variant performs a polylogarithmic number of pivot steps in the worst case , and its overall running time is near linear ."]}
{"orig_sents": ["8", "9", "3", "5", "7", "4", "1", "6", "0", "2"], "shuf_sents": ["We achieve an area under the receiver operating characteristic curve of 0.79 on a held-out set of several hundred patients .", "Once obtained , we use these signals to explore different approaches to time-series classification with the goal of identifying high-risk patterns .", "Our two-stage approach to risk stratification outperforms classifiers that consider only a patient 's current state ( p < 0.05 ) .", "In this paper , we represent patient risk as a time series .", "Thus , we begin by defining and extracting approximate risk processes , the evolving approximate daily risk of a patient .", "In doing so , patient risk stratification becomes a time-series classification task .", "We apply the classification to the specific task of identifying patients at risk of testing positive for hospital acquired Clostridium difficile .", "The task differs from most applications of time-series analysis , like speech processing , since the time series itself must first be extracted .", "A patient 's risk for adverse events is affected by temporal processes including the nature and timing of diagnostic and therapeutic activities , and the overall evolution of the patient 's pathophysiology over time .", "Yet many investigators ignore this temporal aspect when modeling patient outcomes , considering only the patient 's current or aggregate state ."]}
{"orig_sents": ["2", "0", "7", "4", "3", "6", "8", "5", "9", "1"], "shuf_sents": ["Hower , despite considerable research efforts , contact prediction methods are still largely unreliable .", "Furthermore , the approach is applicable to other problems with strong underlying spatial and temporal components .", "Residue-residue contact prediction is a fundamental problem in protein structure prediction .", "The temporal dimension is introduced to capture the fact that protein folding is not an instantaneous process , but rather a progressive refinement .", "For contact prediction , the idea is implemented as a three-dimensional stack of Neural Networks NNkij , where i and j index the spatial coordinates of the contact map and k indexes `` time '' .", "The deep approach leads to an accuracy for difficult long-range contacts of about 30 % , roughly 10 % above the state-of-the-art .", "Networks at level k in the stack can be trained in supervised fashion to refine the predictions produced by the previous level , hence addressing the problem of vanishing gradients , typical of deep architectures .", "Here we introduce a novel deep machine-learning architecture which consists of a multidimensional stack of learning modules .", "Increased accuracy and generalization capabilities of this approach are established by rigorous comparison with other classical machine learning approaches for contact prediction .", "Many variations in the architectures and the training algorithms are possible , leaving room for further improvements ."]}
{"orig_sents": ["1", "3", "2", "4", "0"], "shuf_sents": ["The resulting qualitative behavior matches experimental data from visual cortex .", "To learn reliable rules that can generalize to novel situations , the brain must be capable of imposing some form of regularization .", "The functional role of regularization is considered in a general context in which coupled computational systems receive inputs corrupted by correlated noise .", "Here we suggest , through theoretical and computational arguments , that the combination of noise with synchronization provides a plausible mechanism for regularization in the nervous system .", "Noise on the inputs is shown to impose regularization , and when synchronization upstream induces time-varying correlations across noise variables , the degree of regularization can be calibrated over time ."]}
{"orig_sents": ["4", "0", "5", "2", "3", "6", "1"], "shuf_sents": ["We extend the notion of classification calibration , which has been studied for binary and multiclass 0-1 classification problems ( and for certain other specific learning problems ) , to the general multiclass setting , and derive necessary and sufficient conditions for a surrogate loss to be classification calibrated with respect to a loss matrix in this setting .", "We anticipate the classification calibration dimension may prove to be a useful tool in the study and design of surrogate losses for general multiclass learning problems .", "We derive both upper and lower bounds on this quantity , and use these results to analyze various loss matrices .", "In particular , as one application , we provide a different route from the recent result of Duchi et al .", "We study consistency properties of surrogate loss functions for general multiclass classification problems , defined by a general loss matrix .", "We then introduce the notion of classification calibration dimension of a multiclass loss matrix , which measures the smallest `size ' of a prediction space for which it is possible to design a convex surrogate that is classification calibrated with respect to the loss matrix .", "( 2010 ) for analyzing the difficulty of designing `low-dimensional ' convex surrogates that are consistent with respect to pairwise subset ranking losses ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a fixed distribution .", "This provides new insights into how market prices ( and price paths ) may be interpreted as a summary of the market 's belief distribution by relating them to the optimization problem being solved .", "In particular , we show that under certain conditions the stationary point of the stochastic process of prices generated by the market is equal to the market 's Walrasian equilibrium of classic market analysis .", "Together , these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour ."]}
{"orig_sents": ["1", "3", "2", "6", "5", "4", "0", "7"], "shuf_sents": ["We also present necessary conditions for graph estimation by any method and show that our method nearly matches the lower bound on sample requirements .", "Graphical model selection refers to the problem of estimating the unknown graph structure given observations at the nodes in the model .", "We characterize conditions for tractable graph estimation and develop efficient methods with provable guarantees .", "We consider a challenging instance of this problem when some of the nodes are latent or hidden .", "The proposed method is practical to implement and provides flexibility to control the number of latent variables and the cycle lengths in the output graph .", "We propose an efficient method for graph estimation , and establish its structural consistency - ( +1 ) -2 when the number of samples n scales as n = ( min log p ) , where min is the minimum edge potential , is the depth ( i.e. , distance from a hidden node to the nearest observed nodes ) , and is a parameter which depends on the minimum and maximum node and edge potentials in the Ising model .", "We consider the class of Ising models Markov on locally tree-like graphs , which are in the regime of correlation decay .", "Keywords : Graphical model selection , latent variables , quartet methods , locally tree-like graphs ."]}
{"orig_sents": ["2", "1", "4", "0", "3"], "shuf_sents": ["Secondly , we show how the approximation scheme we consider naturally motivates the use of 1 regularisation to improve estimates and obtain a sparse approximate inverse of the metric , which enables stable and sparse approximations of the local geometry to be made .", "The recent introduction of locally adaptive MCMC methods based on the natural underlying Riemannian geometry of such models goes some way to alleviating these problems for certain classes of models for which the metric tensor is analytically tractable , however computational efficiency is not assured due to the necessity of potentially high-dimensional matrix operations at each iteration .", "One of the enduring challenges in Markov chain Monte Carlo methodology is the development of proposal mechanisms to make moves distant from the current point , that are accepted with high probability and at low computational cost .", "We demonstrate the application of this algorithm for inferring the parameters of a realistic system of ordinary differential equations using a biologically motivated robust Student-t error model , for which the Expected Fisher Information is analytically intractable .", "In this paper we firstly investigate a sampling-based approach for approximating the metric tensor and suggest a valid MCMC algorithm that extends the applicability of Riemannian Manifold MCMC methods to statistical models that do not admit an analytically computable metric tensor ."]}
{"orig_sents": ["0", "2", "3", "8", "4", "5", "6", "7", "1"], "shuf_sents": ["Our personal social networks are big and cluttered , and currently there is no good way to organize them .", "Experiments show that our model accurately identifies circles on a diverse set of data from Facebook , Google+ , and Twitter for all of which we obtain hand-labeled ground-truth .", "Social networking sites allow users to manually categorize their friends into social circles ( e.g .", "`circles ' on Google+ , and `lists ' on Facebook and Twitter ) , however they are laborious to construct and must be updated whenever a user 's network grows .", "We pose the problem as a node clustering problem on a user 's ego-network , a network of connections between her friends .", "We develop a model for detecting circles that combines network structure as well as user profile information .", "For each circle we learn its members and the circle-specific user profile similarity metric .", "Modeling node membership to multiple circles allows us to detect overlapping as well as hierarchically nested circles .", "We define a novel machine learning task of identifying users ' social circles ."]}
{"orig_sents": ["5", "2", "6", "0", "3", "8", "1", "7", "4"], "shuf_sents": ["This work approaches the exploration of a family of SAT solvers as a learning problem .", "Furthermore , we show that a simple perceptron-style learning rule will find an optimal SAT solver with a bounded number of training updates .", "In practice , real-world SAT sentences are drawn from a distribution that may result in efficient algorithms for their solution .", "In particular , we relate polynomial time solvability of a SAT subset to a notion of margin between sentences mapped by a feature function into a Hilbert space .", "Empirical results show an order of magnitude improvement over a state-of-the-art SAT solver on a hardware verification task .", "Boolean satisfiability ( SAT ) as a canonical NP-complete decision problem is one of the most important problems in computer science .", "Such SAT instances are likely to have shared characteristics and substructures .", "We derive a linear time computable set of features and show analytically that margins exist for important polynomial special cases of SAT .", "Provided this mapping is based on polynomial time computable statistics of a sentence , we show that the existance of a margin between these data points implies the existance of a polynomial time solver for that SAT subset based on the Davis-Putnam-Logemann-Loveland algorithm ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["Our method performs better than previous stochastic variational inference algorithms .", "We studied our method with Dirichlet process mixture models and hierarchical Dirichlet process topic models on two large data sets .", "We present a truncation-free stochastic variational inference algorithm for Bayesian nonparametric models .", "While traditional variational inference algorithms require truncations for the model or the variational distribution , our method adapts model complexity on the fly ."]}
{"orig_sents": ["3", "1", "0", "2", "4"], "shuf_sents": ["We show that the new algorithm has highly competitive computational complexity , matching that of alternative approximate inference methods .", "Our method constructs a concave lower bound that is optimized using an efficient fixed-point updating algorithm .", "We also prove that the use of concave variational bounds provides stable and guaranteed convergence - a property not available to other approaches .", "We present a new variational inference algorithm for Gaussian process regression with non-conjugate likelihood functions , with application to a wide array of problems including binary and multi-class classification , and ordinal regression .", "We show empirically for both binary and multi-class classification that our new algorithm converges much faster than existing variational methods , and without any degradation in performance ."]}
{"orig_sents": ["3", "1", "4", "6", "2", "0", "5"], "shuf_sents": ["Given t observations of the function , the posterior can be evaluated efficiently in time O ( t2 ) up to a multiplicative constant .", "Previous work has focused on representing possible functions explicitly , which leads to a two-step procedure of first , doing inference over the function space and second , finding the extrema of these functions .", "The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function .", "We propose a novel Bayesian approach to solve stochastic optimization problems that involve finding extrema of noisy , nonlinear functions .", "Here we skip the representation step and directly model the distribution over extrema .", "Finally , we show how to apply our model to optimize a noisy , non-convex , high-dimensional objective function .", "To this end , we devise a non-parametric conjugate prior based on a kernel regressor ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We also bound the looseness of the elastic net , thus shedding new light on it and providing justification for its use .", "We derive a novel norm that corresponds to the tightest convex relaxation of sparsity combined with an 2 penalty .", "We show that this new k-support norm provides a tighter relaxation than the elastic net and can thus be advantageous in in sparse prediction problems ."]}
{"orig_sents": ["1", "0", "5", "3", "2", "4"], "shuf_sents": ["We consider the case where the structure of the graph to be reconstructed is known to be scale-free .", "A key problem in statistics and machine learning is the determination of network structure from data .", "We show that our method results in an improvement in the accuracy of reconstructed networks for synthetic data .", "For tractable classes such as Gaussian graphical models , this leads to a convex optimization problem that can be efficiently solved .", "We also show how our prior encourages scale-free reconstructions on a bioinfomatics dataset .", "We show that in such cases it is natural to formulate structured sparsity inducing priors using submodular functions , and we use their Lovasz extension to obtain a convex relaxation ."]}
{"orig_sents": ["1", "6", "0", "7", "2", "3", "4", "5"], "shuf_sents": ["The learned distance measure is , however , non-metric , which has prevented multi-metric learning from generalizing to tasks such as dimensionality reduction and regression in a principled way .", "Multi-metric learning techniques learn local metric tensors in different parts of a feature space .", "We then show that this structure gives us a principled way to perform dimensionality reduction and regression according to the learned metrics .", "Algorithmically , we provide the first practical algorithm for computing geodesics according to the learned metrics , as well as algorithms for computing exponential and logarithmic maps on the Riemannian manifold .", "Together , these tools let many Euclidean algorithms take advantage of multi-metric learning .", "We illustrate the approach on regression and dimensionality reduction tasks that involve predicting measurements of the human body from shape data .", "With such an approach , even simple classifiers can be competitive with the state-of-the-art because the distance measure locally adapts to the structure of the data .", "We prove that , with appropriate changes , multi-metric learning corresponds to learning the structure of a Riemannian manifold ."]}
{"orig_sents": ["5", "4", "0", "1", "6", "2", "7", "3"], "shuf_sents": ["Hashing is also a promising approach to value function approximation in large discrete domains such as Go and Hearts , where feature vectors can be constructed by exhaustively combining a set of atomic features .", "Unfortunately , the typical use of hashing in value function approximation results in biased value estimates due to the possibility of collisions .", "Our work investigates the application of this new data structure to linear value function approximation .", "We provide empirical results on two RL benchmark domains and fifty-five Atari 2600 games to highlight the superior learning performance obtained when using tug-of-war hashing .", "In reinforcement learning , hashing is often used in conjunction with tile coding to represent states in continuous spaces .", "Hashing is a common method to reduce large , potentially infinite feature vectors to a fixed-size table .", "Recent work in data stream summaries has led to the development of the tug-of-war sketch , an unbiased estimator for approximating inner products .", "Although in the reinforcement learning setting the use of the tug-of-war sketch leads to biased value estimates , we show that this bias can be orders of magnitude less than that of standard hashing ."]}
{"orig_sents": ["5", "0", "6", "3", "1", "4", "2"], "shuf_sents": ["However , in many real world problems , there are significant dependencies in the variances or energies , which indicates that causality may possibly take place at the level of variances or energies .", "We prove the identifiability of this model under the non-Gaussian assumption on the innovation processes .", "Experiments on synthetic and real world data are conducted to show the applicability of the proposed model and algorithms .", "In particular , the causal mechanism including contemporaneous and temporal causal relations in variances or energies is represented by a Structural Vector AutoRegressive model ( SVAR ) .", "We also propose algorithms to estimate the involved parameters and discover the contemporaneous causal structure .", "In conventional causal discovery , structural equation models ( SEM ) are directly applied to the observed variables , meaning that the causal effect can be represented as a function of the direct causes themselves .", "In this paper , we propose a probabilistic causal scale-mixture model with spatiotemporal variance dependencies to represent a specific type of generating mechanism of the observations ."]}
{"orig_sents": ["0", "1", "3", "4", "5", "2"], "shuf_sents": ["The minimax KL-divergence of any distribution from all distributions in a collection P has several practical implications .", "In compression , it is called redundancy and represents the least additional number of bits over the entropy needed to encode the output of any distribution in P. In online estimation and learning , it is the lowest expected log-loss regret when guessing a sequence of random values generated by a distribution in P. In hypothesis testing , it upper bounds the largest number of distinguishable distributions in P. Motivated by problems ranging from population estimation to text classification and speech recognition , several machine-learning and information-theory researchers have recently considered label-invariant observations and properties induced by i.i.d .", "sequences is between 0.3 * n1/3 and n1/3 log2 n , in particular , establishing its exact growth power .", "distributions .", "A sufficient statistic for all these properties is the data 's profile , the multiset of the number of times each data element appears .", "Improving on a sequence of previous works , we show that the redundancy of the collection of distributions induced over profiles by length-n i.i.d ."]}
{"orig_sents": ["2", "5", "4", "0", "1", "3"], "shuf_sents": ["In addition , our method constructs the final solution directly from the proximal mapping instead of averaging of all previous iterates .", "For widely used sparsity-inducing regularizers ( e.g. , 1 -norm ) , it has the advantage of encouraging sparser solutions .", "This paper considers a wide spectrum of regularized stochastic optimization problems where both the loss function and regularizer can be non-smooth .", "We further develop a multistage extension using the proposed algorithm as a subroutine , which achieves the uniformly-optimal rate O ( N1 + exp { -N } ) for strongly convex loss .", "In particular , for strongly convex loss , it achieves the optimal rate of O ( N1 + N12 ) for N iterations , which improves the rate O ( logNN ) for previous regularized dual averaging algorithms .", "We develop a novel algorithm based on the regularized dual averaging ( RDA ) method , that can simultaneously achieve the optimal convergence rates for both convex and strongly convex loss ."]}
{"orig_sents": ["2", "1", "0", "3", "4", "5"], "shuf_sents": ["We propose an algorithm for learning the SPN architecture from data .", "Designing an SPN network architecture that is suitable for the task at hand is an open question .", "The sum-product network ( SPN ) is a recently-proposed deep model consisting of a network of sum and product nodes , and has been shown to be competitive with state-of-the-art deep models on certain difficult tasks such as image completion .", "The idea is to cluster variables ( as opposed to data instances ) in order to identify variable subsets that strongly interact with one another .", "Nodes in the SPN network are then allocated towards explaining these interactions .", "Experimental evidence shows that learning the SPN architecture significantly improves its performance compared to using a previously-proposed static architecture ."]}
{"orig_sents": ["2", "5", "7", "0", "6", "4", "3", "1"], "shuf_sents": ["When there is a substantial difference between the oracle 's ability and the learner 's policy space , we may fail to find a policy that has low error on the training set .", "Experimental results on UCI datasets show that our method outperforms state-of-the-art imitation learning methods in dynamic feature selection and two static feature selection methods .", "Imitation Learning has been shown to be successful in solving many challenging real-world problems .", "We apply our algorithm to cost-sensitive dynamic feature selection , a hard decision problem that considers a user-specified accuracy-cost trade-off .", "By a reduction of learning by demonstration to online learning , we prove that coaching can yield a lower regret bound than using the oracle .", "Some recent approaches give strong performance guarantees by training the policy iteratively .", "In such cases , we propose to use a coach that demonstrates easy-to-learn actions for the learner and gradually approaches the oracle .", "However , it is important to note that these guarantees depend on how well the policy we found can imitate the oracle on the training data ."]}
{"orig_sents": ["1", "2", "5", "3", "4", "0", "6"], "shuf_sents": ["Based on this bound , we propose a clustering algorithm that attempts to minimize this bound , in order to find effective partitions of the variables .", "We consider the composite log-determinant optimization problem , arising from the 1 regularized Gaussian maximum likelihood estimator of a sparse inverse covariance matrix , in a high-dimensional setting with a very large number of variables .", "Recent work has shown this estimator to have strong statistical guarantees in recovering the true structure of the sparse inverse covariance matrix , or alternatively the underlying graph structure of the corresponding Gaussian Markov Random Field , even in very high-dimensional regimes with a limited number of samples .", "Our proposed algorithm partitions the problem into smaller sub-problems , and uses the solutions of the sub-problems to build a good approximation for the original problem .", "Our key idea for the divide step to obtain a sub-problem partition is as follows : we first derive a tractable bound on the quality of the approximate solution obtained from solving the corresponding sub-divided problems .", "In this paper , we are concerned with the computational cost in solving the above optimization problem .", "For the conquer step , we use the approximate solution , i.e. , solution resulting from solving the sub-problems , as an initial point to solve the original problem , and thereby achieve a much faster computational procedure ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["In particular , we establish both theoretically and computationally that our proposal can serve as a viable alternative to state-of-the-art parametric ADP algorithms , freeing the designer from carefully specifying an approximation architecture .", "This paper presents a novel non-parametric approximate dynamic programming ( ADP ) algorithm that enjoys graceful approximation and sample complexity guarantees .", "Via a computational study on a controlled queueing network , we show that our procedure is competitive with parametric ADP approaches .", "We accomplish this by developing a kernel-based mathematical program for ADP ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We present a new algorithm for differentially private data release , based on a simple combination of the Multiplicative Weights update rule with the Exponential Mechanism .", "Our MWEM algorithm achieves what are the best known and nearly optimal theoretical guarantees , while at the same time being simple to implement and experimentally more accurate on actual data sets than existing techniques ."]}
{"orig_sents": ["0", "3", "1", "5", "2", "4"], "shuf_sents": ["We address the problem of generating multiple hypotheses for structured prediction tasks that involve interaction with users or successive components in a cascaded architecture .", "The standard approach for handling such a scenario is to first learn a single-output model and then produce M -Best Maximum a Posteriori ( MAP ) hypotheses from this model .", "We present a max-margin formulation that minimizes an upper-bound on this lossfunction .", "Given a set of multiple hypotheses , such components/users typically have the ability to retrieve the best ( or approximately the best ) solution in this set .", "Experimental results on image segmentation and protein side-chain prediction show that our method outperforms conventional approaches used for this type of scenario and leads to substantial improvements in prediction accuracy .", "In contrast , we learn to produce multiple outputs by formulating this task as a multiple-output structured-output prediction problem with a loss-function that effectively captures the setup of the problem ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems , which show that our bounds are sharp with respect to all problemdependent quantities : they can not be improved by more than constant factors .", "We show that if pairs of function values are available , algorithms that use gradient estimates based on random perturbations suffer a factor of at most d in convergence rate over traditional stochastic gradient methods , where d is the problem dimension .", "We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients , analyzing their finite-sample convergence rates ."]}
{"orig_sents": ["2", "0", "3", "4", "1", "5"], "shuf_sents": ["We introduce a new algorithm , SCIRL , whose principle is to use the so-called feature expectation of the expert as the parameterization of the score function of a multiclass classifier .", "Moreover , with an appropriate heuristic , it can succeed with only trajectories sampled according to the expert behavior .", "This paper adresses the inverse reinforcement learning ( IRL ) problem , that is inferring a reward for which a demonstrated expert behavior is optimal .", "This approach produces a reward function for which the expert policy is provably near-optimal .", "Contrary to most of existing IRL algorithms , SCIRL does not require solving the direct RL problem .", "This is illustrated on a car driving simulator ."]}
{"orig_sents": ["3", "4", "2", "0", "5", "7", "1", "6"], "shuf_sents": ["Incorporating this uncertainty can substantially speed up active learning , particularly when RFs are smooth , sparse , or local in space and time .", "The core elements of this algorithm are parallelizable , making it computationally efficient for real-time experiments .", "However , existing methods tend to employ simple Gaussian priors over the RF and do not exploit uncertainty at the level of hyperparameters .", "Active learning methods can dramatically improve the yield of neurophysiology experiments by adaptively selecting stimuli to probe a neuron 's receptive field ( RF ) .", "Bayesian active learning methods specify a posterior distribution over the RF given the data collected so far in the experiment , and select a stimulus on each time step that maximally reduces posterior uncertainty .", "Here we describe a novel framework for active learning under hierarchical , conditionally Gaussian priors .", "We apply our algorithm to simulated and real neural data , and show that it can provide highly accurate receptive field estimates from very limited data , even with a small number of hyperparameter samples .", "Our algorithm uses sequential Markov Chain Monte Carlo sampling ( `` particle filtering '' with MCMC ) to construct a mixture-of-Gaussians representation of the RF posterior , and selects optimal stimuli using an approximate infomax criterion ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["To implement the test , we introduce a novel , hierarchical , minimum-volume sets estimator to represent the distributions to be tested .", "We propose an efficient , generalized , nonparametric , statistical KolmogorovSmirnov test for detecting distributional change in high-dimensional data .", "Our work is motivated by the need to detect changes in data streams , and the test is especially efficient in this context .", "We provide the theoretical foundations of our test and show its superiority over existing methods ."]}
{"orig_sents": ["3", "2", "4", "7", "0", "8", "6", "1", "5"], "shuf_sents": ["We show that in addition to this problem , the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain .", "It supports efficient online inference , and can directly model influences between variables within a time slice that do not have a causal direction , in contrast with fully directed models ( e.g. , DBNs ) .", "In many applications , a Markov logic network ( MLN ) is trained in one domain , but used in a different one .", "Markov logic is a widely used tool in statistical relational learning , which uses a weighted first-order logic knowledge base to specify a Markov random field ( MRF ) or a conditional random field ( CRF ) .", "This paper focuses on dynamic Markov logic networks , where the size of the discretized time-domain typically varies between training and testing .", "Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks .", "We propose a new discriminative model , slice normalized dynamic Markov logic networks ( SN-DMLN ) , that suffers from none of these issues .", "It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN .", "Furthermore , even if these representational problems are not significant for a given domain , we show that the more practical problem of generating samples in a sequential conditional random field for the next slice relying on the samples from the previous slice has high computational cost in the general case , due to the need to estimate a normalization factor for each sample ."]}
{"orig_sents": ["8", "4", "6", "2", "3", "9", "1", "10", "0", "5", "7"], "shuf_sents": ["We then construct a neural network implementation of variational inference and learning for LDA that utilizes a linear PPC .", "We apply this approach to a generic problem faced by any given layer of cortex , namely the identification of latent causes of complex mixtures of spikes .", "However , these experiments and the corresponding neural models have largely focused on simple ( tractable ) probabilistic computations such as cue combination , coordinate transformations , and decision making .", "As a result it remains unclear how to generalize this framework to more complex probabilistic computations .", "This ability requires a neural code that represents probability distributions and neural circuits that are capable of implementing the operations of probabilistic inference .", "This network relies critically on two non-linear operations : divisive normalization and super-linear facilitation , both of which are ubiquitously observed in neural circuits .", "The proposed probabilistic population coding ( PPC ) framework provides a statistically efficient neural representation of probability distributions that is both broadly consistent with physiological measurements and capable of implementing some of the basic operations of probabilistic inference in a biologically plausible way .", "We also demonstrate how online learning can be achieved using a variation of Hebb 's rule and describe an extension of this work which allows us to deal with time varying and correlated latent causes .", "Recent experiments have demonstrated that humans and animals typically reason probabilistically about their environment .", "Here we address this short coming by showing that a very general approximate inference algorithm known as Variational Bayesian Expectation Maximization can be naturally implemented within the linear PPC framework .", "We identify a formal equivalent between this spike pattern demixing problem and topic models used for document classification , in particular Latent Dirichlet Allocation ( LDA ) ."]}
{"orig_sents": ["5", "0", "4", "1", "2", "3"], "shuf_sents": ["The field has experimented with approximate inference algorithms that make different speed-accuracy tradeoffs ( for particular problems and datasets ) .", "Unfortunately , off-the-shelf reinforcement learning techniques fail to learn good policies : the state space is simply too large to explore naively .", "An attempt to counteract this by applying imitation learning algorithms also fails : the `` teacher '' follows a far better policy than anything in our learner 's policy space , free of the speed-accuracy tradeoff that arises when oracle information is unavailable , and thus largely insensitive to the known reward functfion .", "We propose a hybrid reinforcement/apprenticeship learning algorithm that learns to speed up an initial policy , trading off accuracy for speed according to various settings of a speed term in the loss function .", "We aim to explore this space automatically , focusing here on the case of agenda-based syntactic parsing .", "Users want inference to be both fast and accurate , but quality often comes at the cost of speed ."]}
{"orig_sents": ["8", "1", "6", "3", "5", "0", "2", "9", "4", "7"], "shuf_sents": ["This self-referential updating method is rather peculiar , but it is efficient and gives superior performance on many natural data sets .", "If the nature of the data is changing over time in that different models predict well on different segments of the data , then adaptivity is typically achieved by mixing into the weights in each round a bit of the initial prior ( kind of like a weak restart ) .", "Also it is important because it introduces a long-term memory : any model that has done well in the past can be recovered quickly .", "the data is likely to be predicted well by models that predicted well before ?", "We build atop the `` specialist '' framework from the online learning literature to give the Mixing Past Posteriors update a proper Bayesian foundation .", "Curiously , fitting such `` sparse composite models '' is achieved by mixing in a bit of all the past posteriors .", "However , what if the favored models in each segment are from a small subset , i.e .", "We apply our method to a well-studied multitask learning problem and obtain a new intriguing efficient update that achieves a significantly better bound .", "We consider sequential prediction algorithms that are given the predictions from a set of models as inputs .", "While Bayesian interpretations can be found for mixing in a bit of the initial prior , no Bayesian interpretation is known for mixing in past posteriors ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We present a general formulation for robust regression -- Variational M-estimation -- that unifies a number of robust regression methods while allowing a tractable approximation strategy .", "Despite the variety of robust regression methods that have been developed , current regression formulations are either NP-hard , or allow unbounded response to even a single leverage point .", "An experimental evaluation demonstrates the effectiveness of the new estimation approach compared to standard methods .", "We develop an estimator that requires only polynomial-time , while achieving certain robustness and consistency guarantees ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We derive the optimal amount of regularization , and show that it can be effectively estimated .", "Simulations and real data experiments demonstrate that MTA outperforms both maximum likelihood and James-Stein estimators , and that our approach to estimating the amount of regularization rivals cross-validation in performance but is more computationally efficient .", "The proposed multi-task averaging ( MTA ) algorithm results in a convex combination of the single-task averages .", "We present a multi-task learning approach to jointly estimate the means of multiple independent data sets ."]}
{"orig_sents": ["0", "2", "4", "3", "5", "1"], "shuf_sents": ["In many applications , one has side information , e.g. , labels that are provided in a semi-supervised manner , about a specific target region of a large data set , and one wants to perform machine learning and data analysis tasks `` nearby '' that pre-specified target region .", "We also provide several empirical examples demonstrating how these semi-supervised eigenvectors can be used to perform locally-biased learning .", "Locally-biased problems of this sort are particularly challenging for popular eigenvector-based machine learning and data analysis tools .", "In this paper , we address this issue by providing a methodology to construct semi-supervised eigenvectors of a graph Laplacian , and we illustrate how these locally-biased eigenvectors can be used to perform locally-biased machine learning .", "At root , the reason is that eigenvectors are inherently global quantities .", "These semi-supervised eigenvectors capture successively-orthogonalized directions of maximum variance , conditioned on being well-correlated with an input seed set of nodes that is assumed to be provided in a semi-supervised manner ."]}
{"orig_sents": ["2", "1", "0", "5", "6", "3", "4"], "shuf_sents": ["In this paper , we propose a novel approach to LSDR that considers both the label and the feature parts .", "Existing approaches to LSDR , such as compressive sensing and principal label space transformation , exploit only the label part of the dataset , but not the feature part .", "Label space dimension reduction ( LSDR ) is an efficient and effective paradigm for multi-label classification with many classes .", "In addition , the approach can be extended to a kernelized version that allows the use of sophisticated feature combinations to assist LSDR .", "The experimental results verify that the proposed approach is more effective than existing ones to LSDR across many real-world datasets .", "The approach , called conditional principal label space transformation , is based on minimizing an upper bound of the popular Hamming loss .", "The minimization step of the approach can be carried out efficiently by a simple use of singular value decomposition ."]}
{"orig_sents": ["3", "2", "0", "9", "7", "1", "5", "8", "6", "4"], "shuf_sents": ["We propose a novel approach that extends the well-acclaimed deformable part-based model to reason in 3D .", "Our model reasons about face visibility patters called aspects .", "Given a monocular image , our aim is to localize the objects in 3D by enclosing them with tight oriented 3D bounding boxes .", "This paper addresses the problem of category-level 3D object detection .", "We demonstrate the effectiveness of our approach in indoor and outdoor scenarios , and show that our approach significantly outperforms the stateof-the-art in both 2D and 3D object detection .", "We train the cuboid model jointly and discriminatively and share weights across all aspects to attain efficiency .", "While for inference we discretize the search space , the variables are continuous in our model .", "We model the appearance of each face in fronto-parallel coordinates , thus effectively factoring out the appearance variation induced by viewpoint .", "Inference then entails sliding and rotating the box in 3D and scoring object hypotheses .", "Our model represents an object class as a deformable 3D cuboid composed of faces and parts , which are both allowed to deform with respect to their anchors on the 3D box ."]}
{"orig_sents": ["8", "2", "9", "0", "4", "12", "3", "10", "1", "11", "7", "6", "5"], "shuf_sents": [".", "This paper shows the difficulty of simultaneously achieving regret asymptotically better than kT and communication better than T .", "At each time-step t , one of the k site nodes has to pick an expert from the set { 1 , .", "The two extreme solutions to this problem are : ( i ) Full communication : This essentially simulates the nondistributed setting to obtain the optimal O ( log ( n ) T ) regret bound at the cost of T communication .", ", n } , and the same site receives information about payoffs of all experts for that round .", "( 2005 ) already gives us strategy that is near optimal in regret vs communication trade-off .", "In this model , we show that the label-efficient forecaster of Cesa-Bianchi et al .", "We also consider a variant of the model , where the coordinator picks the expert .", "We consider the online distributed non-stochastic experts problem , where the distributed system consists of one coordinator node that is connected to k sites , and the sites are required to communicate with each other via the coordinator .", ".", "( ii ) No communication : Each site runs an independent copy - the regret is O ( log ( n ) kT ) and the communication is 0 .", "We give a novel algorithm that for an oblivious adversary achieves a non-trivial trade-off : regret O ( k 5 ( 1+ ) /6 T ) and communication O ( T /k ) , for any value of ( 0 , 1/5 ) .", "The goal of the distributed system is to minimize regret at time horizon T , while simultaneously keeping communication to a minimum ."]}
{"orig_sents": ["5", "3", "1", "6", "4", "7", "0", "2"], "shuf_sents": ["Empirically , we demonstrate that our approach , when compared to that of an edge-based model , has faster runtime and improved accuracy for mixed-membership community detection .", "In contrast , triangular modeling requires less computation , while providing equivalent or better inference quality .", "We conclude with a large-scale demonstration on an N 280 , 000-node network , which is infeasible for network models with ( N 2 ) inference cost .", "Such approaches require both 1-edges and 0-edges ( missing edges ) to be provided as input , and as a consequence , approximate inference algorithms for these models usually require ( N 2 ) time per iteration , precluding their application to larger real-world networks .", "Using this representation , we develop a novel mixed-membership network model and approximate inference algorithm suitable for large networks with low max-degree .", "In this paper , we argue for representing networks as a bag of triangular motifs , particularly for important network problems that current model-based approaches handle poorly due to computational bottlenecks incurred by using edge representations .", "A triangular motif is a vertex triple containing 2 or 3 edges , and the number of such motifs is ( i Di2 ) ( where Di is the degree of vertex i ) , which is much smaller than N 2 for low-maximum-degree networks .", "For networks with high maximum degree , the triangular motifs can be naturally subsampled in a node-centric fashion , allowing for much faster inference at a small cost in accuracy ."]}
{"orig_sents": ["0", "5", "1", "2", "4", "6", "3"], "shuf_sents": ["Principal components analysis ( PCA ) is a standard tool for identifying good lowdimensional approximations to data sets in high dimension .", "Algorithms which operate on such data should be sensitive to the privacy risks in publishing their outputs .", "Differential privacy is a framework for developing tradeoffs between privacy and the utility of these outputs .", "We show that the sample complexity for the two procedures differs in the scaling with the data dimension , and that our method is nearly optimal in terms of this scaling .", "In this paper we investigate the theory and empirical performance of differentially private approximations to PCA and propose a new method which explicitly optimizes the utility of the output .", "Many current data sets of interest contain private or sensitive information about individuals .", "We demonstrate that on real data , there is a large performance gap between the existing method and our method ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We show that organizing the communication among nodes as a k-regular expander graph yields speedups , while when all pairs of nodes communicate ( as in a complete graph ) , there is an optimal number of processors that depends on r. Surprisingly , a speedup can be obtained , in terms of the time to reach a fixed level of accuracy , by communicating less and less frequently as the computation progresses .", "Experiments on a real cluster solving metric learning and non-smooth convex minimization tasks demonstrate strong agreement between theory and practice .", "Central to our analysis is a problem-specific value r which quantifies the communication/computation tradeoff .", "We study the scalability of consensus-based distributed optimization algorithms by considering two questions : How many processors should we use for a given problem , and how often should they communicate when communication is not free ?"]}
{"orig_sents": ["1", "5", "2", "4", "0", "3"], "shuf_sents": ["This framework provides a tractable , conditionally Gaussian representation of the posterior that can be used to design efficient EM and Gibbs sampling based algorithms for inference in regression and dynamic factor models .", "Characterizing the information carried by neural populations in the brain requires accurate statistical models of neural spike responses .", "Here we describe a powerful data-augmentation framework for fully Bayesian inference in neural models with negative-binomial spiking .", "We apply the model to neural data from primate retina and show that it substantially outperforms Poisson regression on held-out data , and reveals latent structure underlying spike count correlations in simultaneously recorded spike trains .", "Our approach relies on a recently described latentvariable representation of the negative-binomial distribution , which equates it to a Polya-gamma mixture of normals .", "The negative-binomial distribution provides a convenient model for over-dispersed spike counts , that is , responses with greater-than-Poisson variability ."]}
{"orig_sents": ["3", "1", "0", "2", "5", "6", "4"], "shuf_sents": ["In this work we propose a simple yet effective technique for accelerating MMP when inference is sampling-based : instead of the above two-stage procedure we directly estimate the posterior probability of each decision variable .", "MMP is typically performed as a two-stage procedure : one estimates each variable 's marginal probability and then forms a prediction from the states of maximal probability .", "This allows us to identify the point of time when we are sufficiently certain about any individual decision .", "We study the problem of maximum marginal prediction ( MMP ) in probabilistic graphical models , a task that occurs , for example , as the Bayes optimal decision rule under a Hamming loss .", "Experiments in two prototypical scenarios , multi-label classification and image inpainting , show that adaptive sampling can drastically accelerate MMP without sacrificing prediction accuracy .", "Whenever this is the case , we dynamically prune the variables we are confident about from the underlying factor graph .", "Consequently , at any time only samples of variables whose decision is still uncertain need to be created ."]}
{"orig_sents": ["1", "5", "6", "3", "4", "0", "2"], "shuf_sents": ["In addition , we prove a similar , tighter bound for AS and other popular MCCFR variants .", "Counterfactual Regret Minimization ( CFR ) is a popular , iterative algorithm for computing strategies in extensive-form games .", "Finally , we validate our work by demonstrating that AS converges faster than previous MCCFR algorithms in both no-limit poker and Bluff .", "In this paper , we present a new MCCFR algorithm , Average Strategy Sampling ( AS ) , that samples a subset of the player 's actions according to the player 's average strategy .", "Our new algorithm is inspired by a new , tighter bound on the number of iterations required by CFR to converge to a given solution quality .", "The Monte Carlo CFR ( MCCFR ) variants reduce the per iteration time cost of CFR by traversing a smaller , sampled portion of the tree .", "The previous most effective instances of MCCFR can still be very slow in games with many player actions since they sample every action for a given player ."]}
{"orig_sents": ["4", "3", "0", "5", "2", "1"], "shuf_sents": ["However , the class of features and image information that is forgotten has not been explored yet .", "We incorporate multiple image region attributes in our algorithm , leading to improved memorability prediction of images as compared to previous works .", "The model automatically discovers memorability maps of individual images without any human annotation .", "Recent works have shown that image memorability is an intrinsic property of an image that can be reliably estimated using state-of-the-art image features and machine learning algorithms .", "While long term human visual memory can store a remarkable amount of visual information , it tends to degrade over time .", "In this work , we propose a probabilistic framework that models how and which local regions from an image may be forgotten using a data-driven approach that combines local and global images features ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["We present an efficient online algorithm for this problem based on alternating directions method of multipliers , and establish a sublinear regret bound for this algorithm .", "Given their pervasive use , social media , such as Twitter , have become a leading source of breaking news .", "A key task in the automated identification of such news is the detection of novel documents from a voluminous stream of text documents in a scalable manner .", "Motivated by this challenge , we introduce the problem of online 1 -dictionary learning where unlike traditional dictionary learning , which uses squared loss , the 1 -penalty is used for measuring the reconstruction error .", "Empirical results on news-stream and Twitter data , shows that this online 1 -dictionary learning algorithm for novel document detection gives more than an order of magnitude speedup over the previously known batch algorithm , without any significant loss in quality of results ."]}
{"orig_sents": ["1", "5", "2", "0", "4", "3"], "shuf_sents": ["We obtain a flexible yet simple Bayesian nonparametric model by placing a Gaussian process prior on the parameter function .", "A fundamental problem in the analysis of structured relational data like graphs , networks , databases , and matrices is to extract a summary of the common structure underlying relations between individual entities .", "Results in probability theory due to Aldous , Hoover and Kallenberg show that exchangeable arrays can be represented in terms of a random measurable function which constitutes the natural model parameter in a Bayesian model .", "We demonstrate applications of the model to network data and clarify its relation to models in the literature , several of which emerge as special cases .", "Efficient inference utilises elliptical slice sampling combined with a random sparse approximation to the Gaussian process .", "Relational data are typically encoded in the form of arrays ; invariance to the ordering of rows and columns corresponds to exchangeable arrays ."]}
{"orig_sents": ["1", "0", "3", "2", "4"], "shuf_sents": ["Our algorithm is based on stochastic variational inference in the mixed-membership stochastic blockmodel ( MMSB ) .", "We develop a scalable algorithm for posterior inference of overlapping communities in large networks .", "We apply our algorithm on ten large , real-world networks with up to 60,000 nodes .", "It naturally interleaves subsampling the network with estimating its community structure .", "It converges several orders of magnitude faster than the state-of-the-art algorithm for MMSB , finds hundreds of communities in large real-world networks , and detects the true communities in 280 benchmark networks with equal or better accuracy compared to other scalable algorithms ."]}
{"orig_sents": ["5", "4", "6", "3", "7", "0", "1", "2"], "shuf_sents": ["The rate is shown to be closely related to the condition number of the optimal point .", "Numerical convergence results and timing comparisons for the proposed method are presented .", "G-ISTA is shown to perform very well , especially when the optimal point is well-conditioned .", "G-ISTA has a linear rate of convergence , resulting in an O ( log ) iteration complexity to reach a tolerance of .", "In this paper , a proximal gradient method ( G-ISTA ) for performing 1 -regularized covariance matrix estimation is presented .", "The 1 -regularized maximum likelihood estimation problem has recently become a topic of great interest within the machine learning , statistics , and optimization communities as a method for producing sparse inverse covariance estimators .", "Although numerous algorithms have been proposed for solving this problem , this simple proximal gradient method is found to have attractive theoretical and numerical properties .", "This paper gives eigenvalue bounds for the G-ISTA iterates , providing a closed-form linear convergence rate ."]}
{"orig_sents": ["2", "5", "1", "4", "3", "0"], "shuf_sents": ["Experiments on benchmark datasets show that the proposed method outperforms the state-of-the-art methods .", "We propose a selective labeling method by analyzing the out-of-sample error of Laplacian regularized Least Squares ( LapRLS ) .", "In many practical machine learning problems , the acquisition of labeled data is often expensive and/or time consuming .", "Since the minimization is a combinational problem , we relax it into continuous domain and solve it by projected gradient descent .", "In particular , we derive a deterministic out-of-sample error bound for LapRLS trained on subsampled data , and propose to select a subset of data points to label by minimizing this upper bound .", "This motivates us to study a problem as follows : given a label budget , how to select data points to label such that the learning performance is optimized ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["Parametric policy search algorithms are one of the methods of choice for the optimisation of Markov Decision Processes , with Expectation Maximisation and natural gradient ascent being popular methods in this field .", "Empirical results suggest that the algorithm has excellent convergence and robustness properties , performing strongly in comparison to both Expectation Maximisation and natural gradient ascent .", "We are able to show that the algorithm has numerous desirable properties , absent in the naive application of Newton 's method , that make it a viable alternative to either Expectation Maximisation or natural gradient ascent .", "In this article we provide a unifying perspective of these two algorithms by showing that their searchdirections in the parameter space are closely related to the search-direction of an approximate Newton method .", "This analysis leads naturally to the consideration of this approximate Newton method as an alternative optimisation method for Markov Decision Processes ."]}
{"orig_sents": ["6", "5", "1", "4", "0", "2", "7", "3"], "shuf_sents": ["In this paper we propose a new algorithm for approximating the MAP problem based on continuous techniques for submodular function maximization .", "This optimization problem , which also arises in experimental design and sensor placement , involves finding the largest principal minor of a positive semidefinite matrix .", "Our method involves a novel continuous relaxation of the log-probability function , which , in contrast to the multilinear extension used for general submodular functions , can be evaluated and differentiated exactly and efficiently .", "We demonstrate that our approach outperforms standard and recent methods on both synthetic and real-world data .", "Because the objective is log-submodular , greedy algorithms have been used in the past with some empirical success ; however , these methods only give approximation guarantees in the special case of monotone objectives , which correspond to a restricted class of DPPs .", "Many DPP inference operations , including normalization and sampling , are tractable ; however , finding the most likely configuration ( MAP ) , which is often required in practice for decoding , is NP-hard , so we must resort to approximate inference .", "Determinantal point processes ( DPPs ) have recently been proposed as computationally efficient probabilistic models of diverse sets for a variety of applications , including document summarization , image search , and pose estimation .", "We obtain a practical algorithm with a 1/4-approximation guarantee for a more general class of non-monotone DPPs ; our algorithm also extends to MAP inference under complex polytope constraints , making it possible to combine DPPs with Markov random fields , weighted matchings , and other models ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["Finally , we provide an implementation of the oracle for soft-margin support vector machines , and a parameterized semi-definite program for matrix completion .", "We consider an abstract class of optimization problems that are parameterized concavely in a single parameter , and show that the solution path along the parameter can always be approximated with accuracy > 0 by a set of size O ( 1/ ) .", "We also devise an algorithm that calls a step-size oracle and computes an approximate path of size O ( 1/ ) .", "A lower bound of size ( 1/ ) shows that the upper bound is tight up to a constant factor ."]}
{"orig_sents": ["5", "0", "3", "2", "1", "4"], "shuf_sents": ["This motivates attempting to find a disjoint partition , i.e .", "Our Dirichlet process variable clustering ( DPVC ) model can discover blockdiagonal covariance structures in data .", "We introduce a Bayesian non-parametric approach to this problem , and demonstrate advantages over heuristic methods proposed to date .", "a simple clustering , of observed variables into highly correlated subsets .", "We evaluate our method on both synthetic and gene expression analysis problems .", "Factor analysis models effectively summarise the covariance structure of high dimensional data , but the solutions are typically hard to interpret ."]}
{"orig_sents": ["4", "1", "2", "3", "0"], "shuf_sents": ["The resulting procedure , called Hierarchical Optimistic Region SElection driven by Curiosity ( HORSE.C ) is provided together with a finite-time regret analysis .", "To that end , we consider the setting where , a fixed partition P of a continuous space X being given , and a process defined on X being unknown , we are asked to sequentially decide which cell of the partition to select as well as where to sample in that cell , in order to minimize a loss function that is inspired from previous work on curiosity-driven learning .", "The loss on each cell consists of one term measuring a simple worst case quadratic sampling error , and a penalty term proportional to the range of the variance in that cell .", "The corresponding problem formulation extends the setting known as active learning for multi-armed bandits to the case when each arm is a continuous region , and we show how an adaptation of recent algorithms for that problem and of hierarchical optimistic sampling algorithms for optimization can be used in order to solve this problem .", "This paper aims to take a step forwards making the term `` intrinsic motivation '' from reinforcement learning theoretically well founded , focusing on curiositydriven learning ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["Our work demonstrates a successful example that integrates Bayesian nonparametrics and max-margin learning , which are conventionally two separate paradigms and enjoy complementary advantages .", "We develop an efficient variational algorithm for posterior inference , and our extensive empirical studies on large-scale MovieLens and EachMovie data sets appear to justify the aforementioned dual advantages .", "We present a probabilistic formulation of max-margin matrix factorization and build accordingly a nonparametric Bayesian model which automatically resolves the unknown number of latent factors ."]}
{"orig_sents": ["1", "0", "2", "4", "3", "5", "6"], "shuf_sents": ["Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events .", "Information , disease , and influence diffuse over networks of entities in both natural systems and human society .", "However , the underlying transmission networks are often hidden and incomplete , and we observe only the time stamps when cascades of events happen .", "The structure discovery problem is complicated by the fact that the influence between networked entities is heterogeneous , which can not be described by a simple parametric model .", "In this paper , we address the challenging problem of uncovering the hidden network only from the cascades .", "Therefore , we propose a kernelbased method which can capture a diverse range of different types of influence without any prior assumption .", "In both synthetic and real cascade data , we show that our model can better recover the underlying diffusion network and drastically improve the estimation of the transmission functions among networked entities ."]}
{"orig_sents": ["4", "1", "3", "5", "0", "2"], "shuf_sents": ["We propose a new topic model , Symmetric Correspondence LDA ( SymCorrLDA ) , that incorporates a hidden variable to control a pivot language , in an extension of CorrLDA .", "A small number of multilingual topic models have recently been explored to discover latent topics among parallel or comparable documents , such as in Wikipedia .", "We experimented with two multilingual comparable datasets extracted from Wikipedia and demonstrate that SymCorrLDA is more effective than some other existing multilingual topic models .", "Other topic models that were originally proposed for structured data are also applicable to multilingual documents .", "Topic modeling is a widely used approach to analyzing large text collections .", "Correspondence Latent Dirichlet Allocation ( CorrLDA ) is one such model ; however , it requires a pivot language to be specified in advance ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["Based on our population-level results , we show how the graphical Lasso may be used to recover the edge structure of certain classes of discrete graphical models , and present simulations to verify our theoretical results .", "We investigate a curious relationship between the structure of a discrete graphical model and the support of the inverse of a generalized covariance matrix .", "Our work extends results that have previously been established only in the context of multivariate Gaussian graphical models , thereby addressing an open question about the significance of the inverse covariance matrix of a non-Gaussian distribution .", "We show that for certain graph structures , the support of the inverse covariance matrix of indicator variables on the vertices of a graph reflects the conditional independence structure of the graph ."]}
{"orig_sents": ["14", "6", "11", "1", "9", "7", "3", "2", "8", "10", "0", "12", "5", "4", "13"], "shuf_sents": ["This paper presents the methodology of building FPGA modules emulating a monosynaptic spinal loop .", "significantly faster than real-time , for producing useful predictions .", "Each physiological component is implemented using models from well documented studies and can be flexibly modified .", "All devices operate asynchronously with 1 millisecond time granularity , and the overall system is accelerated to 365x real-time .", "In conclusion , our platform allows emulating pathological abnormalities such that motor symptoms will emerge and can be analyzed .", "Also discussed is the rationale of approximating neural circuitry by organizing neurons with sparse interconnections .", "To this purpose , quantitative models are convincing only if they can provide multi-scale details ranging from neuron spikes to limb biomechanics .", "The platform is constructed on a scalable , distributed array of Field Programmable Gate Array ( FPGA ) devices .", "Thus the validity of emulation can be easily advised by neurophysiologists and clinicians .", "We designed a platform with digital VLSI hardware for multiscale hyper-time emulations of human motor nervous systems .", "For maximizing the speed of emulation , all calculations are implemented in combinational logic instead of clocked iterative circuits .", "The models also need to be evaluated in hyper-time , i.e .", "Emulated activities are qualitatively similar to real human data .", "It compels us to test the origins of childhood motor disorders and predict their long-term progressions .", "Our central goal is to quantify the long-term progression of pediatric neurological diseases , such as a typical 10-15 years progression of child dystonia ."]}
{"orig_sents": ["1", "2", "5", "4", "0", "3"], "shuf_sents": ["We accomplish this via a hierarchical covering structure that caches previous local sum-product computations .", "We consider the problem of performing efficient sum-product computations in an online setting over a tree .", "A natural application of our methods is to compute the marginal distribution at a vertex in a tree-structured Markov random field .", "Our contribution is three-fold : we i ) give a linear time algorithm to find an optimal hierarchical cover of a tree ; ii ) give a sum-productlike algorithm to efficiently compute marginals with respect to this cover ; and iii ) apply `` i '' and `` ii '' to find an efficient algorithm with a regret bound for the online allocation problem in a multi-task setting .", "With our method we aim to update the data and compute marginals in time that is no more than logarithmic in the size of the tree , and is often significantly less .", "Belief propagation can be used to solve this problem , but requires time linear in the size of the tree , and is therefore too slow in an online setting where we are continuously receiving new data and computing individual marginals ."]}
{"orig_sents": ["3", "1", "4", "0", "2"], "shuf_sents": ["In addition , a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix .", "The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models ( HMMs ) in modeling speech .", "The effectiveness of the proposed model is demonstrated with three experimental results , including parameter estimation and classification performance , on the synthetic and benchmark datasets .", "For phoneme classification , this paper describes an acoustic model based on the variational Gaussian process dynamical system ( VGPDS ) .", "The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["Unlike approaches based on random Fourier features where the basis functions ( i.e. , cosine and sine functions ) are sampled from a distribution independent from the training data , basis functions used by the Nystrom method are randomly sampled from the training examples and are therefore data dependent .", "By exploring this difference , we show that when there is a large gap in the eigen-spectrum of the kernel matrix , approaches based on the Nystrom method can yield impressively better generalization error bound than random Fourier features based approach .", "Both random Fourier features and the Nystrom method have been successfully applied to efficient kernel learning .", "In this work , we investigate the fundamental difference between these two approaches , and how the difference could affect their generalization performances .", "We empirically verify our theoretical findings on a wide range of large data sets ."]}
{"orig_sents": ["2", "5", "0", "7", "6", "3", "4", "1", "8"], "shuf_sents": ["One important issue that arises in using discrete mixtures is low separation in the components ; in particular , different components can be introduced that are very similar and hence redundant .", "The methods are illustrated using synthetic examples and an iris data set .", "Discrete mixtures are used routinely in broad sweeping applications ranging from unsupervised settings to fully supervised multi-task learning .", "To solve this problem , we propose a novel prior that generates components from a repulsive process , automatically penalizing redundant components .", "We characterize this repulsive prior theoretically and propose a Markov chain Monte Carlo sampling algorithm for posterior computation .", "Indeed , finite mixtures and infinite mixtures , relying on Dirichlet processes and modifications , have become a standard tool .", "Redundancy can arise in the absence of a penalty on components placed close together even when a Bayesian approach is used to learn the number of components .", "Such redundancy leads to too many clusters that are too similar , degrading performance in unsupervised learning and leading to computational problems and an unnecessarily complex model in supervised settings .", "Key Words : Bayesian nonparametrics ; Dirichlet process ; Gaussian mixture model ; Model-based clustering ; Repulsive point process ; Well separated mixture ."]}
{"orig_sents": ["1", "5", "6", "2", "0", "4", "7", "3"], "shuf_sents": ["In this paper , we propose kernel latent SVM ( KLSVM ) - a new learning framework that combines latent SVMs and kernel methods .", "Latent SVMs ( LSVMs ) are a class of powerful tools that have been successfully applied to many applications in computer vision .", "Therefore it is desirable to develop the kernel version of LSVM .", "Our KLSVM formulation is very general and can be applied to solve a wide range of applications in computer vision and machine learning .", "We develop an iterative training algorithm to learn the model parameters .", "However , a limitation of LSVMs is that they rely on linear models .", "For many computer vision tasks , linear models are suboptimal and nonlinear models learned with kernels typically perform much better .", "We demonstrate the effectiveness of KLSVM using three different applications in visual recognition ."]}
{"orig_sents": ["7", "0", "1", "2", "4", "5", "6", "3"], "shuf_sents": ["The key idea in compressed sensing for multilabel classification is to first project the label vector to a lower dimensional space using a random transformation and then learn regression functions over these projections .", "Our approach considers both of these components in a single probabilistic model , thereby jointly optimizing over compression as well as learning tasks .", "We then derive an efficient variational inference scheme that provides joint posterior distribution over all the unobserved labels .", "Finally , we also highlight various useful active learning scenarios that are enabled by the probabilistic model .", "The two key benefits of the model are that a ) it can naturally handle datasets that have missing labels and b ) it can also measure uncertainty in prediction .", "The uncertainty estimate provided by the model allows for active learning paradigms where an oracle provides information about labels that promise to be maximally informative for the prediction task .", "Our experiments show significant boost over prior methods in terms of prediction performance over benchmark datasets , both in the fully labeled and the missing labels case .", "In this paper , we present a Bayesian framework for multilabel classification using compressed sensing ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["We offer a regularized , kernel extension of the multi-set , orthogonal Procrustes problem , or hyperalignment .", "Our new method , called Kernel Hyperalignment , expands the scope of hyperalignment to include nonlinear measures of similarity and enables the alignment of multiple datasets with a large number of base features .", "With direct application to fMRI data analysis , kernel hyperalignment is well-suited for multi-subject alignment of large ROIs , including the entire cortex .", "We report experiments using real-world , multi-subject fMRI data ."]}
{"orig_sents": ["0", "5", "6", "2", "3", "4", "1"], "shuf_sents": ["Recent spiking network models of Bayesian inference and unsupervised learning frequently assume either inputs to arrive in a special format or employ complex computations in neuronal activation functions and synaptic plasticity rules .", "Altogether , our theory provides a novel perspective on the interplay of homeostatic processes and synaptic plasticity in cortical microcircuits , and points to an essential role of homeostasis during inference and learning in spiking networks .", "We link homeostatic dynamics to the theory of variational inference , and show that nontrivial terms , which typically appear during probabilistic inference in a large class of models , drop out .", "We demonstrate the feasibility of our approach in a spiking WinnerTake-All architecture of Bayesian inference and learning .", "Finally , we sketch how the mathematical framework can be extended to richer recurrent network architectures .", "Here we show in a rigorous mathematical treatment how homeostatic processes , which have previously received little attention in this context , can overcome common theoretical limitations and facilitate the neural implementation and performance of existing models .", "In particular , we show that homeostatic plasticity can be understood as the enforcement of a 'balancing ' posterior constraint during probabilistic inference and learning with Expectation Maximization ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["We show that a `` passive '' agent given a training set can provide no guarantees on performance beyond what is afforded by the priors , and that an `` omnipotent '' agent , capable of infinite control authority , can achieve arbitrarily good performance ( asymptotically ) .", "We focus on the problem of `` visual search '' of an object in an otherwise known and static scene , propose a measure of control authority , and relate it to the expected risk and its proxy ( conditional entropy of the posterior density ) .", "We show this analytically , as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation , including scaling and occlusions .", "In between these limiting cases , the tradeoff can be characterized empirically .", "We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process ."]}
{"orig_sents": ["4", "2", "8", "7", "9", "3", "1", "5", "0", "6"], "shuf_sents": ["We also demonstrate in measurements that it is possible to overlay short and long term plasticity at a memristive device in the form of the well-known triplet plasticity .", "Bridging this gap , we make use of a plasticity model driven by neuron waveforms that explains a large number of experimental observations and adapt it to the characteristics of the recently introduced BiFeO3 memristive material .", "The plasticity in these memristive devices , i.e .", "The focus seems to be on finding any waveform that achieves spike-timing-dependent plasticity ( STDP ) , without regard to the biological veracity of said waveforms or to further important forms of plasticity .", "Memristive devices have recently been proposed as efficient implementations of plastic synapses in neuromorphic systems .", "Based on this approach , we show STDP for the first time for this material , with learning window replication superior to previous memristor-based STDP implementations .", "To the best of our knowledge , this is the first implementations of triplet plasticity on any physical memristive device .", "This behavior resembles biological synapses , whose plasticity is also triggered by mechanisms that are determined by local waveforms .", "their resistance change , is defined by the applied waveforms .", "However , learning in memristive devices has so far been approached mostly on a pragmatic technological level ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["In this paper , we develop a novel approach to the problem of learning sparse representations in the context of fused sparsity and unknown noise level .", "A special emphasize is put on the particular instance of fused sparsity corresponding to the learning in presence of outliers .", "We propose an algorithm , termed Scaled Fused Dantzig Selector ( SFDS ) , that accomplishes the aforementioned learning task by means of a second-order cone program .", "We establish finite sample risk bounds and carry out an experimental evaluation on both synthetic and real data ."]}
{"orig_sents": ["9", "0", "3", "6", "5", "7", "8", "4", "1", "2"], "shuf_sents": ["As in ordinary regression , the candidate label set is a noisy version of the true label .", "Experimental tests on several real-world problems with superset labels show results that are competitive or superior to the state of the art .", "The discovered underlying structures also provide improved explanations of the classification predictions .", "In this work , we solve the problem by maximizing the likelihood of the candidate label sets of training instances .", "This advantage comes at little cost , since the model introduces few additional parameters .", "The LSBCMM is derived from the logistic stick-breaking process .", "We propose a probabilistic model , the Logistic StickBreaking Conditional Multinomial Model ( LSB-CMM ) , to do the job .", "It first maps data points to mixture components and then assigns to each mixture component a label drawn from a component-specific multinomial distribution .", "The mixture components can capture underlying structure in the data , which is very useful when the model is weakly supervised .", "In the superset label learning problem ( SLL ) , each training instance provides a set of candidate labels of which one is the true label of the instance ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["Our algorithms are motivated by a stochastic model in which edge labels are obtained through perturbations of a initial sign assignment consistent with a two-clustering of the nodes .", "We provide a theoretical analysis within this model , showing that we can achieve an optimal ( to whithin a constant factor ) number of mistakes on any graph G = ( V , E ) such that |E| = ( |V |3/2 ) by querying O ( |V |3/2 ) edge labels .", "The running time of this algorithm is at most of order |E| + |V | log |V | .", "We present very efficient active learning algorithms for link classification in signed networks .", "More generally , we show an algorithm that achieves optimality to within a factor of O ( k ) by querying at most order of |V | + ( |V |/k ) 3/2 edge labels ."]}
{"orig_sents": ["6", "1", "2", "4", "3", "5", "0"], "shuf_sents": ["We empirically demonstrate the effectiveness of the proposed algorithm in the challenging threepole balancing task , in which the ability to process a large number of transitions is crucial for success .", "What sets KBSF apart from other kernel-based approaches is the fact that the size of its MDP is independent of the number of transitions , which makes it possible to control the trade-off between the quality of the resulting approximation and the associated computational cost .", "However , KBSF 's memory usage grows linearly with the number of transitions , precluding its application in scenarios where a large amount of data must be processed .", "The incremental version of KBSF is able to process an arbitrary amount of data , which results in a model-based reinforcement learning algorithm that can be used to solve continuous MDPs in both off-line and on-line regimes .", "In this paper we show that it is possible to construct KBSF 's MDP in a fully incremental way , thus freeing the space complexity of this algorithm from its dependence on the number of sample transitions .", "We present theoretical results showing that KBSF can approximate the value function that would be computed by conventional kernel-based learning with arbitrary precision .", "Kernel-based stochastic factorization ( KBSF ) is an algorithm for solving reinforcement learning tasks with continuous state spaces which builds a Markov decision process ( MDP ) based on a set of sample transitions ."]}
{"orig_sents": ["7", "0", "5", "4", "2", "3", "6", "1"], "shuf_sents": ["The representation is a novel application of compressive sensing to sparse probability distributions rather than to the usual sparse signals .", "This comprises a novel hypothesis for how neurons could encode probabilities in the brain .", "Since the compression preserves the geometric structure of the space of sparse probability distributions , probabilistic computation can be performed in the compressed domain .", "Interestingly , functions satisfying the requirements of compressive sensing can be implemented as simple perceptrons .", "When these expected values are estimated by sampling , the quality of the compressed representation is limited only by the quality of sampling .", "The compressive measurements correspond to expected values of nonlinear functions of the probabilistically distributed variables .", "If we use perceptrons as a simple model of feedforward computation by neurons , these results show that the mean activity of a relatively small number of neurons can accurately represent a highdimensional joint distribution implicitly , even without accounting for any noise correlations .", "This paper shows how sparse , high-dimensional probability distributions could be represented by neurons with exponential compression ."]}
{"orig_sents": ["2", "0", "1", "5", "4", "6", "3"], "shuf_sents": ["The first approach , which we call the Newton-LASSO method , minimizes a piecewise quadratic model of the objective function at every iteration to generate a step .", "We employ the fast iterative shrinkage thresholding algorithm ( FISTA ) to solve this subproblem .", "We propose two classes of second-order optimization methods for solving the sparse inverse covariance estimation problem .", "Numerical results , including comparisons with the method implemented in the QUIC software , suggest that all the techniques described in this paper constitute useful tools for the solution of the sparse inverse covariance estimation problem .", "These methods exploit the structure of the Hessian to efficiently compute the search direction and to avoid explicitly storing the Hessian .", "The second approach , which we call the Orthant-Based Newton method , is a two-phase algorithm that first identifies an orthant face and then minimizes a smooth quadratic approximation of the objective function using the conjugate gradient method .", "We also propose a limited memory BFGS variant of the orthant-based Newton method ."]}
{"orig_sents": ["1", "6", "0", "9", "10", "4", "3", "2", "8", "11", "5", "7"], "shuf_sents": ["Some pedigrees number in the thousands of individuals .", "Pedigrees , or family trees , are directed graphs used to identify sites of the genome that are correlated with the presence or absence of a disease .", "These developments and difficulties call for the creation of modern methods of pedigree analysis .", "LODs are difficult to interpret and nontrivial to extend to consider interactions among sites .", "This is because linkage analysis was originally designed with a different task in mind , that of ordering the sites in the genome , before there were technologies that could reveal the order .", "The technique we use for constructing the variational approximation has potential applications to inference in other large-scale graphical models .", "With the advent of genotyping and sequencing technologies , there has been an explosion in the amount of data available , both in the number of individuals and in the number of sites .", "This method allows inference on larger pedigrees than previously analyzed in the literature , which improves disease site prediction .", "Drawing from recent advances in graphical model inference and transducer theory , we introduce a simple yet powerful formalism for expressing genetic disease models .", "Meanwhile , analysis methods have remained limited to pedigrees of < 100 individuals which limits analyses to many small independent pedigrees .", "Disease models , such those used for the linkage analysis log-odds ( LOD ) estimator , have similarly been limited .", "We show that these disease models can be turned into accurate and computationally efficient estimators ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["We also give a general framework for finding all local optima of a function ( given an oracle for approximately finding just one ) and this is a crucial step in our algorithm , one that has been overlooked in previous attempts , and allows us to control the accumulation of error when we find the columns of A one by one via local search .", "To accomplish this , we introduce a novel `` quasi-whitening '' step that may be useful in other contexts in which the covariance of Gaussian noise is not known in advance .", "We present a new algorithm for Independent Component Analysis ( ICA ) which has provable performance guarantees .", "In particular , suppose we are given samples of the form y = Ax + where A is an unknown n x n matrix and x is a random variable whose components are independent and have a fourth moment strictly less than that of a standard Gaussian random variable and is an n-dimensional Gaussian random variable with unknown covariance : We give an algorithm that provable recovers A and up to an additive and whose running time and sample complexity are polynomial in n and 1/ ."]}
{"orig_sents": ["3", "1", "5", "2", "4", "6", "0"], "shuf_sents": ["We give efficient algorithms for the problem for trees , and show that , for a general dag , the problem is intractable .", "We represent the execution of a pipeline using a directed acyclic graph of AND and OR nodes , where each node represents a data item produced by some operator in the pipeline .", "We want to reduce the uncertainty in the output by issuing queries to a human , where a query consists of checking if a given data item is correct .", "In this paper , we consider the problem of debugging large pipelines by human labeling .", "In this paper , we consider the problem of asking the optimal set of queries to minimize the resulting output uncertainty .", "We assume that each operator assigns a confidence to each of its output data .", "We perform a detailed evaluation of the complexity of the problem for various classes of graphs ."]}
{"orig_sents": ["4", "1", "5", "6", "2", "3", "0"], "shuf_sents": ["We also outline a number of open problems arising from the formulation .", "Instead of relying on convex losses and regularizers such as in SVMs , logistic regression and boosting , or instead non-convex but continuous formulations such as those encountered in neural networks and deep belief networks , our framework entails a non-convex but discrete formulation , where estimation amounts to finding a MAP configuration in a graphical model whose potential functions are low-dimensional discrete surrogates for the misclassification loss .", "We empirically demonstrate in a number of experiments that this approach is promising in dealing with issues such as severe label noise , while still having global optimality guarantees .", "Due to the discrete nature of the formulation , it also allows for direct regularization through cardinality-based penalties , such as the 0 pseudo-norm , thus providing the ability to perform feature selection and trade-off interpretability and predictability in a principled manner .", "We present a new formulation for binary classification .", "We argue that such a discrete formulation can naturally account for a number of issues that are typically encountered in either the convex or the continuous non-convex approaches , or both .", "By reducing the learning problem to a MAP inference problem , we can immediately translate the guarantees available for many inference settings to the learning problem itself ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["In this paper , we consider a nonparametric topic model based on the hierarchical Dirichlet process ( HDP ) , and develop a novel online variational inference algorithm based on split-merge topic updates .", "For streaming analysis of large datasets where batch analysis is infeasible , we show that our split-merge updates better capture the nonparametric properties of the underlying model , allowing continual learning of new topics .", "In practice , however , conventional batch and online variational methods quickly become trapped in local optima .", "We derive a simpler and faster variational approximation of the HDP , and show that by intelligently splitting and merging components of the variational posterior , we can achieve substantially better predictions of test data than conventional online and batch variational algorithms .", "Variational methods provide a computationally scalable alternative to Monte Carlo methods for large-scale , Bayesian nonparametric learning ."]}
{"orig_sents": ["5", "3", "1", "2", "0", "4"], "shuf_sents": ["Second , we use the defined statistic to develop the Fiedler random field model , which allows for efficient estimation of edge distributions over large-scale random networks .", "The key contribution of this paper is twofold .", "First , we introduce the Fiedler delta statistic , based on the Laplacian spectrum of graphs , which allows to dispense with any parametric assumption concerning the modeled network properties .", "Moreover , the vast majority of currently available models are explicitly designed for capturing some specific graph properties ( such as power-law degree distributions ) , which makes them unsuitable for application to domains where the behavior of the target quantities is not known a priori .", "After analyzing the dependence structure involved in Fiedler random fields , we estimate them over several real-world networks , showing that they achieve a much higher modeling accuracy than other well-known statistical approaches .", "Statistical models for networks have been typically committed to strong prior assumptions concerning the form of the modeled distributions ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["This paper introduces a novel classification method for functional magnetic resonance imaging datasets with tens of classes .", "The method is designed to make predictions using information from as many brain locations as possible , instead of resorting to feature selection , and does this by decomposing the pattern of brain activation into differently informative sub-regions .", "We provide results over a complex semantic processing dataset that show that the method is competitive with state-of-the-art feature selection and also suggest how the method may be used to perform group or exploratory analyses of complex class structure ."]}
{"orig_sents": ["3", "4", "1", "2", "5", "0"], "shuf_sents": ["We run a comparative evaluation on multiple large-scale benchmark datasets that highlights the scalability of our approach and shows improved performance over the other state-of-the-art hierarchical methods .", "This paper proposes a set of Bayesian methods to model hierarchical dependencies among class labels using multivariate logistic regression .", "Specifically , the parent-child relationships are modeled by placing a hierarchical prior over the children nodes centered around the parameters of their parents ; thereby encouraging classes nearby in the hierarchy to share similar model parameters .", "A challenging problem in hierarchical classification is to leverage the hierarchical relations among classes for improving classification performance .", "An even greater challenge is to do so in a manner that is computationally feasible for large scale problems .", "We present variational algorithms for tractable posterior inference in these models , and provide a parallel implementation that can comfortably handle largescale problems with hundreds of thousands of dimensions and tens of thousands of classes ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We describe how the pretraining algorithm for Deep Boltzmann Machines ( DBMs ) is related to the pretraining algorithm for Deep Belief Networks and we show that under certain conditions , the pretraining procedure improves the variational lower bound of a two-hidden-layer DBM .", "Based on this analysis , we develop a different method of pretraining DBMs that distributes the modelling work more evenly over the hidden layers .", "Our results on the MNIST and NORB datasets demonstrate that the new pretraining algorithm allows us to learn better generative models ."]}
{"orig_sents": ["3", "0", "1", "4", "2"], "shuf_sents": ["We show that weighting each coordinate i with the estimated norm of the ith derivative of f is an efficient way to significantly improve the performance of distance-based regressors , e.g .", "kernel and k-NN regressors .", "Moreover , the proposed estimator is efficiently learned online .", "In regression problems over Rd , the unknown function f often varies more in some coordinates than in others .", "We propose a simple estimator of these derivative norms and prove its consistency ."]}
{"orig_sents": ["3", "2", "1", "5", "6", "4", "0", "7"], "shuf_sents": ["PDA uses the concept of Pareto optimality to detect anomalies under multiple criteria without having to run an algorithm multiple times with different choices of weights .", "However , in many cases there may not exist a single dissimilarity measure that captures all possible anomalous patterns .", "In most anomaly detection algorithms , the dissimilarity between data samples is calculated by a single criterion , such as Euclidean distance .", "We consider the problem of identifying patterns in a data set that exhibit anomalous behavior , often referred to as anomaly detection .", "In this paper , we introduce a novel non-parametric multi-criteria anomaly detection method using Pareto depth analysis ( PDA ) .", "In such a case , multiple criteria can be defined , and one can test for anomalies by scalarizing the multiple criteria using a linear combination of them .", "If the importance of the different criteria are not known in advance , the algorithm may need to be executed multiple times with different choices of weights in the linear combination .", "The proposed PDA approach scales linearly in the number of criteria and is provably better than linear combinations of the criteria ."]}
{"orig_sents": ["4", "5", "3", "2", "1", "0"], "shuf_sents": ["Our experiments show that our model is competitive both as a generative model of documents and as a document representation learning algorithm .", "The end result is a model whose training complexity scales logarithmically with the vocabulary size instead of linearly as in the Replicated Softmax .", "This paradigm also allows us to replace the expensive softmax distribution over words with a hierarchical distribution over paths in a binary tree of words .", "Specifically , we take inspiration from the conditional mean-field recursive equations of the Replicated Softmax in order to define a neural network architecture that estimates the probability of observing a new word in a given document given the previously observed words .", "We describe a new model for learning meaningful representations of text documents from an unlabeled collection of documents .", "This model is inspired by the recently proposed Replicated Softmax , an undirected graphical model of word counts that was shown to learn a better generative model and more meaningful document representations ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["However , unlike the likelihoodbased supervised topic models , of which posterior inference can be carried out using the Bayes ' rule , the max-margin posterior constraints have made Monte Carlo methods infeasible or at least not directly applicable , thereby limited the choice of inference algorithms to be based on variational approximation with strict mean field assumptions .", "We report thorough experimental results that compare our approach favorably against existing alternatives in both accuracy and efficiency .", "This strategy has been adopted by a number of supervised topic models , such as MedLDA , which employs max-margin posterior constraints .", "In this paper , we develop two efficient Monte Carlo methods under much weaker assumptions for max-margin supervised topic models based on an importance sampler and a collapsed Gibbs sampler , respectively , in a convex dual formulation .", "An effective strategy to exploit the supervising side information for discovering predictive topic representations is to impose discriminative constraints induced by such information on the posterior distributions under a topic model ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["We test this interpolation on simulated data and on the large-scale Netflix and MovieLens ratings data , and find improved accuracy relative to the existing matrix norms .", "We introduce a new family of matrix norms , the `` local max '' norms , generalizing existing methods such as the max norm , the trace norm ( nuclear norm ) , and the weighted or smoothed weighted trace norms , which have been extensively used in the literature as regularizers for matrix reconstruction problems .", "We also provide theoretical results showing learning guarantees for some of the new norms .", "We show that this new family can be used to interpolate between the ( weighted or unweighted ) trace norm and the more conservative max norm ."]}
{"orig_sents": ["6", "0", "4", "1", "3", "7", "2", "5"], "shuf_sents": ["BCI based on sensori-motor rhythms use imaginary motor tasks , such as moving the right or left hand , to send control signals .", "This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button .", "By not wasting time on inefficient tasks , and focusing on the most promising ones , this algorithm results in a faster task selection and a more efficient use of the BCI training session .", "We develop for this purpose an adaptive algorithm , UCB-classif , based on the stochastic bandit theory .", "The performances of a BCI can vary greatly across users but also depend on the tasks used , making the problem of appropriate task selection an important issue .", "Comparing the proposed method to the standard practice in task selection , for a fixed time budget , UCB-classif leads to an improved classification rate , and for a fixed classification rate , to a reduction of the time spent in training by 50 % .", "Brain-computer interfaces ( BCI ) allow users to `` communicate '' with a computer without using their muscles .", "This shortens the training stage , thereby allowing the exploration of a greater variety of tasks ."]}
{"orig_sents": ["4", "1", "3", "0", "5", "2"], "shuf_sents": ["Our models allow one to estimate multivariate Markov networks given any univariate exponential distribution , such as Poisson , negative binomial , and exponential , by fitting penalized GLMs to select the neighborhood for each node .", "The popular instances of these models such as Gaussian Markov Random Fields ( GMRFs ) , Ising models , and multinomial discrete models , however do not capture the characteristics of data in many settings .", "We also provide examples of non-Gaussian high-throughput genomic networks learned via our GLM graphical models .", "We introduce a new class of graphical models based on generalized linear models ( GLMs ) by assuming that node-wise conditional distributions arise from exponential families .", "Undirected graphical models , also known as Markov networks , enjoy popularity in a variety of applications .", "A major contribution of this paper is the rigorous statistical analysis showing that with high probability , the neighborhood of our graphical models can be recovered exactly ."]}
{"orig_sents": ["5", "2", "4", "3", "0", "1"], "shuf_sents": ["Our analysis shows that CPRL inherits many desirable properties from CS , such as guarantees for exact recovery .", "We further provide scalable numerical solvers to accelerate its implementation .", "This limits its application in many areas where CS could make a difference .", "We propose a novel solution using a lifting technique - CPRL , which relaxes the NP-hard problem to a nonsmooth semidefinite program .", "This paper presents a novel extension of CS to the phase retrieval problem , where intensity measurements of a linear system are used to recover a complex sparse signal .", "While compressive sensing ( CS ) has been one of the most vibrant research fields in the past few years , most development only applies to linear models ."]}
{"orig_sents": ["2", "0", "8", "3", "1", "6", "4", "7", "5"], "shuf_sents": ["It is a strong indicator of social saliency because the attention of the participating group is focused on that point .", "We model the gaze as a cone-shaped distribution emanating from the center of the eyes , capturing the variation of eye-in-head motion .", "A gaze concurrence is a point in 3D where the gaze directions of two or more people intersect .", "In this paper , we present a method to construct a 3D social saliency field and locate multiple gaze concurrences that occur in a social scene from videos taken by head-mounted cameras .", "The resulting gaze model enables us to build a social saliency field in 3D .", "Our algorithm is applied to reconstruct multiple gaze concurrences in several real world scenes and evaluated quantitatively against motion-captured ground truth .", "We calibrate the parameters of this distribution by exploiting the fixed relationship between the primary gaze ray and the head-mounted camera pose .", "We estimate the number and 3D locations of the gaze concurrences via provably convergent modeseeking in the social saliency field .", "In scenes occupied by large groups of people , multiple concurrences may occur and transition over time ."]}
{"orig_sents": ["2", "3", "1", "0", "4", "5"], "shuf_sents": ["We introduce a probabilistic approach to collaborative filtering with implicit feedback based on modelling the user 's item selection process .", "However , since explicit feedback is often difficult to collect it is important to develop effective models that take advantage of the more widely available implicit feedback .", "User preferences for items can be inferred from either explicit feedback , such as item ratings , or implicit feedback , such as rental histories .", "Research in collaborative filtering has concentrated on explicit feedback , resulting in the development of accurate and scalable models .", "In the interests of scalability , we restrict our attention to treestructured distributions over items and develop a principled and efficient algorithm for learning item trees from data .", "We also identify a problem with a widely used protocol for evaluating implicit feedback models and propose a way of addressing it using a small quantity of explicit feedback data ."]}
{"orig_sents": ["0", "2", "1", "3", "4", "5"], "shuf_sents": ["Applications of Bayesian nonparametric methods require learning and inference algorithms which efficiently explore models of unbounded complexity .", "By introducing split-merge moves based on sequential allocation , we allow large global changes in the shared feature structure .", "We develop new Markov chain Monte Carlo methods for the beta process hidden Markov model ( BP-HMM ) , enabling discovery of shared activity patterns in large video and motion capture databases .", "We also develop data-driven reversible jump moves which more reliably discover rare or unique behaviors .", "Our proposals apply to any choice of conjugate likelihood for observed data , and we show success with multinomial , Gaussian , and autoregressive emission models .", "Together , these innovations allow tractable analysis of hundreds of time series , where previous inference required clever initialization and lengthy burn-in periods for just six sequences ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["We describe an approach to speed-up inference with latent-variable PCFGs , which have been shown to be highly effective for natural language parsing .", "We also describe an error bound for this approximation , which gives guarantees showing that if the underlying tensors are well approximated , then the probability distribution over trees will also be well approximated .", "Our approach is based on a tensor formulation recently introduced for spectral estimation of latent-variable PCFGs coupled with a tensor decomposition algorithm well-known in the multilinear algebra literature .", "Empirical evaluation on real-world natural language parsing data demonstrates a significant speed-up at minimal cost for parsing performance ."]}
{"orig_sents": ["3", "0", "2", "1", "4"], "shuf_sents": ["A consistency framework is suggested that is suitable for highly dependent time-series , and an asymptotically consistent algorithm is proposed .", "No modeling , independence or parametric assumptions are made ; the data are allowed to be dependent and the dependence can be of arbitrary form .", "In order for the consistency to be established the only assumption required is that the data is generated by stationary ergodic time-series distributions .", "The problem of multiple change point estimation is considered for sequences with unknown number of change points .", "The theoretical results are complemented with experimental evaluations ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["Our framework is based on the theory of random atomic measures , with the prior specified by a gamma process .", "We develop a Bayesian nonparametric extension of the popular Plackett-Luce choice model that can handle an infinite number of choice items .", "We develop a time-varying extension of our model , and apply it to the New York Times lists of weekly bestselling books .", "We derive a posterior characterization and a simple and effective Gibbs sampler for posterior simulation ."]}
{"orig_sents": ["4", "0", "5", "1", "2", "3"], "shuf_sents": ["VPI has two main features : First , it is a nonparametric algorithm that finds a good sparse approximation of the optimal value function given a dictionary of features .", "Second , after each iteration of VPI , the algorithm adds a set of functions based on the currently learned value function to the dictionary .", "This increases the representation power of the dictionary in a way that is directly relevant to the goal of having a good approximation of the optimal value function .", "We theoretically study VPI and provide a finite-sample error upper bound for it .", "Value Pursuit Iteration ( VPI ) is an approximate value iteration algorithm that finds a close to optimal policy for reinforcement learning problems with large state spaces .", "The algorithm is almost insensitive to the number of irrelevant features ."]}
{"orig_sents": ["3", "4", "0", "5", "1", "2"], "shuf_sents": ["This is an interesting result because this convex program is equivalent to a standard compressive sensing problem with a highly-structured aggregate measurement matrix which does not satisfy the RIP requirements in the standard sense , and yet we can achieve exact recovery .", "We supplement our theoretical analysis with simulations and an application to real video data .", "These further support the validity of the proposed approach for acquisition and recovery of signals with time-varying sparsity .", "We consider the problem of recovering a sequence of vectors , ( xk ) K k=0 , for which the increments xk - xk-1 are Sk -sparse ( with Sk typically smaller than S1 ) , based on linear measurements ( yk = Ak xk + ek ) K k=1 , where Ak and ek denote the measurement matrix and noise , respectively .", "Assuming each Ak obeys the restricted isometry property ( RIP ) of a certain order -- depending only on Sk -- we show that in the absence of noise a convex program , which minimizes the weighted sum of the 1 -norm of successive differences subject to the linear measurement constraints , recovers the sequence ( xk ) K k=1 exactly .", "In the presence of bounded noise , we propose a quadratically-constrained convex program for recovery and derive bounds on the reconstruction error of the sequence ."]}
{"orig_sents": ["4", "1", "5", "3", "0", "2"], "shuf_sents": [", while our MF method is closely related to a commonly used EM algorithm .", "However , it has given rise to the computational task of aggregating the crowdsourced labels provided by a collection of unreliable annotators .", "In both cases , we find that the performance of the algorithms critically depends on the choice of a prior distribution on the workers ' reliability ; by choosing the prior properly , both BP and MF ( and EM ) perform surprisingly well on both simulated and real-world datasets , competitive with state-of-the-art algorithms based on more complicated modeling assumptions .", "We show that our BP algorithm generalizes both majority voting and a recent algorithm by Karger et al .", "Crowdsourcing has become a popular paradigm for labeling large datasets .", "We approach this problem by transforming it into a standard inference problem in graphical models , and applying approximate variational methods , including belief propagation ( BP ) and mean field ( MF ) ."]}
{"orig_sents": ["4", "1", "2", "5", "0", "3"], "shuf_sents": ["The notion of a state activation , which offers a simple formalization of the hierarchical transition behavior of HHMMs , enables us to conduct model inference efficiently .", "However , existing HHMM parameter estimation methods require large computations of time complexity O ( T N 2D ) at least for model inference , where D is the depth of the hierarchy , N is the number of states in each level , and T is the sequence length .", "In this paper , we propose a new inference method of HHMMs for which the time complexity is O ( T N D+1 ) .", "We present some experiments to demonstrate that our proposed method works more efficiently to estimate HHMM parameters than do some existing methods such as the flattening method and Gibbs sampling method .", "Hierarchical Hidden Markov Models ( HHMMs ) are sophisticated stochastic models that enable us to capture a hierarchical context characterization of sequence data .", "A key idea of our algorithm is application of the forward-backward algorithm to state activation probabilities ."]}
{"orig_sents": ["6", "3", "5", "2", "0", "1", "4"], "shuf_sents": ["In particular , we show how traditional centralized models , such as probabilistic PCA and missing-data PPCA , can be learned when the data is distributed across a network of sensors .", "We demonstrate the utility of this approach on the problem of distributed affine structure from motion .", "In this work we present an approach to estimation and learning of generative probabilistic models in a distributed context where certain sensor data can be missing .", "However , many problems in wide-area surveillance can benefit from distributed modeling , either because of physical or computational constraints .", "Our experiments suggest that the accuracy of the learned probabilistic structure and motion models rivals that of traditional centralized factorization methods while being able to handle challenging situations such as missing or noisy observations .", "Most distributed models to date use algebraic approaches ( such as distributed SVD ) and as a result can not explicitly deal with missing data .", "Probabilistic approaches to computer vision typically assume a centralized setting , with the algorithm granted access to all observed data points ."]}
{"orig_sents": ["7", "5", "0", "2", "1", "6", "4", "3"], "shuf_sents": ["According to structured sparsity theory , the measurements can be further reduced to O ( K + log n ) for tree-sparse data instead of O ( K + K log n ) for standard K-sparse data with length n. However , few of existing algorithms have utilized this for CS-MRI , while most of them model the problem with total variation and wavelet sparse regularization .", "In this paper , we propose a fast convex optimization algorithm to improve CS-MRI .", "On the other side , some algorithms have been proposed for tree sparse regularization , but few of them have validated the benefit of wavelet tree structure in CS-MRI .", "Numerous experiments have been conducted and show that the proposed algorithm outperforms the state-of-the-art CS-MRI algorithms , and gain better reconstructions results on real MR images than general tree based solvers or algorithms .", "The original complex problem is decomposed into three simpler subproblems then each of the subproblems can be efficiently solved with an iterative scheme .", "This can significantly reduce MR scanning time .", "Wavelet sparsity , gradient sparsity and tree sparsity are all considered in our model for real MR images .", "In Compressive Sensing Magnetic Resonance Imaging ( CS-MRI ) , one can reconstruct a MR image with good quality from only a small number of measurements ."]}
{"orig_sents": ["4", "3", "5", "0", "2", "1"], "shuf_sents": ["We confirm that the first two predictions hold by reporting results from a set of human behavior studies on the connection between saliency and tracking .", "This architecture is fully compliant with the standard physiological models of V1 and MT , and with what is known about attentional control in area LIP , while explaining the results of the human behavior experiments .", "We also show that the third prediction holds by constructing a common neurophysiologically plausible architecture that can computationally solve both saliency and tracking .", "This model is based on the saliency hypothesis for tracking which postulates that tracking is achieved by the top-down tuning , based on target features , of discriminant center-surround saliency mechanisms over time .", "A model connecting visual tracking and saliency has recently been proposed .", "In this work , we identify three main predictions that must hold if the hypothesis were true : 1 ) tracking reliability should be larger for salient than for non-salient targets , 2 ) tracking reliability should have a dependence on the defining variables of saliency , namely feature contrast and distractor heterogeneity , and must replicate the dependence of saliency on these variables , and 3 ) saliency and tracking can be implemented with common low level neural mechanisms ."]}
{"orig_sents": ["2", "3", "4", "1", "6", "5", "0"], "shuf_sents": ["Experiments illustrate that the proposed method produces high quality results .", "The conditional independence of separate sources imposes constraints on their shared latent representation , which , if respected , can improve the quality of a learned low dimensional representation .", "Subspace learning seeks a low dimensional representation of data that enables accurate reconstruction .", "However , in many applications , data is obtained from multiple sources rather than a single source ( e.g .", "an object might be viewed by cameras at different angles , or a document might consist of text and images ) .", "For this formulation , we develop an efficient algorithm that recovers an optimal data reconstruction by exploiting an implicit convex regularizer , then recovers the corresponding latent representation and reconstruction model , jointly and optimally .", "In this paper , we present a convex formulation of multi-view subspace learning that enforces conditional independence while reducing dimensionality ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["In a machine learning context , numerical experiments indicate that the new algorithm can dramatically outperform standard algorithms , both in terms of optimizing the training error and reducing the test error quickly .", "While standard stochastic gradient methods converge at sublinear rates for this problem , the proposed method incorporates a memory of previous gradient values in order to achieve a linear convergence rate .", "We propose a new stochastic gradient method for optimizing the sum of a finite set of smooth functions , where the sum is strongly convex ."]}
{"orig_sents": ["1", "3", "5", "2", "0", "4", "6", "7"], "shuf_sents": ["Nevertheless we show that inference is completely tractable and derive an Expectation-Maximization ( EM ) algorithm for parameter estimation .", "We describe a latent variable model for supervised dimensionality reduction and distance metric learning .", "The model differs significantly from classical factor analysis in that the posterior distribution over these latent variables is not always multivariate Gaussian .", "The model discovers linear projections of high dimensional data that shrink the distance between similarly labeled inputs and expand the distance between differently labeled ones .", "We also compare the model to other approaches in distance metric learning .", "The model 's continuous latent variables locate pairs of examples in a latent space of lower dimensionality .", "The model 's main advantage is its simplicity : at each iteration of the EM algorithm , the distance metric is re-estimated by solving an unconstrained least-squares problem .", "Experiments show that these simple updates are highly effective ."]}
{"orig_sents": ["2", "4", "3", "1", "0"], "shuf_sents": ["In most examples , our solution achieves a better performance in precision at the top .", "Finally , we report the results of several experiments in the bipartite setting evaluating the performance of our solution and comparing the results to several other algorithms seeking high precision at the top .", "We introduce a new notion of classification accuracy based on the top -quantile values of a scoring function , a relevant criterion in a number of problems arising for search engines .", "We also present margin-based guarantees for this algorithm based on the top -quantile value of the scores of the functions in the hypothesis set .", "We define an algorithm optimizing a convex surrogate of the corresponding loss , and discuss its solution in terms of a set of convex optimization problems ."]}
{"orig_sents": ["1", "5", "0", "3", "4", "2"], "shuf_sents": ["A novel latent factor model SLFA is then proposed as a matrix factorization problem with a special regularization term that encourages collaborative reconstruction .", "In this paper , we study latent factor models with dependency structure in the latent space .", "Experimental results on two synthetic data and two real-world data sets demonstrate that pairwise relationships and latent factors learned by our model provide a more structured way of exploring high-dimensional data , and the learned representations achieve the state-of-the-art classification performance .", "The main benefit ( novelty ) of the model is that we can simultaneously learn the lowerdimensional representation for data and model the pairwise relationships between latent factors explicitly .", "An on-line learning algorithm is devised to make the model feasible for large-scale learning problems .", "We propose a general learning framework which induces sparsity on the undirected graphical model imposed on the vector of latent factors ."]}
{"orig_sents": ["3", "5", "2", "1", "0", "4"], "shuf_sents": ["The method , called Excess Correlation Analysis , is based on a spectral decomposition of low-order moments via two singular value decompositions ( SVDs ) .", "For LDA , the procedure correctly recovers both the topic-word distributions and the parameters of the Dirichlet prior over the topic mixtures , using only trigram statistics ( i.e. , third order moments , which may be estimated with documents containing just three words ) .", "This work provides a simple and efficient learning procedure that is guaranteed to recover the parameters for a wide class of topic models , including Latent Dirichlet Allocation ( LDA ) .", "Topic modeling is a generalization of clustering that posits that observations ( words in a document ) are generated by multiple latent factors ( topics ) , as opposed to just one .", "Moreover , the algorithm is scalable , since the SVDs are carried out only on k x k matrices , where k is the number of latent factors ( topics ) and is typically much smaller than the dimension of the observation ( word ) space .", "This increased representational power comes at the cost of a more challenging unsupervised learning problem of estimating the topic-word distributions when only words are observed , and the topics are hidden ."]}
{"orig_sents": ["5", "1", "3", "4", "2", "0"], "shuf_sents": ["New versions of the Follow-the-Perturbed-Leader algorithms are presented , as well as methods based on the Littlestone 's dimension , efficient methods for matrix completion with trace norm , and algorithms for the problems of transductive learning and prediction with static experts .", "Various upper bounds on the minimax value , previously thought to be non-constructive , are shown to yield algorithms .", "To illustrate our approach , we present several new algorithms , including a family of randomized methods that use the idea of a `` random playout '' .", "This allows us to seamlessly recover known methods and to derive new ones , also capturing such `` unorthodox '' methods as Follow the Perturbed Leader and the R2 forecaster .", "Understanding the inherent complexity of the learning problem thus leads to the development of algorithms .", "We show a principled way of deriving online learning algorithms from a minimax analysis ."]}
{"orig_sents": ["6", "0", "3", "4", "5", "1", "2"], "shuf_sents": ["the average Bayes error for a chosen task versus the total number of examples n for all tasks .", "squared exponential kernels .", "We also demonstrate that when learning many tasks , the learning curves separate into an initial phase , where the Bayes error on each task is reduced down to a plateau value by `` collective learning '' even though most tasks have not seen examples , and a final decay that occurs once the number of examples is proportional to the number of tasks .", "For GP covariances that are the product of an input-dependent covariance function and a free-form intertask covariance matrix , we show that accurate approximations for the learning curve can be obtained for an arbitrary number of tasks T .", "We use these to study the asymptotic learning behaviour for large n. Surprisingly , multi-task learning can be asymptotically essentially useless , in the sense that examples from other tasks help only when the degree of inter-task correlation , , is near its maximal value = 1 .", "This effect is most extreme for learning of smooth target functions as described by e.g .", "We study the average case performance of multi-task Gaussian process ( GP ) regression as captured in the learning curve , i.e ."]}
{"orig_sents": ["3", "2", "4", "0", "1", "5"], "shuf_sents": ["We prove a performance bound for the two versions of the algorithm showing that the two problems are characterized by the same notion of complexity .", "We also show how the UGapE algorithm as well as its theoretical analysis can be extended to take into account the variance of the arms and to multiple bandits .", "This problem has been studied in the literature from two different perspectives : fixed budget and fixed confidence .", "We study the problem of identifying the best arm ( s ) in the stochastic multi-armed bandit setting .", "We propose a unifying approach that leads to a meta-algorithm called unified gap-based exploration ( UGapE ) , with a common structure and similar theoretical analysis for these two settings .", "Finally , we evaluate the performance of UGapE and compare it with a number of existing fixed budget and fixed confidence algorithms ."]}
{"orig_sents": ["2", "0", "5", "4", "1", "3", "6"], "shuf_sents": ["A naive approach is a two-step procedure of first estimating two densities separately and then computing their difference .", "We derive a non-parametric finite-sample error bound for the proposed single-shot density-difference estimator and show that it achieves the optimal convergence rate .", "We address the problem of estimating the difference between two probability densities .", "We then show how the proposed density-difference estimator can be utilized in L2 -distance approximation .", "In this paper , we propose a single-shot procedure for directly estimating the density difference without separately estimating two densities .", "However , such a two-step procedure does not necessarily work well because the first step is performed without regard to the second step and thus a small estimation error incurred in the first stage can cause a big error in the second stage .", "Finally , we experimentally demonstrate the usefulness of the proposed method in robust distribution comparison such as class-prior estimation and change-point detection ."]}
{"orig_sents": ["1", "3", "2", "0", "4"], "shuf_sents": ["We provide a `` sanity check '' theoretical analysis , discussing the behavior of our extensions in the standard stationary finite state-action case .", "Formal exploration approaches in model-based reinforcement learning estimate the accuracy of the currently learned model without consideration of the empirical prediction error .", "We propose extensions to such approaches which drive exploration solely based on empirical estimates of the learner 's accuracy and learning progress .", "For example , PAC-MDP approaches such as R- MAX base their model certainty on the amount of collected data , while Bayesian approaches assume a prior over the transition dynamics .", "We then provide experimental studies demonstrating the robustness of these exploration measures in cases of non-stationary environments or where original approaches are misled by wrong domain assumptions ."]}
{"orig_sents": ["0", "7", "2", "3", "4", "6", "5", "1"], "shuf_sents": ["Since its inception , the modus operandi of multi-task learning ( MTL ) has been to minimize the task-wise mean of the empirical risks .", "The results of several MTL formulations on synthetic and real problems in the MTL and LTL test settings are encouraging .", "One endpoint of this spectrum is minimax MTL : a new MTL formulation that minimizes the maximum of the tasks ' empirical risks .", "Via a certain relaxation of minimax MTL , we obtain a continuum of MTL formulations spanning minimax MTL and classical MTL .", "The full paradigm itself is loss-compositional , operating on the vector of empirical risks .", "We show theoretically that minimax MTL tends to avoid worst case outcomes on newly drawn test tasks in the learning to learn ( LTL ) test setting .", "It incorporates minimax MTL , its relaxations , and many new MTL formulations as special cases .", "We introduce a generalized loss-compositional paradigm for MTL that includes a spectrum of formulations as a subfamily ."]}
{"orig_sents": ["2", "3", "5", "1", "0", "4"], "shuf_sents": ["We derive general algorithms for discrete and Gaussian pairwise Markov random fields , showing improvements over standard loopy belief propagation .", "Conversely , our approach leverages multiplier methods with well-understood convergence properties , and uses bound projection methods to ensure that marginal approximations are valid at all iterations .", "We develop convergent minimization algorithms for Bethe variational approximations which explicitly constrain marginal estimates to families of valid distributions .", "While existing message passing algorithms define fixed point iterations corresponding to stationary points of the Bethe free energy , their greedy dynamics do not distinguish between local minima and maxima , and can fail to converge .", "We also apply our method to a hybrid model with both discrete and continuous variables , showing improvements over expectation propagation .", "For continuous estimation problems , this instability is linked to the creation of invalid marginal estimates , such as Gaussians with negative variance ."]}
{"orig_sents": ["5", "0", "4", "6", "3", "2", "1"], "shuf_sents": ["Previous approaches are able to exploit only one of these two structures , yielding a O ( d/T ) convergence rate for strongly convex objectives in d dimensions and O ( s ( log d ) /T ) convergence rate when the optimum is s-sparse .", "The effectiveness of our approach is also confirmed in numerical simulations where we compare to several baselines on a least-squares regression problem .", "By recourse to statistical minimax results , we show that our convergence rates are optimal up to constants .", "Our results apply to locally Lipschitz losses including the logistic , exponential , hinge and least-squares losses .", "Our algorithm is based on successively solving a series of 1 -regularized optimization problems using Nesterov 's dual averaging algorithm .", "We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex , and the optimum is ( approximately ) sparse .", "We establish that the error of our solution after T iterations is at most O ( s ( log d ) /T ) , with natural extensions to approximate sparsity ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["In this paper , we extend such result by weakening the assumptions on the regularization term .", "A recent characterization states that certain classes of regularization functionals with differentiable regularization term admit a linear representer theorem for any choice of the data if and only if the regularization term is a radial nondecreasing function .", "A class of regularization functionals is said to admit a linear representer theorem if every member of the class admits minimizers that lie in the finite dimensional subspace spanned by the representers of the data .", "The representer theorem is a property that lies at the foundation of regularization theory and kernel methods .", "In particular , the main result of this paper implies that , for a sufficiently large family of regularization functionals , radial nondecreasing functions are the only lower semicontinuous regularization terms that guarantee existence of a representer theorem for any choice of the data ."]}
{"orig_sents": ["4", "3", "0", "2", "5", "1"], "shuf_sents": ["In this paper , we consider a generic setting where we aim to diversify the top-k ranking list based on an arbitrary relevance function and an arbitrary similarity function among all the examples .", "Experimental results on real data sets demonstrate the effectiveness of the proposed algorithm .", "We formulate it as an optimization problem and show that in general it is NP-hard .", "It is broadly applicable in many real world problems , e.g. , information retrieval , team assembling , product search , etc .", "Diversified ranking is a fundamental task in machine learning .", "Then , we show that for a large volume of the parameter space , the proposed objective function enjoys the diminishing returns property , which enables us to design a scalable , greedy algorithm to find the ( 1 - 1/e ) near-optimal solution ."]}
{"orig_sents": ["3", "2", "5", "0", "4", "1"], "shuf_sents": ["We explain methods to efficiently maintain a genealogy of particles from which any particle can be reconstructed .", "The timing experiments show that reconstruction of particles is indeed much more efficient as compared to transmission of particles .", "EMC avoids the transmission of particles between nodes , and instead reconstructs them from the particle genealogy .", "We propose a novel method for scalable parallelization of SMC algorithms , Entangled Monte Carlo simulation ( EMC ) .", "We demonstrate using examples from Bayesian phylogenetic that the computational gain from parallelization using EMC significantly outweighs the cost of particle reconstruction .", "In particular , we show that we can reduce the communication to the particle weights for each machine while efficiently maintaining implicit global coherence of the parallel simulation ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["Sudderth , Wainwright , and Willsky conjectured that the Bethe approximation corresponding to any fixed point of the belief propagation algorithm over an attractive , pairwise binary graphical model provides a lower bound on the true partition function .", "In this work , we resolve this conjecture in the affirmative by demonstrating that , for any graphical model with binary variables whose potential functions ( not necessarily pairwise ) are all log-supermodular , the Bethe partition function always lower bounds the true partition function .", "The proof of this result follows from a new variant of the `` four functions '' theorem that may be of independent interest ."]}
{"orig_sents": ["2", "3", "1", "4", "0"], "shuf_sents": ["Importantly , the method is as efficient as standard Gaussian BP , and its convergence properties do not depend on the complexity of the univariate marginals , even when a nonparametric representation is used .", "In this work we present Nonparanormal BP for performing efficient inference on distributions parameterized by a Gaussian copulas network and any univariate marginals .", "The empirical success of the belief propagation approximate inference algorithm has inspired numerous theoretical and algorithmic advances .", "Yet , for continuous non-Gaussian domains performing belief propagation remains a challenging task : recent innovations such as nonparametric or kernel belief propagation , while useful , come with a substantial computational cost and offer little theoretical guarantees , even for tree structured models .", "For tree structured networks , our approach is guaranteed to be exact for this powerful class of non-Gaussian models ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["By establishing a precise connection between optimal transport metrics , optimal quantization , and learning theory , we derive new probabilistic bounds for the performance of a classic algorithm in unsupervised learning ( k-means ) , when used to produce a probability measure derived from the data .", "We study the problem of estimating , in the sense of optimal transport metrics , a measure which is assumed supported on a manifold embedded in a Hilbert space .", "In the course of the analysis , we arrive at new lower bounds , as well as probabilistic upper bounds on the convergence rate of empirical to population measures , which , unlike existing bounds , are applicable to a wide class of measures ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems .", "Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems .", "Continuous relaxations play an important role in discrete optimization , but have not seen much use in approximate probabilistic inference .", "The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference , results in new ways of estimating normalization constants ( partition functions ) , and in general opens up a number of new avenues for inference in difficult discrete systems ."]}
{"orig_sents": ["5", "2", "0", "3", "1", "4"], "shuf_sents": ["We study this problem in the case of kernel ridge regression for functional responses with an r -norm constraint on the combination coefficients ( r 1 ) .", "We propose a multiple operator-valued kernel learning algorithm based on solving a system of linear operator equations by using a block coordinate-descent procedure .", "This paper addresses the problem of learning a finite linear combination of infinite-dimensional operator-valued kernels which are suitable for extending functional data analysis methods to nonlinear contexts .", "The resulting optimization problem is more involved than those of multiple scalar-valued kernel learning since operator-valued kernels pose more technical and theoretical issues .", "We experimentally validate our approach on a functional regression task in the context of finger movement prediction in brain-computer interfaces .", "Positive definite operator-valued kernels generalize the well-known notion of reproducing kernels , and are naturally adapted to multi-output learning situations ."]}
{"orig_sents": ["10", "6", "0", "4", "9", "2", "8", "5", "3", "7", "1"], "shuf_sents": ["Many schemes have been proposed for encoding robot motions using dynamical systems with a single attractor placed at a predefined target in state space .", "We show , via implementations on a simulated 10 degrees of freedom mobile robotic platform , that the model is capable of real-time motion generation and is able to adapt on-the-fly to perturbations .", "We show its applicability in reach-to-grasp tasks where the attractors represent several grasping points on the target object .", "The new constraints modify the original SVM dual whose optimal solution then results in a new class of support vectors ( SV ) .", "Although these enable the robots to react against sudden perturbations without any re-planning , the motions are always directed towards a single target .", "Here we present the Augmented-SVM ( A-SVM ) model which inherits region partitioning ability of the well known SVM classifier and is augmented with novel constraints derived from the individual DS .", "Their applications range from modeling brain dynamics to encoding motor commands .", "These new SV ensure that the resulting multistable DS incurs minimum deviation from the original dynamics and is stable at each of the attractors within a finite region of attraction .", "While exploiting multiple attractors provides more flexibility in recovering from unseen perturbations , it also increases the complexity of the underlying learning problem .", "In this work , we focus on combining several such DS with distinct attractors , resulting in a multi-stable DS .", "Non-linear dynamical systems ( DS ) have been used extensively for building generative models of human behavior ."]}
{"orig_sents": ["0", "3", "5", "1", "2", "4"], "shuf_sents": ["This paper explores unsupervised learning of parsing models along two directions .", "Second , for identifiable models , how do we estimate the parameters efficiently ?", "EM suffers from local optima , while recent work using spectral methods can not be directly applied since the topology of the parse tree varies across sentences .", "First , which models are identifiable from infinite data ?", "We develop a strategy , unmixing , which deals with this additional complexity for restricted classes of parsing models .", "We use a general technique for numerically checking identifiability based on the rank of a Jacobian matrix , and apply it to several standard constituency and dependency parsing models ."]}
{"orig_sents": ["7", "6", "0", "5", "3", "1", "4", "2"], "shuf_sents": ["A generative model , denoted the binary dynamic system ( BDS ) , is proposed to learn both the distribution and dynamics of different activities in this space .", "An algorithm for learning BDS parameters , inspired by a popular LDS learning method from dynamic textures , is proposed .", "The proposed method is shown to outperform similar classifiers derived from the kernel dynamic system ( KDS ) and state-of-the-art approaches for dynamics-based or attribute-based action recognition .", "In this way , it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes .", "A similarity measure between BDSs , which generalizes the BinetCauchy kernel for LDS , is then introduced and used to design activity classifiers .", "The BDS is a non-linear dynamic system , which extends both the binary principal component analysis ( PCA ) and classical linear dynamic systems ( LDS ) , by combining binary observation variables with a hidden Gauss-Markov state process .", "A video sequence is first represented in a semantic feature space , where each feature encodes the probability of occurrence of an activity attribute at a given time .", "In this work , we consider the problem of modeling the dynamic structure of human activities in the attributes space ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["Numerical integration is a key component of many problems in scientific computing , statistical modelling , and machine learning .", "We demonstrate our method on both a number of synthetic benchmarks and a real scientific problem from astronomy .", "We propose a novel Bayesian Quadrature approach for numerical integration when the integrand is non-negative , such as the case of computing the marginal likelihood , predictive distribution , or normalising constant of a probabilistic model .", "Our approach approximately marginalises the quadrature model 's hyperparameters in closed form , and introduces an active learning scheme to optimally select function evaluations , as opposed to using Monte Carlo samples .", "Bayesian Quadrature is a modelbased method for numerical integration which , relative to standard Monte Carlo methods , offers increased sample efficiency and a more robust estimate of the uncertainty in the estimated integral ."]}
{"orig_sents": ["8", "0", "5", "9", "10", "7", "11", "3", "4", "6", "1", "2"], "shuf_sents": ["This paper proposes a novel multiple-cause generative model of low-level image statistics that generalizes the standard SC model in two crucial points : ( 1 ) it uses a spike-and-slab prior distribution for a more realistic representation of component absence/intensity , and ( 2 ) the model uses the highly nonlinear combination rule of maximal causes analysis ( MCA ) instead of a linear combination .", "Similarly high percentages are observed in vivo .", "Our results thus argue in favor of improvements of the standard sparse coding model for simple cells by using flexible priors and nonlinear combinations .", "In contrast to standard SC , we find that the optimal prior favors asymmetric and bimodal activity of simple cells .", "Testing our model for consistency we find that the average posterior is approximately equal to the prior .", "The major challenge is parameter optimization because a model with either ( 1 ) or ( 2 ) results in strongly multimodal posteriors .", "Furthermore , we find that the model predicts a high percentage of globular receptive fields alongside Gabor-like fields .", "This combined training scheme tackles both analytical and computational intractability and enables application of the model to a large number of observed and hidden dimensions .", "Modelling natural images with sparse coding ( SC ) has faced two main challenges : flexibly representing varying pixel intensities and realistically representing lowlevel image components .", "We show for the first time that a model combining both improvements can be trained efficiently while retaining the rich structure of the posteriors .", "We design an exact piecewise Gibbs sampling method and combine this with a variational method based on preselection of latent dimensions .", "Applying the model to image patches we study the optimal encoding of images by simple cells in V1 and compare the model 's predictions with in vivo neural recordings ."]}
{"orig_sents": ["0", "5", "2", "4", "3", "1"], "shuf_sents": ["We introduce a new Bayesian admixture model intended for exploratory analysis of communication networks -- specifically , the discovery and visualization of topic-specific subnetworks in email data sets .", "Finally , we advocate for principled visualization as a primary objective in the development of new network models .", "We validate our modeling assumptions by demonstrating that our model achieves better link prediction performance than three state-of-the-art network models and exhibits topic coherence comparable to that of latent Dirichlet allocation .", "We provide an extensive analysis of these communication patterns , leading us to recommend our model for any exploratory analysis of email networks or other similarly-structured communication data .", "We showcase our model 's ability to discover and visualize topic-specific communication patterns using a new email data set : the New Hanover County email network .", "Our model produces principled visualizations of email networks , i.e. , visualizations that have precise mathematical interpretations in terms of our model and its relationship to the observed data ."]}
{"orig_sents": ["2", "10", "3", "6", "7", "1", "9", "0", "5", "8", "4"], "shuf_sents": ["prior with a determinantal point process ( DPP ) .", "For example , there is no preference in the prior of a mixture model to make components non-overlapping , or in topic model to ensure that co-occurring words only appear in a small number of topics .", "Probabilistic latent variable models are one of the cornerstones of machine learning .", "Such models are useful for exploratory analysis and visualization , for building density models of data , and for providing features that can be used for later discriminative tasks .", "We show how to perform MAP inference with DPP priors in latent Dirichlet allocation and in mixture models , leading to better intuition for the latent variable representation and quantitatively improved unsupervised feature extraction , without compromising the generative aspects of the model .", "The DPP allows us to specify a preference for diversity in our latent variables using a positive definite kernel function .", "A significant limitation of these models , however , is that draws from the prior are often highly redundant due to i.i.d .", "assumptions on internal parameters .", "Using a kernel between probability distributions , we are able to define a DPP on probability measures .", "In this work , we revisit these independence assumptions for probabilistic latent variable models , replacing the underlying i.i.d .", "They offer a convenient and coherent way to specify prior distributions over unobserved structure in data , so that these unknown properties can be inferred via posterior inference ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics .", "Our model has two layers with the first layer modeling generalized sound units with no clear semantic associations , while the second layer models local patterns over these sound units .", "We submit that such models make a simplistic assumption in mapping acoustics directly to semantics , whereas the actual process is likely more complex .", "We evaluate our model on a large-scale retrieval task from TRECVID 2011 , and report significant improvements over standard baselines .", "Approaches to audio classification and retrieval tasks largely rely on detectionbased discriminative models ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["Timeline trees are given some specific predictions to make and learn a decision tree over history .", "an arcade game ) .", "Experiments demonstrate that timeline trees can learn to make high quality predictions in complex , partially observable environments with high-dimensional observations ( e.g .", "This paper introduces timeline trees , which are partial models of partially observable environments .", "The main idea of timeline trees is to use temporally abstract features to identify and split on features of key events , spread arbitrarily far apart in the past ( whereas previous decision-tree-based methods have been limited to a finite suffix of history ) ."]}
{"orig_sents": ["1", "5", "4", "3", "0", "2"], "shuf_sents": ["The proposed method yields state-of-the-art performance on large-scale problems .", "Sparse learning models typically combine a smooth loss with a nonsmooth penalty , such as trace norm .", "We also demonstrate an application to latent multiview learning for which we provide the first efficient weak-oracle .", "Performance is further accelerated by interlacing boosting with fixed-rank local optimization -- exploiting a simpler local objective than previous work .", "In this paper , we propose a boosting method for regularized learning that guarantees accuracy within O ( 1/ ) iterations .", "Although recent developments in sparse approximation have offered promising solution methods , current approaches either apply only to matrix-norm constrained problems or provide suboptimal convergence rates ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["Mirror descent with an entropic regularizer is known to achieve shifting regret bounds that are logarithmic in the dimension .", "This is done using either a carefully designed projection or by a weight sharing technique .", "Via a novel unified analysis , we show that these two approaches deliver essentially equivalent bounds on a notion of regret generalizing shifting , adaptive , discounted , and other related regrets .", "Our analysis also captures and extends the generalized weight sharing technique of Bousquet and Warmuth , and can be refined in several ways , including improvements for small losses and adaptive tuning of parameters ."]}
{"orig_sents": ["4", "1", "0", "3", "2", "6", "5"], "shuf_sents": ["This result is interesting but also surprising , given that the pairwise ranking methods have been shown very effective in practice .", "Recently , it was proven that many commonly used pairwise ranking methods are inconsistent with the weighted pairwise disagreement loss ( WPDL ) , which can be viewed as the true loss of ranking , even in a low-noise setting .", "We give a new assumption that the labels of objects to rank lie in a rank-differentiable probability space ( RDPS ) , and prove that the pairwise ranking methods become consistent with WPDL under this assumption .", "In this paper , we argue that the aforementioned result might not be conclusive , depending on what kind of assumptions are used .", "This paper is concerned with the statistical consistency of ranking methods .", "Our studies provide theoretical justifications of some empirical findings on pairwise ranking methods that are unexplained before , which bridge the gap between theory and applications .", "What is especially inspiring is that RDPS is actually not stronger than but similar to the low-noise setting ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["Beside the existence of an optimal policy which satisfies the Poisson equation , the only assumptions made are Holder continuity of rewards and transition probabilities .", "The proposed algorithm combines state aggregation with the use of upper confidence bounds for implementing optimism in the face of uncertainty .", "We derive sublinear regret bounds for undiscounted reinforcement learning in continuous state space ."]}
{"orig_sents": ["3", "2", "5", "6", "0", "4", "1"], "shuf_sents": ["In our method , the Shannon entropy is approximated by the finite difference of two correlated frequency moments estimated from correlated samples of symmetric stable random variables .", "Our experiments confirm that this method is able to well approximate the Shannon entropy using small storage .", "For nonnegative data streams , the method of Compressed Counting ( CC ) based on maximally-skewed stable random projections can provide accurate estimates of the Shannon entropy using small storage .", "Methods for efficiently estimating Shannon entropy of data streams have important applications in learning , data mining , and network anomaly detections ( e.g. , the DDoS attacks ) .", "Interestingly , the estimator for the moment we recommend for entropy estimation barely has bounded variance itself , whereas the common geometric mean estimator ( which has bounded higher-order moments ) is not sufficient for entropy estimation .", "However , CC is no longer applicable when entries of data streams can be below zero , which is a common scenario when comparing two streams .", "In this paper , we propose an algorithm for entropy estimation in general data streams which allow negative entries ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["The Restricted Boltzmann Machine ( RBM ) is a popular density model that is also good for extracting features .", "We also show how to pass derivatives through the resulting posterior marginals , which makes it possible to fine-tune a pre-trained neural network with sparse hidden layers .", "In this paper we show that a dynamic programming algorithm can be used to implement exact sparsity in the RBM 's hidden units .", "A main source of tractability in RBM models is that , given an input , the posterior distribution over hidden variables is factorizable and can be easily computed and sampled from .", "Sparsity and competition in the hidden representation is beneficial , and while an RBM with competition among its hidden units would acquire some of the attractive properties of sparse coding , such constraints are typically not added , as the resulting posterior over the hidden units seemingly becomes intractable ."]}
{"orig_sents": ["0", "2", "4", "1", "5", "6", "3"], "shuf_sents": ["In this paper , we consider the problem of clustering data points into lowdimensional subspaces in the presence of outliers .", "In addition , we develop two Bayesian methods based on variational Bayesian ( VB ) approximation , which are capable of automatic dimensionality selection .", "We pose the problem using a density estimation formulation with an associated generative model .", "Experimental results suggest that proposed methods are very effective in subspace clustering and identifying outliers .", "Based on this probability model , we first develop an iterative expectation-maximization ( EM ) algorithm and then derive its global solution .", "While the first method is based on an alternating optimization scheme for all unknowns , the second method makes use of recent results in VB matrix factorization leading to fast and effective estimation .", "Both methods are extended to handle sparse outliers for robustness and can handle missing values ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["However , this assumption is refuted by observed human behavior , including studies wherein preferences have been shown to change systematically simply through variation in the set of choice options presented .", "Complementarily , we also characterize the conditions under which a rational agent selecting optimal options indicated by dynamic value inference in our framework will behave identically to one whose preferences are encoded using a static ordinal utility function .", "In this paper , we show that interpreting desirability as a relative comparison between available options at any particular decision instance results in a rational theory of value-inference that explains heretofore intractable violations of rational choice behavior in human subjects .", "Statistical decision theory axiomatically assumes that the relative desirability of different options that humans perceive is well described by assigning them optionspecific scalar utility functions ."]}
{"orig_sents": ["2", "4", "1", "3", "5", "0"], "shuf_sents": ["In comparison with several state-of-art methods , experiments demonstrate the effectiveness and efficiency of Bayesian ( sparse ) PCSA on modeling matrix ( tensor ) data and filling missing values .", "In consequence , PCSA captures the dependencies among entries intricately , and is able to handle non-Gaussian and heteroscedastic densities .", "For modeling data matrices , this paper introduces Probabilistic Co-Subspace Addition ( PCSA ) model by simultaneously capturing the dependent structures among both rows and columns .", "By formulating the posterior updating into the task of solving Sylvester equations , we propose an efficient variational inference algorithm .", "Briefly , PCSA assumes that each entry of a matrix is generated by the additive combination of the linear mappings of two low-dimensional features , which distribute in the row-wise and column-wise latent subspaces respectively .", "Furthermore , PCSA is extended to tackling and filling missing values , to adapting model sparseness , and to modelling tensor data ."]}
{"orig_sents": ["4", "1", "2", "3", "0"], "shuf_sents": ["In our experiments , we demonstrate improved results for the task of pedestrian detection on the challenging TUD data set when compared to state-ofthe-art methods .", "They are tree-structured classifiers with the ability to access intermediate prediction ( here : classification and regression ) information during training and inference time .", "This intermediate prediction is available for each sample and allows us to develop context-based decision criteria , used for refining the prediction process .", "In addition , we introduce a novel split criterion which in combination with a priority based way of constructing the trees , allows more accurate regression mode selection and hence improves the current context information .", "In this paper we introduce Context-Sensitive Decision Forests - A new perspective to exploit contextual information in the popular decision forest framework for the object detection problem ."]}
{"orig_sents": ["1", "5", "4", "6", "0", "3", "2"], "shuf_sents": ["We develop a truncation strategy of these models that is applicable in principle to any backward-simulation-based method , but which is particularly well suited to the PG-AS framework .", "We present a novel method in the family of particle MCMC methods that we refer to as particle Gibbs with ancestor sampling ( PG-AS ) .", "Several application examples are discussed , including Rao-Blackwellized particle smoothing and inference in degenerate state-space models .", "In particular , as we show in a simulation study , PG-AS can yield an order-of-magnitude improved accuracy relative to PG-BS due to its robustness to the truncation error .", "Instead of using separate forward and backward sweeps as in PG-BS , however , we achieve the same effect in a single forward sweep .", "Similarly to the existing PG with backward simulation ( PG-BS ) procedure , we use backward sampling to ( considerably ) improve the mixing of the PG kernel .", "We apply the PG-AS framework to the challenging class of non-Markovian state-space models ."]}
{"orig_sents": ["1", "4", "3", "5", "6", "0", "2"], "shuf_sents": ["Our theoretical convergence analysis is supported with experimental results using data from diverse real-world applications .", "Large-scale 1 -regularized loss minimization problems arise in high-dimensional applications such as compressed sensing and high-dimensional supervised learning , including classification and regression problems .", "We hope that algorithmic approaches and convergence analysis we provide will not only advance the field , but will also encourage researchers to systematically explore the design space of algorithms for solving large-scale 1 -regularization problems .", "Building upon previous work on coordinate descent algorithms for 1 -regularized problems , we introduce a novel family of algorithms called block-greedy coordinate descent that includes , as special cases , several existing algorithms such as SCD , Greedy CD , Shotgun , and Thread-Greedy .", "High-performance algorithms and implementations are critical to efficiently solving these problems .", "We give a unified convergence analysis for the family of block-greedy algorithms .", "The analysis suggests that block-greedy coordinate descent can better exploit parallelism if features are clustered so that the maximum inner product between features in different blocks is small ."]}
{"orig_sents": ["1", "2", "0", "4", "3", "5"], "shuf_sents": ["For example , VB sometimes produces a sparse solution , which is regarded as a practical advantage of VB , but such sparsity is hardly observed in the rigorous Bayesian estimation .", "The variational Bayesian ( VB ) approach is one of the best tractable approximations to the Bayesian estimation , and it was demonstrated to perform well in many applications .", "However , its good performance was not fully understood theoretically .", "More specifically , for the situation where the noise variance is unknown , we derive a sufficient condition for perfect recovery of the true PCA dimensionality in the large-scale limit when the size of an observed matrix goes to infinity .", "In this paper , we focus on probabilistic PCA and give more theoretical insight into the empirical success of VB .", "In our analysis , we obtain bounds for a noise variance estimator and simple closed-form solutions for other parameters , which themselves are actually very useful for better implementation of VB-PCA ."]}
{"orig_sents": ["2", "0", "3", "1", "4"], "shuf_sents": ["The work builds upon recent and elegant results on noncommutative concentration inequalities , i.e .", "We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure .", "This paper provides the first -- to the best of our knowledge -- analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure .", "concentration inequalities that apply to matrices , and , more precisely , to matrix martingales .", "This learning algorithm , called COPA ( for COnfusion Passive-Aggressive ) is a passive-aggressive learning algorithm ; it is shown that the update equations for COPA can be computed analytically and , henceforth , there is no need to recourse to any optimization package to implement it ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["By developing data augmentation methods unique to the negative binomial ( NB ) distribution , we unite seemingly disjoint count and mixture models under the NB process framework .", "We develop fundamental properties of the models and derive efficient Gibbs sampling inference .", "A variety of NB processes with distinct sharing mechanisms are constructed and applied to topic modeling , with connections to existing algorithms , showing the importance of inferring both the NB dispersion and probability parameters .", "We show that the gamma-NB process can be reduced to the hierarchical Dirichlet process with normalization , highlighting its unique theoretical , structural and computational advantages ."]}
{"orig_sents": ["2", "0", "1", "4", "3", "6", "5"], "shuf_sents": ["In the first four methods , the classification is based on a reduction to binary classification .", "We consider the case where the binary classifier comes from a class of VC dimension d , and in particular from the class of halfspaces over Rd .", "We theoretically analyze and compare the following five popular multiclass classification methods : One vs. All , All Pairs , Tree-based classifiers , Error Correcting Output Codes ( ECOC ) with randomly generated code matrices , and Multiclass SVM .", "Our analysis reveals interesting conclusions of practical relevance , regarding the success of the different approaches under various conditions .", "We analyze both the estimation error and the approximation error of these methods .", "This is in contrast to most previous uses of VC theory , which only deal with estimation error .", "Our proof technique employs tools from VC theory to analyze the approximation error of hypothesis classes ."]}
{"orig_sents": ["5", "4", "3", "2", "8", "0", "1", "6", "7"], "shuf_sents": ["We present an adaptive control scheme that achieves a regret bound of O ( p T ) , apart from logarithmic factors .", "In particular , our algorithm has an average cost of ( 1 + ) times the optimum cost after T = polylog ( p ) O ( 1/ 2 ) .", "However , this bound scales exponentially with p , the dimension of the state space .", "More recently , for the average cost LQ problem , a regret bound of O ( T ) was shown , apart form logarithmic factors .", "Previous work established the asymptotic convergence to an optimal controller for various adaptive control schemes .", "We study the problem of adaptive control of a high dimensional linear quadratic ( LQ ) system .", "This is in comparison to previous work on the dense dynamics where the algorithm requires time that scales exponentially with dimension in order to achieve regret of times the optimal cost .", "We believe that our result has prominent applications in the emerging area of computational advertising , in particular targeted online advertising and advertising in social networks .", "In this work we consider the case where the matrices describing the dynamic of the LQ system are sparse and their dimensions are large ."]}
{"orig_sents": ["4", "7", "8", "5", "6", "2", "1", "3", "0"], "shuf_sents": ["We demonstrate state-of-the-art accuracy for detection , viewpoint estimation , and 3D shape reconstruction on challenging images from the PASCAL VOC 2011 dataset .", "We use a morphable model to capture 3D within-class variation , and use a weak-perspective camera model to capture viewpoint .", "These estimates are then refined by our second stage , using an explicit 3D model of shape and viewpoint .", "We learn all model parameters from 2D annotations .", "We present an approach to detecting and analyzing the 3D configuration of objects in real-world images with heavy occlusion and clutter .", "Rather than using a view-based model , we describe a compositional representation that models a large number of effective views and shapes using a small number of local view-based templates .", "We use this model to propose candidate detections and 2D estimates of shape .", "We focus on the application of finding and analyzing cars .", "We do so with a two-stage model ; the first stage reasons about 2D shape and appearance variation due to within-class variation ( station wagons look different than sedans ) and changes in viewpoint ."]}
{"orig_sents": ["6", "5", "0", "3", "4", "2", "1", "7", "8"], "shuf_sents": ["In the case of the retina , Srinivasan et al .", "Here , solving the transient dynamics of nonlinear reciprocal feedback circuits through analogy to a signal-processing algorithm called linearized Bregman iteration we show that nonlinear predictive coding can be implemented in an inhibitory feedback circuit .", "Can such circuits implement predictive coding as well ?", "( 1982 ) suggested that feedforward inhibitory connections subtracting a linear prediction generated from nearby receptors implement such compression , resulting in biphasic center-surround receptive fields .", "However , feedback inhibitory circuits are common in early sensory circuits and furthermore their dynamics may be nonlinear .", "To make more efficient use of limited bandwidth , compression may be achieved using predictive coding , whereby predictable , or redundant , components of the stimulus are removed .", "Early stages of sensory systems face the challenge of compressing information from numerous receptors onto a much smaller number of projection neurons , a so called communication bottleneck .", "In response to a step stimulus , interneuron activity in time constructs progressively less sparse but more accurate representations of the stimulus , a temporally evolving prediction .", "This analysis provides a powerful theoretical framework to interpret and understand the dynamics of early sensory processing in a variety of physiological experiments and yields novel predictions regarding the relation between activity and stimulus statistics ."]}
{"orig_sents": ["3", "4", "1", "5", "0", "2"], "shuf_sents": ["This property allows for efficient inference of the partition itself , for which we employ graph-theoretic techniques .", "Long-range dependencies are captured by the top-level GP while the partition points define the abrupt changes .", "We apply the multiresolution GP to the analysis of magnetoencephalography ( MEG ) recordings of brain activity .", "We propose a multiresolution Gaussian process to capture long-range , nonMarkovian dependencies while allowing for abrupt changes and non-stationarity .", "The multiresolution GP hierarchically couples a collection of smooth GPs , each defined over an element of a random nested partition .", "Due to the inherent conjugacy of the GPs , one can analytically marginalize the GPs and compute the marginal likelihood of the observations given the partition tree ."]}
{"orig_sents": ["0", "2", "8", "1", "4", "5", "7", "6", "3"], "shuf_sents": ["A Deep Boltzmann Machine is described for learning a generative model of data that consists of multiple and diverse input modalities .", "The model works by learning a probability density over the space of multimodal inputs .", "The model can be used to extract a unified representation that fuses modalities together .", "Finally , we compare our model to other deep learning methods , including autoencoders and deep belief networks , and show that it achieves noticeable gains .", "It uses states of latent variables as representations of the input .", "The model can extract this representation even when some modalities are absent by sampling from the conditional distribution over them and filling them in .", "We further demonstrate that this model significantly outperforms SVMs and LDA on discriminative tasks .", "Our experimental results on bi-modal data consisting of images and text show that the Multimodal DBM can learn a good generative model of the joint space of image and text inputs that is useful for information retrieval from both unimodal and multimodal queries .", "We find that this representation is useful for classification and information retrieval tasks ."]}
{"orig_sents": ["1", "2", "5", "4", "6", "3", "0"], "shuf_sents": ["The numerical experiments support our results .", "In this paper , we provide a new framework to study the generalization bound of the learning process for domain adaptation .", "We consider two kinds of representative domain adaptation settings : one is domain adaptation with multiple sources and the other is domain adaptation combining source and target data .", "Meanwhile , we discuss the factors that affect the asymptotic behavior of the learning process .", "Then , we develop the specific Hoeffding-type deviation inequality and symmetrization inequality for either kind of domain adaptation to achieve the corresponding generalization bound based on the uniform entropy number .", "In particular , we use the integral probability metric to measure the difference between two domains .", "By using the resultant generalization bound , we analyze the asymptotic convergence and the rate of convergence of the learning process for domain adaptation ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["A variety of experiments are presented to illustrate the off-policy convergence , sparse feature selection capability and low computational cost of the RO-TD algorithm .", "We present a novel l1 regularized off-policy convergent TD-learning method ( termed RO-TD ) , which is able to learn sparse representations of value functions with low computational complexity .", "The algorithmic framework underlying ROTD integrates two key ideas : off-policy convergent gradient TD methods , such as TDC , and a convex-concave saddle-point formulation of non-smooth convex optimization , which enables first-order solvers and feature selection using online convex regularization .", "A detailed theoretical and experimental analysis of RO-TD is presented ."]}
{"orig_sents": ["5", "3", "1", "7", "2", "0", "4", "6"], "shuf_sents": ["Moreover , the proposed method does not need the information regarding the region that requires inpainting to be given a priori .", "Our method 's performance in the image denoising task is comparable to that of KSVD which is a widely used sparse coding technique .", "Specifically , we can automatically remove complex patterns like superimposed text from an image , rather than simple patterns like pixels missing at random .", "We propose an alternative training scheme that successfully adapts DA , originally designed for unsupervised feature learning , to the tasks of image denoising and blind inpainting .", "Experimental results demonstrate the effectiveness of the proposed method in the tasks of image denoising and blind inpainting .", "We present a novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder ( DA ) .", "We also show that our new training scheme for DA is more effective and can improve the performance of unsupervised feature learning .", "More importantly , in blind image inpainting task , the proposed method provides solutions to some complex problems that have not been tackled before ."]}
{"orig_sents": ["2", "0", "4", "5", "6", "1", "3", "7"], "shuf_sents": ["In this paper , we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores .", "We have successfully used our system to train a deep network 30x larger than previously reported in the literature , and achieves state-of-the-art performance on ImageNet , a visual object recognition task with 16 million images and 21k categories .", "Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance .", "We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service .", "We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models .", "Within this framework , we have developed two algorithms for large-scale distributed training : ( i ) Downpour SGD , an asynchronous stochastic gradient descent procedure supporting a large number of model replicas , and ( ii ) Sandblaster , a framework that supports a variety of distributed batch optimization procedures , including a distributed implementation of L-BFGS .", "Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training .", "Although we focus on and report performance of these methods as applied to training large neural networks , the underlying algorithms are applicable to any gradient-based machine learning algorithm ."]}
{"orig_sents": ["7", "2", "4", "3", "6", "0", "1", "5"], "shuf_sents": ["One difficulty in learning the pairwise similarity measure is that there is a significant amount of noise and inter-worker variations in the manual annotations obtained via crowdsourcing .", "We address this difficulty by developing a metric learning algorithm based on the matrix completion method .", "Crowdclustering addresses this challenge by defining the pairwise similarity based on the manual annotations obtained through crowdsourcing .", "To address this limitation , we propose a new approach for clustering , called semi-crowdsourced clustering that effectively combines the low-level features of objects with the manual annotations of a subset of the objects obtained via crowdsourcing .", "Despite its encouraging results , a key limitation of crowdclustering is that it can only cluster objects when their manual annotations are available .", "Our empirical study with two real-world image data sets shows that the proposed algorithm outperforms state-of-the-art distance metric learning algorithms in both clustering accuracy and computational efficiency .", "The key idea is to learn an appropriate similarity measure , based on the low-level features of objects and from the manual annotations of only a small portion of the data to be clustered .", "One of the main challenges in data clustering is to define an appropriate similarity measure between two objects ."]}
{"orig_sents": ["3", "2", "1", "4", "0"], "shuf_sents": ["We compare our algorithms to traditional greedy and 1 -regularization schemes and show that we obtain a more diverse set of features that result in the regression problem being stable under perturbations .", "We propose several spectral regularizers that capture a notion of diversity of features and show that these are all submodular set functions .", "Diversity is useful for several reasons such as interpretability , robustness to noise , etc .", "We study the problem of diverse feature selection in linear regression : selecting a small subset of diverse features that can predict a given objective .", "These regularizers , when added to the objective function for linear regression , result in approximately submodular functions , which can then be maximized by efficient greedy and local search algorithms , with provable guarantees ."]}
{"orig_sents": ["4", "3", "0", "1", "2"], "shuf_sents": ["We show that the selectron encodes reward estimates into spikes and that an error bound on spikes is controlled by a spiking margin and the sum of synaptic weights .", "Moreover , the efficacy of spikes ( their usefulness to other reward maximizing selectrons ) also depends on total synaptic strength .", "Finally , based on our analysis , we propose a regularized version of STDP , and show the regularization improves the robustness of neuronal learning when faced with multiple stimuli .", "We introduce a model , the selectron , that ( i ) arises as the fast time constant limit of leaky integrate-and-fire neurons equipped with spiking timing dependent plasticity ( STDP ) and ( ii ) is amenable to theoretical analysis .", "This paper suggests a learning-theoretic perspective on how synaptic plasticity benefits global brain functioning ."]}
{"orig_sents": ["6", "0", "7", "5", "3", "4", "2", "1"], "shuf_sents": ["In this paper , we tackle the problem of adapting object detectors learned from images to work well on videos .", "We show promising results on the 2011 TRECVID Multimedia Event Detection and LabelMe Video datasets that illustrate the benefit of our approach to adapt object detectors to video .", "We also show how rich and expressive features specific to the target domain can be incorporated under the same framework .", "At each iteration , the algorithm adapts by considering an increased number of target domain examples , and a decreased number of source domain examples .", "To discover target domain examples from the vast amount of video data , we introduce a simple , robust approach that scores trajectory tracks instead of bounding boxes .", "Our approach , self-paced domain adaptation , seeks to iteratively adapt the detector by re-training the detector with automatically discovered target domain examples , starting with the easiest first .", "Typical object detectors trained on images perform poorly on video , as there is a clear distinction in domain between the two types of data .", "We treat the problem as one of unsupervised domain adaptation , in which we are given labeled data from the source domain ( image ) , but only unlabeled data from the target domain ( video ) ."]}
{"orig_sents": ["3", "2", "5", "6", "7", "0", "4", "1"], "shuf_sents": ["We point out a number of applications , and in particular show that a proximal algorithm defined through the submodular Bregman divergence provides a framework for many mirror-descent style algorithms related to submodular function optimization .", "A unique property of this algorithm is that computing the mean ordering is extremely efficient unlike other order based distance measures .", "We consider two kinds , defined either from tight modular upper or tight modular lower bounds of a submodular function .", "We introduce a class of discrete divergences on sets ( equivalently binary vectors ) that we call the submodular-Bregman divergences .", "We also show that a generalization of the k-means algorithm using the Lovasz Bregman divergence is natural in clustering scenarios where ordering is important .", "We show that the properties of these divergences are analogous to the ( standard continuous ) Bregman divergence .", "We demonstrate how they generalize many useful divergences , including the weighted Hamming distance , squared weighted Hamming , weighted precision , recall , conditional mutual information , and a generalized KL-divergence on sets .", "We also show that the generalized Bregman divergence on the Lovasz extension of a submodular function , which we call the Lovasz-Bregman divergence , is a continuous extension of a submodular Bregman divergence ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["We uncover relations between robust MDPs and risk-sensitive MDPs .", "We also show that a risk-sensitive MDP of minimizing an iterated risk measure that is composed of certain coherent risk measures is equivalent to a robust MDP of minimizing the worst-case expectation when the possible deviations of uncertain parameters from their nominal values are characterized with a concave function .", "The objective of a robust MDP is to minimize a function , such as the expectation of cumulative cost , for the worst case when the parameters have uncertainties .", "We show that a risk-sensitive MDP of minimizing the expected exponential utility is equivalent to a robust MDP of minimizing the worst-case expectation with a penalty for the deviation of the uncertain parameters from their nominal values , which is measured with the Kullback-Leibler divergence .", "The objective of a risk-sensitive MDP is to minimize a risk measure of the cumulative cost when the parameters are known ."]}
{"orig_sents": ["4", "6", "0", "2", "1", "5", "3"], "shuf_sents": ["Such oversampling is consistent with the experimental observation that the precision of the spikegeneration mechanism is an order of magnitude greater than the cut -off frequency of low-pass filtering in dendrites .", "If noise-shaping were used in neurons , it would reduce coding error relative to Poisson spike generator for frequencies below Nyquist by introducing correlations into spike times .", "Additional improvement in the coding accuracy may be achieved by noise-shaping , a technique used in signal processing .", "Therefore , the spike-generation mechanism can be viewed as an oversampling and noise-shaping AD converter .", "We test the hypothesis that the neuronal spike generation mechanism is an analog-to-digital ( AD ) converter encoding rectified low-pass filtered summed synaptic currents into a spike train linearly decodable in postsynaptic neurons .", "By using experimental data from three different classes of neurons , we demonstrate that biological neurons utilize noise-shaping .", "Faithful encoding of an analog waveform by a binary signal requires that the spike generation mechanism has a sampling rate exceeding the Nyquist rate of the analog signal ."]}
{"orig_sents": ["3", "4", "5", "1", "0", "2"], "shuf_sents": ["We also show that the KL divergence , as well as the lower bound , depends not only on the variability of spikes in terms of the coefficient of variation , but also significantly on the higher-order moments of interspike interval ( ISI ) distributions .", "We show that the KL divergence determines the lower bound of the degree of rate fluctuations below which the temporal variation of the firing rates is undetectable from sparse data .", "We examine three specific models that are commonly used for describing the stochastic nature of spikes ( the gamma , inverse Gaussian ( IG ) and lognormal ISI distributions ) , and find that the time-rescaled renewal process with the IG distribution achieves the largest KL divergence , followed by the lognormal and gamma distributions .", "Statistical features of neuronal spike trains are known to be non-Poisson .", "Here , we investigate the extent to which the non-Poissonian feature affects the efficiency of transmitting information on fluctuating firing rates .", "For this purpose , we introduce the Kullback-Leibler ( KL ) divergence as a measure of the efficiency of information encoding , and assume that spike trains are generated by time-rescaled renewal processes ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["Large-sample properties of Conditional Markov Chains have been first studied in .", "Conditional Markov Chains ( also known as Linear-Chain Conditional Random Fields in the literature ) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables .", "The paper extends this work in two directions : first , mixing properties of models with unbounded feature functions are being established ; second , necessary conditions for model identifiability and the uniqueness of maximum likelihood estimates are being given ."]}
{"orig_sents": ["5", "2", "6", "0", "8", "3", "1", "7", "4"], "shuf_sents": ["In this paper , we show how spectral methods can be extended to the problem of learning a general weighted automaton from a sample generated by an arbitrary distribution .", "Combining these two ingredients , matrix completion and spectral method , a whole new family of algorithms for learning general weighted automata is obtained .", "A broad class of such functions can be defined by weighted automata .", "We present a solution to this problem based on solving a constrained matrix completion problem .", "The proofs rely on a joint stability analysis of matrix completion and spectral learning .", "Many tasks in text and speech processing and computational biology require estimating functions mapping strings to real numbers .", "Spectral methods based on the singular value decomposition of a Hankel matrix have been recently proposed for learning a probability distribution represented by a weighted automaton from a training sample drawn according to this same target distribution .", "We present generalization bounds for a particular algorithm in this family .", "The main obstruction to this approach is that , in general , some entries of the Hankel matrix may be missing ."]}
{"orig_sents": ["1", "7", "3", "5", "2", "0", "6", "4"], "shuf_sents": ["Additionally , when simulating variance switching experiments , the model quantitatively fits experimental data over a wide dynamic range .", "Neural adaptation underlies the ability of neurons to maximize encoded information over a wide dynamic range of input stimuli .", "We show that , unlike the additive adaptation model , the firing rate in our multiplicative adaptation model saturates to a realistic maximum spike-rate regardless of input magnitude .", "Such adaptation accurately models neural spiking behavior over a limited dynamic input range .", "We show that when thus encoding rectified filtered stimulus signals , the multiplicative adaptive Spike Response Model achieves a high coding efficiency and maintains this efficiency over changes in the dynamic signal range of several orders of magnitude , without changing model parameters .", "To extend efficient coding over large changes in dynamic input range , we propose a multiplicative adaptive Spike Response Model where the spike-triggered adaptation dynamics are scaled multiplicatively by the adaptation state at the time of spiking .", "Dynamic threshold models of adaptation furthermore suggest a straightforward interpretation of neural activity in terms of dynamic differential signal encoding with shifted and weighted exponential kernels .", "Recent spiking neuron models like the adaptive Spike Response Model implement adaptation as additive fixed-size fast spike-triggered threshold dynamics and slow spike-triggered currents ."]}
{"orig_sents": ["4", "7", "6", "3", "5", "0", "1", "2", "8"], "shuf_sents": ["sample of size N is of order O ( N -0.5+ ) for arbitrarily small > 0 ( affecting the probabilistic estimate ) ; this rate of convergence is close to the one of direct covariance estimation , i.e. , O ( N -0.5 ) .", "Our precise probabilistic estimate implies for some natural settings that the sample complexity of the generalized inverse covariance estimation when using the Frobenius norm is O ( D2+ ) for arbitrarily small > 0 ( whereas the sample complexity of direct covariance estimation with Frobenius norm is O ( D2 ) ) .", "These results provide similar rates of convergence and sample complexity for the corresponding robust subspace recovery algorithm .", "sample from it .", "We estimate the rate of convergence and sample complexity of a recent robust estimator for a generalized version of the inverse covariance matrix .", "Our main result shows with high probability that the norm of the difference between the generalized inverse covariance of the underlying distribution and its estimator from an i.i.d .", "Our model assumes a sub-Gaussian underlying distribution and an i.i.d .", "This estimator is used in a convex algorithm for robust subspace recovery ( i.e. , robust PCA ) .", "To the best of our knowledge , this is the only work analyzing the sample complexity of any robust PCA algorithm ."]}
{"orig_sents": ["5", "4", "3", "1", "0", "2"], "shuf_sents": ["Finally , we present an efficient active learning strategy for querying preferences .", "Approximate inference is implemented using a combination of expectation propagation and variational Bayes .", "The proposed technique performs favorably on real-world data against state-of-the-art multi-user preference learning algorithms .", "The model not only exploits collaborative information from the shared structure in user behavior , but may also incorporate user features if they are available .", "Inference is simplified by using a preference kernel for GPs which allows us to combine supervised GP learning of user preferences with unsupervised dimensionality reduction for multi-user systems .", "We present a new model based on Gaussian processes ( GPs ) for learning pairwise preferences expressed by multiple users ."]}
{"orig_sents": ["4", "9", "3", "2", "10", "6", "0", "1", "8", "5", "7"], "shuf_sents": ["The algorithm is model independent .", "To establish the efficacy of our method , however , we consider the popular Bradley-Terry-Luce ( BTL ) model in which each object has an associated score which determines the probabilistic outcomes of pairwise comparisons between objects .", "player 's rating ) is of interest to understanding the intensity of the preferences .", "In most settings , in addition to obtaining ranking , finding `scores ' for each object ( e.g .", "The question of aggregating pairwise comparisons to obtain a global ranking over a collection of objects has been of interest for a very long time : be it ranking of online gamers ( e.g .", "This , in essence , leads to order-optimal dependence on the number of samples required to learn the scores well by our algorithm .", "The algorithm has a natural random walk interpretation over the graph of objects with edges present between two objects if they are compared ; the scores turn out to be the stationary probability of this random walk .", "Indeed , the experimental evaluation shows that our ( model independent ) algorithm performs as well as the Maximum Likelihood Estimator of the BTL model and outperforms a recently proposed algorithm by Ammar and Shah .", "We bound the finite sample error rates between the scores assumed by the BTL model and those estimated by our algorithm .", "MSR 's TrueSkill system ) and chess players , aggregating social opinions , or deciding which product to sell based on transactions .", "In this paper , we propose a novel iterative rank aggregation algorithm for discovering scores for objects from pairwise comparisons ."]}
{"orig_sents": ["2", "4", "3", "1", "0", "5"], "shuf_sents": ["However , we demonstrate that simple , efficient learning procedures can be derived for more general forms of this model .", "When labels are binary and the prior over counts is a Poisson-Binomial distribution , a standard logistic regression model is recovered , but for other count distributions , such priors induce global dependencies and combinatorics that appear to complicate learning and inference .", "In categorical data there is often structure in the number of variables that take on each label .", "In this paper , we study a probabilistic model that explicitly includes a prior distribution over such counts , along with a count-conditional likelihood that defines probabilities over all subsets of a given size .", "For example , the total number of objects in an image and the number of highly relevant documents per query in web search both tend to follow a structured distribution .", "We illustrate the utility of the formulation by exploring applications to multi-object classification , learning to rank , and top-K classification ."]}
{"orig_sents": ["3", "5", "0", "4", "6", "1", "2"], "shuf_sents": ["This disorder appears to be incongruous , given the uniformity of the neocortex ; however , we hypothesized that both A1 and V1 would adopt an efficient coding strategy and that the disorder in A1 reflects natural sound statistics .", "The auditory model predicted harmonic relationships among neighbouring A1 cells ; furthermore , the same mechanism used to model V1 complex cells reproduced nonlinear responses similar to the pitch selectivity .", "These results contribute to the understanding of the sensory cortices of different modalities in a novel and integrated manner .", "The computational modelling of the primary auditory cortex ( A1 ) has been less fruitful than that of the primary visual cortex ( V1 ) due to the less organized properties of A1 .", "To provide a computational model of the tonotopic disorder in A1 , we used a model that was originally proposed for the smooth V1 map .", "Greater disorder has recently been demonstrated for the tonotopy of A1 that has traditionally been considered to be as ordered as the retinotopy of V1 .", "In contrast to natural images , natural sounds exhibit distant correlations , which were learned and reflected in the disordered map ."]}
{"orig_sents": ["5", "2", "7", "3", "0", "6", "1", "4"], "shuf_sents": ["When our features are combined with TagProp ( Guillaumin et al .", "Furthermore , using 256-bit codes and Hamming distance for training TagProp , we exchange only a small reduction in performance for efficient storage and fast comparisons .", "Consequently , most existing algorithms focus on tag assignment and fix an often large number of hand-crafted features to describe image characteristics .", "We benchmark our model on the STL-10 recognition dataset , achieving state-of-the-art performance .", "Self-taught learning is used in all of our experiments and deeper architectures always outperform shallow ones .", "The task of image auto-annotation , namely assigning a set of relevant tags to an image , is challenging due to the size and variability of tag vocabularies .", ") , we compete with or outperform existing annotation approaches that use over a dozen distinct handcrafted image descriptors .", "In this paper we introduce a hierarchical model for learning representations of standard sized color images from the pixel level , removing the need for engineered feature representations and subsequent feature selection for annotation ."]}
{"orig_sents": ["1", "6", "2", "0", "4", "5", "3"], "shuf_sents": ["We obtain the range of the regularization parameter for which the solution of the proposed optimization program changes from selecting one representative for all data points to selecting all data points as representatives .", "Given pairwise dissimilarities between data points , we consider the problem of finding a subset of data points , called representatives or exemplars , that can efficiently describe the data collection .", "The solution of the proposed optimization program finds the representatives and the probability that each data point is associated with each one of the representatives .", "We demonstrate the effectiveness of the proposed algorithm on synthetic data as well as real-world image and text data .", "When data points are distributed around multiple clusters according to the dissimilarities , we show that the data points in each cluster select representatives only from that cluster .", "Unlike metric-based methods , our algorithm can be applied to dissimilarities that are asymmetric or violate the triangle inequality , i.e. , it does not require that the pairwise dissimilarities come from a metric .", "We formulate the problem as a row-sparsity regularized trace minimization problem that can be solved efficiently using convex programming ."]}
{"orig_sents": ["0", "3", "4", "5", "1", "2"], "shuf_sents": ["Keypoint matching between pairs of images using popular descriptors like SIFT or a faster variant called SURF is at the heart of many computer vision algorithms including recognition , mosaicing , and structure from motion .", "Here , we introduce Locally Uniform Comparison Image Descriptor ( LUCID ) , a simple description method based on linear time permutation distances between the ordering of RGB values of two image patches .", "LUCID is computable in linear time with respect to the number of pixels and does not require floating point computation .", "However , SIFT and SURF do not perform well for real-time or mobile applications .", "As an alternative very fast binary descriptors like BRIEF and related methods use pairwise comparisons of pixel intensities in an image patch .", "We present an analysis of BRIEF and related approaches revealing that they are hashing schemes on the ordinal correlation metric Kendall 's tau ."]}
{"orig_sents": ["6", "1", "2", "0", "3", "4", "5"], "shuf_sents": ["We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems , a nonparametric probabilistic generalization of commonly used state-space models .", "Explaining the phenomena underlying these diverse data sets requires flexible and accurate models .", "In this paper , we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis .", "We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models .", "We show that existing Gaussian filters and smoothers appear as special cases within our inference framework , and that these existing approaches can be improved upon using iterated message passing .", "Using both synthetic and real-world data , we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation , thus leading to improved predictions and more effective decision making .", "Rich and complex time-series data , such as those generated from engineering systems , financial markets , videos , or neural recordings are now a common feature of modern data analysis ."]}
{"orig_sents": ["2", "0", "3", "4", "1"], "shuf_sents": ["We model the distribution of local features as a Gaussian Markov Random Field ( GMRF ) which can efficiently represent the spatial relationship among local features .", "We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset .", "This paper proposes a novel image representation called a Graphical Gaussian Vector ( GGV ) , which is a counterpart of the codebook and local feature matching approaches .", "Using concepts of information geometry , proper parameters and a metric from the GMRF can be obtained .", "Then we define a new image feature by embedding the proper metric into the parameters , which can be directly applied to scalable linear classifiers ."]}
{"orig_sents": ["0", "3", "4", "2", "1"], "shuf_sents": ["Some of the most compelling applications of online convex optimization , including online prediction and classification , are unconstrained : the natural feasible set is Rn .", "We then prove lower bounds showing that our guarantees are near-optimal in this setting .", "In particular , regret with respect to x = 0 is constant .", "Existing algorithms fail to achieve sub-linear regret in this setting unless constraints on the comparator point x are known in advance .", "We present algorithms that , without such prior knowledge , offer near-optimal regret bounds with respect to any choice of x ."]}
{"orig_sents": ["0", "3", "5", "7", "1", "2", "6", "4"], "shuf_sents": ["Multiple Kernel Learning ( MKL ) generalizes SVMs to the setting where one simultaneously trains a linear classifier and chooses an optimal combination of given base kernels .", "This formulation significantly generalizes the widely used 1- and 2-norm MKL objectives .", "We explore the model 's utility via experiments on a challenging Neuroimaging problem , where the goal is to predict a subject 's conversion to Alzheimer 's Disease ( AD ) by exploiting aggregate information from many distinct imaging modalities .", "Model complexity is typically controlled using various norm regularizations on the base kernel mixing coefficients .", "We briefly discuss ramifications in terms of learning bounds ( Rademacher complexity ) .", "Existing methods neither regularize nor exploit potentially useful information pertaining to how kernels in the input set `interact ' ; that is , higher order kernel-pair relationships that can be easily obtained via unsupervised ( similarity , geodesics ) , supervised ( correlation in errors ) , or domain knowledge driven mechanisms ( which features were used to construct the kernel ? ) .", "Here , our new model outperforms the state of the art ( p-values 10-3 ) .", "We show that by substituting the norm penalty with an arbitrary quadratic function Q 0 , one can impose a desired covariance structure on mixing weights , and use this as an inductive bias when learning the concept ."]}
{"orig_sents": ["0", "4", "1", "2", "3"], "shuf_sents": ["We present a novel method for learning densities with bounded support which enables us to incorporate `hard ' topological constraints .", "The proposed formalism facilitates learning of models with bounded support in a principled way , and - by incorporating persistent homology techniques in our approach - we are able to encode algebraic-topological constraints which are not addressed in current state of the art probabilistic models .", "We study the behaviour of our method on two synthetic examples for various sample sizes and exemplify the benefits of the proposed approach on a real-world dataset by learning a motion model for a race car .", "We show how to learn a model which respects the underlying topological structure of the racetrack , constraining the trajectories of the car .", "In particular , we show how emerging techniques from computational algebraic topology and the notion of persistent homology can be combined with kernel-based methods from machine learning for the purpose of density estimation ."]}
{"orig_sents": ["2", "1", "6", "4", "3", "0", "5", "8", "7"], "shuf_sents": ["Experiments are conducted on the PASCAL VOC object detection dataset .", "Our method for timely multi-class detection aims to give the best possible performance at any single point after a start time ; it is terminated at a deadline time .", "In a large visual multi-class detection framework , the timeliness of results can be crucial .", "We evaluate our method with a novel timeliness measure , computed as the area under an Average Precision vs. Time curve .", "In contrast to previous work , our method significantly diverges from the predominant greedy strategies , and is able to learn to take actions with deferred values .", "If execution is stopped when only half the detectors have been run , our method obtains 66 % better AP than a random ordering , and 14 % better performance than an intelligent baseline .", "Toward this goal , we formulate a dynamic , closed-loop policy that infers the contents of the image in order to decide which detector to deploy next .", "Our method is easily extensible , as it treats detectors and classifiers as black boxes and learns from execution traces using reinforcement learning .", "On the timeliness measure , our method obtains at least 11 % better performance ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["The proposed methods significantly improve canonical gradient methods , especially on ill-conditioned matrices , while maintaining established global convegence and exact recovery guarantees .", "The proposed conjugate gradient method based on the scaled gradient outperforms several existing algorithms for matrix completion and is competitive with recently proposed methods .", "A connection between a form of subspace iteration for matrix completion and the scaled gradient descent procedure is also established .", "This paper describes gradient methods based on a scaled metric on the Grassmann manifold for low-rank matrix completion ."]}
{"orig_sents": ["0", "5", "2", "1", "4", "3"], "shuf_sents": ["Fine-grained recognition refers to a subordinate level of recognition , such as recognizing different species of animals and plants .", "We propose a template model for the purpose , which captures common shape patterns of object parts , as well as the cooccurrence relation of the shape patterns .", "We suggest that the key to identifying the fine-grained differences lies in finding the right alignment of image regions that contain the same object parts .", "Learning of the template model is efficient , and the recognition results we achieve significantly outperform the stateof-the-art algorithms .", "Once the image regions are aligned , extracted features are used for classification .", "It differs from recognition of basic categories , such as humans , tables , and computers , in that there are global similarities in shape and structure shared cross different categories , and the differences are in the details of object parts ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["We derive approximate posterior inference algorithms based on variational methods .", "Our model can be used to explore how a lawmaker 's voting patterns deviate from what is expected and how that deviation depends on what is being voted on .", "Across 12 years of legislative data , we demonstrate both improvement in heldout predictive performance and the model 's utility in interpreting an inherently multi-dimensional space .", "We develop a probabilistic model of legislative data that uses the text of the bills to uncover lawmakers ' positions on specific political issues ."]}
{"orig_sents": ["3", "5", "1", "0", "2", "6", "4"], "shuf_sents": ["In this work we propose extensions to the basic joint regression model for network estimation , which explicitly incorporate graph-topological constraints into the corresponding optimization approach .", "However , little work has been done on incorporating prior topological knowledge onto the estimation of the underlying graphical models from sample data .", "The first proposed extension includes an eigenvector centrality constraint , thereby promoting this important prior topological property .", "Graphical models are a very useful tool to describe and understand natural phenomena , from gene expression to climate change and social interactions .", "The presentation of the underlying formulations , which serve as examples of the introduction of topological constraints in network estimation , is complemented with examples in diverse datasets demonstrating the importance of incorporating such critical prior knowledge .", "The topological structure of these graphs/networks is a fundamental part of the analysis , and in many cases the main goal of the study .", "The second developed extension promotes the formation of certain motifs , triangle-shaped ones in particular , which are known to exist for example in genetic regulatory networks ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["We propose strategies to search for objects which intelligently explore the space of windows by making sequential observations at locations decided based on previous observations .", "Although simple and effective , it is also wasteful , unnatural and rigidly hardwired .", "In addition to being more elegant than sliding windows , we demonstrate experimentally on the PASCAL VOC 2010 dataset that our strategies evaluate two orders of magnitude fewer windows while achieving higher object detection performance .", "The dominant visual search paradigm for object class detection is sliding windows .", "Our strategies adapt to the class being searched and to the content of a particular test image , exploiting context as the statistical relation between the appearance of a window and its location relative to the object , as observed in the training set ."]}
{"orig_sents": ["5", "6", "2", "0", "3", "4", "1", "7"], "shuf_sents": ["At present the main performance bottleneck is the readout layer which uses slow , digital postprocessing .", "Its performance is better than non-reservoir methods , with ample room for further improvement .", "Operating speeds allowing for real time information operation have been reached using optoelectronic systems .", "We have designed an analog readout suitable for time-multiplexed optoelectronic reservoir computers , capable of working in real time .", "The readout has been built and tested experimentally on a standard benchmark task .", "Reservoir computing is a new , powerful and flexible machine learning technique that is easily implemented in hardware .", "Recently , by using a timemultiplexed architecture , hardware reservoir computers have reached performance comparable to digital implementations .", "The present work thereby overcomes one of the major limitations for the future development of hardware reservoir computers ."]}
{"orig_sents": ["5", "2", "4", "3", "6", "0", "1"], "shuf_sents": ["Here , we propose a large-scale feature learning system that enables us to carry out this experiment , learning 150,000 features from tens of millions of unlabeled images .", "Based on two scalable clustering algorithms ( K-means and agglomerative clustering ) , we find that our simple system can discover features sensitive to a commonly occurring object class ( human faces ) and can also combine these into detectors invariant to significant global distortions like large translations and scale .", "Much progress has been made in this direction , but in most cases it is still standard to use a large amount of labeled data in order to construct detectors sensitive to object classes or other complex patterns in the data .", "Though a handful of prior results suggest that this is possible when each object class accounts for a large fraction of the data ( as in many labeled datasets ) , it is unclear whether something similar can be accomplished when dealing with completely unlabeled data .", "In this paper , we aim to test the hypothesis that unsupervised feature learning methods , provided with only unlabeled data , can learn high-level , invariant features that are sensitive to commonly-occurring objects .", "Recent work in unsupervised feature learning has focused on the goal of discovering high-level features from unlabeled images .", "A major obstacle to this test , however , is scale : we can not expect to succeed with small datasets or with small numbers of learned features ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["There is no generally accepted way to define wavelets on permutations .", "We address this issue by introducing the notion of coset based multiresolution analysis ( CMRA ) on the symmetric group , find the corresponding wavelet functions , and describe a fast wavelet transform for sparse signals .", "We discuss potential applications in ranking , sparse approximation , and multi-object tracking ."]}
{"orig_sents": ["2", "5", "4", "3", "1", "6", "0"], "shuf_sents": ["We illustrate the advantage of the proposed approach on two problems : cart-balancing with swing-up , and teaching a robot to grasp unknown objects .", "This distribution corresponds to a Markov Random Field .", "We use a graphical model for representing policies in Markov Decision Processes .", "smoother policies .", "A bias is then introduced into the policy search process by sampling policies from a distribution that assigns high probabilities to policies that agree with the provided state similarity graph , i.e .", "This new representation can easily incorporate domain knowledge in the form of a state similarity graph that loosely indicates which states are supposed to have similar optimal actions .", "We also present forward and inverse reinforcement learning algorithms for learning such policy distributions ."]}
{"orig_sents": ["10", "5", "4", "1", "0", "7", "6", "8", "9", "3", "2"], "shuf_sents": ["The current standard is follow up the trial with an auxiliary questionnaire , which allows trial participants to express their belief concerning the assigned intervention and which is used to compute a measure of the extent of blinding in the trial .", "Yet , in practice perfect blinding is impossible to ensure or even verify .", "Unlike previous approaches , ours is void of any ad hoc free parameters , is robust to small changes in auxiliary data and is not predicated on any strong assumptions used to interpret participants ' feedback .", "We too adopt a post-trial feedback questionnaire but interpret the collected data using an original approach , fundamentally different from those previously proposed .", "to blind it .", "Thus in clinical trials an effort is made to conceal the nature of the administered intervention from the participants in the trial i.e .", "In this paper we make several important contributions .", "If the estimated extent of blinding exceeds a threshold the trial is deemed sufficiently blinded ; otherwise , the trial is deemed to have failed .", "Firstly , we identify a series of fundamental problems of the aforesaid practice and discuss them in context of the most commonly used blinding measures .", "Secondly , motivated by the highlighted problems , we formulate a novel method for handling imperfectly blinded trials .", "The interaction between the patient 's expected outcome of an intervention and the inherent effects of that intervention can have extraordinary effects ."]}
{"orig_sents": ["5", "1", "3", "2", "4", "0"], "shuf_sents": ["We conclude with empirical evidence of improvement over convex relaxations and mean-field based bounds .", "We introduce a novel message-passing algorithm called Density Propagation ( DP ) for estimating this distribution .", "Further , we use density of states and tree decomposition to introduce a new family of upper and lower bounds on the partition function .", "We show that DP is exact for tree-structured graphical models and is , in general , a strict generalization of both sum-product and max-product algorithms .", "For any tree decomposition , the new upper bound based on finer-grained density of state information is provably at least as tight as previously known bounds based on convexity of the log-partition function , and strictly stronger if a general condition holds .", "Given a probabilistic graphical model , its density of states is a distribution that , for any likelihood value , gives the number of configurations with that probability ."]}
{"orig_sents": ["0", "4", "1", "6", "2", "5", "3"], "shuf_sents": ["This paper proposes an efficient online learning algorithm to track the smoothing functions of Additive Models .", "In order to quickly track changes in the model and put more weight on recent data , the RLS filter uses a forgetting factor which exponentially weights down observations by the order of their arrival .", "Using results from Lyapunov stability theory , upper bounds for the learning rate are analyzed .", "Compared to state-of-the-art methods , it achieves a superior performance in terms of model tracking and prediction accuracy .", "The key idea is to combine the linear representation of Additive Models with a Recursive Least Squares ( RLS ) filter .", "The proposed algorithm is applied to 5 years of electricity load data provided by the French utility company Electricite de France ( EDF ) .", "The tracking behaviour is further enhanced by using an adaptive forgetting factor which is updated based on the gradient of the a priori errors ."]}
{"orig_sents": ["6", "3", "5", "2", "4", "7", "1", "0"], "shuf_sents": ["We also show improved robustness to label noise .", "We present experimental results demonstrating improved performance over state of the art classification techniques on benchmark datasets .", "Nevertheless , we consider locally linear schemes by learning linear partitions and linear region classifiers .", "We formulate an empirical risk minimization problem that incorporates both partitioning and classification in to a single global objective .", "Locally linear schemes can not only approximate complex decision boundaries and ensure low training error but also provide tight control on over-fitting and generalization error .", "We show that space partitioning can be equivalently reformulated as a supervised learning problem and consequently any discriminative learning method can be utilized in conjunction with our approach .", "We develop a novel approach for supervised learning based on adaptively partitioning the feature space into different regions and learning local region-specific classifiers .", "We train locally linear classifiers by using LDA , logistic regression and perceptrons , and so our scheme is scalable to large data sizes and high-dimensions ."]}
{"orig_sents": ["7", "9", "1", "8", "2", "5", "3", "6", "4", "0"], "shuf_sents": ["This classification gives meaning to these suboptimal solutions and helps to explain , in terms of graph structure , when the 1 -relaxation provides the solution of the original Cheeger cut problem .", "The 1 -relaxation , in contrast , is non-convex but is provably equivalent to the original problem .", "The first challenge is understanding convergence of algorithms .", "The second challenge entails comprehending the 1 energy landscape , i.e .", "We show that 1 -algorithms can get trapped in local minima that are not globally optimal and we provide a classification theorem to interpret these local minima .", "This paper provides the first complete proof of convergence for algorithms that minimize the 1 -relaxation .", "the set of possible points to which an algorithm might converge .", "This paper provides both theoretical and algorithmic results for the 1 -relaxation of the Cheeger cut problem .", "The 1 -relaxation therefore trades convexity for exactness , yielding improved clustering results at the cost of a more challenging optimization .", "The 2 -relaxation , known as spectral clustering , only loosely relates to the Cheeger cut ; however , it is convex and leads to a simple optimization problem ."]}
{"orig_sents": ["6", "2", "5", "4", "1", "7", "0", "3"], "shuf_sents": ["These properties make the kernel selection and test procedures suited to data streams , where the observations can not all be stored in memory .", "For a given test level ( an upper bound on the probability of making a Type I error ) , the kernel is chosen so as to maximize the test power , and minimize the probability of making a Type II error .", "One choice of test statistic is the maximum mean discrepancy ( MMD ) , which is a distance between embeddings of the probability distributions in a reproducing kernel Hilbert space .", "In experiments , the new kernel selection approach yields a more powerful test than earlier kernel selection heuristics .", "A means of parameter selection for the two-sample test based on the MMD is proposed .", "The kernel used in obtaining these embeddings is critical in ensuring the test has high power , and correctly distinguishes unlike distributions with high probability .", "Given samples from distributions p and q , a two-sample test determines whether to reject the null hypothesis that p = q , based on the value of a test statistic measuring the distance between the samples .", "The test statistic , test threshold , and optimization over the kernel parameters are obtained with cost linear in the sample size ."]}
{"orig_sents": ["1", "2", "6", "4", "7", "5", "3", "0"], "shuf_sents": ["In particular , we show that our methods efficiently solve an advertisement prediction problem from the Chinese SoSo Search Engine , which consists of N 2.4 x 108 samples and d 700 , 000 dimensions .", "We study two communication-efficient algorithms for distributed statistical optimization on large-scale data .", "The first algorithm is an averaging method that distributes the N data samples evenly to m machines , performs separate minimization on each subset , and then averages the estimates .", "We complement our theoretical results with experiments on largescale problems from the internet search domain .", "Whenever m N , this guarantee matches the best possible rate achievable by a centralized algorithm having access to all N samples .", "Requiring only a single round of communication , it has mean-squared error that decays as O ( N -1 + ( N/m ) -3 ) , and so is more robust to the amount of parallelization .", "We provide a sharp analysis of this average mixture algorithm , showing that under a reasonable set of conditions , the combined parameter achieves mean-squared error that decays as O ( N -1 + ( N/m ) -2 ) .", "The second algorithm is a novel method , based on an appropriate form of the bootstrap ."]}
{"orig_sents": ["1", "0", "4", "2", "5", "3", "6"], "shuf_sents": ["It has been successfully applied to many applications including computer vision and biomedical informatics .", "Multi-task sparse feature learning aims to improve the generalization performance by exploiting the shared features among tasks .", "In this paper , we propose a non-convex formulation for multi-task sparse feature learning based on a novel regularizer .", "Moreover , we present a detailed theoretical analysis showing that MSMTFL achieves a better parameter estimation error bound than the convex formulation .", "Most of the existing multi-task sparse feature learning algorithms are formulated as a convex sparse regularization problem , which is usually suboptimal , due to its looseness for approximating an 0 -type regularizer .", "To solve the non-convex optimization problem , we propose a MultiStage Multi-Task Feature Learning ( MSMTFL ) algorithm .", "Empirical studies on both synthetic and real-world data sets demonstrate the effectiveness of MSMTFL in comparison with the state of the art multi-task sparse feature learning algorithms ."]}
{"orig_sents": ["5", "0", "4", "2", "1", "3"], "shuf_sents": ["With tracked sequences as input , a hierarchical network of modules learns invariant features using a temporal slowness constraint .", "We applied our features to four datasets ( COIL-100 , Caltech 101 , STL-10 , PubFig ) , and observe a consistent improvement of 4 % to 5 % in classification accuracy .", "Although learned from videos , our features are spatial instead of spatial-temporal , and well suited for extracting features from still images .", "With this approach , we achieve state-of-the-art recognition accuracy 61 % on STL-10 dataset .", "The network encodes invariance which are increasingly complex with hierarchy .", "We apply salient feature detection and tracking in videos to simulate fixations and smooth pursuit in human vision ."]}
{"orig_sents": ["4", "10", "5", "2", "3", "6", "0", "8", "1", "9", "7"], "shuf_sents": ["This MWIS problem exhibits a special structure .", "We propose a variant of simulated annealing method that takes advantage of this special structure .", "The edges connect the vertices whose corresponding clusters overlap .", "Intuitively , an optimal aggregated clustering can be obtained by selecting an optimal subset of non-overlapping clusters partitioning the dataset together .", "We formulate clustering aggregation as a special instance of Maximum-Weight Independent Set ( MWIS ) problem .", "The vertices , which represent the distinct clusters , are weighted by an internal index measuring both cohesion and separation .", "We formalize this intuition as the MWIS problem on the attributed graph , i.e. , finding the heaviest subset of mutually non-adjacent vertices .", "Extensive experiments on many challenging datasets show that : 1. our approach to clustering aggregation automatically decides the optimal number of clusters ; 2. it does not require any parameter tuning for the underlying clustering algorithms ; 3. it can combine the advantages of different underlying clustering algorithms to achieve superior performance ; 4. it is robust against moderate or even bad input clusterings .", "Since the clusters of each input clustering form a partition of the dataset , the vertices corresponding to each clustering form a maximal independent set ( MIS ) in the attributed graph .", "Our algorithm starts from each MIS , which is close to a distinct local optimum of the MWIS problem , and utilizes a local search heuristic to explore its neighborhood in order to find the MWIS .", "For a given dataset , an attributed graph is constructed from the union of the input clusterings generated by different underlying clustering algorithms with different parameters ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["Moreover , the rejected volume vanishes with the training set size , under certain conditions .", "We then develop efficient and exact implementation of these selective regressors for the case of linear regression .", "It is shown that using rejection it is theoretically possible to learn `selective ' regressors that can -pointwise track the best regressor in hindsight from the same hypothesis class , while rejecting only a bounded portion of the domain .", "Empirical evaluation over a suite of real-world datasets corroborates the theoretical analysis and indicates that our selective regressors can provide substantial advantage by reducing estimation error .", "This paper examines the possibility of a `reject option ' in the context of least squares regression ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["For further computational cost reduction , an efficient method is developed to list all orbits by their symmetry orders and calculate all index function orbit sums and data function orbit sums recursively .", "The computational complexity analysis shows reduction in the computational cost from n !", "or nn level to low-order polynomial level .", "In this paper , a novel and computationally fast algorithm for computing weighted v-statistics in resampling both univariate and multivariate data is proposed .", "To avoid any real resampling , we have linked this problem with finite group action and converted it into a problem of orbit enumeration ."]}
{"orig_sents": ["1", "4", "3", "2", "0"], "shuf_sents": ["Experiments with both synthetic and real datasets demonstrate the effectiveness of our classification criteria .", "This paper sheds light on some fundamental connections of the diffusion decision making model of neuroscience and cognitive psychology with k-nearest neighbor classification .", "Making use of the sequential probability ratio test ( SPRT ) and Bayesian analysis , we propose five different criteria for adaptively acquiring nearest neighbors .", "By applying the optimal strategy associated with the diffusion decision model , an adaptive rule is developed for determining appropriate values of k in knearest neighbor classification .", "We show that conventional k-nearest neighbor classification can be viewed as a special problem of the diffusion decision model in the asymptotic situation ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce .", "A special case that has received significant attention is the Plackett-Luce model , for which fast inference methods for maximum likelihood estimators are available .", "This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM , providing concave loglikelihood functions and bounded sets of global maxima solutions .", "Random utility theory models an agent 's preferences on alternatives by drawing a real-valued score on each alternative ( typically independently ) from a parameterized distribution , and then ranking the alternatives according to scores ."]}
{"orig_sents": ["4", "0", "3", "5", "1", "2", "6"], "shuf_sents": ["Several approaches are based , for example , on generalized message-passing , or on transformation to a pairwise model with extra `auxiliary ' variables .", "These vertex-cover instances can then be attacked by existing algorithms ( e.g .", "belief propagation , QPBO ) , where they often run 4-15 times faster and find better solutions than when applied to the original problem .", "We focus on a special case where a much more efficient transformation is possible .", "Inference in high-order graphical models has become important in recent years .", "Instead of adding variables , we transform the original problem into a comparatively small instance of submodular vertex-cover .", "We evaluate our approach on synthetic data , then we show applications within a fast hierarchical clustering and model-fitting framework ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["We provide an efficient Metropolis-Hastings sampling algorithm utilizing the gradient of the posterior to estimate the underlying reward functions , and demonstrate that our approach outperforms previous ones via experiments on a number of problem domains .", "Most previous IRL algorithms assume that the behaviour data is obtained from an agent who is optimizing a single reward function , but this assumption is hard to guarantee in practice .", "We present a nonparametric Bayesian approach to inverse reinforcement learning ( IRL ) for multiple reward functions .", "Our approach is based on integrating the Dirichlet process mixture model into Bayesian IRL ."]}
{"orig_sents": ["6", "5", "4", "8", "0", "1", "2", "9", "11", "7", "3", "10"], "shuf_sents": ["And can saturating dendrites equally expand computational capacity ?", "To address these questions we use a binary neuron model and Boolean algebra .", "First , we confirm that spiking dendrites enable a neuron to compute lnBFs using an architecture based on the disjunctive normal form ( DNF ) .", "Consequently , we show that an important family of lnBFs implemented with a CNF-architecture can require an exponential number of saturating dendritic units , whereas the same family implemented with either a DNF-architecture or a CNF-architecture always require a linear number of spiking dendritic units .", "Decomposing a dendritic tree into independent dendritic spiking units greatly extends its computational capacity , as the neuron then maps onto a two layer neural network , enabling it to compute linearly non-separable Boolean functions ( lnBFs ) .", "If this depolarization is bigger than the arithmetic sum , the dendrite is spiking ; if the depolarization is smaller , the dendrite is saturating .", "The integration of excitatory inputs in dendrites is non-linear : multiple excitatory inputs can produce a local depolarization departing from the arithmetic sum of each input 's response taken separately .", "Third , we show that one can not use a DNF-based architecture with saturating dendrites .", "How can these lnBFs be implemented by dendritic architectures in practise ?", "Second , we prove that saturating dendrites as well as spiking dendrites enable a neuron to compute lnBFs using an architecture based on the conjunctive normal form ( CNF ) .", "This minimization could explain why a neuron spends energetic resources to make its dendrites spike .", "Contrary to a DNF-based architecture , in a CNF-based architecture , dendritic unit tunings do not imply the neuron tuning , as has been observed experimentally ."]}
{"orig_sents": ["4", "0", "1", "7", "5", "6", "2", "3"], "shuf_sents": ["partition the nodes into disjoint clusters so that there is higher density within clusters , and low across clusters .", "By sparsity we mean the setting where both the in-cluster and across cluster edge densities are very small , possibly vanishing in the size of the graph .", "We analyze our algorithm 's performance on the natural , classical and widely studied `` planted partition '' model ( also called the stochastic block model ) ; we show that our algorithm can cluster sparser graphs , and with smaller clusters , than all previous methods .", "This is seen empirically as well .", "We develop a new algorithm to cluster sparse unweighted graphs - i.e .", "Any clustering involves a tradeoff between minimizing two kinds of errors : missing edges within clusters and present edges across clusters .", "Our insight is that in the sparse case , these must be penalized differently .", "Sparsity makes the problem noisier , and hence more difficult to solve ."]}
{"orig_sents": ["1", "3", "2", "0"], "shuf_sents": ["We also demonstrate the performance of these methods using problems of relevance in machine learning and statistics .", "We seek to solve convex optimization problems in composite form : minimize f ( x ) : = g ( x ) + h ( x ) , n xR where g is convex and continuously differentiable and h : Rn R is a convex but not necessarily differentiable function whose proximal mapping can be evaluated efficiently .", "We prove such methods are globally convergent and achieve superlinear rates of convergence in the vicinity of an optimal solution .", "We derive a generalization of Newton-type methods to handle such convex but nonsmooth objective functions ."]}
{"orig_sents": ["7", "2", "5", "3", "0", "4", "9", "8", "6", "1", "10"], "shuf_sents": ["The input layer maps each window pixel to a neuron .", "rand error , warping error and pixel error .", "This is necessary to efficiently map 3D brain structure and connectivity .", "The label of each pixel ( membrane or nonmembrane ) is predicted from raw pixel values in a square window centered on it .", "It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction .", "To segment biological neuron membranes , we use a special type of deep artificial neural network as a pixel classifier .", "Even without problem-specific postprocessing , our approach outperforms competing techniques by a large margin in all three considered metrics , i.e .", "We address a central problem of neuroanatomy , namely , the automatic segmentation of neuronal structures depicted in stacks of electron microscopy ( EM ) images .", "The classifier is trained by plain gradient descent on a 512 x 512 x 30 stack with known ground truth , and tested on a stack of the same size ( ground truth unknown to the authors ) by the organizers of the ISBI 2012 EM Segmentation Challenge .", "The output layer produces a calibrated probability for each class .", "For pixel error , our approach is the only one outperforming a second human observer ."]}
{"orig_sents": ["0", "3", "7", "6", "1", "5", "2", "4"], "shuf_sents": ["Many visual and auditory neurons have response properties that are well explained by pooling the rectified responses of a set of spatially shifted linear filters .", "We refer to these initial LN elements as the `subunits ' of the receptive field .", "We present a method for directly fitting this model to spike data , and apply it to both simulated and real neuronal data from primate V1 .", "These filters can not be estimated using spike-triggered averaging ( STA ) .", "The subunit model significantly outperforms STA and STC in terms of cross-validated accuracy and efficiency .", "The second linear stage then computes a weighted sum of the responses of the rectified subunits .", "Here , we assume a linear-nonlinear-linear-nonlinear ( LN-LN ) cascade model in which the first linear stage is a set of shifted ( `convolutional ' ) copies of a common filter , and the first nonlinear stage consists of rectifying scalar nonlinearities that are identical for all filter outputs .", "Subspace methods such as spike-triggered covariance ( STC ) can recover multiple filters , but require substantial amounts of data , and recover an orthogonal basis for the subspace in which the filters reside rather than the filters themselves ."]}
{"orig_sents": ["9", "6", "8", "0", "1", "3", "2", "7", "5", "4"], "shuf_sents": ["We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo ( MCMC ) inference algorithms .", "We take the `white ' noise that drives a diffusion process and decompose it into two terms .", "The second term is small and enables us to form a linear Gaussian `small noise ' approximation .", "The first is a `coloured noise ' term that can be deterministically controlled by a set of auxilliary variables .", "Our results show that this method is a promising new tool for use in inference and parameter estimation problems .", "We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems , and we demonstrate experimentally that our method performs well in such situations .", "Crucial to the process of using SDE to build mathematical models is the ability to estimate parameters of those models from observed data .", "The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods .", "Over the past few decades , significant progress has been made on this problem , but we are still far from having a definitive solution .", "Stochastic differential equations ( SDE ) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes ."]}
{"orig_sents": ["2", "4", "5", "3", "6", "0", "1"], "shuf_sents": ["We illustrate the performance of our approach on standard tensor-factorization datasets where we attain , or outperform , state-of-the-art results .", "Finally , a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations .", "Many data such as social networks , movie preferences or knowledge bases are multi-relational , in that they describe multiple relations between entities .", "In this paper , we propose a method for modeling large multi-relational datasets , with possibly thousands of relations .", "While there is a large body of work focused on modeling these data , modeling these multiple types of relations jointly remains challenging .", "Further , existing approaches tend to breakdown when the number of these types grows .", "Our model is based on a bilinear structure , which captures various orders of interaction of the data , and also shares sparse latent factors across different relations ."]}
{"orig_sents": ["0", "1", "4", "2", "3"], "shuf_sents": ["The CUR matrix decomposition is an important extension of Nystrom approximation to a general matrix .", "It approximates any data matrix in terms of a small number of its columns and rows .", "The proposed algorithm has the advantages over the existing relative-error CUR algorithms that it possesses tighter theoretical bound and lower time complexity , and that it can avoid maintaining the whole data matrix in main memory .", "Finally , experiments on several real-world datasets demonstrate significant improvement over the existing relative-error algorithms .", "In this paper we propose a novel randomized CUR algorithm with an expected relative-error bound ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We propose a simple and novel framework for MCMC inference in continuoustime discrete-state systems with pure jump trajectories .", "The first step can be performed efficiently using properties of the Poisson process , while the second step can avail of discrete-time MCMC techniques based on the forward-backward algorithm .", "We show the advantage of our approach compared to particle MCMC and a uniformization-based sampler .", "We construct an exact MCMC sampler for such systems by alternately sampling a random discretization of time given a trajectory of the system , and then a new trajectory given the discretization ."]}
{"orig_sents": ["6", "1", "0", "5", "2", "4", "3"], "shuf_sents": ["We propose a deep non-linear classifier whose layers are SVMs and which incorporates random projection as its core stacking element .", "Deep learning methods can find more compact representations but current methods employ multilayer perceptrons that require solving a difficult , non-convex optimization problem .", "Our method scales as linear SVMs , does not rely on any kernel computations or nonconvex optimization , and exhibits better generalization ability than kernel-based SVMs .", "The use of random projections is key to our method , as we show in the experiments section , in which we observe a consistent improvement over previous -often more complicated- methods on several vision and speech benchmarks .", "This is especially true when the number of training samples is smaller than the dimensionality of data , a common scenario in many real-world applications .", "Our method learns layers of linear SVMs recursively transforming the original data manifold through a random projection of the weak prediction computed from each layer .", "Linear Support Vector Machines ( SVMs ) have become very popular in vision as part of state-of-the-art object recognition and other classification tasks but require high dimensional feature spaces for good performance ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["This motivates our approach of using stagewise linear combinations of collaborative filtering algorithms , with non-constant combination coefficients based on kernel smoothing .", "Recent approaches to collaborative filtering have concentrated on estimating an algebraic or statistical model , and using the model for predicting missing ratings .", "In this paper we observe that different models have relative advantages in different regions of the input space .", "The resulting stagewise model is computationally scalable and outperforms a wide selection of state-of-the-art collaborative filtering algorithms ."]}
{"orig_sents": ["2", "4", "1", "3", "0"], "shuf_sents": ["Analyzing a dataset of humans captured in dozens of poses , we infer parts which provide quantitatively better deformation predictions than conventional clustering methods .", "To allow analysis of datasets in which object instances have varying 3D shapes , we model part variability across poses via affine transformations .", "We develop a method for discovering the parts of an articulated object from aligned meshes of the object in various three-dimensional poses .", "By placing a matrix normal-inverse-Wishart prior on these affine transformations , we develop a ddCRP Gibbs sampler which tractably marginalizes over transformation uncertainty .", "We adapt the distance dependent Chinese restaurant process ( ddCRP ) to allow nonparametric discovery of a potentially unbounded number of parts , while simultaneously guaranteeing a spatially connected segmentation ."]}
{"orig_sents": ["6", "1", "5", "0", "2", "7", "4", "3"], "shuf_sents": ["The learning rule acts to minimise the membrane potential magnitude , which can be interpreted as a representation error after learning .", "We answer this question by deriving spiking dynamics and learning dynamics directly from a measure of network performance .", "In this way , learning reduces the representation error and drives the network into a robust , balanced regime .", "Altogether , these results suggest that several observed features of cortical dynamics , such as excitatory-inhibitory balance , integrate-and-fire dynamics and Hebbian plasticity , are signatures of a robust , optimal spike-based code .", "The representation is robust because neurons become self-correcting , only spiking if the representation error exceeds a threshold .", "We find that a network of integrate-and-fire neurons undergoing Hebbian plasticity can learn an optimal spike-based representation for a linear decoder .", "How can neural networks learn to represent information optimally ?", "The network becomes balanced because small representation errors correspond to small membrane potentials , which in turn results from a balance of excitation and inhibition ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["We show empirically that ( i ) our approach results in improved convergence over non-Bayesian baselines , ( ii ) using both task hierarchies and Bayesian priors is better than either alone , ( iii ) taking advantage of the task hierarchy reduces the computational cost of Bayesian reinforcement learning and ( iv ) in this framework , task pseudo-rewards can be learned instead of being manually specified , leading to hierarchically optimal rather than recursively optimal policies .", "We describe an approach to incorporating Bayesian priors in the MAXQ framework for hierarchical reinforcement learning ( HRL ) .", "We define priors on the primitive environment model and on task pseudo-rewards .", "Since models for composite tasks can be complex , we use a mixed model-based/model-free learning approach to find an optimal hierarchical policy ."]}
{"orig_sents": ["2", "4", "1", "0", "3"], "shuf_sents": ["This setting proves to be more difficult than the standard multi-arm bandit setting due in part to an exploration risk which introduces a regret associated to the variability of an algorithm .", "In this paper , we introduce a novel setting based on the principle of risk-aversion where the objective is to compete against the arm with the best risk-return trade-off .", "Stochastic multi-armed bandits solve the Exploration-Exploitation dilemma and ultimately maximize the expected reward .", "Using variance as a measure of risk , we define two algorithms , investigate their theoretical guarantees , and report preliminary empirical results .", "Nonetheless , in many practical problems , maximizing the expected reward is not the most desirable objective ."]}
{"orig_sents": ["2", "6", "7", "1", "9", "8", "5", "4", "0", "3"], "shuf_sents": ["We also provide a simple dual to primal mapping that yields feasible primal solutions with a guaranteed rate of convergence .", "In recent years , several authors have proposed message passing updates corresponding to coordinate descent in the dual LP .", "Finding maximum a posteriori ( MAP ) assignments in graphical models is an important task in many applications .", "Empirical evaluation supports our theoretical claims and shows that the method is highly competitive with state of the art approaches that yield global optima .", "Here we perform a thorough rate analysis of such schemes and derive primal and dual convergence rates .", "However , little is known about the convergence rate of this procedure .", "Since the problem is generally hard , linear programming ( LP ) relaxations are often used .", "Solving these relaxations efficiently is thus an important practical problem .", "One approach to remedy this is to smooth the LP , and perform coordinate descent on the smoothed dual .", "However , these are generally not guaranteed to converge to a global optimum ."]}
{"orig_sents": ["5", "6", "2", "0", "4", "1", "3"], "shuf_sents": ["We restrict attention to two-phased strategies : first predict ( i.e. , learn ) ; second , optimize .", "We exploit auction properties to represent the MDP in a more compact state space , and we use Monte Carlo simulation to make estimating the MDP tractable .", "In this paper , we combine methods from game theory and decision theory to search for approximate equilibria in sequential auction domains , in which bidders do not know their opponents ' values for goods , bidders only partially observe the actions of their opponents ' , and bidders demand multiple goods .", "We show how equilibria found using our search procedure compare to known equilibria for simpler auction domains , and we approximate an equilibrium for a more complex auction domain where analytical solutions are unknown .", "We use best-reply dynamics for prediction ( i.e. , to predict other bidders ' strategies ) , and then assuming fixed other-bidder strategies , we estimate and solve the ensuing Markov decision processes ( MDP ) for optimization .", "In many large economic markets , goods are sold through sequential auctions .", "Examples include eBay , online ad auctions , wireless spectrum auctions , and the Dutch flower auctions ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["To this end , we make two important contributions : ( 1 ) we show how previous exact symbolic dynamic programming solutions for continuous state MDPs can be generalized to continuous state POMDPs with discrete observations , and ( 2 ) we show how recently developed symbolic integration methods allow this solution to be extended to PBVI for continuous state and observation POMDPs with potentially correlated , multivariate continuous observation spaces .", "Our key insight is that while there may be an infinite number of observations , there are only a finite number of continuous observation partitionings that are relevant for optimal decision-making when a finite , fixed set of reachable belief states is considered .", "Point-based value iteration ( PBVI ) methods have proven extremely effective for finding ( approximately ) optimal dynamic programming solutions to partiallyobservable Markov decision processes ( POMDPs ) when a set of initial belief states is known .", "However , no PBVI work has provided exact point-based backups for both continuous state and observation spaces , which we tackle in this paper ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["We here consider an extension of this problem to the case when the arms are the cells of a finite partition P of a continuous sampling space X Rd .", "Although this extension is not trivial , we show that a simple algorithm based on upper confidence bounds can be proved to be adaptive to the function itself in a near-optimal way , when |P| is chosen to be of minimax-optimal order on the class of -Holder functions .", "Our goal is now to build a piecewise constant approximation of a noisy function ( where each piece is one region of P and P is fixed beforehand ) in order to maintain the local quadratic error of approximation on each cell equally low .", "In the setting of active learning for the multi-armed bandit , where the goal of a learner is to estimate with equal precision the mean of a finite number of arms , recent results show that it is possible to derive strategies based on finite-time confidence bounds that are competitive with the best possible strategy ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["We provide an analysis of what such a model learns from natural images as a function of number of mixture components including covariance structure , contrast variation and intricate structures such as textures , boundaries and more .", "We show that such a GMM model is able to compete with even the most successful models of natural images in log likelihood scores , denoising performance and sample quality .", "Finally , we show that the salient properties of the GMM learned from natural images can be derived from a simplified Dead Leaves model which explicitly models occlusion , explaining its surprising success relative to other models .", "Here we provide an in depth analysis of this simple yet rich model .", "Simple Gaussian Mixture Models ( GMMs ) learned from pixels of natural image patches have been recently shown to be surprisingly strong performers in modeling the statistics of natural images ."]}
{"orig_sents": ["0", "1", "3", "5", "6", "4", "2"], "shuf_sents": ["Early stages of visual processing are thought to decorrelate , or whiten , the incoming temporally varying signals .", "Motivated by the cascade structure of the visual pathway ( retina lateral geniculate nucelus ( LGN ) primary visual cortex , V1 ) we propose to model its function using lattice filters - signal processing devices for stage-wise decorrelation of temporal signals .", "Therefore , lattice filter is a useful abstraction that captures temporal aspects of visual processing .", "Lattice filter models predict neuronal responses consistent with physiological recordings in cats and primates .", "In addition , lattice filters can model visual processing in insects .", "In particular , they predict temporal receptive fields of two different types resembling so-called lagged and non-lagged cells in the LGN .", "Moreover , connection weights in the lattice filter can be learned using Hebbian rules in a stage-wise sequential manner reminiscent of the neuro-developmental sequence in mammals ."]}
{"orig_sents": ["3", "0", "6", "2", "4", "1", "5"], "shuf_sents": ["While an object taxonomy specifying the categories ' semantic relationships could bolster the learning process , not all relationships are relevant to a given visual classification task , nor does a single taxonomy capture all ties that are relevant .", "To learn the weights , we introduce a novel hierarchical regularization term that further exploits the taxonomies ' structure .", "For each taxonomy , we first learn a tree of semantic kernels , where each node has a Mahalanobis kernel optimized to distinguish between the classes in its children nodes .", "When learning features for complex visual recognition problems , labeled image exemplars alone can be insufficient .", "Then , using the resulting semantic kernel forest , we learn class-specific kernel combinations to select only those relationships relevant to recognize each object class .", "We demonstrate our method on challenging object recognition datasets , and show that interleaving multiple taxonomic views yields significant accuracy improvements .", "In light of these issues , we propose a discriminative feature learning approach that leverages multiple hierarchical taxonomies representing different semantic views of the object categories ( e.g. , for animal classes , one taxonomy could reflect their phylogenic ties , while another could reflect their habitats ) ."]}
{"orig_sents": ["1", "4", "2", "3", "5", "0"], "shuf_sents": ["This offers a simpler and more unified account of how people search their memory , postulating a single process rather than one process for exploring a cluster and one process for switching between clusters .", "The human mind has a remarkable ability to store a vast amount of information in memory , and an even more remarkable ability to retrieve these experiences when needed .", "Psychological studies have revealed clear regularities in how people search their memory , with clusters of semantically related items tending to be retrieved together .", "These findings have recently been taken as evidence that human memory search is similar to animals foraging for food in patchy environments , with people making a rational decision to switch away from a cluster of related information as it becomes depleted .", "Understanding the representations and algorithms that underlie human memory search could potentially be useful in other information retrieval settings , including internet search .", "We demonstrate that the results that were taken as evidence for this account also emerge from a random walk on a semantic network , much like the random web surfer model used in internet search engines ."]}
{"orig_sents": ["6", "7", "5", "2", "3", "4", "1", "0"], "shuf_sents": ["Finally , we frame these objectives in the context of a two-player , zero-sum , extensive-form game and employ a no-regret algorithm to approximate an optimal policy , with computation only polynomial in the number of states and actions of the MDP .", "We then introduce a broad subclass of this family for which robust policies can be approximated efficiently .", "In this paper , we take a Bayesian approach to parameter uncertainty , but unlike other methods avoid making any distributional assumptions about the form of this uncertainty .", "Instead we focus on identifying optimization objectives for which solutions can be efficiently approximated .", "We introduce percentile measures : a very general class of objectives for robust policy optimization , which encompasses most existing approaches , including ones known to be intractable .", "One might prefer to accept lower utility in expectation in order to avoid , or reduce the likelihood of , unacceptable levels of utility under harmful parameter realizations .", "Robust policy optimization acknowledges that risk-aversion plays a vital role in real-world decision-making .", "When faced with uncertainty about the effects of actions , the policy that maximizes expected utility over the unknown parameters of the system may also carry with it a risk of intolerably poor performance ."]}
{"orig_sents": ["5", "3", "0", "4", "2", "6", "1"], "shuf_sents": ["Accordingly , we propose a novel approach for the construction of sparsityinducing nonconvex penalties .", "Furthermore , the relationship between these two penalties is due to asymmetricity of the KL distance .", "Additionally , we explore the concave conjugate of nonconvex penalties .", "We define such a penalty as the Laplace exponent of a subordinator .", "Particularly , we show that the nonconvex logarithmic ( LOG ) and exponential ( EXP ) penalty functions are the Laplace exponents of Gamma and compound Poisson subordinators , respectively .", "In this paper we study sparsity-inducing nonconvex penalty functions using Levy processes .", "We find that the LOG and EXP penalties are the concave conjugates of negative Kullback-Leiber ( KL ) distance functions ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["Moreover , using this setting we derive the first provably consistent regularized method with training/tuning complexity that is independent to the number of classes .", "We introduce tools from convex analysis that can be used beyond the scope of this paper .", "In this framework , we develop a relaxation error analysis that avoids constraints on the considered hypotheses class .", "In this paper we discuss a novel framework for multiclass learning , defined by a suitable coding/decoding strategy , namely the simplex coding , that allows us to generalize to multiple classes a relaxation approach commonly used in binary classification ."]}
{"orig_sents": ["4", "2", "3", "0", "1"], "shuf_sents": ["Furthermore , the presented approach provides a methodology to construct a primal optimal solution from its dual optimal counterpart .", "We demonstrate the efficiency of the presented approach on spin glass models and protein interaction problems and show that our approach outperforms state-of-the-art solvers .", "However , the most efficient methods that perform block coordinate descent can get stuck in sub-optimal points as they are not globally convergent .", "In this work we propose to augment these algorithms with an -descent approach and present a method to efficiently optimize for a descent direction in the subdifferential using a margin-based formulation of the Fenchel-Young duality theorem .", "While finding the exact solution for the MAP inference problem is intractable for many real-world tasks , MAP LP relaxations have been shown to be very effective in practice ."]}
{"orig_sents": ["0", "5", "1", "2", "3", "4"], "shuf_sents": ["We present a general method for deriving collapsed variational inference algorithms for probabilistic models in the conjugate exponential family .", "Our collapsed variational inference leads to a new lower bound on the marginal likelihood .", "We exploit the information geometry of the bound to derive much faster optimization methods based on conjugate gradients for these models .", "Our approach is very general and is easily applied to any model where the mean field update equations have been derived .", "Empirically we show significant speed-ups for probabilistic inference using our bound .", "Our method unifies many existing approaches to collapsed variational inference ."]}
{"orig_sents": ["0", "2", "1", "3", "4"], "shuf_sents": ["Bayesian model-based reinforcement learning is a formally elegant approach to learning optimal behaviour under model uncertainty , trading off exploration and exploitation in an ideal way .", "In this paper we introduce a tractable , sample-based method for approximate Bayesoptimal planning which exploits Monte-Carlo tree search .", "Unfortunately , finding the resulting Bayes-optimal policies is notoriously taxing , since the search space becomes enormous .", "Our approach outperformed prior Bayesian model-based RL algorithms by a significant margin on several well-known benchmark problems - because it avoids expensive applications of Bayes rule within the search tree by lazily sampling models from the current beliefs .", "We illustrate the advantages of our approach by showing it working in an infinite state space domain which is qualitatively out of reach of almost all previous work in Bayesian exploration ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["Previous results on mutual information estimation only bounded expected error .", "The advantage of having the exponential inequality is that , combined with the union bound , we can guarantee accurate estimators of the mutual information for many pairs of random variables simultaneously .", "We prove a new exponential concentration inequality for a plug-in estimator of the Shannon mutual information .", "As an application , we show how to use such a result to optimally estimate the density function and graph of a distribution which is Markov to a forest graph ."]}
{"orig_sents": ["5", "7", "2", "8", "3", "1", "4", "9", "6", "0"], "shuf_sents": ["We also match the accuracy for the best available commercial method .", "Through deep learning , we obtain features that can represent the image at differing resolutions based on network depth , and that are tuned to the statistics of the specific data being aligned .", "However , prior work on unsupervised alignment of complex , real-world images has required the careful selection of feature representation based on hand-crafted image descriptors , in order to achieve an appropriate , smooth optimization landscape .", "Specifically , we incorporate deep learning into the congealing alignment framework .", "In addition , we modify the learning algorithm for the restricted Boltzmann machine by incorporating a group sparsity penalty , leading to a topographic organization of the learned filters and improving subsequent alignment results .", "Unsupervised joint alignment of images has been demonstrated to improve performance on recognition tasks such as face verification .", "Using the aligned images produced by our proposed unsupervised algorithm , we achieve higher accuracy in face verification compared to prior work in both unsupervised and supervised alignment .", "Such alignment reduces undesired variability due to factors such as pose , while only requiring weak supervision in the form of poorly aligned examples .", "In this paper , we instead propose a novel combination of unsupervised joint alignment with unsupervised feature learning .", "We apply our method to the Labeled Faces in the Wild database ( LFW ) ."]}
{"orig_sents": ["2", "6", "0", "5", "1", "3", "4"], "shuf_sents": ["A discriminative learning algorithm , extended from the CCCP , is proposed to train the model in a dynamical manner : the model structure ( e.g. , the configuration of the leaf-nodes associated with the or-nodes ) is automatically determined with optimizing the multi-layer parameters during the iteration .", "( i ) The And-Or graph model enables us to handle well large intra-class variance and background clutters for object shape detection from images .", "This paper studies a novel discriminative part-based model to represent and recognize object shapes with an `` And-Or graph '' .", "( ii ) The proposed learning algorithm is able to obtain the And-Or graph representation without requiring elaborate supervision and initialization .", "We validate the proposed method on several challenging databases ( e.g. , INRIA-Horse , ETHZ-Shape , and UIUC-People ) , and it outperforms the state-of-the-arts approaches .", "The advantages of our method are two-fold .", "We define this model consisting of three layers : the leaf-nodes with collaborative edges for localizing local parts , the or-nodes specifying the switch of leaf-nodes , and the root-node encoding the global verification ."]}
{"orig_sents": ["2", "1", "4", "3", "0"], "shuf_sents": ["Through theoretical and empirical assessments , we demonstrate the accuracy and efficiency of the approximation , especially for large problems .", "The main challenges , however , for such an analysis of fMRI data are : a ) defining a physiologically meaningful feature-space for representing the spatial patterns across time ; b ) dealing with the high-dimensionality of the data ; and c ) robustness to the various artifacts and confounds in the fMRI time-series .", "Identifying patterns from the neuroimaging recordings of brain activity related to the unobservable psychological or mental state of an individual can be treated as a unsupervised pattern recognition problem .", "This feature-space is obtained from a spherical relaxation of the transportation distance metric which measures the cost of transporting `` mass '' over the network to transform one function into another .", "In this paper , we present a network-aware feature-space to represent the states of a general network , that enables comparing and clustering such states in a manner that is a ) meaningful in terms of the network connectivity structure ; b ) computationally efficient ; c ) low-dimensional ; and d ) relatively robust to structured and random noise artifacts ."]}
{"orig_sents": ["4", "1", "0", "2", "3"], "shuf_sents": ["In this paper , we improve the scalability of MPE inference in a class of graphical models with piecewise-linear and piecewise-quadratic dependencies and linear constraints over continuous domains .", "However , finding most-probable explanations ( MPEs ) in these models can be computationally expensive .", "We derive algorithms based on a consensus-optimization framework and demonstrate their superior performance over state of the art .", "We show empirically that in a large-scale voter-preference modeling problem our algorithms scale linearly in the number of dependencies and constraints .", "Probabilistic graphical models are powerful tools for analyzing constrained , continuous domains ."]}
{"orig_sents": ["3", "0", "5", "4", "1", "6", "2"], "shuf_sents": ["Most current methods rely on very well-designed features for this new 3D modality .", "RNNs can be seen as combining convolution and pooling into one efficient , hierarchical operation .", "Our model obtains state of the art performance on a standard RGB-D object dataset while being more accurate and faster during training and testing than comparable architectures such as two-layer CNNs .", "Recent advances in 3D sensing technologies make it possible to easily record color and depth images which together can improve object recognition .", "The CNN layer learns low-level translationally invariant features which are then given as inputs to multiple , fixed-tree RNNs in order to compose higher order features .", "We introduce a model based on a combination of convolutional and recursive neural networks ( CNN and RNN ) for learning features and classifying RGB-D images .", "Our main result is that even RNNs with random weights compose powerful features ."]}
{"orig_sents": ["3", "5", "4", "1", "0", "2"], "shuf_sents": ["Parts-based object segmentations are obtained simply by performing probabilistic inference in the model .", "We combine the MSBM with an appearance model to form a fully generative model of images of objects .", "We apply the model to two challenging datasets which exhibit significant shape and appearance variability , and find that it obtains results that are comparable to the state-of-the-art .", "The Shape Boltzmann Machine ( SBM ) has recently been introduced as a stateof-the-art model of foreground/background object shape .", "Our new model , the Multinomial SBM ( MSBM ) , can capture both local and global statistics of part shapes accurately .", "We extend the SBM to account for the foreground object 's parts ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["In this contribution we introduce a set of unsupervised hierarchical probabilistic models that tackle both problems simultaneously by incorporating prior knowledge from two sources : information from other training subjects ( through transfer learning ) and information about the words being spelled ( through language models ) .", "The usability of Brain Computer Interfaces ( BCI ) based on the P300 speller is severely hindered by the need for long training times and many repetitions of the same stimulus .", "We show , that due to this prior knowledge , the performance of the unsupervised models parallels and in some cases even surpasses that of supervised models , while eliminating the tedious training session ."]}
{"orig_sents": ["2", "1", "5", "4", "3", "0"], "shuf_sents": ["We also find that when the speed of the stimulus coincides with the natural speed of the network state , the delay becomes effectively independent of the stimulus amplitude .", "To achieve real-time tracking , it is critical to compensate the transmission and processing delays in a neural system .", "Time delay is pervasive in neural information processing .", "The parameter regions for delayed , perfect and anticipative tracking correspond to network states that are static , ready-to-move and spontaneously moving , respectively , demonstrating the strong correlation between tracking performance and the intrinsic dynamics of the network .", "The state of the network can either track the instantaneous position of a moving stimulus perfectly ( with zero-lag ) or lead it with an effectively constant time , in agreement with experiments on the head-direction systems in rodents .", "In the present study we show that dynamical synapses with shortterm depression can enhance the mobility of a continuous attractor network to the extent that the system tracks time-varying stimuli in a timely manner ."]}
{"orig_sents": ["5", "2", "3", "1", "4", "0"], "shuf_sents": ["In the case of k-flats , both the results and the mathematical tools are new .", "First , we provide new results for k-means reconstruction on manifolds and , secondly , we prove reconstruction bounds for higher-order approximation ( k-flats ) , for which no known results were previously available .", "In particular , we consider piecewise constant and piecewise linear estimators induced by k-means and k-flats , and analyze their performance .", "We extend previous results for k-means in two separate directions .", "While the results for k-means are novel , some of the technical tools are well-established in the literature .", "We study the problem of estimating a manifold from random samples ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["In this paper , we derive a novel algorithm to cluster hidden Markov models ( HMMs ) according to their probability distributions .", "We illustrate the benefits of the proposed algorithm on hierarchical clustering of motion capture sequences as well as on automatic music tagging .", "We propose a variational hierarchical EM algorithm that i ) clusters a given collection of HMMs into groups of HMMs that are similar , in terms of the distributions they represent , and ii ) characterizes each group by a `` cluster center '' , i.e. , a novel HMM that is representative for the group ."]}
{"orig_sents": ["0", "5", "8", "7", "3", "2", "4", "6", "1"], "shuf_sents": ["Natural sounds exhibit complex statistical regularities at multiple scales .", "This allows us to use the second-layer representation to synthesize sounds directly , and to perform model-based denoising , on which we demonstrate a significant improvement over standard methods .", "Patterns in the positions of first layer spikes are learned from the data : on a coarse scale , statistical regularities are encoded by a second-layer spiking representation , while fine-scale structure is captured by recurrent interactions within the first layer .", "The first layer consists of a sparse spiking representation that encodes the sound using kernels positioned precisely in time and frequency .", "When fit to speech data , the second layer acoustic features include harmonic stacks , sweeps , frequency modulations , and precise temporal onsets , which can be composed to represent complex acoustic events .", "Acoustic events underlying speech , for example , are characterized by precise temporal and frequency relationships , but they can also vary substantially according to the pitch , duration , and other high-level properties of speech production .", "Unlike spectrogram-based methods , the model gives a probability distribution over sound pressure waveforms .", "Here we develop Hierarchical Spike Coding , a two-layer probabilistic generative model for complex acoustic structure .", "Learning this structure from data while capturing the inherent variability is an important first step in building auditory processing systems , as well as understanding the mechanisms of auditory perception ."]}
{"orig_sents": ["4", "2", "1", "3", "0"], "shuf_sents": ["The algorithm outperforms SVM and the recently proposed AROW algorithm on a majority of 30 NLP datasets and binarized USPS optical character recognition datasets .", "Two versions of the learning process are cast as convex optimization problems , and it is shown how to solve them efficiently .", "Our learning algorithm seeks for a box of large volume that contains `` simple '' weight vectors which most of are accurate on the training set .", "The formulation yields a natural PAC-Bayesian performance bound and it is shown to minimize a quantity directly aligned with it .", "We introduce a large-volume box classification for binary prediction , which maintains a subset of weight vectors , and specifically axis-aligned boxes ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["Our model can be thought of as a discrete analogue of the continuous fragmentation-coagulation process , preserving the important properties of projectivity , exchangeability and reversibility , while being more scalable .", "The partitions at consecutive locations in the genome are related by the splitting and merging of their clusters .", "We apply this model to the problem of genotype imputation , showing improved computational efficiency while maintaining accuracies comparable to other state-of-the-art genotype imputation methods .", "We present a Bayesian nonparametric model for genetic sequence data in which a set of genetic sequences is modelled using a Markov model of partitions ."]}
{"orig_sents": ["0", "3", "1", "2", "4"], "shuf_sents": ["In this work we study how the stimulus distribution influences the optimal coding of an individual neuron .", "We consider a variety of optimality criteria , including maximizing discriminability , maximizing mutual information and minimizing estimation error under a general Lp norm .", "We generalize the Cramer-Rao lower bound and show how the Lp loss can be written as a functional of the Fisher Information in the asymptotic limit , by proving the moment convergence of certain functions of Poisson random variables .", "Closed-form solutions to the optimal sigmoidal tuning curve are provided for a neuron obeying Poisson statistics under a given stimulus distribution .", "In this manner , we show how the optimal tuning curve depends upon the loss function , and the equivalence of maximizing mutual information with minimizing Lp loss in the limit as p goes to zero ."]}
{"orig_sents": ["2", "4", "0", "1", "3"], "shuf_sents": ["Our model incorporates structured word priors and learns a sparse product of factors .", "Experiments on research abstracts show that our model can learn latent factors such as research topic , scientific discipline , and focus ( methods vs. applications ) .", "Latent variable models can be enriched with a multi-dimensional structure to consider the many latent factors in a text corpus , such as topic , author perspective and sentiment .", "Our modeling improvements reduce test perplexity and improve human interpretability of the discovered factors .", "We introduce factorial LDA , a multi-dimensional model in which a document is influenced by K different factors , and each word token depends on a K-dimensional vector of latent variables ."]}
{"orig_sents": ["5", "6", "1", "2", "0", "3", "4"], "shuf_sents": ["Within our new framework we derive both batch and incremental proximal splitting algorithms .", "This class includes the extensively studied class of convex composite objective problems as a subclass .", "To solve composite nonconvex problems we introduce a powerful new framework based on asymptotically nonvanishing errors , avoiding the common stronger assumption of vanishing errors .", "To our knowledge , our work is first to develop and analyze incremental nonconvex proximalsplitting algorithms , even if we were to disregard the ability to handle nonvanishing errors .", "We illustrate one instance of our general framework by showing an application to large-scale nonsmooth matrix factorization .", "We study a class of large-scale , nonsmooth , and nonconvex optimization problems .", "In particular , we focus on nonconvex problems with composite objectives ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["We introduce a new prior for use in Nonparametric Bayesian Hierarchical Clustering .", "The prior is constructed by marginalizing out the time information of Kingman 's coalescent , providing a prior over tree structures which we call the Time-Marginalized Coalescent ( TMC ) .", "This allows for models which factorize the tree structure and times , providing two benefits : more flexible priors may be constructed and more efficient Gibbs type inference can be used .", "We demonstrate this on an example model for density estimation and show the TMC achieves competitive experimental results ."]}
{"orig_sents": ["2", "6", "5", "3", "1", "4", "0"], "shuf_sents": ["Moreover , our learning approach can easily adapt to novel sensor data such as Kinect-style RGB-D cameras : Sparse Code Gradients on depth maps and surface normals lead to promising contour detection using depth and depth+color , as verified on the NYU Depth Dataset .", "By extracting rich representations from pixels and avoiding collapsing them prematurely , Sparse Code Gradients effectively learn how to measure local contrasts and find contours .", "Finding contours in natural images is a fundamental problem that serves as the basis of many tasks such as image segmentation and object recognition .", "We use K-SVD for dictionary learning and Orthogonal Matching Pursuit for computing sparse codes on oriented local neighborhoods , and apply multi-scale pooling and power transforms before classifying them with linear SVMs .", "We improve the F-measure metric on the BSDS500 benchmark to 0.74 ( up from 0.71 of gPb contours ) .", "In this work , we show that contour detection accuracy can be significantly improved by computing Sparse Code Gradients ( SCG ) , which measure contrast using patch representations automatically learned through sparse coding .", "At the core of contour detection technologies are a set of hand-designed gradient features , used by most approaches including the state-of-the-art Global Pb ( gPb ) operator ."]}
{"orig_sents": ["5", "1", "3", "2", "6", "4", "0"], "shuf_sents": ["The coupling of the text and legislation is also shown to yield insight into the properties of the matrix decomposition for roll-call data .", "The documents are modeled with a focused topic model , inferring interpretable latent binary features for each document .", "The matrix decomposition and topic model are coupled by sharing the latent binary feature vectors associated with each .", "A new matrix decomposition is developed , with latent binary features associated with the rows/columns , and with imposition of a low-rank constraint .", "Advantages of the proposed model are demonstrated for prediction of votes on a new piece of legislation , based only on the observed text of legislation .", "A new methodology is developed for joint analysis of a matrix and accompanying documents , with the documents associated with the matrix rows/columns .", "The model is applied to roll-call data , with the associated documents defined by the legislation ."]}
{"orig_sents": ["3", "1", "0", "4", "2"], "shuf_sents": ["We generalize the concept of proper loss to this scenario , we establish a necessary and sufficient condition for a loss function to be proper , and we show a direct procedure to construct a proper loss for partial labels from a conventional proper loss .", "Each instance is assumed to be labelled as belonging to one of several candidate categories , at most one of them being true .", "The full knowledge of this matrix is not required , and losses can be constructed that are proper for a wide set of mixing probability matrices .", "This paper discusses the problem of calibrating posterior class probabilities from partially labelled data .", "The problem can be characterized by the mixing probability matrix relating the true class of the data and the observed labels ."]}
{"orig_sents": ["4", "1", "5", "3", "0", "2"], "shuf_sents": ["This multi-to-multi association distinguishes the proposed method from previous ones that require the model structure to be a tree or a chain , allowing more flexible designs .", "In this paper , we develop a new method that jointly estimates mixture models over multiple data sets by exploiting the statistical dependencies between them .", "We also derive a sampling algorithm that jointly infers the model parameters and present experiments on both document analysis and image modeling .", "Each mixture model may acquire atoms from different latent DPs , while each atom may be shared by multiple mixtures .", "Mixture distributions are often used to model complex data .", "Specifically , we introduce a set of latent Dirichlet processes as sources of component models ( atoms ) , and for each data set , we construct a nonparametric mixture model by combining sub-sampled versions of the latent DPs ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["In such cases the decision process must be transparent and comprehensible , simultaneously requiring minimal assumptions on the underlying data distributions .", "We develop a regression-based approach called RECIP that efficiently solves this problem by finding projections that minimize a nonparametric conditional entropy estimator .", "To tackle this problem , we formulate an axis-aligned subspace-finding task under the assumption that query specific information dictates the complementary use of the subspaces .", "Experiments show that the method is accurate in identifying the informative projections of the dataset , picking the correct views to classify query points , and facilitates visual evaluation by users .", "In many applications , classification systems often require human intervention in the loop ."]}
{"orig_sents": ["0", "8", "10", "11", "3", "6", "4", "2", "13", "7", "5", "12", "1", "9"], "shuf_sents": ["A weighted graph is used as an underlying structure of many algorithms like semisupervised learning and spectral clustering .", "We demonstrate the advantages of the proposed approach on the task of visual tracking , where different aspects of the appearance similarity between the target object in frame t - 1 and target object candidates in frame t are integrated .", "However , a higher order graph like the TPG usually means significant increase in time complexity .", "First pairs of similarity measures are combined with a diffusion process on their tensor product graph ( TPG ) .", "We call this process Fusion with Diffusion ( FD ) .", "Moreover , it is not necessary to explicitly construct the TPG in our framework .", "Hence the diffused similarity of each pair of objects becomes a function of joint diffusion of the two original similarities , which in turn depends on the neighborhood structure of the TPG .", "A key feature of our approach is that the time complexity of the diffusion on the TPG is the same as the diffusion process on each of the original graphs .", "If the edge weights are determined by a single similarity measure , then it hard if not impossible to capture all relevant aspects of similarity when using a single similarity measure .", "The obtained method is tested on several challenge video sequences and the experimental results show that it outperforms state-of-the-art tracking methods .", "In particular , in the case of visual object matching it is beneficial to integrate different similarity measures that focus on different visual representations .", "In this paper , a novel approach to integrate multiple similarity measures is proposed .", "Finally all diffused pairs of similarity measures are combined as a weighted sum .", "This is not the case in the proposed approach ."]}
{"orig_sents": ["5", "1", "0", "2", "4", "3"], "shuf_sents": ["In this paper , we study hash function learning in the context of multimodal data .", "To obtain compact hash codes , a recent trend seeks to learn the hash functions from data automatically .", "We propose a novel multimodal hash function learning method , called Co-Regularized Hashing ( CRH ) , based on a boosted coregularization framework .", "We empirically compare CRH with two state-of-the-art multimodal hash function learning methods on two publicly available data sets .", "The hash functions for each bit of the hash codes are learned by solving DC ( difference of convex functions ) programs , while the learning for multiple bits proceeds via a boosting procedure so that the bias introduced by the hash functions can be sequentially minimized .", "Hashing-based methods provide a very promising approach to large-scale similarity search ."]}
{"orig_sents": ["6", "1", "2", "3", "4", "0", "5"], "shuf_sents": ["The intractable inference and learning problems are addressed by leveraging an efficient Max-Path search method , thus making it feasible to optimize the model over the whole structured space .", "Its extension to action localization in videos , however , is much more challenging , because we need to predict the locations of the action patterns both spatially and temporally , i.e. , identifying a sequence of bounding boxes that track the action in video .", "The problem becomes intractable due to the exponentially large size of the structured video space where actions could occur .", "We propose a novel structured learning approach for spatio-temporal action localization .", "The mapping between a video and a spatio-temporal action trajectory is learned .", "Experiments on two challenging benchmark datasets show that our proposed method outperforms the state-of-the-art methods .", "Structured output learning has been successfully applied to object localization , where the mapping between an image and an object bounding box can be well captured ."]}
{"orig_sents": ["0", "3", "5", "1", "4", "2"], "shuf_sents": ["Learning the number of clusters is a key problem in data clustering .", "The proposed algorithm considers each cluster member as an individual `viewer ' and applies a univariate statistic hypothesis test for unimodality ( dip-test ) on the distribution of distances between the viewer and the cluster members .", "Experimental results on artificial and real datasets indicate the effectiveness of our method and its superiority over analogous approaches .", "We present dip-means , a novel robust incremental method to learn the number of data clusters that can be used as a wrapper around any iterative clustering algorithm of k-means family .", "Important advantages are : i ) the unimodality test is applied on univariate distance vectors , ii ) it can be directly applied with kernel-based methods , since only the pairwise distances are involved in the computations .", "In contrast to many popular methods which make assumptions about the underlying cluster distributions , dip-means only assumes a fundamental cluster property : each cluster to admit a unimodal distribution ."]}
{"orig_sents": ["3", "4", "0", "6", "1", "2", "5", "7"], "shuf_sents": ["As the clinical questions of interest move towards identifying very early signs of diseases , the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify .", "In contrast to hypothesis tests on point-wise measurements , in this paper , we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex .", "Our descriptors are based on recent results from harmonic analysis , that show how wavelet theory extends to non-Euclidean settings ( i.e. , irregular weighted graphs ) .", "Hypothesis testing on signals defined on surfaces ( such as the cortical surface ) is a fundamental component of a variety of studies in Neuroscience .", "The goal here is to identify regions that exhibit changes as a function of the clinical condition under study .", "We provide strong evidence that these descriptors successfully pick up group-wise differences , where traditional methods either fail or yield unsatisfactory results .", "Indeed , after a multiple comparisons correction is adopted ( to account for correlated statistical tests over all surface points ) , very few regions may survive .", "Other than this primary application , we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["Although many variants of stochastic gradient descent have been proposed for large-scale convex optimization , most of them require projecting the solution at each iteration to ensure that the obtained solution stays within the feasible domain .", "Instead , only one projection at the last iteration is needed to obtain a feasible solution in the given domain .", "For complex domains ( e.g. , positive semidefinite cone ) , the projection step can be computationally expensive , making stochastic gradient descent unattractive for large-scale optimization problems .", "Our theoretical analysis shows that with a high probability , the proposed algorithms achieve an O ( 1/ T ) convergence rate for general convex optimization , and an O ( ln T /T ) rate for strongly convex optimization under mild conditions about the domain and the objective function .", "We address this limitation by developing novel stochastic optimization algorithms that do not need intermediate projections ."]}
{"orig_sents": ["4", "0", "5", "2", "1", "3"], "shuf_sents": ["Kernel density plug-in estimators are simple , easy to implement and widely used for estimation of entropy .", "Furthermore , it is shown that these optimal weights can be determined by solving a convex optimization problem which does not require training data or knowledge of the underlying density , and therefore can be performed offline .", "In this paper , it is shown that for sufficiently smooth densities , an ensemble of kernel plug-in estimators can be combined via a weighted convex combination , such that the resulting weighted estimator has a superior parametric MSE rate of convergence of order O ( T -1 ) .", "This novel result is remarkable in that , while each of the individual kernel plug-in estimators belonging to the ensemble suffer from the curse of dimensionality , by appropriate ensemble averaging we can achieve parametric convergence rates .", "The problem of estimation of entropy functionals of probability densities has received much attention in the information theory , machine learning and statistics communities .", "However , for large feature dimension d , kernel plug-in estimators suffer from the curse of dimensionality : the MSE rate of convergence is glacially slow - of order O ( T -/d ) , where T is the number of samples , and > 0 is a rate parameter ."]}
{"orig_sents": ["8", "0", "2", "6", "5", "3", "1", "4", "7"], "shuf_sents": ["This demand has led to feature descriptors of ever increasing dimensionality like co-occurrence statistics and self-similarity .", "Consequently , there is a natural need for feature selection when using present-day informative features and , particularly , curvature self-similarity .", "In this paper we propose a new object representation based on curvature self-similarity that goes beyond the currently popular approximation of objects using straight lines .", "Given only a limited amount of training data , even sophisticated learning algorithms such as the popular kernel methods are not able to suppress noisy or superfluous dimensions of such high-dimensional data .", "We therefore suggest an embedded feature selection method for SVMs that reduces complexity and improves generalization capability of object models .", "Although improving discriminability , the high dimensionality becomes a critical issue due to lack of generalization ability and curse of dimensionality .", "However , like all descriptors using second order statistics , ours also exhibits a high dimensionality .", "By successfully integrating the proposed curvature self-similarity representation together with the embedded feature selection in a widely used state-of-the-art object detection framework we show the general pertinence of the approach .", "Category-level object detection has a crucial need for informative object representations ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["Using Value and Policy Iteration with some error at each iteration , it is well-known that one 2 can compute stationary policies that are ( 1- ) 2 -optimal .", "Surprisingly , this shows that the problem of `` computing near-optimal non-stationary policies '' is much simpler than that of `` computing near-optimal stationary policies '' .", "We consider infinite-horizon stationary -discounted Markov Decision Processes , for which it is known that there exists a stationary optimal policy .", "After arguing that this guarantee is tight , we develop variations of Value and Policy Iteration for com2 -optimal , which constitutes a puting non-stationary policies that can be up to 1- significant improvement in the usual situation when is close to 1 ."]}
{"orig_sents": ["5", "4", "2", "3", "0", "6", "1"], "shuf_sents": ["We develop a graph learning algorithm by solving a convex optimization problem and further develop an efficient optimization to obtain global optimal solutions with theoretical guarantees .", "As a preprocessing of graphs , our method has a wide range of potential applications machine learning and data mining .", "In this paper , we proposed a robust approach with convex optimization to `` forge '' a graph : with an input of a graph , to learn a graph with higher quality .", "Our major concern is that an ideal graph shall satisfy all the following constraints : non-negative , symmetric , low rank , and positive semidefinite .", "However , in real-world applications , especially in semisupervised learning and unsupervised learning , the evaluation of the quality of a graph is often expensive and sometimes even impossible , due the cost or the unavailability of ground truth .", "In many graph-based machine learning and data mining approaches , the quality of the graph is critical .", "With only one non-sensitive parameter , our method is shown by experimental results to be robust and achieve higher accuracy in semi-supervised learning and clustering under various settings ."]}
{"orig_sents": ["4", "0", "2", "3", "1"], "shuf_sents": ["The presented method factorizes any multivariate density into a product of marginal distributions and bivariate copula functions .", "Experimental results on regression problems with real-world data illustrate the efficacy of the proposed approach when compared to state-of-the-art techniques .", "Therefore , changes in each of these factors can be detected and corrected to adapt a density model accross different learning domains .", "Importantly , we introduce a novel vine copula model , which allows for this factorization in a non-parametric manner .", "A new framework based on the theory of copulas is proposed to address semisupervised domain adaptation problems ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["We extend BEETLE , a model-based BRL method , for learning in the environment with cost constraints .", "In order to formalize cost-sensitive exploration , we use the constrained Markov decision process ( CMDP ) as the model of the environment , in which we can naturally encode exploration requirements using the cost function .", "In this paper , we consider Bayesian reinforcement learning ( BRL ) where actions incur costs in addition to rewards , and thus exploration has to be constrained in terms of the expected total cost while learning to maximize the expected longterm total reward .", "We demonstrate the cost-sensitive exploration behaviour in a number of simulated problems ."]}
{"orig_sents": ["2", "1", "3", "8", "5", "6", "7", "0", "4"], "shuf_sents": ["Decision making in the model reduces to ( 1 ) computing beliefs given observations and prior information in a Bayesian manner , and ( 2 ) selecting actions based on these beliefs to maximize the expected sum of future rewards .", "Two competing descriptive models have been proposed based on experimental data .", "How does the brain combine prior knowledge with sensory evidence when making decisions under uncertainty ?", "The first posits an additive offset to a decision variable , implying a static effect of the prior .", "We show that the model can explain both data previously explained using the additive offset model as well as more recent data on the time-varying influence of prior knowledge on decision making .", "To explain this data , a second model has been proposed which assumes a time-varying influence of the prior .", "Here we present a normative model of decision making that incorporates prior knowledge in a principled way .", "We show that the additive offset model and the time-varying prior model emerge naturally when decision making is viewed within the framework of partially observable Markov decision processes ( POMDPs ) .", "However , this model is inconsistent with recent data from a motion discrimination task involving temporal integration of uncertain sensory evidence ."]}
{"orig_sents": ["1", "3", "0", "2", "4"], "shuf_sents": ["The agent 's goal is to elicit a latent target policy from the expert with as few queries as possible .", "We consider the problem of learning control policies via trajectory preference queries to an expert .", "To tackle this problem we propose a novel Bayesian model of the querying process and introduce two methods that exploit this model to actively select expert queries .", "In particular , the agent presents an expert with short runs of a pair of policies originating from the same state and the expert indicates which trajectory is preferred .", "Experimental results on four benchmark problems indicate that our model can effectively learn policies from trajectory preference queries and that active query selection can be substantially more efficient than random selection ."]}
{"orig_sents": ["0", "3", "1", "4", "2", "6", "5"], "shuf_sents": ["We introduce a new discrepancy score between two distributions that gives an indication on their similarity .", "The new score gives an intuitive interpretation of similarity ; it optimally perturbs the distributions so that they best fit each other .", "We provide convergence bounds of the estimated score , and develop hypothesis testing procedures that test if two data sets come from similar distributions .", "While much research has been done to determine if two samples come from exactly the same distribution , much less research considered the problem of determining if two finite samples come from similar distributions .", "The score is defined between distributions , and can be efficiently estimated from samples .", "We also compare the score 's capacity to detect similarity with that of other known measures on real data .", "The statistical power of this procedures is presented in simulations ."]}
{"orig_sents": ["9", "8", "7", "6", "0", "4", "2", "11", "5", "10", "3", "1"], "shuf_sents": ["We argue that vector fields provide a natural way to exploit the geometric structure of data as well as the shared differential structure of tasks , both of which are crucial for semi-supervised multi-task learning .", "The experimental results on synthetic and real data demonstrate the effectiveness of our proposed approach .", "MTVFL has the following key properties .", "We formalize our idea in a regularization framework and also provide a convex relaxation method to solve the original non-convex problem .", "In this paper , we develop multi-task vector field learning ( MTVFL ) which learns the predictor functions and the vector fields simultaneously .", "( 2 ) Within each task , the vector field is required to be as parallel as possible which is expected to span a low dimensional subspace .", "A vector field is a smooth mapping from the manifold to the tangent spaces which can be viewed as a directional derivative of functions on the manifold .", "We propose a novel semi-supervised and nonlinear approach for MTL using vector fields .", "Most of existing MTL methods focus on learning linear models under the supervised setting .", "Multi-task learning ( MTL ) aims to improve generalization performance by learning multiple related tasks simultaneously and identifying the shared information among tasks .", "( 3 ) The vector fields from all tasks share a low dimensional subspace .", "( 1 ) The vector fields MTVFL learns are close to the gradient fields of the predictor functions ."]}
{"orig_sents": ["3", "1", "2", "5", "4", "0"], "shuf_sents": ["We show strong retrieval performance on CIFAR-10 and MNIST , with promising classification results using no more than kNN on the binary codes .", "Binary codes are well suited to large-scale applications as they are storage efficient and permit exact sub-linear kNN search .", "The framework is applicable to broad families of mappings , and uses a flexible form of triplet ranking loss .", "Motivated by large-scale multimedia applications we propose to learn mappings from high-dimensional data to binary codes that preserve semantic similarity .", "We develop a new loss-augmented inference algorithm that is quadratic in the code length .", "We overcome discontinuous optimization of the discrete mappings by minimizing a piecewise-smooth upper bound on empirical loss , inspired by latent structural SVMs ."]}
{"orig_sents": ["7", "5", "0", "4", "2", "3", "1", "6"], "shuf_sents": ["The semiparametric model assumes that , after unspecified marginally monotone transformations , the distributions are multivariate Gaussian .", "Careful numerical experiments on the synthetic and real data are conducted to back up the theoretical results .", "The robust nonparametric rank-based correlation coefficient estimator , Spearman 's rho , is exploited in estimation .", "We prove that , under suitable conditions , although the marginal distributions can be arbitrarily continuous , the COCA and Copula PCA estimators obtain fast estimation rates and are feature selection consistent in the setting where the dimension is nearly exponentially large relative to the sample size .", "The COCA and Copula PCA accordingly estimate the leading eigenvectors of the correlation and covariance matrices of the latent Gaussian distribution .", "The according methods are named Copula Component Analysis ( COCA ) and Copula PCA .", "We also discuss the relationship with the transelliptical component analysis proposed by Han and Liu ( 2012 ) .", "We propose two new principal component analysis methods in this paper utilizing a semiparametric model ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["In particularly , we focus on the nonparanormal graphical model and provide theoretical guarantees for graph estimation consistency .", "We introduce a new learning algorithm , named smooth-projected neighborhood pursuit , for estimating high dimensional undirected graphs .", "In addition to new computational and theoretical analysis , we also provide an alternative view to analyze the tradeoff between computational efficiency and statistical error under a smoothing optimization framework .", "Numerical results on both synthetic and real datasets are provided to support our theory ."]}
{"orig_sents": ["1", "0", "4", "5", "3", "2"], "shuf_sents": ["While being common for settings like conventional classification , abstention has been studied much less in learning to rank .", "Several machine learning methods allow for abstaining from uncertain predictions .", "These theoretical results are complemented by experiments demonstrating the practical usefulness of the approach .", "We formally analyze this approach for the Mallows and the Plackett-Luce model , showing that it produces proper partial orders as predictions and characterizing the expressiveness of the induced class of partial orders .", "We address abstention for the label ranking setting , allowing the learner to declare certain pairs of labels as being incomparable and , thus , to predict partial instead of total orders .", "In our method , such predictions are produced via thresholding the probabilities of pairwise preferences between labels , as induced by a predicted probability distribution on the set of all rankings ."]}
{"orig_sents": ["0", "2", "8", "6", "5", "1", "9", "4", "7", "3"], "shuf_sents": ["Multi-Agent Plan Recognition ( MAPR ) aims to recognize dynamic team structures and team behaviors from the observed team traces ( activity sequences ) of a set of intelligent agents .", "Such models are often already created to describe domain physics ; i.e. , the preconditions and effects of effects actions .", "Previous MAPR approaches required a library of team activity sequences ( team plans ) be given as input .", "Our empirical studies demonstrate that our algorithm is both effective and efficient in comparison to state-of-the-art MAPR methods based on plan libraries .", "We encode the resulting MAPR problem as a satisfiability problem and solve the problem using a state-of-the-art weighted MAX-SAT solver .", "We assume instead that a set of action models are available .", "In this paper , we relax this constraint , so that team plans are not required to be provided beforehand .", "Our approach also allows for incompleteness in the observed plan traces .", "However , collecting a library of team plans to ensure adequate coverage is often difficult and costly .", "We propose a novel approach for recognizing multi-agent team plans based on such action models rather than libraries of team plans ."]}
{"orig_sents": ["9", "2", "8", "5", "0", "6", "7", "3", "1", "4"], "shuf_sents": ["The model has memory units which learn useful internal state representations to solve working memory tasks by transforming partially observable Markov decision problems ( POMDP ) into MDPs .", "The learning scheme is generic because it can train networks in different tasks , simply by varying inputs and rewards .", "Neurons in association cortex play an important role in this process : by learning these neurons become tuned to relevant features and represent the information that is required later as a persistent elevation of their activity .", "The neuromodulatory signal interacts with tagged synapses to determine the sign and strength of plasticity .", "It explains how neurons in association cortex learn to 1 ) temporarily store task-relevant information in non-linear stimulus-response mapping tasks and 2 ) learn to optimally integrate probabilistic evidence for perceptual decision making .", "Here we introduce a biologically plausible learning scheme grounded in Reinforcement Learning ( RL ) theory that explains how neurons become selective for relevant information by trial and error learning .", "We propose that synaptic plasticity is guided by a combination of attentional feedback signals from the action selection stage to earlier processing levels and a globally released neuromodulatory signal .", "Feedback signals interact with feedforward signals to form synaptic tags at those connections that are responsible for the stimulus-response mapping .", "It is however not well known how such neurons acquire these task-relevant working memories .", "A key function of brains is undoubtedly the abstraction and maintenance of information from the environment for later use ."]}
{"orig_sents": ["4", "5", "0", "3", "1", "2"], "shuf_sents": ["We use an online approximate inference scheme that can be mapped to the dynamics of networks of neurons .", "Most model neurons also show speed tuning and respond equally well to a range of motion directions and speeds aligned to the constraint line of their respective preferred speed .", "We show how these computations are enabled by a specific pattern of recurrent connections learned by the model .", "Probed with drifting grating stimuli and moving bars of light , neurons in the model show patterns of responses analogous to those of direction-selective simple cells in primary visual cortex .", "We present a dynamic nonlinear generative model for visual motion based on a latent representation of binary-gated Gaussian variables .", "Trained on sequences of images , the model learns to represent different movement directions in different variables ."]}
{"orig_sents": ["3", "0", "1", "2", "4"], "shuf_sents": ["Although they have brought much progress in practical applications of RL , there still remains an unsolved problem in DPS related to model selection for the policy .", "In this paper , we propose a novel DPS method , weighted likelihood policy search ( WLPS ) , where a policy is efficiently learned through the weighted likelihood estimation .", "WLPS naturally connects DPS to the statistical inference problem and thus various sophisticated techniques in statistics can be applied to DPS problems directly .", "Reinforcement learning ( RL ) methods based on direct policy search ( DPS ) have been actively discussed to achieve an efficient approach to complicated Markov decision processes ( MDPs ) .", "Hence , by following the idea of the information criterion , we develop a new measurement for model comparison in DPS based on the weighted log-likelihood ."]}
{"orig_sents": ["5", "6", "3", "1", "0", "2", "4"], "shuf_sents": ["We also extend the theoretical results of Short-Sighted Probabilistic Planner ( SSiPP ) by proving that SSiPP always finishes and is asymptotically optimal under sufficient conditions on the structure of short-sighted SSPs .", "In this paper , we introduce trajectory-based short-sighted Stochastic Shortest Path Problems ( SSPs ) , a novel approach to manage uncertainty for probabilistic planning problems in which states reachable with low probability are substituted by artificial goals that heuristically estimate their cost to reach a goal state .", "We empirically compare SSiPP using trajectorybased short-sighted SSPs with the winners of the previous probabilistic planning competitions and other state-of-the-art planners in the triangle tireworld problems .", "Several approaches to manage uncertainty were proposed , e.g. , consider all paths at once , perform determinization of actions , and sampling .", "Trajectory-based SSiPP outperforms all the competitors and is the only planner able to scale up to problem number 60 , a problem in which the optimal solution contains approximately 1070 states .", "Probabilistic planning captures the uncertainty of plan execution by probabilistically modeling the effects of actions in the environment , and therefore the probability of reaching different states from a given state and action .", "In order to compute a solution for a probabilistic planning problem , planners need to manage the uncertainty associated with the different paths from the initial state to a goal state ."]}
{"orig_sents": ["2", "1", "0", "3", "4"], "shuf_sents": ["Our main contribution is to show that this intractability can be avoided as long as the constrained features possess a certain kind of low dimensional structure .", "We consider the problem of applying MaxEnt to distributions over paths in continuous spaces of high dimensionality -- a problem for which inference is generally intractable .", "Maximum entropy ( MaxEnt ) modeling is a popular choice for sequence analysis in applications such as natural language processing , where the sequences are embedded in discrete , tractably-sized spaces .", "In this case , we show that the associated partition function is symmetric and that this symmetry can be exploited to compute the partition function efficiently in a compressed form .", "Empirical results are given showing an application of our method to learning models of high-dimensional human motion capture data ."]}
{"orig_sents": ["7", "3", "6", "2", "4", "0", "5", "1"], "shuf_sents": ["We constrain the metric matrix function by imposing on the linear combinations manifold regularization which makes the learned metric matrix function vary smoothly along the geodesics of the data manifold .", "We experimented with several largescale classification problems , tens of thousands of instances , and compared it with several state of the art metric learning methods , both global and local , as well as to SVM with automatic kernel selection , all of which it outperforms in a significant manner .", "We present a new parametric local metric learning method in which we learn a smooth metric matrix function over the data manifold .", "Most previous works on local metric learning learn a number of local unrelated metrics .", "Using an approximation error bound of the metric matrix function we learn local metrics as linear combinations of basis metrics defined on anchor points over different regions of the instance space .", "Our metric learning method has excellent performance both in terms of predictive power and scalability .", "While this `` independence '' approach delivers an increased flexibility its downside is the considerable risk of overfitting .", "We study the problem of learning local metrics for nearest neighbor classification ."]}
{"orig_sents": ["0", "5", "3", "1", "4", "8", "7", "2", "6"], "shuf_sents": ["Linear chains and trees are basic building blocks in many applications of graphical models , and they admit simple exact maximum a-posteriori ( MAP ) inference algorithms based on message passing .", "For this reason there has been significant previous interest in beam search and its variants ; however , these methods provide only approximate results .", "Our algorithm is also extendable to new techniques for approximate inference , to faster 0/1 loss oracles , and new opportunities for connections between inference and learning .", "The standard algorithms are inefficient because they compute scores for hypotheses for which there is strong negative local evidence .", "This paper presents new exact inference algorithms based on the combination of column generation and pre-computed bounds on terms of the model 's scoring function .", "However , in many cases this computation is prohibitively expensive , due to quadratic dependence on variables ' domain sizes .", "We encourage further exploration of high-level reasoning about the optimization problem implicit in dynamic programs .", "Experiments show our method to be twice as fast as exact Viterbi for Wall Street Journal part-of-speech tagging and over thirteen times faster for a joint part-of-speed and named-entity-recognition task .", "While we do not improve worst-case performance , our method substantially speeds real-world , typical-case inference in chains and trees ."]}
{"orig_sents": ["0", "1", "2", "3"], "shuf_sents": ["We consider the problem of actively learning multi-index functions of the form k f ( x ) = g ( Ax ) = i=1 gi ( aTi x ) from point evaluations of f .", "We assume that the function f is defined on an 2 -ball in Rd , g is twice continuously differentiable almost everywhere , and A Rkxd is a rank k matrix , where k d. We propose a randomized , active sampling scheme for estimating such functions with uniform approximation guarantees .", "Our theoretical developments leverage recent techniques from low rank matrix recovery , which enables us to derive an estimator of the function f along with sample complexity bounds .", "We also characterize the noise robustness of the scheme , and provide empirical evidence that the highdimensional scaling of our sample complexity bounds are quite accurate ."]}
{"orig_sents": ["2", "3", "1", "4", "0"], "shuf_sents": ["We test the effectiveness of our upper-confidence scheme by contrasting against full-information baselines on real-world multilabel datasets , often obtaining comparable performance .", "We analyze this algorithm in a partial adversarial setting , where covariates can be adversarial , but multilabel probabilities are ruled by ( generalized ) linear models .", "We present a novel multilabel/ranking algorithm working in partial information settings .", "The algorithm is based on 2nd-order descent methods , and relies on upper-confidence bounds to trade-off exploration and exploitation .", "We show O ( T 1/2 log T ) regret bounds , which improve in several ways on the existing results ."]}
{"orig_sents": ["1", "6", "2", "0", "3", "5", "4"], "shuf_sents": ["Just as the nonparanormal extends the normal by transforming the variables using univariate functions , the transelliptical extends the elliptical family in the same way .", "We advocate the use of a new distribution family -- the transelliptical -- for robust inference of high dimensional graphical models .", "( 2009 ) .", "We propose a nonparametric rank-based regularization estimator which achieves the parametric rates of convergence for both graph recovery and parameter estimation .", "We also discuss the relationship between this work with the transelliptical component analysis proposed by Han and Liu ( 2012 ) .", "Such a result suggests that the extra robustness and flexibility obtained by the semiparametric transelliptical modeling incurs almost no efficiency loss .", "The transelliptical family is an extension of the nonparanormal family proposed by Liu et al ."]}
{"orig_sents": ["5", "4", "6", "2", "3", "1", "0"], "shuf_sents": ["Simulation results are presented to compare our proposal with previous ones .", "This provides a unified analysis of the noisy and noiseless matrix completion problems .", "A calibration step follows to correct the bias caused by the Frobenius penalty .", "Under proper coherence conditions and for suitable penalties levels , we prove that the proposed estimator achieves an error bound of nearly optimal order and in proportion to the noise level .", "We propose a calibrated spectrum elastic net method with a sum of the nuclear and Frobenius penalties and develop an iterative algorithm to solve the convex minimization problem .", "This paper concerns the problem of matrix completion , which is to estimate a matrix from observations in a small subset of indices .", "The iterative algorithm alternates between imputing the missing entries in the incomplete matrix by the current guess and estimating the matrix by a scaled soft-thresholding singular value decomposition of the imputed matrix until the resulting matrix converges ."]}
{"orig_sents": ["2", "4", "5", "3", "1", "0"], "shuf_sents": ["We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3 % , compared to 26.2 % achieved by the second-best entry .", "To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called `` dropout '' that proved to be very effective .", "We trained a large , deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes .", "To make training faster , we used non-saturating neurons and a very efficient GPU implementation of the convolution operation .", "On the test data , we achieved top-1 and top-5 error rates of 37.5 % and 17.0 % which is considerably better than the previous state-of-the-art .", "The neural network , which has 60 million parameters and 650,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully-connected layers with a final 1000-way softmax ."]}
{"orig_sents": ["4", "2", "5", "6", "0", "1", "3"], "shuf_sents": ["Our analyses of SMMs provides several insights into their relationship to traditional SVMs .", "Based on such insights , we propose a flexible SVM ( FlexSVM ) that places different kernel functions on each training example .", "Rather than relying on large collections of vectorial training examples , our framework learns using a collection of probability distributions that have been constructed to meaningfully represent training data .", "Experimental results on both synthetic and real-world data demonstrate the effectiveness of our proposed framework .", "This paper presents a kernel-based discriminative learning framework on probability measures .", "By representing these probability distributions as mean embeddings in the reproducing kernel Hilbert space ( RKHS ) , we are able to apply many standard kernel-based learning techniques in straightforward fashion .", "To accomplish this , we construct a generalization of the support vector machine ( SVM ) called a support measure machine ( SMM ) ."]}
{"orig_sents": ["0", "5", "3", "2", "4", "1"], "shuf_sents": ["The National Epidemiologic Survey on Alcohol and Related Conditions ( NESARC ) database contains a large amount of information , regarding the way of life , medical conditions , etc. , of a representative sample of the U.S. population .", "Finally , the experiments over the NESARC database show that our model properly captures some of the hidden causes that model suicide attempts .", "We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix .", "Due to the nature of the data , we need to adapt the observation model for discrete random variables .", "The implementation of an efficient Gibbs sampler is accomplished using the Laplace approximation , which allows integrating out the weighting factors of the multinomial-logit likelihood model .", "In this paper , we are interested in seeking the hidden causes behind the suicide attempts , for which we propose to model the subjects using a nonparametric latent model based on the Indian Buffet Process ( IBP ) ."]}
{"orig_sents": ["6", "0", "3", "7", "2", "5", "1", "4"], "shuf_sents": ["This phenomenon was discovered more than 30 years ago but the canonical view of only a small number of categories has been validated experimentally .", "We also present a simple method to find the most likely view in an image collection and apply it to hundreds of categories .", "We start by manually finding the most common view in the results returned by Internet search engines when queried with the objects used in psychophysical experiments .", "Moreover , the explanation for why humans prefer the canonical view over other views remains elusive .", "Using the new data we have collected we present strong evidence against the two most prominent formal theories of canonical views and provide novel constraints for new theories .", "Our results clearly show that the most likely view in the search engine corresponds to the same view preferred by human subjects in experiments .", "Although human object recognition is supposedly robust to viewpoint , much research on human perception indicates that there is a preferred or `` canonical '' view of objects .", "In this paper we ask : Can we use Internet image collections to learn more about canonical views ?"]}
{"orig_sents": ["6", "3", "2", "5", "4", "1", "0"], "shuf_sents": ["Both theories and experiments confirm that TCA can achieve model flexibility , estimation accuracy and robustness at almost no cost .", "TCA is further implemented in both numerical simulations and largescale stock data to illustrate its empirical usefulness .", "In this paper we extend the meta-elliptical distribution family to a even larger family , called transelliptical .", "Elliptical distribution family includes many well-known multivariate distributions like multivariate Gaussian , t and logistic and it is extended to the meta-elliptical by Fang et.al ( 2002 ) using the copula techniques .", "A feature selection result with explicit rate is also provided .", "We prove that TCA can obtain a near-optimal s log d/n estimation consistency rate in recovering the leading eigenvector of the latent generalized correlation matrix under the transelliptical distribution family , even if the distributions are very heavy-tailed , have infinite second moments , do not have densities and possess arbitrarily continuous marginal distributions .", "We propose a high dimensional semiparametric scale-invariant principle component analysis , named TCA , by utilize the natural connection between the elliptical distribution family and the principal component analysis ."]}
{"orig_sents": ["3", "4", "2", "0", "1"], "shuf_sents": ["Our novel method is highly efficient , with only seventeen parameters to optimize and a single hyperparameter to tune , and beats the state-of-the-art collaborative ranking methods .", "We also show that parameters learned on datasets from one item domain yield excellent results on a dataset from very different item domain , without any retraining .", "In this work we present a method for collaborative ranking that leverages the strengths of the two main CF approaches , neighborhood- and model-based .", "The primary application of collaborate filtering ( CF ) is to recommend a small set of items to a user , which entails ranking .", "Most approaches , however , formulate the CF problem as rating prediction , overlooking the ranking perspective ."]}
{"orig_sents": ["4", "0", "2", "3", "1"], "shuf_sents": ["The inherently graph-like , non-vectorial nature of molecular data gives rise to a unique and difficult machine learning problem .", "Our results improve the state-of-the-art by a factor of almost three , bringing statistical methods one step closer to chemical accuracy .", "In this paper , we adopt a learning-from-scratch approach where quantum-mechanical molecular energies are predicted directly from the raw molecular geometry .", "The study suggests a benefit from setting flexible priors and enforcing invariance stochastically rather than structurally .", "The accurate prediction of molecular energetics in chemical compound space is a crucial ingredient for rational compound design ."]}
{"orig_sents": ["2", "0", "3", "1", "5", "4", "6"], "shuf_sents": ["The similarity of such feature vectors is commonly measured using the cosine of the angle between them .", "In its most basic form , AQBC works by mapping each non-negative feature vector onto the vertex of the binary hypercube with which it has the smallest angle .", "This paper focuses on the problem of learning binary codes for efficient retrieval of high-dimensional non-negative data that arises in vision and text applications where counts or frequencies are used as features .", "In this work , we introduce a novel angular quantization-based binary coding ( AQBC ) technique for such data and analyze its properties .", "Further , we propose a method for learning a linear transformation of the data to minimize the quantization error , and show that it results in improved binary codes .", "Even though the number of vertices ( quantization landmarks ) in this scheme grows exponentially with data dimensionality d , we propose a method for mapping feature vectors to their smallest-angle binary vertices that scales as O ( d log d ) .", "Experiments on image and text datasets show that the proposed AQBC method outperforms the state of the art ."]}
{"orig_sents": ["2", "0", "3", "5", "6", "1", "4"], "shuf_sents": ["Particular emphasis is placed on statistical image modeling , where overcomplete models have played an important role in discovering sparse representations .", "We evaluate the likelihood and quantitatively compare the performance of the overcomplete linear model to its complete counterpart as well as a product of experts model , which represents another overcomplete generalization of the complete linear model .", "We present a new learning strategy based on an efficient blocked Gibbs sampler for sparse overcomplete linear models .", "Our Gibbs sampler is faster than general purpose sampling schemes while also requiring no tuning as it is free of parameters .", "In contrast to previous claims , we find that overcomplete representations lead to significant improvements , but that the overcomplete linear model still underperforms other models .", "Using the Gibbs sampler and a persistent variant of expectation maximization , we are able to extract highly sparse distributions over latent sources from data .", "When applied to natural images , our algorithm learns source distributions which resemble spike-and-slab distributions ."]}
{"orig_sents": ["3", "4", "0", "1", "2"], "shuf_sents": ["We prove that under proper absorption rates , a random walk starting from a set S of low conductance will be mostly absorbed in S. Moreover , the absorption probabilities vary slowly inside S , while dropping sharply outside , thus implementing the desirable cluster assumption for graph-based learning .", "Remarkably , the partially absorbing process unifies many popular models arising in a variety of contexts , provides new insights into them , and makes it possible for transferring findings from one paradigm to another .", "Simulation results demonstrate its promising applications in retrieval and classification .", "We propose a novel stochastic process that is with probability i being absorbed at current state i , and with probability 1 - i follows a random edge out of it .", "We analyze its properties and show its potential for exploring graph structures ."]}
{"orig_sents": ["0", "5", "4", "3", "2", "1"], "shuf_sents": ["We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data .", "Our model outperforms general , unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking , and military conflicts among nations .", "We then extend the Infinite Relational Model by using these reciprocating Hawkes processes to parameterise its edges , making events associated with edges co-dependent through time .", "We consider a particular class of Hawkes processes , a doubly stochastic point process , that is able to model reciprocity between groups of individuals .", "Yet many models of social networks use explicitly declared relationships to infer social structure .", "Social groups are often formed implicitly , through actions among members of groups ."]}
{"orig_sents": ["2", "5", "0", "3", "1", "4"], "shuf_sents": ["We provide another piece of the puzzle by showing that an important concept in sequential prediction , the mixability of a loss , has a natural counterpart in the statistical setting , which we call stochastic mixability .", "We show that , in the special case of log-loss , stochastic mixability reduces to a well-known ( but usually unnamed ) martingale condition , which is used in existing convergence theorems for minimum description length and Bayesian inference .", "Statistical learning and sequential prediction are two different but related formalisms to study the quality of predictions .", "Just as ordinary mixability characterizes fast rates for the worst-case regret in sequential prediction , stochastic mixability characterizes fast rates in statistical learning .", "In the case of 0/1-loss , it reduces to the margin condition of Mammen and Tsybakov , and in the case that the model under consideration contains all possible predictors , it is equivalent to ordinary mixability .", "Mapping out their relations and transferring ideas is an active area of investigation ."]}
{"orig_sents": ["3", "5", "1", "2", "4", "0"], "shuf_sents": ["These benefits are shown to extend to real neural data .", "We use this approach to obtain estimates of parameters for a dynamical model of neural population data , where the observed spike-counts are Poisson-distributed with log-rates determined by the latent dynamical process , possibly driven by external inputs .", "We show that the extended subspace identification algorithm is consistent and accurately recovers the correct parameters on large simulated data sets with a single calculation , avoiding the costly iterative computation of approximate expectation-maximisation ( EM ) .", "Latent linear dynamical systems with generalised-linear observation models arise in a variety of applications , for instance when modelling the spiking activity of populations of neurons .", "Even on smaller data sets , it provides an effective initialisation for EM , avoiding local optima and speeding convergence .", "Here , we show how spectral learning methods ( usually called subspace identification in this context ) for linear systems with linear-Gaussian observations can be extended to estimate the parameters of a generalised-linear dynamical system model despite a non-linear and non-Gaussian observation process ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["The model is based on the theory of completely random measures and is able to handle a potentially infinite number of nodes .", "Our model is shown to be well fitted to several real-world social networks .", "We derive a posterior characterization , a generative process for network growth , and a simple Gibbs sampler for posterior simulation .", "We develop a novel Bayesian nonparametric model for random bipartite graphs .", "We show that the model has appealing properties and in particular it may exhibit a power-law behavior ."]}
{"orig_sents": ["4", "2", "1", "3", "5", "0"], "shuf_sents": ["The proposed system substantially outperforms existing ones in a variety of noises .", "To account for temporal dynamics in speech , we employ conditional random fields ( CRFs ) to classify speech dominance within each time-frequency unit for a sound mixture .", "We show that the cocktail party problem , or the speech separation problem , can be effectively approached via structured prediction .", "To capture complex , nonlinear relationship between input and output , both state and transition feature functions in CRFs are learned by deep neural networks .", "While human listeners excel at selectively attending to a conversation in a cocktail party , machine performance is still far inferior by comparison .", "The formulation of the problem as classification allows us to directly optimize a measure that is well correlated with human speech intelligibility ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["However , the inference algorithms are often slow and unwieldy , and are in general highly specific to a given model formulation .", "A number of dependent nonparametric processes have been proposed to model non-stationary data with unknown latent dimensionality .", "In this paper , we describe a large class of dependent nonparametric processes , including several existing models , and present a slice sampler that allows efficient inference across this class of models ."]}
{"orig_sents": ["1", "0", "2"], "shuf_sents": ["The two approaches achieve this goal in fundamentally different ways : 2 -LMNN inherits the computational benefits of a linear mapping from linear metric learning , but uses a non-linear 2 -distance to explicitly capture similarities within histogram data sets ; GB-LMNN applies gradient-boosting to learn non-linear mappings directly in function space and takes advantage of this approach 's robustness , speed , parallelizability and insensitivity towards the single additional hyperparameter .", "In this paper , we introduce two novel metric learning algorithms , 2 -LMNN and GB-LMNN , which are explicitly designed to be non-linear and easy-to-use .", "On various benchmark data sets , we demonstrate these methods not only match the current state-of-the-art in terms of kNN classification error , but in the case of 2 -LMNN , obtain best results in 19 out of 20 learning settings ."]}
{"orig_sents": ["4", "3", "0", "2", "1"], "shuf_sents": ["A recent characterization states that certain classes of regularization functionals with differentiable regularization term admit a linear representer theorem for any choice of the data if and only if the regularization term is a radial nondecreasing function .", "In particular , the main result of this paper implies that , for a sufficiently large family of regularization functionals , radial nondecreasing functions are the only lower semicontinuous regularization terms that guarantee existence of a representer theorem for any choice of the data .", "In this paper , we extend such result by weakening the assumptions on the regularization term .", "A class of regularization functionals is said to admit a linear representer theorem if every member of the class admits minimizers that lie in the finite dimensional subspace spanned by the representers of the data .", "The representer theorem is a property that lies at the foundation of regularization theory and kernel methods ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["In this paper we seek to detect rectangular cuboids and localize their corners in uncalibrated single-view images depicting everyday scenes .", "We introduce a database of images with cuboid annotations that spans a variety of indoor and outdoor scenes and show qualitative and quantitative results on our collected database .", "In contrast to recent approaches that rely on detecting vanishing points of the scene and grouping line segments to form cuboids , we build a discriminative parts-based detector that models the appearance of the cuboid corners and internal edges while enforcing consistency to a 3D cuboid model .", "Our model copes with different 3D viewpoints and aspect ratios and is able to detect cuboids across many different object categories .", "Our model out-performs baseline detectors that use 2D constraints alone on the task of localizing cuboid corners ."]}
{"orig_sents": ["4", "5", "3", "2", "1", "0"], "shuf_sents": ["The methods are illustrated on gene expression data .", "Oracle inequalities on excess risk are derived that exhibit the scaling behavior of the procedure in the high dimensional setting .", "Backfitting algorithms are derived and justified using a nonparametric form of the nuclear norm subdifferential .", "To control the complexity of the model , we employ a functional form of the Ky-Fan or nuclear norm , resulting in a set of function estimates that have low rank .", "We propose an approach to multivariate nonparametric regression that generalizes reduced rank regression for linear models .", "An additive model is estimated for each dimension of a q-dimensional response , with a shared p-dimensional predictor variable ."]}
{"orig_sents": ["2", "4", "3", "1", "0"], "shuf_sents": ["We support our claims theoretically by listing a set of theorems that relate our metric to R ( X , Y ) , and experimentally by studying the nonconvex problem of computing matrix geometric means based on squared distances .", "To allay some of these difficulties , we introduce a new metric on spd matrices , which not only respects non-Euclidean geometry but also offers faster computation than R while being less complicated to use .", "Symmetric positive definite ( spd ) matrices pervade numerous scientific disciplines , including machine learning and optimization .", "Typical non-Euclidean distance measures such as the Riemannian metric R ( X , Y ) = log ( Y -1/2 XY -1/2 ) F , are computationally demanding and also complicated to use .", "We consider the key task of measuring distances between two spd matrices ; a task that is often nontrivial whenever the distance function must respect the non-Euclidean geometry of spd matrices ."]}
{"orig_sents": ["6", "3", "0", "4", "5", "1", "2"], "shuf_sents": ["Here we propose a new NMF clustering method which replaces the approximated matrix with its smoothed version using random walk .", "The new learning objective is optimized by a multiplicative Majorization-Minimization algorithm with a scalable implementation for learning the factorizing matrix .", "Extensive experimental results on real-world datasets show that our method has strong performance in terms of cluster purity .", "However , conventional NMF methods that directly approximate the pairwise similarities using the least square error often yield mediocre performance for data in curved manifolds because they can capture only the immediate similarities between data samples .", "Our method can thus accommodate farther relationships between data samples .", "Furthermore , we introduce a novel regularization in the proposed objective function in order to improve over spectral clustering .", "Nonnegative Matrix Factorization ( NMF ) is a promising relaxation technique for clustering analysis ."]}
{"orig_sents": ["3", "1", "2", "5", "0", "4"], "shuf_sents": ["In this paper , we propose a novel method , called isotropic hashing ( IsoHash ) , to learn projection functions which can produce projected dimensions with isotropic variances ( equal variances ) .", "Typically , the variances of different projected dimensions are different for existing projection functions such as principal component analysis ( PCA ) .", "Using the same number of bits for different projected dimensions is unreasonable because larger-variance dimensions will carry more information .", "Most existing hashing methods adopt some projection functions to project the original data into several dimensions of real values , and then each of these projected dimensions is quantized into one bit ( zero or one ) by thresholding .", "Experimental results on real data sets show that IsoHash can outperform its counterpart with different variances for different dimensions , which verifies the viewpoint that projections with isotropic variances will be better than those with anisotropic variances .", "Although this viewpoint has been widely accepted by many researchers , it is still not verified by either theory or experiment because no methods have been proposed to find a projection with equal variances for different dimensions ."]}
{"orig_sents": ["0", "4", "2", "3", "1"], "shuf_sents": ["Sign-random-projection locality-sensitive hashing ( SRP-LSH ) is a probabilistic dimension reduction method which provides an unbiased estimate of angular similarity , yet suffers from the large variance of its estimation .", "Moreover , SBLSH shows the superiority over SRP-LSH in approximate nearest neighbor ( ANN ) retrieval experiments .", "It is easy to implement , which orthogonalizes the random projection vectors in batches , and it is theoretically guaranteed that SBLSH also provides an unbiased estimate of angular similarity , yet with a smaller variance when the angle to estimate is within ( 0 , /2 ] .", "The extensive experiments on real data well validate that given the same length of binary code , SBLSH may achieve significant mean squared error reduction in estimating pairwise angular similarity .", "In this work , we propose the Super-Bit locality-sensitive hashing ( SBLSH ) ."]}
{"orig_sents": ["7", "6", "0", "1", "2", "4", "5", "3"], "shuf_sents": ["This representation can be improved using machine learning , however , past approaches have been mostly limited to learning linear feature mappings in either the original input or a kernelized input feature space .", "While kernelized methods have proven somewhat effective for learning non-linear local feature descriptors , they rely heavily on the choice of an appropriate kernel function whose selection is often difficult and non-intuitive .", "We propose to use the boosting-trick to obtain a non-linear mapping of the input to a high-dimensional feature space .", "As demonstrated in our experiments , the resulting descriptor can be learned directly from intensity patches achieving state-of-the-art performance .", "The non-linear feature mapping obtained with the boosting-trick is highly intuitive .", "We employ gradient-based weak learners resulting in a learned descriptor that closely resembles the well-known SIFT .", "The main goal of local feature descriptors is to distinctively represent a salient image region while remaining invariant to viewpoint and illumination changes .", "In this paper we apply boosting to learn complex non-linear local visual feature representations , drawing inspiration from its successful application to visual object detection ."]}
{"orig_sents": ["2", "6", "0", "5", "4", "1", "3"], "shuf_sents": ["We term this method as learning with target priors ( LTP ) .", "Compared to the Bayesian approach , the learned parametric regressor in LTP can be more efficiently implemented and deployed in tasks where running efficiency is critical .", "In the conventional approaches for supervised parametric learning , relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables .", "We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video .", "Compared to the conventional ( semi ) supervised learning approach , LTP can make efficient use of prior knowledge of the target variables in the form of probabilistic distributions , and thus removes/reduces the reliance on training data in learning .", "Specifically , LTP learning seeks parameter that maximizes the log likelihood of f ( X ) on a uncorresponded training set with regards to p ( y ) .", "In this work , we describe a new learning scheme for parametric learning , in which the target variables y can be modeled with a prior model p ( y ) and the relations between data and target variables are estimated with p ( y ) and a set of uncorresponded data X in training ."]}
{"orig_sents": ["3", "2", "1", "0", "4"], "shuf_sents": ["We demonstrate the estimated performance of our MPGP on both simulated and real large data sets .", "Meanwhile , it provides a new online method for training hyperparameters with a number of weighted particles .", "Using a state space model established by the data construction procedure , our MPGP recursively filters out the estimation of hidden function values by a Gaussian mixture .", "We present a novel marginalized particle Gaussian process ( MPGP ) regression , which provides a fast , accurate online Bayesian filtering framework to model the latent function .", "The results show that our MPGP is a robust estimation algorithm with high computational efficiency , which outperforms other state-of-art sparse GP methods ."]}
{"orig_sents": ["2", "3", "0", "4", "1"], "shuf_sents": ["Our output is a tree-mixture model which serves as a good approximation to the underlying graphical model mixture .", "Keywords : Graphical models , mixture models , spectral methods , tree approximation .", "We consider unsupervised estimation of mixtures of discrete graphical models , where the class variable is hidden and each mixture component can have a potentially different Markov graph structure and parameters over the observed variables .", "We propose a novel method for estimating the mixture components with provable guarantees .", "The sample and computational requirements for our method scale as poly ( p , r ) , for an r-component mixture of pvariate graphical models , for a wide class of models which includes tree mixtures and mixtures over bounded degree graphs ."]}
{"orig_sents": ["0", "3", "2", "1", "4"], "shuf_sents": ["In the paper , we consider the problem of link prediction in time-evolving graphs .", "Oracle inequalities are derived and illustrate the trade-offs in the choice of smoothing parameters when modeling the joint effect of sparsity and low rank property .", "Our strategy involves a joint optimization procedure over the space of adjacency matrices and VAR matrices which takes into account both sparsity and low rank properties of the matrices .", "We assume that certain graph features , such as the node degree , follow a vector autoregressive ( VAR ) model and we propose to use this information to improve the accuracy of prediction .", "The estimate is computed efficiently using proximal methods through a generalized forward-backward agorithm ."]}
{"orig_sents": ["6", "3", "5", "1", "4", "0", "2"], "shuf_sents": ["Utilizing connections between exponential family distributions and Bregman divergences , we derive novel clustering algorithms from the asymptotic limit of the DP and HDP mixtures that features the scalability of existing hard clustering methods as well as the flexibility of Bayesian nonparametric models .", "For instance , in the context of clustering , such an approach yields connections between the kmeans and EM algorithms .", "We focus on special cases of our analysis for discrete-data problems , including topic modeling , and we demonstrate the utility of our results by applying variants of our algorithms to problems arising in vision and document analysis .", "An alternative is to relax the probabilistic model into a non-probabilistic formulation which has a scalable associated algorithm .", "In this paper , we explore small-variance asymptotics for exponential family Dirichlet process ( DP ) and hierarchical Dirichlet process ( HDP ) mixture models .", "This can often be fulfilled by performing small-variance asymptotics , i.e. , letting the variance of particular distributions in the model go to zero .", "Sampling and variational inference techniques are two standard methods for inference in probabilistic models , but for many problems , neither approach scales effectively to large-scale data ."]}
{"orig_sents": ["3", "2", "4", "0", "1"], "shuf_sents": ["Without predefined mapping strategies , we introduce a general approach to support transfer learning across different state spaces .", "We demonstrate the potential impact of our system through improved jumpstart and faster convergence to near optimum policy in two benchmark domains .", "We address the challenges of transfer learning in heterogeneous environments with varying tasks .", "We study how to automatically select and adapt multiple abstractions or representations of the world to support model-based reinforcement learning .", "We present an efficient , online framework that , through a sequence of tasks , learns a set of relevant representations to be used in future tasks ."]}
{"orig_sents": ["2", "4", "5", "3", "1", "6", "0"], "shuf_sents": ["Experimental results show advantages over state-of-the-art optimization methods .", "For large-scale problems , low-rank versions of the bound are provided and outperform LBFGS as well as first-order methods .", "The partition function plays a key role in probabilistic modeling including conditional random fields , graphical models , and maximum likelihood estimation .", "Such bounds remain efficient to compute even when the partition function involves a graphical model ( with small tree-width ) or in latent likelihood settings .", "To optimize partition functions , this article introduces a quadratic variational upper bound .", "This inequality facilitates majorization methods : optimization of complicated functions through the iterative solution of simpler sub-problems .", "Several learning applications are shown and reduce to fast and convergent update rules ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["Accurate and detailed models of neurodegenerative disease progression are crucially important for reliable early diagnosis and the determination of effective treatments .", "We describe efficient learning algorithms for ALPACA and discuss promising experimental results on a real cohort of Alzheimer 's patients from the Alzheimer 's Disease Neuroimaging Initiative .", "In contrast with previous works which model disease progression as a fixed event ordering , we explicitly model the variability over such orderings among patients which is more realistic , particularly for highly detailed progression models .", "We introduce the ALPACA ( Alzheimer 's disease Probabilistic Cascades ) model , a generative model linking latent Alzheimer 's progression dynamics to observable biomarker data ."]}
{"orig_sents": ["4", "2", "3", "5", "0", "1"], "shuf_sents": ["When used as a subroutine in a greedy influence maximization approach , our proposed algorithm is guaranteed to find a set of C nodes with the influence of at least ( 1 - 1/e ) OPT -2C , where OPT is the optimal value .", "Experiments on both synthetic and real-world data show that the proposed algorithm can easily scale up to networks of millions of nodes while significantly improves over previous state-of-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence .", "This influence estimation problem is very challenging since both the time-sensitive nature of the task and the requirement of scalability need to be addressed simultaneously .", "In this paper , we propose a randomized algorithm for influence estimation in continuous-time diffusion networks .", "If a piece of information is released from a media site , can we predict whether it may spread to one million web pages , in a month ?", "Our algorithm can estimate the influence of every node in a network with |V| nodes and |E| edges to an accuracy of using n = O ( 1/ 2 ) randomizations and up to logarithmic factors O ( n|E|+n|V| ) computations ."]}
{"orig_sents": ["1", "3", "0", "2", "4"], "shuf_sents": ["Novel algorithms and theory are provided to implement this type of anonymity .", "The adaptive anonymity problem is formalized where each individual shares their data along with an integer value to indicate their personal level of desired privacy .", "The relaxation achieves better utility , admits theoretical privacy guarantees that are as strong , and , most importantly , accommodates a variable level of anonymity for each individual .", "This problem leads to a generalization of k-anonymity to the b-matching setting .", "Empirical results confirm improved utility on benchmark and social data-sets ."]}
{"orig_sents": ["4", "5", "1", "2", "3", "6", "0"], "shuf_sents": ["In addition , we apply our algorithm on a temporal collaborative filtering task and obtain state-of-the-art results .", "In this paper , we study the recovery algorithm for pairwise interaction tensors , which has recently gained considerable attention for modeling multiple attribute data due to its simplicity and effectiveness .", "Specifically , in the absence of noise , we show that one can exactly recover a pairwise interaction tensor by solving a constrained convex program which minimizes the weighted sum of nuclear norms of matrices from O ( nr log2 ( n ) ) observations .", "For the noisy cases , we also prove error bounds for a constrained convex program for recovering the tensors .", "Tensor completion from incomplete observations is a problem of significant practical interest .", "However , it is unlikely that there exists an efficient algorithm with provable guarantee to recover a general tensor from a limited number of observations .", "Our experiments on the synthetic dataset demonstrate that the recovery performance of our algorithm agrees well with the theory ."]}
{"orig_sents": ["2", "0", "4", "3", "1"], "shuf_sents": ["In addition to the non-convexity shared with other matrix factorization schemes , our problem is further complicated by a combinatorial constraint set of size 2m*r , where m is the dimension of the data points and r the rank of the factorization .", "To obtain this result , we use theory around the Littlewood-Offord lemma from combinatorics .", "Motivated by an application in computational biology , we consider low-rank matrix factorization with { 0 , 1 } -constraints on one of the factors and optionally convex constraints on the second one .", "( 2012 ) - an algorithm that provably recovers the underlying factorization in the exact case with O ( mr2r + mnr + r2 n ) operations for n datapoints .", "Despite apparent intractability , we provide - in the line of recent work on non-negative matrix factorization by Arora et al ."]}
{"orig_sents": ["0", "1", "6", "4", "3", "2", "5"], "shuf_sents": ["Lifted inference algorithms exploit symmetries in probabilistic models to speed up inference .", "They show impressive performance when calculating unconditional probabilities in relational models , but often resort to non-lifted inference when computing conditional probabilities .", "In particular , we show that conditioning on binary evidence with bounded Boolean rank is efficient .", "In this paper , we balance this negative result by identifying the Boolean rank of the evidence as a key parameter for characterizing the complexity of conditioning in lifted inference .", "Recent theoretical results show , for example , that conditioning on evidence which corresponds to binary relations is # P-hard , suggesting that no lifting is to be expected in the worst case .", "This opens up the possibility of approximating evidence by a low-rank Boolean matrix factorization , which we investigate both theoretically and empirically .", "The reason is that conditioning on evidence breaks many of the model 's symmetries , which can preempt standard lifting techniques ."]}
{"orig_sents": ["4", "0", "3", "6", "2", "1", "5"], "shuf_sents": ["Recently Balle et al .", "Under this formulation , we provide identifiability results for FST distributions .", "We frame FST learning as finding a low rank Hankel matrix satisfying constraints derived from observable statistics .", "presented a spectral algorithm for learning FST from samples of aligned input-output sequences .", "Finite-State Transducers ( FST ) are a standard tool for modeling paired inputoutput sequences and are used in numerous applications , ranging from computational biology to natural language processing .", "Then , following previous work on rank minimization , we propose a regularized convex relaxation of this objective which is based on minimizing a nuclear norm penalty subject to linear constraints and can be solved efficiently .", "In this paper we address the more realistic , yet challenging setting where the alignments are unknown to the learning algorithm ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Motivated by the need of combining regularizers to simultaneously induce different types of structures , this paper initiates a systematic investigation of when the proximal map of a sum of functions decomposes into the composition of the proximal maps of the individual summands .", "The proximal map is the key step in gradient-type algorithms , which have become prevalent in large-scale high-dimensional problems .", "For simple functions this proximal map is available in closed-form while for more complicated functions it can become highly nontrivial .", "We not only unify a few known results scattered in the literature but also discover several new decompositions obtained almost effortlessly from our theory ."]}
{"orig_sents": ["5", "1", "6", "2", "3", "0", "4"], "shuf_sents": ["The algorithm can be implemented using an optimization strategy that is virtually tuning-parameter free and simpler than existing methods , and likely can be applied in other settings such as dictionary learning .", "Consequently , successful blind deconvolution for removing shake artifacts requires the estimation of a spatiallyvarying or non-uniform blur operator .", "Through an implicit normalization process , this penalty automatically adjust its shape based on the estimated degree of local blur and image structure such that regions with large blur or few prominent edges are discounted .", "Remaining regions with modest blur and revealing edges therefore dominate on average without explicitly incorporating structureselection heuristics .", "Detailed theoretical analysis and empirical comparisons on real images serve as validation .", "Typical blur from camera shake often deviates from the standard uniform convolutional assumption , in part because of problematic rotations which create greater blurring away from some unknown center point .", "Using ideas from Bayesian inference and convex analysis , this paper derives a simple non-uniform blind deblurring algorithm with a spatially-adaptive image penalty ."]}
{"orig_sents": ["3", "1", "4", "0", "2"], "shuf_sents": ["Because the representation matrix is often simultaneously sparse and low-rank , we propose a new algorithm , termed Low-Rank Sparse Subspace Clustering ( LRSSC ) , by combining SSC and LRR , and develops theoretical guarantees of when the algorithm succeeds .", "The two methods are fundamentally similar in that both are convex optimizations exploiting the intuition of `` Self-Expressiveness '' .", "The results reveal interesting insights into the strength and weakness of SSC and LRR and demonstrate how LRSSC can take the advantages of both methods in preserving the `` Self-Expressiveness Property '' and `` Graph Connectivity '' at the same time .", "Sparse Subspace Clustering ( SSC ) and Low-Rank Representation ( LRR ) are both considered as the state-of-the-art methods for subspace clustering .", "The main difference is that SSC minimizes the vector 1 norm of the representation matrix to induce sparsity while LRR minimizes nuclear norm ( aka trace norm ) to promote a low-rank structure ."]}
{"orig_sents": ["8", "4", "5", "6", "1", "0", "2", "11", "10", "3", "7", "9"], "shuf_sents": [") .", "The performance of this approach under the assumption that the revealed entries are sampled randomly has received considerable attention ( e.g .", "In practice , often the set of revealed entries is not chosen at random and these results do not apply .", "The first step remains the same : find a matrix of lowest possible complexity that agrees with the partially specified matrix .", "This problem comes up in many application areas , and has received a great deal of attention in the context of the netflix prize .", "A central approach to this problem is to output a matrix of lowest possible complexity ( e.g .", "rank or trace norm ) that agrees with the partially specified matrix .", "We give a new way to interpret the output of this algorithm by next finding a probability distribution over the non-revealed entries with respect to which a bound on the generalization error can be proven .", "In the matrix completion problem the aim is to recover an unknown real matrix from a subset of its entries .", "The more complex the set of revealed entries according to a certain measure , the better the bound on the generalization error .", "We present a means to obtain performance guarantees with respect to any set of initial observations .", "We are therefore left with no guarantees on the performance of the algorithm we are using ."]}
{"orig_sents": ["3", "2", "0", "4", "1"], "shuf_sents": ["Instead of proposing another local training method , we develop a convex relaxation of hidden-layer conditional models that admits global training .", "The resulting methods are able to acquire two-layer models that can not be represented by any single-layer model over the same features , while improving training quality over local heuristics .", "Unfortunately , such models are difficult to train because inference over latent variables must be performed concurrently with parameter optimization -- creating a highly non-convex problem .", "Latent variable prediction models , such as multi-layer networks , impose auxiliary latent variables between inputs and outputs to allow automatic inference of implicit features useful for prediction .", "Our approach extends current convex modeling approaches to handle two nested nonlinearities separated by a non-trivial adaptive latent layer ."]}
{"orig_sents": ["0", "2", "6", "4", "3", "1", "5"], "shuf_sents": ["There are two major routes to address linear inverse problems .", "Second , we characterize conditions under which the penalty function associated to the conditional mean estimator can satisfy certain popular properties such as convexity , separability , and smoothness .", "Whereas regularization-based approaches build estimators as solutions of penalized regression optimization problems , Bayesian estimators rely on the posterior distribution of the unknown , given some assumed family of priors .", "First , we extend the additive white Gaussian denoising results to general linear inverse problems with colored Gaussian noise .", "The contribution of this paper is twofold .", "This sheds light on some tradeoff between computational efficiency and estimation accuracy in sparse regularization , and draws some connections between Bayesian estimation and proximal optimization .", "While these may seem radically different approaches , recent results have shown that , in the context of additive white Gaussian denoising , the Bayesian conditional mean estimator is always the solution of a penalized regression problem ."]}
{"orig_sents": ["3", "8", "4", "0", "1", "7", "5", "6", "2"], "shuf_sents": ["Secondly , we propose and analyze a new robust sparse principal component regression on high dimensional elliptically distributed data .", "The elliptical distribution is a semiparametric generalization of the Gaussian , including many well known distributions such as multivariate Gaussian , rank-deficient Gaussian , t , Cauchy , and logistic .", "Experiments on synthetic and real world data are conducted to illustrate the empirical usefulness of the proposed method .", "In this paper we focus on the principal component regression and its application to high dimension non-Gaussian data .", "First , in low dimensions and under the Gaussian model , by borrowing the strength from recent development in minimax optimal principal component estimation , we first time sharply characterize the potential advantage of classical principal component regression over least square estimation .", "These extra flexibilities make it very suitable for modeling finance and biomedical imaging data .", "Under the elliptical model , we prove that our method can estimate the regression coefficients in the optimal parametric rate and therefore is a good alternative to the Gaussian based methods .", "It allows the random vector to be heavy tailed and have tail dependence .", "The major contributions are two folds ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["This paper observes that if the inference problem is `` smoothed '' through the addition of entropy terms , for fixed messages , the learning objective reduces to a traditional ( non-structured ) logistic regression problem with respect to parameters .", "Based on this insight , the structured energy function can be extended from linear factors to any function class where an `` oracle '' exists to minimize a logistic loss .", "In these logistic regression problems , each training example has a bias term determined by the current set of messages .", "A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages , and iterate between updates to each ."]}
{"orig_sents": ["2", "3", "4", "1", "5", "0"], "shuf_sents": ["We therefore show how addressing the problem of synaptic correlations leads to a novel functional account of key biophysical features of the neural substrate .", "We derive optimal network dynamics for recall in the face of synaptic correlations caused by a range of synaptic plasticity rules .", "It has long been recognised that statistical dependencies in neuronal activity need to be taken into account when decoding stimuli encoded in a neural population .", "Less studied , though equally pernicious , is the need to take account of dependencies between synaptic weights when decoding patterns previously encoded in an auto-associative memory .", "We show that activity-dependent learning generically produces such correlations , and failing to take them into account in the dynamics of memory retrieval leads to catastrophically poor recall .", "These dynamics involve well-studied circuit motifs , such as forms of feedback inhibition and experimentally observed dendritic nonlinearities ."]}
{"orig_sents": ["2", "0", "5", "1", "4", "3"], "shuf_sents": ["To understand the functional contribution of such molecular complexity to learning and memory , it is essential to expand our theoretical conception of a synapse from a single scalar to an entire dynamical system with many internal molecular functional states .", "This raises the fundamental question , how does synaptic complexity give rise to memory ?", "An incredible gulf separates theoretical models of synapses , often described solely by a single scalar value denoting the size of a postsynaptic potential , from the immense complexity of molecular signaling pathways underlying real synapses .", "Moreover , in proving such theorems , we uncover a framework , based on first passage time theory , to impose an order on the internal states of complex synaptic models , thereby simplifying the relationship between synaptic structure and function .", "To address this , we develop new mathematical theorems elucidating the relationship between the structural organization and memory properties of complex synapses that are themselves molecular networks .", "Moreover , theoretical considerations alone demand such an expansion ; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity ."]}
{"orig_sents": ["2", "0", "4", "6", "8", "7", "1", "9", "5", "3"], "shuf_sents": ["Estimating the entropy of a discrete distribution from samples is an important and difficult problem that has received considerable attention in statistics and theoretical neuroscience .", "The parametric model captures high-level statistical features of the data , such as the average spike count in a spike word , which allows the posterior over entropy to concentrate more rapidly than with standard estimators ( e.g. , in cases where the probability of spiking differs strongly from 0.5 ) .", "Shannon 's entropy is a basic quantity in information theory , and a fundamental building block for the analysis of neural codes .", "We apply these estimators to simulated and real neural data and show that they substantially outperform traditional methods .", "However , neural responses have characteristic statistical structure that generic entropy estimators fail to exploit .", "We devise a compact representation of the data and prior that allow for computationally efficient implementations of Bayesian least squares and empirical Bayes entropy estimators with large numbers of neurons .", "For example , existing Bayesian entropy estimators make the naive assumption that all spike words are equally likely a priori , which makes for an inefficient allocation of prior probability mass in cases where spikes are sparse .", "We define two prior distributions over spike words using mixtures of Dirichlet distributions centered on simple parametric models .", "Here we develop Bayesian estimators for the entropy of binary spike trains using priors designed to flexibly exploit the statistical structure of simultaneouslyrecorded spike responses .", "Conversely , the Dirichlet distributions assign prior mass to distributions far from the parametric model , ensuring consistent estimates for arbitrary distributions ."]}
{"orig_sents": ["3", "4", "5", "0", "2", "1"], "shuf_sents": ["Here we contribute a statistical method for `` stitching '' together sequentially imaged sets of neurons into one model by phrasing the problem as fitting a latent dynamical system with missing observations .", "In particular , we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs .", "This method allows us to substantially expand the population-sizes for which population dynamics can be characterized -- beyond the number of simultaneously imaged neurons .", "Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit , shedding light on the computations performed .", "It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging .", "However , many computations are thought to involve circuits consisting of thousands of neurons , such as cortical barrels in rodent somatosensory cortex ."]}
{"orig_sents": ["2", "5", "0", "3", "6", "1", "4"], "shuf_sents": ["Here we consider associative memories with noisy internal computations and analytically characterize performance .", "Computational experiments lend additional support to our theoretical analysis .", "Recent advances in associative memory design through structured pattern sets and graph-based inference algorithms allow reliable learning and recall of exponential numbers of patterns .", "As long as internal noise is less than a specified threshold , error probability in the recall phase can be made exceedingly small .", "This work suggests a functional benefit to noisy neurons in biological neuronal networks .", "Though these designs correct external errors in recall , they assume neurons compute noiselessly , in contrast to highly variable neurons in hippocampus and olfactory cortex .", "More surprisingly , we show internal noise actually improves performance of the recall phase ."]}
{"orig_sents": ["3", "4", "7", "5", "6", "0", "8", "9", "1", "2"], "shuf_sents": ["After mapping the two algorithms onto neural dynamics , we find that both can infer correct odors in less than 100 ms .", "Thus , they should be distinguishable experimentally .", "If so , that would provide insight into the mechanisms employed by the olfactory system , and , because the two algorithms use very different coding strategies , that would also provide insight into how networks represent probabilities .", "The olfactory system faces a difficult inference problem : it has to determine what odors are present based on the distributed activation of its receptor neurons .", "Here we derive neural implementations of two approximate inference algorithms that could be used by the brain .", "et al. , 2012 ) , the other is based on sampling .", "Importantly , we use a more realistic prior distribution over odors than has been used in the past : we use a `` spike and slab '' prior , for which most odors have zero concentration .", "One is a variational algorithm ( which builds on the work of Beck .", "Thus , at the behavioral level , the two algorithms make very similar predictions .", "However , they make different assumptions about connectivity and neural computations , and make different predictions about neural activity ."]}
{"orig_sents": ["0", "5", "4", "7", "3", "1", "6", "2", "8"], "shuf_sents": ["Population neural recordings with long-range temporal structure are often best understood in terms of a common underlying low-dimensional dynamical process .", "We also introduce the cascaded generalised-linear model ( CGLM ) to capture low-dimensional instantaneous correlations in neural populations .", "The CGLM can also be seen as a generalisation of a lowrank Gaussian model , in this case factor analysis .", "We show that RLMs describe motor-cortical population data better than either directly-coupled generalised-linear models or latent linear dynamical system models with generalised-linear observations .", "We describe a new , scalable approach to discovering low-dimensional dynamics that underlie simultaneously recorded spike trains from a neural population .", "Advances in recording technology provide access to an ever-larger fraction of the population , but the standard computational approaches available to identify the collective dynamics scale poorly with the size of the dataset .", "The CGLM describes the cortical recordings better than either Ising or Gaussian models and , like the RLM , can be fit exactly and quickly .", "We formulate the Recurrent Linear Model ( RLM ) by generalising the Kalman-filter-based likelihood calculation for latent linear dynamical systems to incorporate a generalised-linear observation process .", "The computational tractability of the RLM and CGLM allow both to scale to very high-dimensional neural data ."]}
{"orig_sents": ["0", "2", "4", "1", "3"], "shuf_sents": ["Dropout is a relatively new algorithm for training neural networks which relies on stochastically `` dropping out '' neurons during training in order to avoid the co-adaptation of feature detectors .", "We provide estimates and bounds for these approximations and corroborate the results with simulations .", "We introduce a general formalism for studying dropout on either units or connections , with arbitrary probability values , and use it to analyze the averaging and regularizing properties of dropout in both linear and non-linear networks .", "Among other results , we also show how dropout performs stochastic gradient descent on a regularized error function .", "For deep neural networks , the averaging properties of dropout are characterized by three recursive equations , including the approximation of expectations by normalized weighted geometric means ."]}
{"orig_sents": ["3", "2", "4", "0", "1"], "shuf_sents": ["We analyze the asymptotic performance of both the geometric and moment averages paths and derive an asymptotically optimal piecewise linear schedule .", "AIS with moment averaging performs well empirically at estimating partition functions of restricted Boltzmann machines ( RBMs ) , which form the building blocks of many deep learning models .", "The near-universal practice is to use geometric averages of the initial and target distributions , but alternative paths can perform substantially better .", "Many powerful Monte Carlo techniques for estimating partition functions , such as annealed importance sampling ( AIS ) , are based on sampling from a sequence of intermediate distributions which interpolate between a tractable initial distribution and the intractable target distribution .", "We present a novel sequence of intermediate distributions for exponential families defined by averaging the moments of the initial and target distributions ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["However , it turns out that this posterior is not consistent -- it does not concentrate at the true number of components .", "In this note , we give an elementary proof of this inconsistency in what is perhaps the simplest possible setting : a DPM with normal components of unit variance , applied to data from a `` mixture '' with one standard normal component .", "The typical approach is to use the posterior distribution on the number of clusters -- that is , the posterior on the number of components represented in the observed data .", "Further , we show that this example exhibits severe inconsistency : instead of going to 1 , the posterior probability that there is one cluster converges ( in probability ) to 0 .", "For data assumed to come from a finite mixture with an unknown number of components , it has become common to use Dirichlet process mixtures ( DPMs ) not only for density estimation , but also for inferences about the number of components ."]}
{"orig_sents": ["5", "1", "2", "4", "0", "3", "6", "7"], "shuf_sents": ["Representations and algorithms from computer graphics are used as the deterministic backbone for highly approximate and stochastic generative models .", "Instead , most vision tasks are approached via complex bottom-up processing pipelines .", "Here we show that it is possible to write short , simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images .", "This formulation combines probabilistic programming , computer graphics , and approximate Bayesian computation , and depends only on generalpurpose , automatic inference techniques .", "Generative probabilistic graphics programs ( GPGP ) consist of a stochastic scene generator , a renderer based on graphics software , a stochastic likelihood model linking the renderer 's output and the data , and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood .", "The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance , but it has proved difficult to directly implement .", "We describe two applications : reading sequences of degraded and adversarially obscured characters , and inferring 3D road models from vehicle-mounted camera images .", "Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code , and yields accurate , approximately Bayesian inferences about real-world images ."]}
{"orig_sents": ["1", "3", "0", "4", "2", "5"], "shuf_sents": ["Using this viewpoint , we show that the dropout regularizer is first-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix .", "Dropout and other feature noising schemes control overfitting by artificially corrupting the training data .", "By casting dropout as regularization , we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer .", "For generalized linear models , dropout performs a form of adaptive regularization .", "We also establish a connection to AdaGrad , an online learning algorithm , and find that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems .", "We apply this idea to document classification tasks , and show that it consistently boosts the performance of dropout training , improving on state-of-the-art results on the IMDB reviews dataset ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["In this paper we investigate the use of Langevin Monte Carlo methods on the probability simplex and propose a new method , Stochastic gradient Riemannian Langevin dynamics , which is simple to implement and can be applied to large scale data .", "We apply this method to latent Dirichlet allocation in an online minibatch setting , and demonstrate that it achieves substantial performance improvements over the state of the art online variational Bayesian methods ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["Distributions over matrices with exchangeable rows and infinitely many columns are useful in constructing nonparametric latent variable models .", "In this paper , we propose a class of exchangeable nonparametric priors obtained by restricting the domain of existing models .", "Such models allow us to specify the distribution over the number of features per data point , and can achieve better performance on data sets where the number of features is not well-modeled by the original distribution .", "However , the distribution implied by such models over the number of features exhibited by each data point may be poorly-suited for many modeling tasks ."]}
{"orig_sents": ["4", "0", "3", "1", "2"], "shuf_sents": ["We show that the continuous time limit of the expectation propagation algorithm exists and results in a hybrid fixed point iteration consisting of ( 1 ) expectation propagation updates for discrete time terms and ( 2 ) variational updates for the continuous time term .", "This approach extends the classical Kalman-Bucy smoothing procedure to non-Gaussian observations , enabling continuous-time inference in a variety of models , including spiking neuronal models ( state-space models with point process observations ) and box likelihood models .", "Experimental results on real and simulated data demonstrate high distributional accuracy and significant computational savings compared to discrete-time approaches in a neural application .", "We introduce postinference corrections methods that improve on the marginals of the approximation .", "We propose an approximate inference algorithm for continuous time Gaussian Markov process models with both discrete and continuous time likelihoods ."]}
{"orig_sents": ["2", "3", "1", "0"], "shuf_sents": ["The sequential inference algorithm and its supporting theory are illustrated by simulated examples .", "As an application of the general theory we analyze convergence behaviors of exact and approximate message-passing algorithms that arise in a sequential change point detection problem formulated via a latent variable directed graphical model .", "We propose a general formalism of iterated random functions with semigroup property , under which exact and approximate Bayesian posterior updates can be viewed as specific instances .", "A convergence theory for iterated random functions is presented ."]}
{"orig_sents": ["0", "1", "3", "8", "7", "2", "9", "6", "5", "4"], "shuf_sents": ["Psychologists are interested in developing instructional policies that boost student learning .", "An instructional policy specifies the manner and content of instruction .", "For example , in concept learning , policies might be described by a fading function that specifies exemplar difficulty over time .", "For example , in the domain of concept learning , a policy might specify the nature of exemplars chosen over a training sequence .", "We evaluate the method via two behavioral studies , and suggest that the method has broad applicability to optimization problems involving humans outside the educational arena .", "Even though individual subjects provide only a noisy estimate of the population mean , the optimization method allows us to determine the shape of the policy space and to identify the global optimum , and is as efficient in its subject budget as a traditional A-B comparison .", "Instead of evaluating a few experimental conditions each with many human subjects , as the traditional methodology does , our technique evaluates many experimental conditions each with a few subjects .", "We propose an alternative to the traditional methodology in which we define a parameterized space of policies and search this space to identify the optimal policy .", "Traditional psychological studies compare several hand-selected policies , e.g. , contrasting a policy that selects only difficult-to-classify exemplars with a policy that gradually progresses over the training sequence from easy exemplars to more difficult ( known as fading ) .", "We propose an experimental technique for searching policy spaces using Gaussian process surrogate-based optimization and a generative model of student performance ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["This paper develops these ideas further and examines their empirical relevance in 51 natural environments .", "This research has identified three environmental structures that aid heuristics : dominance , cumulative dominance , and noncompensatoriness .", "The results show that all three structures are prevalent , making it possible for simple rules to reach , and occasionally exceed , the accuracy of the linear decision rule , using less information and less computation .", "Several attempts to understand the success of simple decision heuristics have examined heuristics as an approximation to a linear decision rule ."]}
{"orig_sents": ["2", "0", "1", "4", "5", "3"], "shuf_sents": ["A challenging aspect of combining the crowd 's answers is that workers ' reliabilities and biases are usually unknown and highly diverse .", "Control items with known answers can be used to evaluate workers ' performance , and hence improve the combined results on the target items with unknown answers .", "We study the problem of estimating continuous quantities , such as prices , probabilities , and point spreads , using a crowdsourcing approach .", "As a byproduct , we also provide theoretical analysis of the accuracy of different consensus methods .", "This raises the problem of how many control items to use when the total number of items each workers can answer is limited : more control items evaluates the workers better , but leaves fewer resources for the target items that are of direct interest , and vice versa .", "We give theoretical results for this problem under different scenarios , and provide a simple rule of thumb for crowdsourcing practitioners ."]}
{"orig_sents": ["3", "2", "1", "4", "0"], "shuf_sents": ["Due to the technical challenges and sparsity of these systems , it is important to focus experimental time stimulating the neurons whose synaptic strength is most ambiguous , therefore we also develop an online optimal design algorithm for choosing which neurons to stimulate at each trial .", "The input to our algorithm is data from experiments in which action potentials from putative presynaptic neurons can be evoked while a subthreshold recording is made from a single postsynaptic neuron .", "In this work , we develop a method for efficiently inferring posterior distributions over synaptic strengths in neural microcircuits .", "With the advent of modern stimulation techniques in neuroscience , the opportunity arises to map neuron to neuron connectivity .", "We present a realistic statistical model which accounts for the main sources of variability in this experiment and allows for significant prior information about the connectivity and neuronal cell types to be incorporated if available ."]}
{"orig_sents": ["3", "4", "0", "2", "1", "5"], "shuf_sents": ["The main contribution of this paper is a new procedure called Sparse Overlapping Sets ( SOS ) lasso , a convex optimization that automatically selects similar features for related learning tasks .", "In particular , SOSlasso is motivated by multisubject fMRI studies in which functional activity is classified using brain voxels as features .", "Error bounds are derived for SOSlasso and its consistency is established for squared error loss .", "Multitask learning can be effective when features useful in one task are also useful for other tasks , and the group lasso is a standard method for selecting a common subset of features .", "In this paper , we are interested in a less restrictive form of multitask learning , wherein ( 1 ) the available features can be organized into subsets according to a notion of similarity and ( 2 ) features useful in one task are similar , but not necessarily identical , to the features best suited for other tasks .", "Experiments with real and synthetic data demonstrate the advantages of SOSlasso compared to the lasso and group lasso ."]}
{"orig_sents": ["2", "5", "0", "4", "1", "9", "7", "8", "3", "6"], "shuf_sents": ["To improve the efficiency of solving large-scale Lasso problems , El Ghaoui and his colleagues have proposed the SAFE rules which are able to quickly identify the inactive predictors , i.e. , predictors that have 0 components in the solution vector .", "By transforming the standard Lasso to its dual form , it can be shown that the inactive predictors include the set of inactive constraints on the optimal dual solution .", "Lasso is a widely used regression technique to find sparse representations .", "We have evaluated our screening rule using many real data sets .", "Then , the inactive predictors or features can be removed from the optimization problem to reduce its scale .", "When the dimension of the feature space and the number of samples are extremely large , solving the Lasso problem remains challenging .", "Results show that our rule is more effective in identifying inactive predictors than existing state-of-the-art screening rules for Lasso .", "Moreover , we show that our screening rule can be extended to identify inactive groups in group Lasso .", "To the best of our knowledge , there is currently no `` exact '' screening rule for group Lasso .", "In this paper , we propose an efficient and effective screening rule via Dual Polytope Projections ( DPP ) , which is mainly based on the uniqueness and nonexpansiveness of the optimal dual solution due to the fact that the feasible set in the dual space is a convex and closed polytope ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["The resulting test statistics are straightforward to compute , and are used in powerful interaction tests , which are consistent against all alternatives for a large family of reproducing kernels .", "We introduce kernel nonparametric tests for Lancaster three-variable interaction and for total independence , using embeddings of signed measures into a reproducing kernel Hilbert space .", "This makes the Lancaster test especially suited to finding structure in directed graphical models , where it outperforms competing nonparametric tests in detecting such V-structures .", "We show the Lancaster test to be sensitive to cases where two independent causes individually have weak influence on a third dependent variable , but their combined effect has a strong influence ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["This significantly increases the proportion of time workers spend computing , as opposed to waiting .", "We provide a proof of correctness under SSP , as well as empirical results demonstrating that the SSP model achieves faster algorithm convergence on several different ML problems , compared to fully-synchronous and asynchronous schemes .", "The parameter server provides an easy-to-use shared interface for read/write access to an ML model 's values ( parameters and variables ) , and the SSP model allows distributed workers to read older , stale versions of these values from a local cache , instead of waiting to get them from a central storage .", "Furthermore , the SSP model ensures ML algorithm correctness by limiting the maximum age of the stale values .", "We propose a parameter server system for distributed ML , which follows a Stale Synchronous Parallel ( SSP ) model of computation that maximizes the time computational workers spend doing useful work on ML algorithms , while still providing correctness guarantees ."]}
{"orig_sents": ["2", "1", "3", "0", "7", "5", "4", "6"], "shuf_sents": ["In this paper , we propose a framework for learning in reproducing kernel Hilbert spaces ( RKHS ) using local invariances that explicitly characterize the behavior of the target function around data instances .", "To exploit invariances , most existing methods resort to approximations that either lead to expensive optimization problems such as semi-definite programming , or rely on separation oracles to retain tractability .", "Incorporating invariance information is important for many learning problems .", "Some methods further limit the space of functions and settle for non-convex models .", "For the representer theorem to hold , the linear functionals are required to be bounded in the RKHS , and we show that this is true for a variety of commonly used RKHS and invariances .", "Based on a representer theorem that we establish , our formulation can be efficiently optimized via a convex program .", "Experiments on learning with unlabeled data and transform invariances show that the proposed method yields better or similar results compared with the state of the art .", "These invariances are compactly encoded as linear functionals whose value are penalized by some loss function ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We also report the results of experiments with both algorithms in both binary and multi-class classification tasks .", "We devise two new learning kernel algorithms : one based on a convex optimization problem for which we give an efficient solution using existing learning kernel techniques , and another one that can be formulated as a DC-programming problem for which we describe a solution in detail .", "Our algorithms thereby benefit from the sharper learning bounds based on that notion which , under certain general conditions , guarantee a faster convergence rate .", "We use the notion of local Rademacher complexity to design new algorithms for learning kernels ."]}
{"orig_sents": ["2", "9", "4", "7", "10", "3", "5", "0", "1", "8", "6"], "shuf_sents": ["Model selection for unsupervised or semi-supervised inference is generally a difficult problem .", "It turns out that in the density ratio estimation setting , when samples from both distributions are available , simple completely unsupervised model selection methods are available .", "We address the problem of estimating the ratio pq where p is a density function and q is another density , or , more generally an arbitrary function .", "The resulting family of algorithms ( FIRE , for Fredholm Inverse Regularized Estimator ) is flexible , simple and easy to implement .", "It is also closely related to the problem of covariate shift in transfer learning .", "We provide detailed theoretical analysis including concentration bounds and convergence rates for the Gaussian kernel for densities defined on Rd and smooth d-dimensional sub-manifolds of the Euclidean space .", "We show encouraging experimental results including applications to classification within the covariate shift framework .", "Our approach is based on reformulating the problem of estimating the ratio as an inverse problem in terms of an integral operator corresponding to a kernel , known as the Fredholm problem of the first kind .", "We call this mechanism CD-CV for Cross-Density Cross-Validation .", "Knowing or approximating this ratio is needed in various problems of inference and integration often referred to as importance sampling in statistical inference .", "This formulation , combined with the techniques of regularization leads to a principled framework for constructing algorithms and for analyzing them theoretically ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We consider the problem of maintaining the data-structures of a partition-based regression procedure in a setting where the training data arrives sequentially over time .", "We prove that it is possible to maintain such a structure in time O ( log n ) at n-2/ ( 2+d ) any time step n while achieving a nearly-optimal regression rate of O in terms of the unknown metric dimension d. Finally we prove a new regression lower-bound which is independent of a given data size , and hence is more appropriate for the streaming setting ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["Using this representation , we derive conditions that the graph should satisfy to ensure recoverability and devise algorithms to detect the presence of these conditions in the graph .", "deciding whether there exists a consistent estimator of a given relation Q , when data are missing not at random .", "We employ a formal representation called `Missingness Graphs ' to explicitly portray the causal mechanisms responsible for missingness and to encode dependencies between these mechanisms and the variables being measured .", "We address the problem of recoverability i.e ."]}
{"orig_sents": ["2", "4", "3", "5", "1", "0"], "shuf_sents": ["For these algorithms , we provide a non-asymptotic analysis of the generalization error ( in expectation , and also in high probability for least-squares ) , and run extensive experiments showing that they often outperform existing approaches .", "For logistic regression , this is achieved by a simple novel stochastic gradient algorithm that ( a ) constructs successive local quadratic approximations of the loss functions , while ( b ) preserving the same running-time complexity as stochastic gradient descent .", "We consider the stochastic approximation problem where a convex function has to be minimized , given only the knowledge of unbiased estimates of its gradients at certain points , a framework which includes machine learning methods based on the minimization of the empirical risk .", "We consider and analyze two algorithms that achieve a rate of O ( 1/n ) for classical supervised learning problems .", "We focus on problems without strong convexity , for which all previously known algorithms achieve a convergence rate for function values of O ( 1/ n ) after n iterations .", "For least-squares regression , we show that averaged stochastic gradient descent with constant step-size achieves the desired rate ."]}
{"orig_sents": ["7", "0", "4", "6", "3", "2", "5", "1"], "shuf_sents": ["In the future such abstractions might enable nanoscale devices that can sense and control the world at a molecular scale .", "As with standard sum-product inference , this procedure yields exact results for tree-structured graphs , and approximate solutions for loopy graphs .", "In particular , we show that marginalization based on sum-product message passing can be implemented in terms of reactions between chemical species whose concentrations represent probabilities .", "In this work , we develop a procedure that can take arbitrary probabilistic graphical models , represented as factor graphs over discrete random variables , and compile them into chemical reaction networks that implement inference .", "Just as in macroscale robotics , it is critical that such devices can learn about their environment and reason under uncertainty .", "We show algebraically that the steady state concentration of these species correspond to the marginal distributions of the random variables in the graph and validate the results in simulations .", "At this small scale , systems are typically modeled as chemical reaction networks .", "Recent work on molecular programming has explored new possibilities for computational abstractions with biomolecules , including logic gates , neural networks , and linear systems ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["We establish lower bounds for several problems , including various types of location models , as well as for parameter estimation in regression models .", "We study two classes of protocols : one in which machines send messages independently , and a second allowing for interactive communication .", "Such lower bounds reveal the minimum amount of communication required by any procedure to achieve the centralized minimax-optimal rates for statistical estimation .", "We establish lower bounds on minimax risks for distributed statistical estimation under a communication budget ."]}
{"orig_sents": ["4", "0", "2", "3", "1"], "shuf_sents": ["The inequality is based on a combination of the PAC-Bayesian bounding technique with an Empirical Bernstein bound .", "The PAC-Bayes-Empirical-Bernstein inequality is an interesting example of an application of the PAC-Bayesian bounding technique to self-bounding functions .", "We show that when the empirical variance is significantly smaller than the empirical loss the PAC-Bayes-Empirical-Bernstein inequality is significantly tighter than the PAC-Bayes-kl inequality of Seeger ( 2002 ) and otherwise it is comparable .", "Our theoretical analysis is confirmed empirically on a synthetic example and several UCI datasets .", "We present a PAC-Bayes-Empirical-Bernstein inequality ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["On the optimization side , we show that a simple adaptation of composite gradient descent may be used to compute a global optimum up to the statistical precision stat in log ( 1/ stat ) iterations , the fastest possible rate for any first-order method .", "We establish theoretical results concerning local optima of regularized M estimators , where both loss and penalty functions are allowed to be nonconvex .", "Our results show that as long as the loss satisfies restricted strong convexity and the penalty satisfies suitable regularity conditions , any local optimum of the composite objective lies within statistical precision of the true parameter vector .", "Our theory covers a broad class of nonconvex objective functions , including corrected versions of the Lasso for errors-in-variables linear models and regression in generalized linear models using nonconvex regularizers such as SCAD and MCP .", "We provide simulations to illustrate the sharpness of our theoretical predictions ."]}
{"orig_sents": ["4", "2", "7", "3", "1", "6", "0", "5"], "shuf_sents": ["On the other hand , we show a new algorithm that learns this class efficiently n2 / 2 examples .", "Our main contribution is a novel , non-cryptographic , methodology for establishing computational-statistical gaps , which allows us to show that , under a widely believed assumption that refuting random 3CNF formulas is hard , it is impossible to efficiently learn this class using only O n/ 2 examples .", "That is , if more data is available , beyond the sample complexity limit , is it possible to use the extra examples to speed up the computation time required to perform the learning task ?", "This class is inefficiently learnable using O n/ 2 examples .", "The increased availability of data in recent years has led several authors to ask whether it is possible to use data as a computational resource .", "This formally establishes the tradeoff between sample using and computational complexity for a natural supervised learning problem .", "We further show that under stronger hardness assumptions , even O n1.499 / 2 examples do not suffice .", "We give the first positive answer to this question for a natural supervised learning problem -- we consider agnostic PAC learning of halfspaces over 3-sparse vectors in { -1 , 1 , 0 } n ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["The design of convex , calibrated surrogate losses , whose minimization entails consistency with respect to a desired target loss , is an important concept to have emerged in the theory of machine learning in recent years .", "We use this result to design convex calibrated surrogates for a variety of subset ranking problems , with target losses including the precision @ q , expected rank utility , mean average precision , and pairwise disagreement .", "We give an explicit construction of a convex least-squares type surrogate loss that can be designed to be calibrated for any multiclass learning problem for which the target loss matrix has a low-rank structure ; the surrogate loss operates on a surrogate target space of dimension at most the rank of the target loss ."]}
{"orig_sents": ["5", "0", "3", "2", "4", "1"], "shuf_sents": ["It is known that a good binary CPE model can be used to obtain a good binary classification model ( by thresholding at 0.5 ) , and also to obtain a good bipartite ranking model ( by using the CPE model directly as a ranking model ) ; it is also known that a binary classification model does not necessarily yield a CPE model .", "We then show that , in this weaker sense , a good bipartite ranking model can be used to construct a good classification model ( by thresholding at a suitable point ) , and more surprisingly , also to construct a good binary CPE model ( by calibrating the scores of the ranking model ) .", "Formally , these relationships involve regret transfer bounds .", "However , not much is known about other directions .", "In this paper , we introduce the notion of weak regret transfer bounds , where the mapping needed to transform a model from one problem to another depends on the underlying probability distribution ( and in practice , must be estimated from data ) .", "We investigate the relationship between three fundamental problems in machine learning : binary classification , bipartite ranking , and binary class probability estimation ( CPE ) ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph ( which must be accessible before selecting an action ) .", "Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efficient manner .", "In the undirected case , we show that the learner can achieve optimal regret without even accessing the observability graph before selecting an action .", "We consider the partial observability model for multi-armed bandits , introduced by Mannor and Shamir ."]}
{"orig_sents": ["2", "5", "1", "4", "6", "3", "0"], "shuf_sents": ["Compared to UCB algorithm regret bounds for specific model classes , our general bound matches the best available for linear models and is stronger than the best available for generalized linear models .", "The clearest example of this is the class of upper confidence bound ( UCB ) algorithms , but recent work has shown that a simple posterior sampling algorithm , sometimes called Thompson sampling , can be analyzed in the same manner as optimistic approaches .", "This paper considers the sample complexity of the multi-armed bandit with dependencies among the arms .", "It depends on a new notion we refer to as the eluder dimension , which measures the degree of dependence among action rewards .", "In this paper , we develop a regret bound that holds for both classes of algorithms .", "Some of the most successful algorithms for this problem use the principle of optimism in the face of uncertainty to guide exploration .", "This bound applies broadly and can be specialized to many model classes ."]}
{"orig_sents": ["5", "3", "4", "0", "2", "1"], "shuf_sents": ["We propose a class of `` spread-based '' market making strategies whose performance can be controlled even under worst-case ( adversarial ) settings .", "We run a set of experiments showing favorable performance on recent real-world stock price data .", "We prove structural properties of these strategies which allows us to design a master algorithm which obtains low regret relative to the best such strategy in hindsight .", "A market maker generally seeks to profit from the difference between the buy and sell price of an asset , yet the market maker also takes exposure risk in the event of large price movements .", "Profit guarantees for market making strategies have typically required certain stochastic assumptions on the price fluctuations of the asset in question ; for example , assuming a model in which the price process is mean reverting .", "We consider the design of strategies for market making in an exchange ."]}
{"orig_sents": ["4", "1", "3", "2", "6", "5", "0"], "shuf_sents": ["Finally , we empirically demonstrate the performance and good scalability properties of our algorithms .", "We are motivated by a number of real-world applications in machine learning including sensor placement and data subset selection , which require maximizing a certain submodular function ( like coverage or diversity ) while simultaneously minimizing another ( like cooperative cost ) .", "We show , however , that by phrasing these problems as constrained optimization , which is more natural for many applications , we achieve a number of bounded approximation guarantees .", "These problems are often posed as minimizing the difference between submodular functions which is in the worst case inapproximable .", "We investigate two new optimization problems -- minimizing a submodular function subject to a submodular lower bound constraint ( submodular cover ) and maximizing a submodular function subject to a submodular upper bound constraint ( submodular knapsack ) .", "We provide hardness results for both problems thus showing that our approximation factors are tight up to log-factors .", "We also show that both these problems are closely related and an approximation algorithm solving one can be used to obtain an approximation guarantee for the other ."]}
{"orig_sents": ["1", "0", "3", "4", "2"], "shuf_sents": ["In the Black-Scholes option pricing model from 1973 , the Investor can continuously hedge the risk of an option by trading the underlying asset , assuming that the asset 's price fluctuates according to Geometric Brownian Motion ( GBM ) .", "We consider a popular problem in finance , option pricing , through the lens of an online learning game between Nature and an Investor .", "We use significantly weaker assumptions than previous work -- for instance , we allow large jumps in the asset price -- and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework .", "We consider a worst-case model , in which Nature chooses a sequence of price fluctuations under a cumulative quadratic volatility constraint , and the Investor can make a sequence of hedging decisions .", "Our main result is to show that the value of our proposed game , which is the `` regret '' of hedging strategy , converges to the Black-Scholes option price ."]}
{"orig_sents": ["2", "1", "5", "0", "4", "3", "6"], "shuf_sents": ["This analysis is then extended to the Bayesian nonparametric case , yielding a simple , scalable , and flexible algorithm for discrete-state sequence data with a non-fixed number of states .", "We present a smallvariance asymptotic analysis of the Hidden Markov Model and its infinite-state Bayesian nonparametric extension .", "Small-variance asymptotics provide an emerging technique for obtaining scalable combinatorial algorithms from rich probabilistic models .", "A key property of such algorithms is that -- particularly in the nonparametric setting -- standard probabilistic inference algorithms lack scalability and are heavily dependent on good initialization .", "We also derive the corresponding combinatorial objective functions arising from our analysis , which involve a k-means-like term along with penalties based on state transitions and the number of states .", "Starting with the standard HMM , we first derive a `` hard '' inference algorithm analogous to k-means that arises when particular variances in the model tend to zero .", "A number of results on synthetic and real data sets demonstrate the advantages of the proposed framework ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Hypergraphs allow one to encode higher-order relationships in data and are thus a very flexible modeling tool .", "Current learning methods are either based on approximations of the hypergraphs via graphs or on tensor methods which are only applicable under special conditions .", "The key element is a family of regularization functionals based on the total variation on hypergraphs .", "In this paper , we present a new learning framework on hypergraphs which fully uses the hypergraph structure ."]}
{"orig_sents": ["4", "2", "3", "6", "5", "8", "7", "1", "9", "0"], "shuf_sents": ["The methods , when applied to topic modeling , allow generalization to words not present in the training data .", "Instead of pooling the data into one sample , we prove that it is possible to use the differences between the samples to better recover the underlying structure .", ".", ".", "In the mixture models problem it is assumed that there are K distributions 1 , .", "The goal is to associate instances with their generating distributions , or to identify the parameters of the hidden distributions .", ", K and one gets to observe a sample from a mixture of these distributions with unknown coefficients .", "As with topic modeling , having multiple samples is often a reasonable assumption .", "In this work we make the assumption that we have access to several samples drawn from the same K underlying distributions , but with different mixing weights .", "We present algorithms that recover the underlying structure under milder assumptions than the current state of art when either the dimensionality or the separation is high ."]}
{"orig_sents": ["5", "2", "1", "0", "3", "6", "4"], "shuf_sents": ["Recently , there has been growing interest in using DPPs defined on continuous spaces .", "This discrete setting admits an efficient sampling algorithm based on the eigendecomposition of the defining kernel matrix .", "In machine learning , the focus of DPP-based models has been on diverse subset selection from a discrete and finite base set .", "While the discrete-DPP sampler extends formally to the continuous case , computationally , the steps required are not tractable in general .", "We demonstrate the utility of continuous DPPs in repulsive mixture modeling and synthesizing human poses spanning activity spaces .", "Determinantal point processes ( DPPs ) are random point processes well-suited for modeling repulsion .", "In this paper , we present two efficient DPP sampling schemes that apply to a wide range of kernel functions : one based on low rank approximations via Nystrom and random Fourier feature techniques and another based on Gibbs sampling ."]}
{"orig_sents": ["2", "4", "0", "5", "1", "7", "3", "6", "8"], "shuf_sents": ["However , optimizing many such criteria is known to be a hard problem .", "For each formulation , we first define a measure of variability for a policy , which in turn gives us a set of risk-sensitive criteria to optimize .", "In many sequential decision-making problems we may want to manage risk by minimizing some measure of variability in rewards in addition to maximizing a standard criterion .", "We then devise actor-critic algorithms for estimating the gradient and updating the policy parameters in the ascent direction .", "Variance-related risk measures are among the most common risk-sensitive criteria in finance and operations research .", "In this paper , we consider both discounted and average reward Markov decision processes .", "We establish the convergence of our algorithms to locally risk-sensitive optimal policies .", "For each of these criteria , we derive a formula for computing its gradient .", "Finally , we demonstrate the usefulness of our algorithms in a traffic signal control application ."]}
{"orig_sents": ["4", "0", "3", "2", "5", "1"], "shuf_sents": ["We achieve this by using both expert data , as well as reinforcement signals gathered through trial-and-error interactions with the environment .", "Our experiments include simulations as well as a real robot path-finding task .", "We prove an upper bound on the Bellman error of the estimate computed by APID at each iteration .", "The key idea of our approach , Approximate Policy Iteration with Demonstration ( APID ) , is that expert 's suggestions are used to define linear constraints which guide the optimization performed by Approximate Policy Iteration .", "We propose a Learning from Demonstration ( LfD ) algorithm which leverages expert data , even if they are very few or inaccurate .", "Moreover , we show empirically that APID outperforms pure Approximate Policy Iteration , a state-of-the-art LfD algorithm , and supervised learning in a variety of scenarios , including when very few and/or suboptimal demonstrations are available ."]}
{"orig_sents": ["5", "1", "4", "3", "6", "2", "0"], "shuf_sents": ["On the other extreme , we present an algorithm that achieves the ideal factor k speed-up in learning performance , with communication only logarithmic in 1/ .", "Our motivation comes from recent employment of bandit algorithms in computationally intensive , large-scale applications .", "We complement this result with a lower bound showing this is in general the best possible .", "In particular , our main result shows that by allowing the k players to communicate only once , they are able to learn k times faster than a single player .", "Our results demonstrate a non-trivial tradeoff between the number of arm pulls required by each of the players , and the amount of communication between them .", "We study exploration in Multi-Armed Bandits in a setting where k players collaborate in order to identify an -optimal arm .", "That is , distributing learning to k players gives rise to a factor k parallel speedup ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["I present a new online learning algorithm that extends the exponentiated gradient framework to infinite dimensional spaces .", "For this analysis , I introduce novel tools for algorithms with time-varying regularizers , through the use of local smoothness .", "My analysis shows that the algorithm is implicitly able to estimate the L2 norm of the unknown competitor , U , achieving a regret bound of the order of O ( U log ( U T + 1 ) ) T ) , instead of the standard O ( ( U 2 + 1 ) T ) , achievable without knowing U .", "Through a lower bound , I also show that the algorithm is optimal up to log ( U T ) term for linear and Lipschitz losses ."]}
{"orig_sents": ["1", "2", "3", "0", "4"], "shuf_sents": ["In addition , we propose an extension of analytic shrinkage -orthogonal complement shrinkage- which adapts to the covariance structure .", "Analytic shrinkage is a statistical technique that offers a fast alternative to crossvalidation for the regularization of covariance matrices and has appealing consistency properties .", "We show that the proof of consistency requires bounds on the growth rates of eigenvalues and their dispersion , which are often violated in data .", "We prove consistency under assumptions which do not restrict the covariance structure and therefore better match real world data .", "Finally we demonstrate the superior performance of our novel approach on data from the domains of finance , spoken letter and optical character recognition , and neuroscience ."]}
{"orig_sents": ["0", "5", "4", "1", "6", "7", "2", "3"], "shuf_sents": ["The efficiency of Brain-Computer Interfaces ( BCI ) largely depends upon a reliable extraction of informative features from the high-dimensional EEG signal .", "However , CSP is highly sensitive to artifacts in the EEG data , i.e .", "More precisely , we formulate CSP as a divergence maximization problem and utilize the property of a particular type of divergence , namely beta divergence , for robustifying the estimation of spatial filters in the presence of artifacts in the data .", "We demonstrate the usefulness of our method on toy data and on EEG recordings from 80 subjects .", "The Common Spatial Patterns ( CSP ) algorithm computes filters that maximize the difference in band power between two conditions , thus it is tailored to extract the relevant information in motor imagery experiments .", "A crucial step in this protocol is the computation of spatial filters .", "few outliers may alter the estimate drastically and decrease classification performance .", "Inspired by concepts from the field of information geometry we propose a novel approach for robustifying CSP ."]}
{"orig_sents": ["5", "4", "6", "0", "2", "1", "3"], "shuf_sents": ["In this paper , we develop an algorithm B IG QUIC , which can solve 1 million dimensional 1 regularized Gaussian MLE problems ( which would thus have 1000 billion parameters ) using a single machine , with bounded memory .", "Our innovations include a novel block-coordinate descent method with the blocks chosen via a clustering scheme to minimize repeated computations ; and allowing for inexact computation of specific components .", "In order to do so , we carefully exploit the underlying structure of the problem .", "In spite of these modifications , we are able to theoretically analyze our procedure and show that B IG QUIC can achieve super-linear or even quadratic convergence rates .", "However , it requires solving a difficult non-smooth log-determinant program with number of parameters scaling quadratically with the number of Gaussian variables .", "The 1 -regularized Gaussian maximum likelihood estimator ( MLE ) has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix even under high-dimensional settings .", "State-of-the-art methods thus do not scale to problems with more than 20 , 000 variables ."]}
{"orig_sents": ["4", "7", "0", "6", "3", "5", "1", "2"], "shuf_sents": ["The well known Bonferroni correction method , while simple to implement , is quite conservative , and can substantially under-power a study because it ignores dependencies between test statistics .", "Our evaluations on four different neuroimaging datasets show that a computational speedup factor of roughly 50x can be achieved while recovering the FWER distribution up to very high accuracy .", "Further , we show that the estimated -threshold is also recovered faithfully , and is stable .", "In this paper , we show that permutation testing in fact amounts to populating the columns of a very large matrix P. By analyzing the spectrum of this matrix , under certain conditions , we see that P has a low-rank plus a low-variance residual decomposition which makes it suitable for highly sub-sampled -- on the order of 0.5 % -- matrix completion methods .", "Multiple hypothesis testing is a significant problem in nearly all neuroimaging studies .", "Based on this observation , we propose a novel permutation testing methodology which offers a large speedup , without sacrificing the fidelity of the estimated FWER .", "Permutation testing , on the other hand , is an exact , non-parametric method of estimating the FWER for a given -threshold , but for acceptably low thresholds the computational burden can be prohibitive .", "In order to correct for this phenomena , we require a reliable estimate of the Family-Wise Error Rate ( FWER ) ."]}
{"orig_sents": ["6", "3", "2", "5", "4", "1", "0", "7"], "shuf_sents": ["We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging ( fMRI ) data .", "The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs .", "We cast the problem , resembling group or collaborative sparsity formulations , as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques .", "We propose a robust graph matching algorithm inspired in sparsityrelated techniques .", "The proposed approach is also naturally integrated with collaborative graph inference techniques , solving general network inference problems where the observed variables , possibly coming from different modalities , are not in correspondence .", "The method can deal with weighted or unweighted graphs , as well as multimodal data , where different graphs represent different types of data .", "Graph matching is a challenging problem with very important applications in a wide range of fields , from image and video analysis to biological and biomedical problems .", "The code is publicly available ."]}
{"orig_sents": ["0", "5", "1", "3", "6", "4", "2"], "shuf_sents": ["As massively parallel computations have become broadly available with modern GPUs , deep architectures trained on very large datasets have risen in popularity .", "However , elements of these architectures are similar to standard hand-crafted representations used in computer vision .", "We also show that convolutional networks and Fisher vector encodings are complementary in the sense that their combination further improves the accuracy .", "In this paper , we explore the extent of this analogy , proposing a version of the stateof-the-art Fisher vector image encoding that can be stacked in multiple layers .", "Our hybrid architecture allows us to assess how the performance of a conventional hand-crafted image classification pipeline changes with increased depth .", "Discriminatively trained convolutional neural networks , in particular , were recently shown to yield state-of-the-art performance in challenging image classification benchmarks such as ImageNet .", "This architecture significantly improves on standard Fisher vectors , and obtains competitive results with deep convolutional networks at a smaller computational learning cost ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["We propose in this work a new family of optimal transport distances that look at transport problems from a maximumentropy perspective .", "We also show that this regularized distance improves upon classic optimal transport distances on the MNIST classification problem .", "Despite their appealing theoretical properties , excellent performance in retrieval tasks and intuitive formulation , their computation involves the resolution of a linear program whose cost can quickly become prohibitive whenever the size of the support of these measures or the histograms ' dimension exceeds a few hundred .", "We smooth the classic optimal transport problem with an entropic regularization term , and show that the resulting optimum is also a distance which can be computed through Sinkhorn 's matrix scaling algorithm at a speed that is several orders of magnitude faster than that of transport solvers .", "Optimal transport distances are a fundamental family of distances for probability measures and histograms of features ."]}
{"orig_sents": ["4", "3", "1", "0", "2"], "shuf_sents": ["We then show that this MDI importance of a variable is equal to zero if and only if the variable is irrelevant and that the MDI importance of a relevant variable is invariant with respect to the removal or the addition of irrelevant variables .", "We derive a three-level decomposition of the information jointly provided by all input variables about the output in terms of i ) the MDI importance of each input variable , ii ) the degree of interaction of a given input variable with the other input variables , iii ) the different interaction terms of a given degree .", "We illustrate these properties on a simple example and discuss how they may change in the case of non-totally randomized trees such as Random Forests and Extra-Trees .", "In this work we characterize the Mean Decrease Impurity ( MDI ) variable importances as measured by an ensemble of totally randomized trees in asymptotic sample and ensemble size conditions .", "Despite growing interest and practical use in various scientific areas , variable importances derived from tree-based ensemble methods are not well understood from a theoretical point of view ."]}
{"orig_sents": ["4", "0", "2", "3", "1"], "shuf_sents": ["These two cases are deeply related : Language users invent new terms in conversation , and language learners learn the literal meanings of words based on their pragmatic inferences about how those words are used .", "This model captures phenomena in word learning and pragmatic inference ; it additionally leads to insights about the emergence of communicative systems in conversation and the mechanisms by which pragmatic inferences become incorporated into word meanings .", "While pragmatic inference and word learning have both been independently characterized in probabilistic terms , no current work unifies these two .", "We describe a model in which language learners assume that they jointly approximate a shared , external lexicon and reason recursively about the goals of others in using this lexicon .", "Language users are remarkably good at making inferences about speakers ' intentions in context , and children learning their native language also display substantial skill in acquiring the meanings of unknown words ."]}
{"orig_sents": ["5", "0", "1", "3", "2", "4"], "shuf_sents": ["A popular approach is to estimate the regression coefficients through the Lasso ( 1 -regularized least squares ) .", "This is known to correctly identify the active set only if the irrelevant covariates are roughly orthogonal to the relevant ones , as quantified through the so called `irrepresentability ' condition .", "We formulate `generalized irrepresentability condition ' ( GIC ) , an assumption that is substantially weaker than irrepresentability .", "In this paper we study the `Gauss-Lasso ' selector , a simple two-stage method that first solves the Lasso , and then performs ordinary least squares restricted to the Lasso active set .", "We prove that , under GIC , the Gauss-Lasso correctly recovers the active set .", "In the high-dimensional regression model a response variable is linearly related to p covariates , but the sample size n is smaller than p. We assume that only a small subset of covariates is `active ' ( i.e. , the corresponding coefficients are non-zero ) , and consider the model-selection problem of identifying the active covariates ."]}
{"orig_sents": ["9", "7", "0", "5", "2", "4", "10", "3", "8", "1", "6"], "shuf_sents": ["This in turn implies that it is extremely challenging to quantify the uncertainty associated with a certain parameter estimate .", "Furthermore , proofs are remarkably simple .", "We consider here a broad class of regression problems , and propose an efficient algorithm for constructing confidence intervals and p-values .", "Our approach is based on constructing a `de-biased ' version of regularized Mestimators .", "The resulting confidence intervals have nearly optimal size .", "Concretely , no commonly accepted procedure exists for computing classical measures of uncertainty and statistical significance as confidence intervals or p-values .", "We test our method on a diabetes prediction problem .", "As a consequence , it is generally impossible to obtain an exact characterization of the probability distribution of the parameter estimates .", "The new construction improves over recent work in the field in that it does not assume a special structure on the design matrix .", "Fitting high-dimensional statistical models often requires the use of non-linear parameter estimation procedures .", "When testing for the null hypothesis that a certain parameter is vanishing , our method has nearly optimal power ."]}
{"orig_sents": ["5", "4", "3", "2", "0", "7", "1", "6"], "shuf_sents": ["As our method is unsupervised , features may be extracted once and subsequently used in a variety of tasks .", "Our compressed feature space is two orders of magnitude smaller than the full k-gram space and matches the text categorization accuracy achieved in the full feature space .", "We formulate document compression as a binary optimization task and show how to solve it approximately via a sequence of reweighted linear programs that are efficient to solve and parallelizable .", "Specifically , our method finds a set of word k-grams that minimizes the cost of reconstructing the text losslessly .", "Our method is grounded in the principle of minimum description length and uses a dictionary-based compression scheme to extract a succinct feature set .", "This paper addresses the problem of unsupervised feature learning for text data .", "This dimensionality reduction not only results in faster training times , but it can also help elucidate structure in unsupervised learning tasks and reduce the amount of training data necessary for supervised learning .", "We demonstrate the performance of these features over a range of scenarios including unsupervised exploratory analysis and supervised text categorization ."]}
{"orig_sents": ["2", "0", "3", "5", "1", "6", "4"], "shuf_sents": ["We propose a new algorithm , a modification of the classical pivoted QR algorithm of Businger and Golub , that requires a small number of passes over the data .", "We describe experiments on real-world datasets which sometimes show improvements of several orders of magnitude over the classical algorithm .", "The goal of unsupervised feature selection is to identify a small number of important features that can represent the data .", "The improvements are based on two ideas : keeping track of multiple features in each pass , and skipping calculations that can be shown not to affect the final selection .", "On the other hand , the randomized algorithms may produce more accurate features , at the cost of small probability of failure .", "Our algorithm selects the exact same features as the classical pivoted QR algorithm , and has the same favorable numerical stability .", "These results appear to be competitive with recently proposed randomized algorithms in terms of pass efficiency and run time ."]}
{"orig_sents": ["3", "1", "4", "2", "0"], "shuf_sents": ["Numerical experiments conducted on two important applications , overlapping group lasso and graph-guided fused lasso , corroborate the theoretical claims .", "In large-scale machine learning applications , nonsmooth losses/regularizers that entail great computational challenges are usually approximated by smooth functions .", "The new approximation is justified using a recent convex analysis tool -- proximal average , and yields a novel proximal gradient algorithm that is strictly better than the one based on smoothing , without incurring any extra overhead .", "It is a common practice to approximate `` complicated '' functions with more friendly ones .", "We re-examine this powerful methodology and point out a nonsmooth approximation which simply pretends the linearity of the proximal map ."]}
{"orig_sents": ["4", "2", "1", "3", "0"], "shuf_sents": ["We also demonstrate a new reduction of polar to proximal maps that enables more efficient latent fused lasso .", "Our first contribution is to uncover a rich class of structured sparse regularizers whose polar operator can be evaluated efficiently .", "Unfortunately , these estimators normally create computational difficulties that entail sophisticated algorithms .", "With such an operator , a simple conditional gradient method can then be developed that , when combined with smoothing and local optimization , significantly reduces training time vs. the state of the art .", "Structured sparse estimation has become an important technique in many areas of data analysis ."]}
{"orig_sents": ["2", "3", "4", "1", "0"], "shuf_sents": ["A key ingredient in our proof is a new Lipschitzian error bound for the aforementioned trace norm-regularized problem , which may be of independent interest .", "Our result is established without any strong convexity assumption on the loss function .", "Motivated by various applications in machine learning , the problem of minimizing a convex smooth loss function with trace norm regularization has received much attention lately .", "Currently , a popular method for solving such problem is the proximal gradient method ( PGM ) , which is known to have a sublinear rate of convergence .", "In this paper , we show that for a large class of loss functions , the convergence rate of the PGM is in fact linear ."]}
{"orig_sents": ["0", "2", "4", "3", "1"], "shuf_sents": ["Stochastic gradient descent is popular for large scale optimization but has slow convergence asymptotically due to the inherent variance .", "Moreover , unlike SDCA or SAG , our method does not require the storage of gradients , and thus is more easily applicable to complex problems such as some structured prediction problems and neural network learning .", "To remedy this problem , we introduce an explicit variance reduction method for stochastic gradient descent which we call stochastic variance reduced gradient ( SVRG ) .", "However , our analysis is significantly simpler and more intuitive .", "For smooth and strongly convex functions , we prove that this method enjoys the same fast convergence rate as those of stochastic dual coordinate ascent ( SDCA ) and Stochastic Average Gradient ( SAG ) ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["This paper considers an extension of SDCA under the mini-batch setting that is often used in practice .", "Stochastic dual coordinate ascent ( SDCA ) is an effective technique for solving regularized loss minimization problems in machine learning .", "Our main contribution is to introduce an accelerated mini-batch version of SDCA and prove a fast convergence rate for this method .", "We discuss an implementation of our method over a parallel computing system , and compare the results to both the vanilla stochastic dual coordinate ascent and to the accelerated deterministic gradient descent method of Nesterov ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We study stochastic optimization problems when the data is sparse , which is in a sense dual to current perspectives on high-dimensional statistical learning and optimization .", "Concretely , we derive matching upper and lower bounds on the minimax rate for optimization and learning with sparse data , and we exhibit algorithms achieving these rates .", "We also show how leveraging sparsity leads to ( still minimax optimal ) parallel and asynchronous algorithms , providing experimental evidence complementing our theoretical results on several medium to large-scale learning tasks .", "We highlight both the difficulties -- in terms of increased sample complexity that sparse data necessitates -- and the potential benefits , in terms of allowing parallelism and asynchrony in the design of algorithms ."]}
{"orig_sents": ["2", "5", "3", "0", "4", "1"], "shuf_sents": ["To this end , we present a novel algorithm named Epoch Mixed Gradient Descent ( EMGD ) that is able to utilize two kinds of gradients .", "Theoretical analysis shows that EMGD is able to find an -optimal solution by computing O ( log 1/ ) full gradients and O ( 2 log 1/ ) stochastic gradients .", "For smooth and strongly convex optimizations , the optimal iteration complexity of the gradient-based algorithm is O ( log 1/ ) , where is the condition number .", "In this paper , we propose to remove the dependence on the condition number by allowing the algorithm to access stochastic gradients of the objective function .", "A distinctive step in EMGD is the mixed gradient descent , where we use a combination of the full and stochastic gradients to update the intermediate solution .", "In the case that the optimization problem is ill-conditioned , we need to evaluate a large number of full gradients , which could be computationally expensive ."]}
{"orig_sents": ["1", "2", "0", "3", "4"], "shuf_sents": ["In this work , we consider a new setup for optimizing smooth functions , termed as Mixed Optimization , which allows to access both a stochastic oracle and a full gradient oracle .", "It is well known that the optimal convergence rate for stochastic optimization of smooth functions is O ( 1/ T ) , which is same as stochastic optimization of Lipschitz continuous convex functions .", "This is in contrast to optimizing smooth functions using full gradients , which yields a convergence rate of O ( 1/T 2 ) .", "Our goal is to significantly improve the convergence rate of stochastic optimization of smooth functions by having an additional small number of accesses to the full gradient oracle .", "We show that , with an O ( ln T ) calls to the full gradient oracle and an O ( T ) calls to the stochastic oracle , the proposed mixed optimization algorithm is able to achieve an optimization error of O ( 1/T ) ."]}
{"orig_sents": ["1", "5", "2", "3", "0", "4"], "shuf_sents": ["Our second approach is an efficient primal-dual stochastic algorithm .", "In this paper , we are interested in the development of efficient algorithms for convex optimization problems in the simultaneous presence of multiple objectives and stochasticity in the first-order information .", "We first examine a two stages exploration-exploitation based algorithm which first approximates the stochastic objectives by sampling and then solves a constrained stochastic optimization problem by projected gradient method .", "This method attains a suboptimal convergence rate even under strong assumption on the objectives .", "It leverages on the theory of Lagrangian method in constrained optimization and attains the optimal convergence rate of O ( 1/ T ) in high probability for general Lipschitz continuous objectives .", "We cast the stochastic multiple objective optimization problem into a constrained optimization problem by choosing one function as the objective and try to bound other objectives by appropriate thresholds ."]}
{"orig_sents": ["4", "3", "6", "0", "1", "2", "5"], "shuf_sents": ["However , we show that by employing polynomial and histogram density estimates , we can introduce robustness with respect to distributional uncertainty sets without making the problem harder .", "We show that the optimum to the distributionally robust problem is the limit of a sequence of tractable semidefinite programming relaxations .", "We also give finite-sample consistency guarantees for the data-driven uncertainty sets .", "This set is a ball around a density function estimated from data samples , i.e. , it is data-driven and random .", "We consider robust optimization for polynomial optimization problems where the uncertainty set is a set of candidate probability density functions .", "Finally , we apply our model and solution method in a water network optimization problem .", "Polynomial optimization problems are inherently hard due to nonconvex objectives and constraints ."]}
{"orig_sents": ["5", "1", "3", "4", "2", "0"], "shuf_sents": ["State of the art predictive performance is demonstrated for toy examples and two neuroscience applications including up to a million features .", "It is important to allow not only the mean but also the variance and shape of the response density to change flexibly with features , which are massive-dimensional .", "The algorithm scales efficiently to approximately one million features .", "We propose a multiscale dictionary learning model , which expresses the conditional response density as a convex combination of dictionary densities , with the densities used and their weights dependent on the path through a tree decomposition of the feature space .", "A fast graph partitioning algorithm is applied to obtain the tree decomposition , with Bayesian methods then used to adaptively prune and average over different sub-trees in a soft probabilistic manner .", "Nonparametric estimation of the conditional distribution of a response given highdimensional features is a challenging problem ."]}
{"orig_sents": ["0", "3", "1", "2", "4"], "shuf_sents": ["A large number of algorithms in machine learning , from principal component analysis ( PCA ) , and its non-linear ( kernel ) extensions , to more recent spectral embedding and support estimation methods , rely on estimating a linear subspace from samples .", "Our results rely on natural assumptions on the spectral properties of the covariance operator associated to the data distribution , and hold for a wide class of metrics between subspaces .", "As special cases , we discuss sharp error estimates for the reconstruction properties of PCA and spectral support estimation .", "In this paper we introduce a general formulation of this problem and derive novel learning error estimates .", "Key to our analysis is an operator theoretic approach that has broad applicability to spectral learning methods ."]}
{"orig_sents": ["1", "0", "4", "2", "3"], "shuf_sents": ["Our method generalizes similar approaches to this problem such as spike triggered average , spike triggered covariance , or maximally informative dimensions .", "We present a novel non-parametric method for finding a subspace of stimulus features that contains all information about the response of a system .", "Since estimators of these metrics access the data via kernels , are easy to compute , and exhibit good theoretical convergence properties , our method can easily be generalized to populations of neurons or spike patterns .", "By using a particular expansion of the mutual information , we can show that the informative features must contain all information if we can make the uninformative features independent of the rest .", "Instead of maximizing the mutual information between features and responses directly , we use integral probability metrics in kernel Hilbert spaces to minimize the information between uninformative features and the combination of informative features and responses ."]}
{"orig_sents": ["7", "2", "8", "0", "3", "4", "6", "5", "1"], "shuf_sents": ["In this paper we study the so-called blind calibration , i.e .", "We study numerically the phase diagram of the blind calibration problem , and show that even in cases where convex relaxation is possible , our algorithm requires a smaller number of measurements and/or signals in order to perform well .", "As such it is very attractive for hardware implementations .", "when the training signals that are available to perform the calibration are sparse but unknown .", "We extend the approximate message passing ( AMP ) algorithm used in CS to the case of blind calibration .", "Our algorithm is also applicable to settings in which the sensors distort the measurements in other ways than multiplication by a gain , unlike previously suggested blind calibration algorithms based on convex relaxations .", "In the calibration-AMP , both the gains on the sensors and the elements of the signals are treated as unknowns .", "Compressed sensing ( CS ) is a concept that allows to acquire compressible signals with a small number of measurements .", "Therefore , correct calibration of the hardware is a central issue ."]}
{"orig_sents": ["4", "1", "8", "3", "6", "0", "7", "2", "5"], "shuf_sents": ["We establish high-dimensional consistency of our estimators for sequences of matrices X of increasing dimensions , with independent Gaussian entries .", "In particular , we consider the problem of learning a coefficient vector 0 Rp from noisy linear observations y = X0 + w Rn ( p > n ) and the popular estimation procedure of solving the 1 -penalized least squares objective known as the LASSO or Basis Pursuit DeNoising ( BPDN ) .", "To the best of our knowledge , this result is the first that provides an asymptotically consistent risk estimator for the LASSO solely based on data .", "These can be used to select the regularization parameter optimally .", "We study the fundamental problems of variance and risk estimation in high dimensional statistical modeling .", "In addition , we demonstrate through simulations that our variance estimation outperforms several existing methods in the literature .", "Our approach combines Stein 's unbiased risk estimate and the recent results of on the analysis of approximate message passing and the risk of LASSO .", "We establish validity for a broader class of Gaussian designs , conditional on a certain conjecture from statistical physics .", "In this context , we develop new estimators for the 2 estimation risk - 0 2 and the variance of the noise when distributions of 0 and w are unknown ."]}
{"orig_sents": ["5", "0", "4", "1", "2", "8", "6", "3", "7"], "shuf_sents": ["It was recently shown that BP converges to the correct MAP assignment for a class of loopy GMs with the following common feature : the Linear Programming ( LP ) relaxation to the MAP problem is tight ( has no integrality gap ) .", "The failure of BP in such cases motivates reverse engineering a solution - namely , given a tight LP , can we design a `good ' BP algorithm .", "In this paper , we design a BP algorithm for the Maximum Weight Matching ( MWM ) problem over general graphs .", "Our theoretical result suggests an efficient BP-based heuristic for the MWM problem , which consists of making sequential , `` cutting plane '' , modifications to the underlying GM .", "Unfortunately , tightness of the LP relaxation does not , in general , guarantee convergence and correctness of the BP algorithm .", "Max-product `belief propagation ' ( BP ) is a popular distributed heuristic for finding the Maximum A Posteriori ( MAP ) assignment in a joint probability distribution represented by a Graphical Model ( GM ) .", "The most significant part of our approach is the introduction of a novel graph transformation designed to force convergence of BP .", "Our experiments show that this heuristic performs as well as traditional cutting-plane algorithms using LP solvers on MWM problems .", "We prove that the algorithm converges to the correct optimum if the respective LP relaxation , which may include inequalities associated with non-intersecting odd-sized cycles , is tight ."]}
{"orig_sents": ["4", "1", "2", "0", "3"], "shuf_sents": ["Experimental results demonstrate the comparative efficiency of our algorithms for sensor selection in high-dimensional distributions .", "For pairs of vertices connected by a unique path in the graph , we show that there exist decompositions of nonlocal mutual information into local information measures that can be computed efficiently from the output of message passing algorithms .", "We integrate these decompositions into a computationally efficient greedy selector where the computational expense of quantification can be distributed across nodes in the network .", "We additionally derive an online-computable performance bound based on augmentations of the relevant latent variable set that , when such a valid augmentation exists , is applicable for any distribution with nuisances .", "We consider the sensor selection problem on multivariate Gaussian distributions where only a subset of latent variables is of inferential interest ."]}
{"orig_sents": ["8", "5", "3", "4", "0", "7", "1", "6", "2"], "shuf_sents": ["We consider a new criterion we call -optimality , which queries the node that minimizes the sum of the elements in the predictive covariance .", "In this paper we extend submodularity guarantees from V-optimality to -optimality using properties specific to GRFs .", "We test optimality on real-world graphs with both synthetic and real data and show that it outperforms V-optimality and other related methods on classification .", "V-optimality satisfies a submodularity property showing that greedy reduction produces a ( 1 - 1/e ) globally optimal solution .", "However , L2 loss may not characterise the true nature of 0/1 loss in classification problems and thus may not be the best choice for active learning .", "For active learning on GRFs , the commonly used V-optimality criterion queries nodes that reduce the L2 ( regression ) loss .", "We further show that GRFs satisfy the suppressor-free condition in addition to the conditional independence inherited from Markov random fields .", "-optimality directly optimizes the risk of the surveying problem , which is to determine the proportion of nodes belonging to one class .", "A common classifier for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes , equivalent to the harmonic predictor on Gaussian random fields ( GRFs ) ."]}
{"orig_sents": ["9", "8", "3", "2", "0", "6", "4", "7", "5", "1"], "shuf_sents": ["Subjects click on a blank screen and are shown the ordinate of the function at each clicked abscissa location .", "In 6 follow-up controlled experiments over 76 subjects , covering interpolation , extrapolation , and optimization tasks , we further confirm that Gaussian Processes provide a general and unified theoretical account to explain passive and active function learning and search in humans .", "We try to unravel the general underlying algorithm people may be using while searching for the maximum of an invisible 1D function .", "Many optimization algorithms have also been developed for this same purpose , but how do they compare to humans in terms of both performance and behavior ?", "Subjects win if they get close enough to the maximum location .", "Bayesian Optimization based on Gaussian Processes , which exploits all the x values tried and all the f ( x ) values obtained so far to pick the next x , predicts human performance and searched locations better .", "Their task is to find the function 's maximum in as few clicks as possible .", "Analysis over 23 non-maths undergraduates , optimizing 25 functions from different families , shows that humans outperform 24 well-known optimization algorithms .", "To optimize such functions , humans utilize sophisticated sequential decision-making strategies .", "Many real-world problems have complicated objective functions ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["To reduce the amount of labeling necessary to learn good models , our algorithms operate with weakly labeled data and we query additional examples based on entropies of local marginals , which are a good surrogate for uncertainty .", "In particular , the same performance as using the full training set can be obtained while only labeling 10 % of the random variables .", "In this paper we present active learning algorithms in the context of structured prediction problems .", "We demonstrate the effectiveness of our approach in the task of 3D layout prediction from single images , and show that good models are learned when labeling only a handful of random variables ."]}
{"orig_sents": ["3", "5", "4", "1", "0", "2"], "shuf_sents": ["For noisy recovery , our algorithm consistently estimates a low rank matrix corrupted with noise using ( nr3/2 polylog ( n ) ) entries .", "We also show that one can recover an order T tensor using ( nrT 1/2 T 2 log ( r ) ) entries .", "We complement our study with simulations that verify our theory and demonstrate the scalability of our algorithms .", "We study low rank matrix and tensor completion and propose novel algorithms that employ adaptive sampling schemes to obtain strong performance guarantees .", "In the absence of noise , we show that one can exactly recover a n n matrix of rank r from merely ( nr3/2 log ( r ) ) matrix entries .", "Our algorithms exploit adaptivity to identify entries that are highly informative for learning the column space of the matrix ( tensor ) and consequently , our results hold even when the row space is highly coherent , in contrast with previous analyses ."]}
{"orig_sents": ["3", "4", "2", "1", "5", "6", "0"], "shuf_sents": ["We evaluate our method on a preference elicitation problem and show that non-trivial K-step policies can be learned from just a few hundred interactions with the problem .", "We propose an efficient algorithm for solving our problem and prove that its expected cumulative regret increases logarithmically with time .", "In this paper , we study the setting where the expected gain is initially unknown , and it is learned by interacting repeatedly with the optimized function .", "Maximization of submodular functions has wide applications in machine learning and artificial intelligence .", "Adaptive submodular maximization has been traditionally studied under the assumption that the model of the world , the expected gain of choosing an item given previously selected items and their states , is known .", "Our regret bound captures the inherent property of submodular maximization , earlier mistakes are more costly than later ones .", "We refer to our approach as Optimistic Adaptive Submodular Maximization ( OASM ) because it trades off exploration and exploitation based on the optimism in the face of uncertainty principle ."]}
{"orig_sents": ["1", "0", "5", "4", "3", "2"], "shuf_sents": ["We study binary classification in an extreme case , where the algorithm only pays for negative labels .", "We propose a learning setting in which unlabeled data is free , and the cost of a label depends on its value , which is not known in advance .", "We also show a general competitive approach for learning with outcome-dependent costs .", "We design auditing algorithms for simple hypothesis classes ( thresholds and rectangles ) , and show that with these algorithms , the auditing complexity can be significantly lower than the active label complexity .", "We term the setting auditing , and consider the auditing complexity of an algorithm : the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error .", "Our motivation are applications such as fraud detection , in which investigating an honest transaction should be avoided if possible ."]}
{"orig_sents": ["2", "3", "0", "1", "4"], "shuf_sents": ["In this work , we study the label complexity of active learning algorithms that request labels in a given number of batches , as well as the tradeoff between the total number of queries and the number of rounds allowed .", "We additionally study the total cost sufficient for learning , for an abstract notion of the cost of requesting the labels of a given number of examples at once .", "In many practical applications of active learning , it is more cost-effective to request labels in large batches , rather than one-at-a-time .", "This is because the cost of labeling a large batch of examples at once is often sublinear in the number of examples in the batch .", "In particular , we find that for sublinear cost functions , it is often desirable to request labels in large batches ( i.e. , buying in bulk ) ; although this may increase the total number of labels requested , it reduces the total cost required for learning ."]}
{"orig_sents": ["4", "2", "3", "5", "0", "1", "6"], "shuf_sents": ["In each scenario , we prove that the criterion achieves near-maximal policy Gibbs error when constrained to a fixed budget .", "For practical implementations , we provide approximations to the maximum Gibbs error criterion for Bayesian conditional random fields and transductive Naive Bayes .", "This objective function , called the policy Gibbs error , is the expected error rate of a random classifier drawn from the prior distribution on the examples adaptively selected by the active learning policy .", "Exact maximization of the policy Gibbs error is hard , so we propose a greedy strategy that maximizes the Gibbs error at each iteration , where the Gibbs error on an instance is the expected error of a random classifier selected from the posterior label distribution on that instance .", "We introduce a new objective function for pool-based Bayesian active learning with probabilistic hypotheses .", "We apply this maximum Gibbs error criterion to three active learning scenarios : non-adaptive , adaptive , and batch active learning .", "Our experimental results on a named entity recognition task and a text classification task show that the maximum Gibbs error criterion is an effective active learning criterion for noisy models ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["We prove general and efficient reductions between a number of these problems , which demonstrate that algorithmic progress in inference automatically yields progress for `` pure data '' problems .", "We consider a number of classical and new computational problems regarding marginal distributions , and inference in models specifying a full joint distribution .", "Our main technique involves formulating the problems as linear programs , and proving that the dual separation oracle required by the ellipsoid method is provided by the target problem .", "This technique may be of independent interest in probabilistic inference ."]}
{"orig_sents": ["3", "2", "1", "0"], "shuf_sents": ["The resulting translations into propositional satisfiability and its extensions such as maximum satisfiability , satisfiability modulo theories , and answer set programming , enable us to prove optimal certain networks which have been previously found by stochastic search .", "To achieve efficient encodings , we develop a novel characterization of Markov network structure using a balancing condition on the separators between cliques forming the network .", "It is shown that the structure of such networks can be described in terms of constraints which enables the use of existing solver technology with optimization capabilities to compute optimal networks starting from initial scores computed from the data .", "We investigate the problem of learning the structure of a Markov network from data ."]}
{"orig_sents": ["5", "6", "1", "0", "4", "7", "3", "2"], "shuf_sents": ["We impose a Dirichlet process prior on the parameters .", "We show that even when the grouping is unknown , we can infer these parameter groups during learning via a Bayesian approach .", "Models learned with Gibbs SBA also generalize better than the models learned by MLE on real-world Senate voting data .", "Gibbs SBA 's performance is close to Gibbs sampling with exact likelihood calculation .", "Posterior inference usually involves calculating intractable terms , and we propose two approximation algorithms , namely a Metropolis-Hastings algorithm with auxiliary variables and a Gibbs sampling algorithm with `` stripped '' Beta approximation ( Gibbs SBA ) .", "In large-scale applications of undirected graphical models , such as social networks and biological networks , similar patterns occur frequently and give rise to similar parameters .", "In this situation , it is beneficial to group the parameters for more efficient learning .", "Simulations show that both algorithms outperform conventional maximum likelihood estimation ( MLE ) ."]}
{"orig_sents": ["4", "2", "0", "3", "1"], "shuf_sents": ["Our approach also leads to new ways to derive lower bounds on partition functions .", "The setting results in ragged energy landscapes that are challenging for alternative approaches to sampling and/or lower bounds .", "Specifically , we provide means for drawing either approximate or unbiased samples from Gibbs ' distributions by introducing low dimensional perturbations and solving the corresponding MAP assignments .", "We demonstrate empirically that our method excels in the typical `` high signal high coupling '' regime .", "In this paper we describe how MAP inference can be used to sample efficiently from Gibbs distributions ."]}
{"orig_sents": ["3", "6", "7", "2", "5", "4", "0", "1"], "shuf_sents": ["Second , it facilitates the design of EDML algorithms for new graphical models , leading to a new algorithm for learning parameters in Markov networks .", "We derive this algorithm in this paper , and show , empirically , that it can sometimes learn estimates more efficiently from complete data , compared to commonly used optimization methods , such as conjugate gradient and L-BFGS .", "In this paper , we propose a greatly simplified perspective on EDML , which casts it as a general approach to continuous optimization .", "EDML is a recently proposed algorithm for learning parameters in Bayesian networks .", "First , it makes immediate some results that were non-trivial to prove initially .", "The new perspective has several advantages .", "It was originally derived in terms of approximate inference on a metanetwork , which underlies the Bayesian approach to parameter estimation .", "While this initial derivation helped discover EDML in the first place and provided a concrete context for identifying some of its properties ( e.g. , in contrast to EM ) , the formal setting was somewhat tedious in the number of concepts it drew on ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["Moreover , when interactions are strong , Gibbs sampling may take exponential time to converge to the stationary distribution .", "We find that Gibbs sampling using the projected parameters is more accurate than with the original parameters when interaction strengths are strong and when limited time is available for sampling .", "We present an algorithm to project Ising model parameters onto a parameter set that is guaranteed to be fast mixing , under several divergences .", "Inference in general Ising models is difficult , due to high treewidth making treebased algorithms intractable ."]}
{"orig_sents": ["1", "0", "3", "2"], "shuf_sents": ["We propose a sampling algorithm , called PAWS , based on embedding the set into a higher-dimensional space which is then randomly projected using universal hash functions to a lower-dimensional subspace and explored using combinatorial search methods .", "We consider the problem of sampling from a probability distribution defined over a high-dimensional discrete set , specified for instance by a graphical model .", "We demonstrate that by using state-of-the-art combinatorial search tools , PAWS can efficiently sample from Ising grids with strong interactions and from software verification instances , while MCMC and variational methods fail in both cases .", "Our scheme can leverage fast combinatorial optimization tools as a blackbox and , unlike MCMC methods , samples produced are guaranteed to be within an ( arbitrarily small ) constant factor of the true probability distribution ."]}
{"orig_sents": ["1", "5", "2", "3", "4", "0", "6", "7"], "shuf_sents": ["We show that estimated inverses converge asymptotically in number of ( prior or posterior ) training samples .", "We describe a class of algorithms for amortized inference in Bayesian networks .", "Our approach is based on learning an inverse factorization of a model 's joint distribution : a factorization that turns observations into root nodes .", "Our algorithms accumulate information to estimate the local conditional distributions that constitute such a factorization .", "These stochastic inverses can be used to invert each of the computation steps leading to an observation , sampling backwards in order to quickly find a likely explanation .", "In this setting , we invest computation upfront to support rapid online inference for a wide range of queries .", "To make use of inverses before convergence , we describe the Inverse MCMC algorithm , which uses stochastic inverses to make block proposals for a Metropolis-Hastings sampler .", "We explore the efficiency of this sampler for a variety of parameter regimes and Bayes nets ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["The posterior over states is approximated by a piecewise linearized process of the Ornstein-Uhlenbeck type and the MAP estimation of the drift is facilitated by a sparse Gaussian process regression .", "Using a Gaussian process prior over the drift as a function of the state vector , we develop an approximate EM algorithm to deal with the unobserved , latent dynamics between observations .", "We introduce a nonparametric approach for estimating drift functions in systems of stochastic differential equations from sparse observations of the state vector ."]}
{"orig_sents": ["0", "2", "5", "4", "3", "6", "1"], "shuf_sents": ["Reliance on computationally expensive algorithms for inference has been limiting the use of Bayesian nonparametric models in large scale applications .", "Experiments on both synthetic data and real datasets demonstrate remarkable improvement on efficiency - orders of magnitude speed-up compared to the state-of-the-art .", "To tackle this problem , we propose a Bayesian learning algorithm for DP mixture models .", "In this process , new components will be incorporated on the fly when needed .", "Starting with a given prior , our method recursively transforms it into an approximate posterior through sequential variational approximation .", "Instead of following the conventional paradigm - random initialization plus iterative update , we take an progressive approach .", "The algorithm can reliably estimate a DP mixture model in one pass , making it particularly suited for applications with massive data ."]}
{"orig_sents": ["0", "5", "6", "2", "3", "1", "4"], "shuf_sents": ["Variational inference algorithms provide the most effective framework for largescale training of Bayesian nonparametric models .", "Births adaptively add components to the model to escape local optima , while merges remove redundancy and improve speed .", "Our algorithm maintains finite-dimensional sufficient statistics from batches of the full dataset , requiring some additional memory but still scaling to millions of examples .", "Exploiting nested families of variational bounds for infinite nonparametric models , we develop principled birth and merge moves allowing non-local optimization .", "Using Dirichlet process mixture models for image clustering and denoising , we demonstrate major improvements in robustness and accuracy .", "Stochastic online approaches are promising , but are sensitive to the chosen learning rate and often converge to poor local optima .", "We present a new algorithm , memoized online variational inference , which scales to very large ( yet finite ) datasets while avoiding the complexities of stochastic gradient ."]}
{"orig_sents": ["0", "4", "3", "5", "6", "2", "1"], "shuf_sents": ["In this paper , we seek robust policies for uncertain Markov Decision Processes ( MDPs ) .", "We also provide a Sample Average Approximation ( SAA ) analysis to compute a posteriori error bounds .", "Finally , to demonstrate the empirical effectiveness of our sampling approaches , we provide comparisons against benchmark algorithms on two domains from literature .", "Recent work has proposed minimax regret as a suitable alternative to the maximin objective for robust optimization .", "Most robust optimization approaches for these problems have focussed on the computation of maximin policies which maximize the value corresponding to the worst realization of the uncertainty .", "However , existing algorithms for handling minimax regret are restricted to models with uncertainty over rewards only .", "We provide algorithms that employ sampling to improve across multiple dimensions : ( a ) Handle uncertainties over both transition and reward models ; ( b ) Dependence of model uncertainties across state , action pairs and decision epochs ; ( c ) Scalability and quality bounds ."]}
{"orig_sents": ["1", "5", "0", "2", "3", "4"], "shuf_sents": ["PI 1 We2Ishow that 1 Howard 's 1 22 terminates 1 1 nm 1 after at most n ( m 1 ) 1 '' log 1 '' = O 1 '' log 1 '' iterations , improving by a factor O ( log 1 n ) a result by1 , while 22 Simplex-PI 1 2 terminates 1 22 2 1 m 1 2 after at most n ( m 1 ) 1 + 1 '' log 1 '' = O n1 '' log 1 '' iterations , improving by a factor O ( log n ) a result by .", "Given a Markov Decision Process ( MDP ) with n states and m actions per state , we study the number of iterations needed by Policy Iteration ( PI ) algorithms to converge to the optimal `` -discounted optimal policy .", "Under some structural assumptions of the MDP , we then consider bounds that are independent of the discount factor `` : given a measure of the maximal transient time *t and the maximal time *r to revisit states in recurrent classes under all policies , we show that Simplex-PI terminates after at most n2 ( m # $ 1 ) ( A*r log ( n*r ) E + A*r log ( n*t ) E ) ( m 1 ) An*t log ( n*t ) E + An*t log ( n2 *t ) E = ! ``n3 m2 *t *r iterations .", "This generalizes a recent result for determinO istic MDPs by , in which *t AE n and *r AE n. We explain why similar results seem hard to derive for Howard 's PI .", "Finally , under the additional ( restrictive ) assumption that the state space is partitioned in two sets , respectively states that are transient and recurrent for all policies , we show that Howard 's PI terminates after at most n ( m 1 ) ( A*t log n*t E + A*r log n*r E ) = O ( nm ( * t + *r ) ) iterations while Simplex-PI terminates after n ( m 1 ) ( An*t log n*t E + A*r log n*r E ) = 2 m ( *t + *r ) ) iterations .", "We consider two variations of PI : Howard 's PI that changes the actions in all states with a positive advantage , and Simplex-PI that only changes the action in the state with maximal Iadvantage ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We establish further efficiency and asymptotic performance guarantees that apply even if Q does not lie in Q , for the special case where Q is the span of pre-specified indicator functions over disjoint sets .", "We establish that when the true value function Q lies within the hypothesis class Q , OCP selects optimal actions over all but at most dimE episodes , where dimE denotes the eluder dimension .", "We consider the problem of reinforcement learning over episodes of a finitehorizon deterministic system and as a solution propose optimistic constraint propagation ( OCP ) , an algorithm designed to synthesize efficient exploration and value function generalization ."]}
{"orig_sents": ["5", "1", "3", "4", "2", "6", "0"], "shuf_sents": ["Our algorithm performs as well as state-of-the-art optimistic planning algorithms , and better than a related algorithm which additionally assumes the knowledge of all transition distributions .", "We propose a new algorithm which is based on the construction of a forest of planning trees , where each tree corresponds to a random realization of the stochastic environment .", "We provide a finite-sample analysis and discuss the trade-off between the principles of optimism and safety .", "The trees are constructed using a `` safe '' optimistic planning strategy combining the optimistic principle ( in order to explore the most promising part of the search space first ) with a safety principle ( which guarantees a certain amount of uniform exploration ) .", "In the decision-making step of the algorithm , the individual trees are aggregated and an immediate action is recommended .", "This paper addresses the problem of online planning in Markov decision processes using a randomized simulator , under a budget constraint .", "We also report numerical results on a benchmark problem ."]}
{"orig_sents": ["4", "1", "3", "0", "2"], "shuf_sents": ["We describe a variant of the recently proposed Relative Entropy Policy Search algorithm and show that its regret after T episodes is 2 L|X ||A|T log ( |X ||A|/L ) in the bandit setting and 2L T log ( |X ||A|/L ) in the full information setting , given that the learner has perfect knowledge of the transition probabilities of the underlying MDP .", "The natural performance measure in this learning problem is the regret defined as the difference between the total loss of the best stationary policy and the total loss suffered by the learner .", "These guarantees largely improve previously known results under much milder assumptions and can not be significantly improved under general assumptions .", "We assume that the learner is given access to a finite action space A and the state space X has a layered structure with L layers , so that state transitions are only possible between consecutive layers .", "We study the problem of online learning in finite episodic Markov decision processes ( MDPs ) where the loss function is allowed to change between episodes ."]}
{"orig_sents": ["1", "3", "2", "13", "11", "4", "9", "6", "7", "5", "8", "0", "12", "10"], "shuf_sents": ["We show that it also can be efficiently solved for adversarial graphs and randomly chosen losses .", "We study the problem of online learning Markov Decision Processes ( MDPs ) when both the transition distributions and loss functions are chosen by an adversary .", "The regret is independent of the size of the state and action spaces .", "We present an algorithm that , under a mixing assumption , achieves O ( T log || + log || ) regret with respect to a comparison set of policies .", "Here , in each episode an adversary may choose a weighted directed acyclic graph with an identified start and finish node .", "This problem is a special case of the online MDP problem .", "At the end of each episode the loss function ( given by weights on the edges ) is revealed to the learning algorithm .", "The goal is to minimize regret with respect to a fixed policy for selecting paths .", "It was shown that for randomly chosen graphs and adversarial losses , the problem can be efficiently solved .", "The goal of the learning algorithm is to choose a path that minimizes the loss while traversing from the start to finish node .", "Finally , we present an efficient algorithm whose regret scales linearly with the number of distinct graphs .", "We also consider the episodic adversarial online shortest path problem .", "When both graphs and losses are adversarially chosen , we show that designing efficient algorithms for the adversarial online shortest path problem ( and hence for the adversarial MDP problem ) is as hard as learning parity with noise , a notoriously difficult problem that has been used to design efficient cryptographic schemes .", "When expectations over sample paths can be computed efficiently and the comparison set has polynomial size , this algorithm is efficient ."]}
{"orig_sents": ["7", "2", "4", "6", "5", "0", "8", "3", "1"], "shuf_sents": ["We establish a tight bound on the rate of change of the underlying state , under which individuals can track the parameter with a bounded variance .", "Finally , we provide an upper bound on the regret of the proposed methods , measured as an average of errors in estimating the parameter in a finite time .", "We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period .", "We observe that only one of the estimators recovers the optimal MSD , which underscores the impact of the objective function decomposition on the learning quality .", "Unlike many existing approaches , the underlying state is dynamic , and evolves according to a geometric random walk .", "Based on the decomposition of the global loss function , we introduce two update mechanisms , each of which generates an estimate of the true state .", "We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss .", "This paper addresses the problem of online learning in a dynamic setting .", "Then , we characterize explicit expressions for the steady state mean-square deviation ( MSD ) of the estimates from the truth , per individual ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We develop a probabilistic approach for accurate network modeling using node popularities within the framework of the mixed-membership stochastic blockmodel ( MMSB ) .", "We evaluate the link prediction accuracy of our algorithm on nine real-world networks with up to 60,000 nodes , and on simulated networks with degree distributions that follow a power law .", "Our model integrates two basic properties of nodes in social networks : homophily and preferential connection to popular nodes .", "We develop a scalable algorithm for posterior inference , based on a novel nonconjugate variant of stochastic variational inference .", "We demonstrate that the AMP predicts significantly better than the MMSB ."]}
{"orig_sents": ["0", "2", "1"], "shuf_sents": ["We propose a scalable approach for making inference about latent spaces of large networks .", "When compared to the state-of-the-art probabilistic approaches , our method is several orders of magnitude faster , with competitive or improved accuracy for latent space recovery and link prediction .", "With a succinct representation of networks as a bag of triangular motifs , a parsimonious statistical model , and an efficient stochastic variational inference algorithm , we are able to analyze real networks with over a million vertices and hundreds of latent roles on a single machine in a matter of hours , a setting that is out of reach for many existing methods ."]}
{"orig_sents": ["0", "4", "5", "2", "1", "3"], "shuf_sents": ["Unstructured social group activity recognition in web videos is a challenging task due to 1 ) the semantic gap between class labels and low-level visual features and 2 ) the lack of labeled training data .", "An efficient variational EM algorithm is presented for model parameter estimation and inference .", "Rectified linear units are utilized to increase the expressive power of topics so as to explain better video data containing complex contents and make variational inference tractable for the proposed model .", "Experimental results on the Unstructured Social Activity Attribute dataset show that our model achieves state of the art performance and outperforms other supervised topic model in terms of classification accuracy , particularly in the case of a very small number of labeled training videos .", "To tackle this problem , we propose a `` relevance topic model '' for jointly learning meaningful mid-level representations upon bagof-words ( BoW ) video representations and a classifier with sparse weights .", "In our approach , sparse Bayesian learning is incorporated into an undirected topic model ( i.e. , Replicated Softmax ) to discover topics which are relevant to video classes and suitable for prediction ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We demonstrate the usefulness of our framework , with variational Bayes ( VB ) as the primitive , by fitting the latent Dirichlet allocation model to two large-scale document collections .", "We demonstrate the advantages of our algorithm over stochastic variational inference ( SVI ) by comparing the two after a single pass through a known amount of data -- a case where SVI may be applied -- and in the streaming setting , where SVI does not apply .", "The framework makes streaming updates to the estimated posterior according to a user-specified approximation batch primitive .", "We present SDA-Bayes , a framework for ( S ) treaming , ( D ) istributed , ( A ) synchronous computation of a Bayesian posterior ."]}
{"orig_sents": ["1", "5", "3", "4", "2", "0"], "shuf_sents": ["Extensive empirical results demonstrate the promise .", "Logistic-normal topic models can effectively discover correlation structures among latent topics .", "To improve time efficiency , we further present a parallel implementation that can deal with large-scale applications and learn the correlation structures of thousands of topics from millions of documents .", "Existing algorithms either make restricting mean-field assumptions or are not scalable to large-scale applications .", "This paper presents a partially collapsed Gibbs sampling algorithm that approaches the provably correct distribution by exploring the ideas of data augmentation .", "However , their inference remains a challenge because of the non-conjugacy between the logistic-normal prior and multinomial topic mixing proportions ."]}
{"orig_sents": ["5", "1", "7", "3", "9", "10", "4", "2", "0", "8", "6"], "shuf_sents": ["Our identifiability results allow for general ( non-degenerate ) distributions for modeling the topic proportions , and thus , we can handle arbitrarily correlated topics in our framework .", "In this paper , we specify which overcomplete models can be identified given observable moments of a certain order .", "in the overcomplete regime .", "While general overcomplete topic models are not identifiable , we establish generic identifiability under a constraint , referred to as topic persistence .", "We establish that random structured topic models are identifiable w.h.p .", "Overcomplete latent representations have been very popular for unsupervised feature learning in recent years .", "Keywords : Overcomplete representation , admixture models , generic identifiability , tensor decomposition .", "We consider probabilistic admixture or topic models in the overcomplete regime , where the number of latent topics can greatly exceed the size of the observed word vocabulary .", "Our identifiability results imply uniqueness of a class of tensor decompositions with structured sparsity which is contained in the class of Tucker decompositions , but is more general than the Candecomp/Parafac ( CP ) decomposition .", "Our sufficient conditions for identifiability involve a novel set of `` higher order '' expansion conditions on the topic-word matrix or the population structure of the model .", "This set of higher-order expansion conditions allow for overcomplete models , and require the existence of a perfect matching from latent topics to higher order observed words ."]}
{"orig_sents": ["1", "3", "0", "2"], "shuf_sents": ["If there is a sparse subset of relevant dimensions that determine the mean separation , then the sample complexity only depends on the number of relevant dimensions and mean separation , and can be achieved by a simple computationally efficient procedure .", "While several papers have investigated computationally and statistically efficient methods for learning Gaussian mixtures , precise minimax bounds for their statistical performance as well as fundamental limits in high-dimensional settings are not well-understood .", "Our results provide the first step of a theoretical basis for recent methods that combine feature selection and clustering .", "In this paper , we provide precise information theoretic bounds on the clustering accuracy and sample complexity of learning a mixture of two isotropic Gaussians in high dimensions under small mean separation ."]}
{"orig_sents": ["3", "4", "5", "0", "1", "2"], "shuf_sents": ["In particular , when the unknown true tensor is low-rank in a specific unknown mode , this approach performs as well as knowing the mode with the smallest rank .", "Along the way , we show a novel duality result for structured Schatten norms , which is also interesting in the general context of structured sparsity .", "We confirm through numerical simulations that our theory can precisely predict the scaling behaviour of the mean squared error .", "We study a new class of structured Schatten norms for tensors that includes two recently proposed norms ( `` overlapped '' and `` latent '' ) for convex-optimizationbased tensor decomposition .", "We analyze the performance of `` latent '' approach for tensor decomposition , which was empirically found to perform better than the `` overlapped '' approach in some settings .", "We show theoretically that this is indeed the case ."]}
{"orig_sents": ["0", "5", "4", "2", "1", "3"], "shuf_sents": ["Seriation seeks to reconstruct a linear order between variables using unsorted similarity information .", "This relaxation also allows us to impose additional structural constraints on the solution , to solve semi-supervised seriation problems .", "The seriation problem can be solved exactly by a spectral algorithm in the noiseless case and we produce a convex relaxation for the 2-SUM problem to improve the robustness of solutions in a noisy setting .", "We present numerical experiments on archeological data , Markov chains and gene sequences .", "We prove the equivalence between the seriation and the combinatorial 2-SUM problem ( a quadratic minimization problem over permutations ) over a class of similarity matrices .", "It has direct applications in archeology and shotgun gene sequencing for example ."]}
{"orig_sents": ["2", "1", "0", "3"], "shuf_sents": ["In contrast , we propose a new method , Permutation Synchronization , which finds all the matchings jointly , in one shot , via a relaxation to eigenvector decomposition .", "At present it is usually solved by matching the sets pairwise , in series .", "The problem of matching not just two , but m different sets of objects to each other arises in many contexts , including finding the correspondence between feature points across multiple images in computer vision .", "The resulting algorithm is both computationally efficient , and , as we demonstrate with theoretical arguments as well as experimental results , much more stable to noise than previous methods ."]}
{"orig_sents": ["6", "7", "3", "0", "1", "2", "5", "4"], "shuf_sents": ["In contrast to previous approaches , our method is neither approximate , nor impractical , nor does it need any cumbersome parameter tuning .", "Moreover , it is easy to implement and parallelize .", "A key component of our method is a formulation of the discrete submodular minimization problem as a continuous best approximation problem that is solved through a sequence of reflections , and its solution can be easily thresholded to obtain an optimal discrete solution .", "While general submodular minimization is challenging , we propose a new method that exploits existing decomposability of submodular functions .", "In our experiments , we illustrate the benefits of our method on two image segmentation tasks .", "This method solves both the continuous and discrete formulations of the problem , and therefore has applications in learning , inference , and reconstruction .", "Recently , it has become evident that submodularity naturally captures widely occurring concepts in machine learning , signal processing and computer vision .", "Consequently , there is need for efficient optimization procedures for submodular functions , especially for minimization problems ."]}
{"orig_sents": ["3", "2", "4", "5", "1", "0"], "shuf_sents": ["We complete this picture , and also support our theoretical claims by empirical results .", "Curiously , curvature has been known to influence approximations for submodular maximization , but its effect on minimization , approximation and learning has hitherto been open .", "We show that the complexity of all three problems depends on the `` curvature '' of the submodular function , and provide lower and upper bounds that refine and improve previous results .", "We investigate three related and important problems connected to machine learning : approximating a submodular function everywhere , learning a submodular function ( in a PAC-like setting ) , and constrained minimization of submodular functions .", "Our proof techniques are fairly generic .", "We either use a black-box transformation of the function ( for approximation and learning ) , or a transformation of algorithms to use an appropriate surrogate function ( for minimization ) ."]}
{"orig_sents": ["2", "1", "0", "4", "3"], "shuf_sents": ["These approximate LP solutions can be computed efficiently by applying a parallel stochastic-coordinate-descent method to a quadratic-penalty formulation of the LP .", "This paper shows that we can recover solutions of comparable quality by rounding an approximate LP solution instead of the exact one .", "Many problems in machine learning can be solved by rounding the solution of an appropriate linear program ( LP ) .", "Our experiments demonstrate that on such combinatorial problems as vertex cover , independent set and multiway-cut , our approximate rounding scheme is up to an order of magnitude faster than Cplex ( a commercial LP solver ) while producing solutions of similar quality .", "We derive worst-case runtime and solution quality guarantees of this scheme using novel perturbation and convergence analysis ."]}
{"orig_sents": ["4", "1", "3", "6", "2", "5", "0"], "shuf_sents": ["The model , while novel in the optimization procedure , further develops a long-standing functional hypothesis that the ventral visual stream is a hierarchically arranged series of processing stages optimized for visual object recognition .", "To understand this ability , we seek to construct models of the ventral stream , the series of cortical areas thought to subserve object recognition .", "Previous work has shown that all known models of the ventral stream fail to capture the RDM pattern observed in either IT cortex , the highest ventral area , or in the human ventral stream .", "One tool to assess the quality of a model of the ventral stream is the Representational Dissimilarity Matrix ( RDM ) , which uses a set of visual stimuli and measures the distances produced in either the brain ( i.e .", "Humans recognize visually-presented objects rapidly and accurately .", "In this work , we construct models of the ventral stream using a novel optimization procedure for category-level object recognition problems , and produce RDMs resembling both macaque IT and human ventral stream .", "fMRI voxel responses , neural firing rates ) or in models ( features ) ."]}
{"orig_sents": ["7", "2", "3", "0", "6", "8", "4", "5", "1"], "shuf_sents": ["Here we address these challenges by developing Bayesian reduced rank regression methods for RF estimation .", "We develop these methods for Gaussian and Poisson noise models , and show that low-rank estimates substantially outperform full rank estimates using neural data from retina and V1 .", "In typical experiments with naturalistic or flickering spatiotemporal stimuli , RFs are very high-dimensional , due to the large number of coefficients needed to specify an integration profile across time and space .", "Estimating these coefficients from small amounts of data poses a variety of challenging statistical and computational problems .", "We introduce a novel prior over low-rank RFs using the restriction of a matrix normal prior to the manifold of low-rank matrices , and use `` localized '' row and column covariances to obtain sparse , smooth , localized estimates of the spatial and temporal RF components .", "We develop two methods for inference in the resulting hierarchical model : ( 1 ) a fully Bayesian method using blocked-Gibbs sampling ; and ( 2 ) a fast , approximate method that employs alternating ascent of conditional marginal likelihoods .", "This corresponds to modeling the RF as a sum of space-time separable ( i.e. , rank-1 ) filters .", "The receptive field ( RF ) of a sensory neuron describes how the neuron integrates sensory stimuli over time and space .", "This approach substantially reduces the number of parameters needed to specify the RF , from 1K-10K down to mere 100s in the examples we consider , and confers substantial benefits in statistical power and computational efficiency ."]}
{"orig_sents": ["1", "2", "8", "3", "6", "0", "7", "4", "5"], "shuf_sents": ["The resulting theory generalizes moment-based estimators such as the spike-triggered covariance , and , in the Gaussian noise case , provides closed-form estimators under a large class of non-Gaussian stimulus distributions .", "We describe a set of fast , tractable methods for characterizing neural responses to high-dimensional sensory stimuli using a model we refer to as the generalized quadratic model ( GQM ) .", "The GQM consists of a low-rank quadratic function followed by a point nonlinearity and exponential-family noise .", "Special cases of the GQM include the 2nd-order Volterra model and the elliptical Linear-Nonlinear-Poisson model .", "Moreover , the GQM provides a natural framework for combining multi-dimensional stimulus sensitivity and spike-history dependencies within a single model .", "We show applications to both analog and spiking data using intracellular recordings of V1 membrane potential and extracellular recordings of retinal spike trains .", "Here we show that for `` canonical form '' GQMs , spectral decomposition of the first two response-weighted moments yields approximate maximumlikelihood estimators via a quantity called the expected log-likelihood .", "We show that these estimators are fast and provide highly accurate estimates with far lower computational cost than full maximum likelihood .", "The quadratic function characterizes the neuron 's stimulus selectivity in terms of a set linear receptive fields followed by a quadratic combination rule , and the invertible nonlinearity maps this output to the desired response range ."]}
{"orig_sents": ["1", "4", "6", "0", "3", "5", "2"], "shuf_sents": ["We analytically derive the solution that minimizes the L2 reconstruction loss .", "In many neural systems , information about stimulus variables is often represented in a distributed manner by means of a population code .", "Results illustrating these optimal representations are shown for some input distributions that may be relevant for understanding the coding of perceptual pathways .", "We compared our solution with other well-known criteria such as maximal mutual information .", "It is generally assumed that the responses of the neural population are tuned to the stimulus statistics , and most prior work has investigated the optimal tuning characteristics of one or a small number of stimulus variables .", "Our solution suggests that the optimal weights do not necessarily decorrelate the inputs , and the optimal nonlinearity differs from the conventional equalization solution .", "In this work , we investigate the optimal tuning for diffeomorphic representations of high-dimensional stimuli ."]}
{"orig_sents": ["2", "1", "7", "6", "4", "8", "0", "3", "5"], "shuf_sents": ["We show on model data that the parameters of latent linear dynamical systems can be recovered , and that even if the dynamics are not stationary we can still recover the true latent subspace .", "Finding these dynamics requires models that take into account biophysical constraints and can be fit efficiently and robustly .", "Recordings from large populations of neurons make it possible to search for hypothesized low-dimensional dynamics .", "We also demonstrate an extension of nuclear norm minimization that can separate sparse local connections from global latent dynamics .", "The basic method extends PCA to the exponential family using nuclear norm minimization .", "Finally , we demonstrate improved prediction on real neural data from monkey motor cortex compared to fitting linear dynamical models without nuclear norm smoothing .", "The results can be combined with spectral methods to learn dynamical systems models .", "Here , we present an approach to dimensionality reduction for neural data that is convex , does not make strong assumptions about dynamics , does not require averaging over many trials and is extensible to more complex statistical models that combine local and global influences .", "We evaluate the effectiveness of this method using an exact decomposition of the Bregman divergence that is analogous to variance explained for PCA ."]}
{"orig_sents": ["5", "4", "2", "0", "1", "3"], "shuf_sents": ["By exploiting the sparsity of neural spiking we demonstrate that the number of measurements needed per timestep is significantly smaller than the total number of neurons , a result that can potentially enable imaging of larger populations at considerably faster rates compared to traditional raster-scanning techniques .", "Unlike traditional CS setups , our problem involves a block-diagonal sensing matrix and a non-orthogonal sparse basis that spans multiple timesteps .", "We also address the problem of demixing the spatial locations of the neurons using rank-penalized matrix factorization methods .", "We provide tight approximations to the number of measurements needed for perfect deconvolution for certain classes of spiking processes , and show that this number undergoes a `` phase transition , '' which we characterize using modern tools relating conic geometry to compressed sensing .", "We develop scalable nonnegative deconvolution methods for extracting the neuronal spike time series from such observations .", "We propose a compressed sensing ( CS ) calcium imaging framework for monitoring large neuronal populations , where we image randomized projections of the spatial calcium concentration at each timestep , instead of measuring the concentration at individual locations ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["Our technique is based on breaking the full rankings into pairwise comparisons , and then computing parameters that satisfy a set of generalized moment conditions .", "In this paper we propose a class of efficient Generalized Method-of-Moments ( GMM ) algorithms for computing parameters of the Plackett-Luce model , where the data consists of full rankings over alternatives .", "We identify conditions for the output of GMM to be unique , and identify a general class of consistent and inconsistent breakings .", "We then show by theory and experiments that our algorithms run significantly faster than the classical Minorize-Maximization ( MM ) algorithm , while achieving competitive statistical efficiency ."]}
{"orig_sents": ["2", "1", "3", "0"], "shuf_sents": ["Results on both real and simulated data provide support for the scalability of our approach .", "Our model extends the popular setup in Berry , Levinsohn and Pakes ( 1995 ) to allow for the data-driven classification of agents ' types using agent-level data .", "We propose a model for demand estimation in multi-agent , differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents ' types .", "We focus on applications involving data on agents ' ranking over alternatives , and present theoretical conditions that establish the identifiability of the model and uni-modality of the likelihood/posterior ."]}
{"orig_sents": ["0", "2", "3", "4", "1"], "shuf_sents": ["In standard matrix completion theory , it is required to have at least O ( n ln2 n ) observed entries to perfectly recover a low-rank matrix M of size n x n , leading to a large number of observations when n is large .", "We demonstrate the effectiveness of the proposed approach for matrix completion in transductive incomplete multi-label learning .", "In many real tasks , side information in addition to the observed entries is often available .", "In this work , we develop a novel theory of matrix completion that explicitly explore the side information to reduce the requirement on the number of observed entries .", "We show that , under appropriate conditions , with the assistance of side information matrices , the number of observed entries needed for a perfect recovery of matrix M can be dramatically reduced to O ( ln n ) ."]}
{"orig_sents": ["1", "4", "2", "6", "3", "5", "0"], "shuf_sents": ["We show that XNV consistently outperforms a state-of-the-art algorithm for semi-supervised learning : substantially improving predictive performance and reducing the variability of performance on a wide variety of real-world datasets , whilst also reducing runtime by orders of magnitude .", "This paper presents Correlated Nystrom Views ( XNV ) , a fast semi-supervised algorithm for regression and classification .", "First , it generates two views consisting of computationally inexpensive random features .", "It has been shown that CCA regression can substantially reduce variance with a minimal increase in bias if the views contains accurate estimators .", "The algorithm draws on two main ideas .", "Recent theoretical and empirical work shows that regression with random features closely approximates kernel regression , implying that the accuracy requirement holds for random views .", "Second , multiview regression , using Canonical Correlation Analysis ( CCA ) on unlabeled data , biases the regression towards useful features ."]}
{"orig_sents": ["5", "3", "2", "6", "4", "1", "0"], "shuf_sents": ["Experimental results demonstrated the effectiveness of our approach both in synthetic and real datasets .", "For further justification , we provide analytical considerations including an interpretation as a cross-validation of a propagation model in the feature space , and an error analysis based on a low dimensional manifold model .", "Consequently , the label estimation heavily depends on edge weights in a graph which represent similarity of each node pair .", "Label propagation assumes that data points ( nodes ) connected in a graph should have similar labels .", "In this approach , edge weights represent both similarity and local reconstruction weight simultaneously , both being reasonable for label propagation .", "Label propagation is one of the state-of-the-art methods for semi-supervised learning , which estimates labels by propagating label information through a graph .", "We propose a method for a graph to capture the manifold structure of input features using edge weights parameterized by a similarity function ."]}
{"orig_sents": ["1", "6", "2", "0", "3", "4", "5"], "shuf_sents": ["By restricting the operators to be shift invariant , our approach can be thought as a way of learning sparsity-promoting convolutional operators .", "In this paper , we propose a new computationally efficient framework for learning sparse models .", "The supervised training of the proposed model is formulated as a bilevel optimization problem , in which the operators are optimized to achieve the best possible performance on a specific task , e.g. , reconstruction or classification .", "Leveraging recent ideas on fast trainable regressors designed to approximate exact sparse codes , we propose a way of constructing feed-forward networks capable of approximating the learned models at a fraction of the computational cost of exact solvers .", "In the shift-invariant case , this leads to a principled way of constructing a form of taskspecific convolutional networks .", "We illustrate the proposed models on several experiments in music analysis and image processing applications .", "We formulate a unified approach that contains as particular cases models promoting sparse synthesis and analysis type of priors , and mixtures thereof ."]}
{"orig_sents": ["2", "0", "4", "3", "1", "5"], "shuf_sents": ["It is well known that standard computationally tractable sparse recovery algorithms , such as the Lasso , OMP , and their various extensions , perform poorly when the measurement matrix contains highly correlated columns .", "We prove that SWAP can easily be used as a wrapper around standard sparse recovery algorithms for improved performance .", "We consider the problem of accurately estimating a high-dimensional sparse vector using a small number of linear measurements that are contaminated by noise .", "SWAP is surprisingly effective in handling measurement matrices with high correlations .", "We develop a simple greedy algorithm , called SWAP , that iteratively swaps variables until a desired loss function can not be decreased any further .", "We theoretically quantify the statistical guarantees of SWAP and complement our analysis with numerical results on synthetic and real data ."]}
{"orig_sents": ["2", "6", "4", "1", "3", "0", "5"], "shuf_sents": ["We show that using predicted latent factors produces sensible recommendations , despite the fact that there is a large semantic gap between the characteristics of a song that affect user preference and the corresponding audio signal .", "In this paper , we propose to use a latent factor model for recommendation , and predict the latent factors from music audio when they can not be obtained from usage data .", "Automatic music recommendation has become an increasingly relevant problem in recent years , since a lot of music is now sold and consumed digitally .", "We compare a traditional approach using a bag-of-words representation of the audio signals with deep convolutional neural networks , and evaluate the predictions quantitatively and qualitatively on the Million Song Dataset .", "However , this approach suffers from the cold start problem : it fails when no usage data is available , so it is not effective for recommending new and unpopular songs .", "We also show that recent advances in deep learning translate very well to the music recommendation setting , with deep convolutional neural networks significantly outperforming the traditional approach .", "Most recommender systems rely on collaborative filtering ."]}
{"orig_sents": ["3", "4", "0", "2", "1", "5"], "shuf_sents": ["By exploiting a mixture model representation of this penalty , we show that a suitably chosen set of latent variables enables to derive an ExpectationMaximization algorithm to obtain a Maximum A Posteriori estimate of the completed low rank matrix .", "The algorithm is simple to implement and can scale to large matrices .", "The resulting algorithm is an iterative soft-thresholded algorithm which iteratively adapts the shrinkage coefficients associated to the singular values .", "We propose a novel class of algorithms for low rank matrix completion .", "Our approach builds on novel penalty functions on the singular values of the low rank matrix .", "We provide numerical comparisons between our approach and recent alternatives showing the interest of the proposed approach for low rank matrix completion ."]}
{"orig_sents": ["5", "2", "0", "6", "1", "3", "7", "4"], "shuf_sents": ["For instance , content may be served to a group of users by taking advantage of an underlying network of social relationships among them .", "More specifically , we design and analyze a global recommendation strategy which allocates a bandit algorithm to each network node ( user ) and allows it to `` share '' signals ( contexts and payoffs ) with the neghboring nodes .", "In many cases , however , these applications have a strong social component , whose integration in the bandit algorithm could lead to a dramatic performance increase .", "We then derive two more scalable variants of this strategy based on different ways of clustering the graph nodes .", "Our experiments , carried out on synthetic and real-world datasets , show a consistent increase in prediction performance obtained by exploiting the network structure .", "Multi-armed bandit problems formalize the exploration-exploitation trade-offs arising in several industrially relevant applications , such as online advertisement and , more generally , recommendation systems .", "In this paper , we introduce novel algorithmic approaches to the solution of such networked bandit problems .", "We experimentally compare the algorithm and its variants to state-of-the-art methods for contextual bandits that do not use the relational information ."]}
{"orig_sents": ["6", "1", "2", "0", "4", "5", "3"], "shuf_sents": ["This paper formalizes this notion of contrastive learning for mixture models , and develops spectral algorithms for inferring mixture components specific to a foreground data set when contrasted with a background data set .", "For example , given a background corpus of news articles together with writings of a particular author , one may want a topic model that explains word patterns and themes specific to the author .", "Another example comes from genomics , in which biological signals may be collected from different regions of a genome , and one wants a model that captures the differential statistics observed in these regions .", "The method is demonstrated on applications in contrastive topic modeling and genomic sequence analysis .", "The method builds on recent moment-based estimators and tensor decompositions for latent variable models , and has the intuitive feature of using background data statistics to appropriately modify moments estimated from foreground data .", "A key advantage of the method is that the background data need only be coarsely modeled , which is important when the background is too complex , noisy , or not of interest .", "In many natural settings , the analysis goal is not to characterize a single data set in isolation , but rather to understand the difference between one set of observations and another ."]}
{"orig_sents": ["2", "4", "1", "3", "0", "5"], "shuf_sents": ["In addition , we show that this framework can be extended to sampling from cardinalityconstrained DPPs .", "However , computing the determinant requires time cubic in the number of items , and is hence impractical for large sets .", "Determinantal Point Process ( DPP ) has gained much popularity for modeling sets of diverse items .", "In this paper , we address this problem by constructing a rapidly mixing Markov chain , from which we can acquire a sample from the given DPP in sub-cubic time .", "The gist of DPP is that the probability of choosing a particular set of items is proportional to the determinant of a positive definite matrix that defines the similarity of those items .", "As an application , we show how our sampling algorithm can be used to provide a fast heuristic for determining the number of clusters , resulting in better clustering ."]}
{"orig_sents": ["1", "3", "7", "4", "6", "2", "5", "0"], "shuf_sents": ["Simulation results show MCs for which this method gives tight estimates .", "Computing the stationary distribution of a large finite or countably infinite state space Markov Chain ( MC ) has become central in many problems such as statistical inference and network analysis .", "Our algorithm is constant time , using information from a local neighborhood of the state on the graph induced by the MC , which has constant size relative to the state space .", "Standard methods involve large matrix multiplications as in power iteration , or simulations of long random walks , as in Markov Chain Monte Carlo ( MCMC ) .", "For MCMC , it is difficult to determine whether the random walks are long enough to guarantee convergence .", "The multiplicative error of the estimate is upper bounded by a function of the mixing properties of the MC .", "In this paper , we provide a novel algorithm that answers whether a chosen state in a MC has stationary probability larger than some ( 0 , 1 ) , and outputs an estimate of the stationary probability .", "Power iteration is costly , as it involves computation at every state ."]}
{"orig_sents": ["1", "0", "5", "4", "2", "3"], "shuf_sents": ["We model the buyer as a strategic agent , whose goal is to maximize her long-term surplus , and we are interested in mechanisms that maximize the seller 's long-term revenue .", "Inspired by real-time ad exchanges for online display advertising , we consider the problem of inferring a buyer 's value distribution for a good when the buyer is repeatedly interacting with a seller through a posted-price mechanism .", "the buyer prefers showing advertisements to users sooner rather than later .", "We also give a lower bound on strategic regret that increases as the buyer 's discounting weakens and shows , in particular , that any seller algorithm will suffer linear strategic regret if there is no discounting .", "We present seller algorithms that are no ( strategic ) -regret when the buyer discounts her future surplus -- i.e .", "We define the natural notion of strategic regret -- the lost revenue as measured against a truthful ( non-strategic ) buyer ."]}
{"orig_sents": ["1", "4", "5", "0", "6", "2", "3"], "shuf_sents": ["The mechanism first outputs a summary of the database .", "We study differentially private mechanisms for answering smooth queries on databases consisting of data points in Rd .", "Outputting the summary runs in time d O ( n1+ 2d+K ) , and the evaluation algorithm for answering a query runs in time d+2+ 2d K 2d+K ) .", "Our mechanism is based on L O ( n -approximation of ( transformed ) smooth functions by low degree even trigonometric polynomials with small and efficiently computable coefficients .", "A K-smooth query is specified by a function whose partial derivatives up to order K are all bounded .", "We develop an -differentially private mechanism which for the class of K-smooth queries has K accuracy O ( n- 2d+K / ) .", "To obtain an answer of a query , the user runs a public evaluation algorithm which contains no information of the database ."]}
{"orig_sents": ["2", "0", "3", "5", "1", "6", "4"], "shuf_sents": ["Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms , one for each data point .", "In the full information setting , our algorithms improve over the regret bounds of previous work ( due to Dwork , Naor , Pitassi and Rothblum ( 2010 ) and Jain , Kothari and Thakurta ( 2012 ) ) .", "We give differentially private algorithms for a large class of online learning algorithms , in both the full information and bandit settings .", "To design our algorithms , we modify the popular mirror descent approach , or rather a variant called follow the approximate leader .", "Our algorithms require logarithmic space and update time .", "The technique leads to the first nonprivate algorithms for private online learning in the bandit setting .", "In many cases , our algorithms ( in both settings ) match the dependence on the input length , T , of the optimal nonprivate regret bounds up to logarithmic factors in T ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["We provide a detailed study of the estimation of probability distributions -- discrete and continuous -- in a stringent setting in which data is kept private even from the statistician .", "We give sharp minimax rates of convergence for estimation in these locally private settings , exhibiting fundamental trade-offs between privacy and convergence rate , as well as providing tools to allow movement along the privacy-statistical efficiency continuum .", "One of the consequences of our results is that Warner 's classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents ."]}
{"orig_sents": ["1", "2", "3", "4", "0"], "shuf_sents": ["We apply our generic procedure to two fundamental tasks in statistics and machine-learning - training a regularized linear classifier and building a histogram density estimator that result in end-toend differentially private solutions for these problems .", "Differential privacy is a cryptographically motivated definition of privacy which has gained considerable attention in the algorithms , machine-learning and datamining communities .", "While there has been an explosion of work on differentially private machine learning algorithms , a major barrier to achieving end-to-end differential privacy in practical machine learning applications is the lack of an effective procedure for differentially private parameter tuning , or , determining the parameter value , such as a bin size in a histogram , or a regularization parameter , that is suitable for a particular application .", "In this paper , we introduce a generic validation procedure for differentially private machine learning algorithms that apply when a certain stability condition holds on the training algorithm and the validation performance metric .", "The training data size and the privacy budget used for training in our procedure is independent of the number of parameter values searched over ."]}
{"orig_sents": ["7", "5", "0", "1", "8", "6", "10", "9", "2", "4", "11", "3"], "shuf_sents": ["However , similarity is a richer and broader notion than what metrics entail .", "For example , similarity can arise from the process of aggregating the decisions of multiple latent components , where each latent component compares data in its own way by focusing on a different subset of features .", "We validate the SCA model on synthetic datasets where SCA discovers the ground-truth about the latent components .", "Moreover , we show how SCA can be instrumental in exploratory analysis of data , where we gain insights about the data by examining patterns hidden in its latent components ' local similarity values .", "We also apply SCA to a multiway classification task and a link prediction task .", "To this end , metric learning has been the dominant paradigm .", "In SCA , a latent component generates a local similarity value , computed with its own metric , independently of other components .", "Measuring similarity is crucial to many learning tasks .", "In this paper , we propose Similarity Component Analysis ( SCA ) , a probabilistic graphical model that discovers those latent components from data .", "We derive an EM-based algorithm for fitting the model parameters with similarity-annotated data from pairwise comparisons .", "The final similarity measure is then obtained by combining the local similarity values with a ( noisy- ) OR gate .", "For both tasks , SCA attains significantly better prediction accuracies than competing methods ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["We describe a novel approach for computing collision-free global trajectories for p agents with specified initial and final configurations , based on an improved version of the alternating direction method of multipliers ( ADMM ) .", "We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space .", "We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals .", "Compared with existing methods , our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["When approximating binary similarity using the hamming distance between short binary hashes , we show that even if the similarity is symmetric , we can have shorter and more accurate hashes by using two distinct code maps .", "I.e .", "by approximating the similarity between x and x as the hamming distance between f ( x ) and g ( x ) , for two distinct binary codes f , g , rather than as the hamming distance between f ( x ) and f ( x ) ."]}
{"orig_sents": ["3", "4", "2", "1", "5", "0"], "shuf_sents": ["Our method was competitive against state-of-the-art methods and , in most cases , was more efficient for the same rank approximation quality .", "Conditions on spaces where the VP-tree is applicable are discussed .", "Both methods are evaluated using data sets with metric ( Euclidean ) and non-metric ( KL-divergence and Itakura-Saito ) distance functions .", "Our focus is on approximate nearest neighbor retrieval in metric and non-metric spaces .", "We employ a VP-tree and explore two simple yet effective learning-toprune approaches : density estimation through sampling and `` stretching '' of the triangle inequality .", "The VP-tree with a learned pruner is compared against the recently proposed state-of-the-art approaches : the bbtree , the multi-probe locality sensitive hashing ( LSH ) , and permutation methods ."]}
{"orig_sents": ["2", "1", "0", "5", "4", "3"], "shuf_sents": ["This schema , although proven successful on a range of matching tasks , is insufficient for capturing the rich structure in the matching process of more complicated objects .", "The matching level of two objects is usually measured as the inner product in a certain feature space , while the modeling effort focuses on mapping of objects from the original space to the feature space .", "Many machine learning problems can be interpreted as learning for matching two types of objects ( e.g. , images and captions , users and products , queries and documents , etc . ) .", "This new architecture naturally combines the localness and hierarchy intrinsic to the natural language problems , and therefore greatly improves upon the state-of-the-art models .", "More specifically , we apply this model to matching tasks in natural language , e.g. , finding sensible responses for a tweet , or relevant answers to a given question .", "In this paper , we propose a new deep architecture to more effectively model the complicated matching relations between two objects from heterogeneous domains ."]}
{"orig_sents": ["2", "0", "3", "4", "1"], "shuf_sents": ["We characterize the RBM 's unnormalized log-likelihood function as a type of neural network , and through a series of simulation results relate these networks to ones whose representational properties are better understood .", "By formally demonstrating that a relatively simple distribution can not be represented efficiently by an RBM our results provide a new rigorous justification for the use of potentially more expressive generative models , such as deeper ones .", "This paper examines the question : What kinds of distributions can be efficiently represented by Restricted Boltzmann Machines ( RBMs ) ?", "We show the surprising result that RBMs can efficiently capture any distribution whose density depends on the number of 1 's in their input .", "We also provide the first known example of a particular type of distribution that provably can not be efficiently represented by an RBM , assuming a realistic exponential upper bound on the weights ."]}
{"orig_sents": ["5", "1", "6", "3", "4", "2", "0"], "shuf_sents": ["Motivated by this example , we present a simple method for finding phrases in text , and show that learning good vector representations for millions of phrases is possible .", "In this paper we present several extensions that improve both the quality of the vectors and the training speed .", "For example , the meanings of `` Canada '' and `` Air '' can not be easily combined to obtain `` Air Canada '' .", "We also describe a simple alternative to the hierarchical softmax called negative sampling .", "An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases .", "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships .", "By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations ."]}
{"orig_sents": ["2", "3", "1", "0", "4"], "shuf_sents": ["To generalize this idea to RBMs , we propose a stochastic ratio-matching algorithm that inherits all the computational advantages and unbiasedness of the importance sampling scheme .", "An algorithm was recently developed to successfully handle the case of auto-encoders , based on an importance sampling scheme stochastically selecting which input elements to actually reconstruct during training for each particular example .", "Sparse high-dimensional data vectors are common in many application domains where a very large number of rarely non-zero features can be devised .", "Unfortunately , this creates a computational bottleneck for unsupervised feature learning algorithms such as those based on auto-encoders and RBMs , because they involve a reconstruction step where the whole input vector is predicted from the current feature values .", "We show that stochastic ratio matching is a good estimator , allowing the approach to beat the state-of-the-art on two bag-of-word text classification benchmarks ( 20 Newsgroups and RCV1 ) , while keeping computational cost linear in the number of non-zeros ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["This has led to various proposals for sampling from this implicitly learned density function , using Langevin and Metropolis-Hastings MCMC .", "Another issue is the mathematical justification which is only valid in the limit of small corruption noise .", "However , it remained unclear how to connect the training procedure of regularized auto-encoders to the implicit estimation of the underlying datagenerating distribution when the data are discrete , or using other forms of corruption process and reconstruction errors .", "We propose here a different attack on the problem , which deals with all these issues : arbitrary ( but noisy enough ) corruption , arbitrary reconstruction loss ( seen as a log-likelihood ) , handling both discrete and continuous-valued variables , and removing the bias due to non-infinitesimal corruption noise ( or non-infinitesimal contractive penalty ) .", "Recent work has shown how denoising and contractive autoencoders implicitly capture the structure of the data-generating density , in the case where the corruption noise is Gaussian , the reconstruction error is the squared error , and the data is continuous-valued ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["We introduce the multi-prediction deep Boltzmann machine ( MP-DBM ) .", "Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily , one layer at a time .", "The MPDBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood , or as a family of recurrent nets that share parameters and approximately solve different inference problems .", "The MP-DBM does not require greedy layerwise pretraining , and outperforms the standard DBM at classification , classification with missing inputs , and mean field prediction tasks.1"]}
{"orig_sents": ["4", "1", "0", "2", "3"], "shuf_sents": ["Moreover , we show that not only can the parameter values be predicted , but many of them need not be learned at all .", "Given only a few weight values for each feature it is possible to accurately predict the remaining values .", "We train several different architectures by learning only a small number of weights and predicting the rest .", "In the best case we are able to predict more than 95 % of the weights of a network without any drop in accuracy .", "We demonstrate that there is significant redundancy in the parameterization of several deep learning models ."]}
{"orig_sents": ["7", "2", "6", "10", "5", "3", "4", "1", "0", "9", "8"], "shuf_sents": ["A new Generalized EM training procedure using importance sampling allows us to efficiently learn complicated conditional distributions .", "In this paper , we propose a stochastic feedforward network with hidden layers composed of both deterministic and stochastic variables .", "As regressors , MLPs model the conditional distribution of the predictor variables Y given the input variables X .", "By using stochastic hidden variables rather than deterministic ones , Sigmoid Belief Nets ( SBNs ) can induce a rich multimodal distribution in the output space .", "However , previously proposed learning algorithms for SBNs are not efficient and unsuitable for modeling real-valued data .", "For tasks involving structured prediction , the conditional distribution should be multi-modal , resulting in one-to-many mappings .", "However , this predictive distribution is assumed to be unimodal ( e.g .", "Multilayer perceptrons ( MLPs ) or neural networks are popular models used for nonlinear regression and classification tasks .", "In addition , the latent features of our model improves classification and can learn to generate colorful textures of objects .", "Our model achieves superior performance on synthetic and facial expressions datasets compared to conditional Restricted Boltzmann Machines and Mixture Density Networks .", "Gaussian ) ."]}
{"orig_sents": ["1", "2", "0", "3", "5", "6", "4", "7"], "shuf_sents": ["Unlike previous zero-shot learning models , which can only differentiate between unseen classes , our model can operate on a mixture of seen and unseen classes , simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes .", "This work introduces a model that can recognize objects in images even if no training data is available for the object class .", "The only necessary knowledge about unseen visual categories comes from unsupervised text corpora .", "This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like .", "We then use novelty detection methods to differentiate unseen classes from seen classes .", "Our deep learning model does not require any manually defined semantic or visual features for either words or images .", "Images are mapped to be close to semantic word vectors corresponding to their classes , and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class .", "We demonstrate two novelty detection strategies ; the first gives high accuracy on unseen classes , while the second is conservative in its prediction of novelty and keeps the seen classes ' accuracy high ."]}
{"orig_sents": ["4", "7", "1", "2", "6", "0", "5", "3"], "shuf_sents": ["Lastly , we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora .", "Previous work represented entities as either discrete atomic units or with a single entity vector representation .", "We show that performance can be improved when entities are represented as an average of their constituting word vectors .", "Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2 % and 90.0 % , respectively .", "Knowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships .", "We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base .", "This allows sharing of statistical strength between , for instance , facts involving the `` Sumatran tiger '' and `` Bengal tiger . ''", "In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities ."]}
{"orig_sents": ["5", "2", "8", "1", "7", "3", "4", "6", "0"], "shuf_sents": ["Our method achieves state-of-the-art classification results on the CIFAR-100 image data set and the MIR Flickr image-text data set .", "This tree structure imposes a prior over the classifier 's parameters .", "We propose a method for improving classification performance for such classes by discovering similar classes and transferring knowledge among them .", "Our method combines the strength of discriminatively trained deep neural networks , which typically require large amounts of training data , with tree-based priors , making deep neural networks work well on infrequent classes as well .", "We also propose an algorithm for learning the underlying tree structure .", "High capacity classifiers , such as deep neural networks , often struggle on classes that have very few training examples .", "Starting from an initial pre-specified tree , this algorithm modifies the tree to make it more pertinent to the task being solved , for example , removing semantic relationships in favour of visual ones for an image classification task .", "We show that the performance of deep neural networks can be improved by applying these priors to the weights in the last layer .", "Our method learns to organize the classes into a tree hierarchy ."]}
{"orig_sents": ["2", "4", "3", "5", "0", "1"], "shuf_sents": ["We show that state-of-the-art denoising performance can be achieved with a single system on a variety of different noise types .", "Additionally , we demonstrate the efficacy of AMC-SSDA as a preprocessing ( denoising ) algorithm by achieving strong classification performance on corrupted MNIST digits .", "Stacked sparse denoising autoencoders ( SSDAs ) have recently been shown to be successful at removing noise from corrupted images .", "To address this limitation , we present the adaptive multi-column stacked sparse denoising autoencoder ( AMC-SSDA ) , a novel technique of combining multiple SSDAs by ( 1 ) computing optimal column weights via solving a nonlinear optimization program and ( 2 ) training a separate network to predict the optimal weights .", "However , like most denoising techniques , the SSDA is not robust to variation in noise types beyond what it has seen during training .", "We eliminate the need to determine the type of noise , let alone its statistics , at test time and even show that the system can be robust to noise not seen in the training set ."]}
{"orig_sents": ["3", "2", "0", "7", "6", "4", "5", "1"], "shuf_sents": ["We suggest a deep learning strategy that bridges the gap between the two phases , resulting in a three-phase learning procedure .", "Object recognition results on the Caltech-101 dataset also yield competitive results .", "The current approach involves two training phases : a fully unsupervised learning followed by a strongly discriminative optimization .", "Designing a principled and effective algorithm for learning deep architectures is a challenging problem .", "A global optimization procedure that merges samples from a forward bottom-up pass and a top-down pass is used .", "Experiments on the MNIST dataset show improvements over the existing algorithms for deep belief networks .", "The network is constructed from building blocks of restricted Boltzmann machines learned by combining bottom-up and top-down sampled signals .", "We propose to implement the scheme using a method to regularize deep belief networks with top-down information ."]}
{"orig_sents": ["3", "4", "5", "2", "0", "1"], "shuf_sents": ["When evaluated on the MNIST and NORB datasets , we found that our method achieves lower classification error rates than other feature learning methods , including standard dropout , denoising auto-encoders , and restricted Boltzmann machines .", "For example , our method achieves 0.80 % and 5.8 % errors on the MNIST and NORB test sets , which is better than state-of-the-art results obtained using feature learning methods , including those that use convolutional architectures .", "Interestingly , experiments show that the learnt dropout network parameters recapitulate the neural network parameters , suggesting that a good dropout network regularizes activities according to magnitude .", "Recently , it was shown that deep neural networks can perform very well if the activities of hidden units are regularized during learning , e.g , by randomly dropping out 50 % of their activities .", "We describe a method called `standout ' in which a binary belief network is overlaid on a neural network and is used to regularize of its hidden units by selectively setting activities to zero .", "This `adaptive dropout network ' can be trained jointly with the neural network by approximately computing local expectations of binary dropout variables , computing derivatives using back-propagation , and using stochastic gradient descent ."]}
{"orig_sents": ["1", "0"], "shuf_sents": ["We study the method both theoretically and empirically .", "We study PCA as a stochastic optimization problem and propose a novel stochastic approximation algorithm which we refer to as `` Matrix Stochastic Gradient '' ( MSG ) , as well as a practical variant , Capped MSG ."]}
{"orig_sents": ["6", "5", "7", "2", "1", "3", "0", "4"], "shuf_sents": ["One is convex -- the MAP estimation for logistic regression , and the other is non-convex -- stochastic variational inference for latent Dirichlet allocation .", "Data statistics such as low-order moments ( pre-computed or estimated online ) is used to form the control variate .", "In this paper , we develop a general approach of using control variate for variance reduction in stochastic gradient .", "We demonstrate how to construct the control variate for two practical problems using stochastic gradient optimization .", "On both problems , our approach shows faster convergence and better performance than the classical approach .", "To optimize an objective , it uses the noisy gradient computed from the random data samples instead of the true gradient computed from the entire dataset .", "Stochastic gradient optimization is a class of widely used algorithms for training machine learning models .", "However , when the variance of the noisy gradient is large , the algorithm might spend much time bouncing around , leading to slower convergence and worse performance ."]}
{"orig_sents": ["0", "7", "2", "6", "3", "4", "5", "1"], "shuf_sents": ["We consider streaming , one-pass principal component analysis ( PCA ) , in the highdimensional regime , with limited memory .", "While our theoretical analysis focuses on the spiked covariance model , our simulations show that our algorithm is successful on much more general models for the data .", "Standard algorithms require O ( p2 ) memory ; meanwhile no algorithm can do better than O ( kp ) memory , since this is what the output itself requires .", "Sample complexity for high-dimensional PCA is typically studied in the setting of the spiked covariance model , where p-dimensional points are generated from a population covariance equal to the identity ( white noise ) plus a low-dimensional perturbation ( the spike ) which is the signal to be recovered .", "It is now well-understood that the spike can be recovered when the number of samples , n , scales proportionally with the dimension , p. Yet , all algorithms that provably achieve this , have memory complexity O ( p2 ) .", "Meanwhile , algorithms with memory-complexity O ( kp ) do not have provable bounds on sample complexity comparable to p. We present an algorithm that achieves both : it uses O ( kp ) memory ( meaning storage of any kind ) and is able to compute the k-dimensional spike with O ( p log p ) samplecomplexity - the first algorithm of its kind .", "Memory ( or storage ) complexity is most meaningful when understood in the context of computational and sample complexity .", "Here , p-dimensional samples are presented sequentially , and the goal is to produce the k-dimensional subspace that best approximates these points ."]}
{"orig_sents": ["5", "1", "7", "3", "6", "4", "0", "2"], "shuf_sents": ["Note that the probabilities in the optimal offline distribution may be complex functions of all the entries in the matrix .", "For large m n matrices , such that n m ( for example , representing n observations over m attributes ) we give sampling distributions that exhibit four important properties .", "Therefore , regardless of computational complexity , the optimal distribution might be impossible to compute in the streaming model .", "Second , they allow sketching of matrices whose non-zeros are presented to the algorithm in arbitrary order as a stream , with O 1 computation per non-zero .", "Lastly , and most importantly , under mild assumptions , our distributions are provably competitive with the optimal offline distribution .", "We consider the problem of selecting non-zero entries of a matrix A in order to produce a sparse sketch of it , B , that minimizes A B 2 .", "Third , the resulting sketch matrices are not only sparse , but their non-zero entries are highly compressible .", "First , they have closed forms computable from minimal information regarding A ."]}
{"orig_sents": ["4", "5", "3", "1", "2", "0"], "shuf_sents": ["Experimental results show that our algorithm is substantially more scalable than state-of-the-art methods and scales almost linearly with the number of cores .", "The proposed framework solves CLIME in columnblocks and only involves elementwise operations and parallel matrix multiplications .", "We evaluate our algorithm on both shared-memory and distributed-memory architectures , which can use block cyclic distribution of data and parameters to achieve load balance and improve the efficiency in the use of memory hierarchies .", "Further , we develop a large scale distributed framework for the computations , which scales to millions of dimensions and trillions of parameters , using hundreds of cores .", "We consider the problem of sparse precision matrix estimation in high dimensions using the CLIME estimator , which has several desirable theoretical properties .", "We present an inexact alternating direction method of multiplier ( ADMM ) algorithm for CLIME , and establish rates of convergence for both the objective and optimality conditions ."]}
{"orig_sents": ["1", "3", "0", "2", "4"], "shuf_sents": ["We view this `` optimistic concurrency control '' paradigm as particularly appropriate for large-scale machine learning algorithms , particularly in the unsupervised setting .", "Research on distributed machine learning algorithms has focused primarily on one of two extremes -- algorithms that obey strict concurrency constraints or algorithms that obey few or no such constraints .", "We demonstrate our approach in three problem areas : clustering , feature learning and online facility location .", "We consider an intermediate alternative in which algorithms optimistically assume that conflicts are unlikely and if conflicts do arise a conflict-resolution protocol is invoked .", "We evaluate our methods via large-scale experiments in a cluster computing environment ."]}
{"orig_sents": ["1", "4", "7", "6", "3", "2", "0", "5"], "shuf_sents": ["We theoretically analyze our approach , and show , that under certain natural conditions , performance close to the ( impractical ) centralized approach can be achieved .", "Many large-scale machine learning problems ( such as clustering , non-parametric learning , kernel machines , etc . )", "We develop a simple , two-stage protocol G REE D I , that is easily implemented using MapReduce style computations .", "In this paper , we consider the problem of submodular function maximization in a distributed fashion .", "require selecting , out of a massive data set , a manageable yet representative subset .", "In our extensive experiments , we demonstrate the effectiveness of our approach on several applications , including sparse Gaussian process inference and exemplar-based clustering , on tens of millions of data points using Hadoop .", "Classical approaches require centralized access to the full data set ; but for truly large-scale problems , rendering the data centrally is often impractical .", "Such problems can often be reduced to maximizing a submodular set function subject to cardinality constraints ."]}
{"orig_sents": ["3", "6", "1", "5", "4", "0", "2"], "shuf_sents": ["The proposed method can be easily applied to simultaneously rectify and align multiple images or videos frames .", "To improve the computational efficiency , we introduce a proximal gradient step to the alternating direction minimization method .", "In this context , the state-of-the-art algorithms `` RASL '' and `` TILT '' can be viewed as two special cases of our work , and yet each only performs part of the function of our method .", "In this work , we propose a general method for recovering low-rank three-order tensors , in which the data can be deformed by some unknown transformation and corrupted by arbitrary sparse errors .", "Both simulations and experiments show that our methods are more efficient and effective than previous work .", "We have provided proof for the convergence of the linearized version of the problem which is the inner loop of the overall algorithm .", "Since the unfolding matrices of a tensor are interdependent , we introduce auxiliary variables and relax the hard equality constraints by the augmented Lagrange multiplier method ."]}
{"orig_sents": ["6", "1", "8", "5", "4", "3", "2", "7", "0"], "shuf_sents": ["Our work represents the only known theoretical guarantee for alternating minimization for any variant of phase retrieval problems in the non-convex setting .", "Over the last two decades , a popular generic empirical approach to the many variants of this problem has been one of alternating minimization ; i.e .", "Analytically , we show geometric convergence to the solution , and sample complexity that is off by log factors from obvious lower bounds .", "However , our algorithm is much more efficient and can scale to large problems .", "Empirically , our algorithm performs similar to recently proposed convex techniques for this variant ( which are based on `` lifting '' to a convex matrix problem ) in sample complexity and robustness to noise .", "In this paper , we show that a simple alternating minimization algorithm geometrically converges to the solution of one such problem - finding a vector x from y , A , where y = |AT x| and |z| denotes a vector of element-wise magnitudes of z - under the assumption that A is Gaussian .", "Phase retrieval problems involve solving linear equations , but with missing sign ( or phase , for complex numbers ) .", "We also establish close to optimal scaling for the case when the unknown vector is sparse .", "alternating between estimating the missing phase information , and the candidate solution ."]}
{"orig_sents": ["1", "6", "5", "3", "2", "4", "0"], "shuf_sents": ["We give several examples to illustrate our framework .", "What if there is a teacher who knows the learning goal and wants to design good training data for a machine learner ?", "In the case where the learner employs conjugate exponential family models , we present an approximate algorithm for finding the optimal teaching set .", "This optimization problem is in general hard .", "Our algorithm optimizes the aggregate sufficient statistics , then unpacks them into actual teaching examples .", "Our framework is expressed as an optimization problem over teaching examples that balance the future loss of the learner and the effort of the teacher .", "We propose an optimal teaching framework aimed at learners who employ Bayesian models ."]}
{"orig_sents": ["1", "3", "0", "2", "4", "5"], "shuf_sents": ["Empirical work has shown that some models can be sampled effectively by going `` Hogwild '' and simply running Gibbs updates in parallel with only periodic global communication , but the successes and limitations of such a strategy are not well understood .", "Sampling inference methods are computationally difficult to scale for many models in part because global dependencies can reduce opportunities for parallel computation .", "As a step towards such an understanding , we study the Hogwild Gibbs sampling strategy in the context of Gaussian distributions .", "Without strict conditional independence structure among variables , standard Gibbs sampling theory requires sample updates to be performed sequentially , even if dependence between most variables is not strong .", "We develop a framework which provides convergence conditions and error bounds along with simple proofs and connections to methods in numerical linear algebra .", "In particular , we show that if the Gaussian precision matrix is generalized diagonally dominant , then any Hogwild Gibbs sampler , with any update schedule or allocation of variables to processors , yields a stable sampling process with the correct sample mean ."]}
{"orig_sents": ["5", "2", "4", "3", "1", "7", "0", "6"], "shuf_sents": ["The result is slow mixing when using off-the-shelf Gibbs sampling .", "The main idea is to represent data by their observable rank statistics , ignoring any other information from the marginals .", "More recently , the framework of copula modeling has gained popularity due to its modular parameterization of joint distributions .", "More radically , the extended rank likelihood approach of Hoff ( 2007 ) bypasses learning marginal models completely when such information is ancillary to the learning task at hand as in , e.g. , standard dimensionality reduction problems or copula parameter estimation .", "Among other properties , copulas provide a recipe for combining flexible models for univariate marginal distributions with parametric families suitable for potentially high dimensional dependence structures .", "Learning the joint dependence of discrete variables is a fundamental problem in machine learning , with many applications including prediction , clustering and dimensionality reduction .", "We present an efficient algorithm based on recent advances on constrained Hamiltonian Markov chain Monte Carlo that is simple to implement and does not require paying for a quadratic cost in sample size .", "Inference is typically done in a Bayesian framework with Gaussian copulas , and it is complicated by the fact this implies sampling within a space where the number of constraints increases quadratically with the number of data points ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We illustrate the advantages of these algorithms in several examples in which they outperform the Metropolis or Gibbs samplers .", "An extension of this idea to distributions over mixtures of binary and possibly-truncated Gaussian or exponential variables allows us to sample from posteriors of linear and probit regression models with spike-and-slab priors and truncated parameters .", "We present a new approach to sample from generic binary distributions , based on an exact Hamiltonian Monte Carlo algorithm applied to a piecewise continuous augmentation of the binary distribution of interest ."]}
{"orig_sents": ["5", "7", "6", "3", "4", "2", "1", "0"], "shuf_sents": ["Improved sparsity of our wavelet transform for the test signals is confirmed via experiments both on synthetic and real data .", "After training is completed , we obtain a linear wavelet transform that can be applied to any graph signal in time and memory linear in the size of the graph .", "The training is unsupervised , and is conducted similarly to the greedy pre-training of a stack of auto-encoders .", "Our construction uses the lifting scheme , and is based on the observation that the recurrent nature of the lifting scheme gives rise to a structure resembling a deep auto-encoder network .", "Particular properties that the resulting wavelets must satisfy determine the training objective and the structure of the involved neural networks .", "An increasing number of applications require processing of signals defined on weighted graphs .", "This paper introduces a machine learning framework for constructing graph wavelets that can sparsely represent a given class of signals .", "While wavelets provide a flexible tool for signal processing in the classical setting of regular domains , the existing graph wavelet constructions are less flexible - they are guided solely by the structure of the underlying graph and do not take directly into consideration the particular class of signals to be processed ."]}
{"orig_sents": ["5", "4", "1", "3", "2", "0"], "shuf_sents": ["We show that , by approximating the graphon with a stochastic block model , the graphon can be consistently estimated , that is , the estimation error vanishes as the size of the graph approaches infinity .", "This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data .", "This procedure is based on a stochastic blockmodel approximation ( SBA ) of the graphon .", "In this paper , we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it .", "The key object that defines an ExGM is often referred to as a graphon .", "Non-parametric approaches for analyzing network data based on exchangeable graph models ( ExGM ) have recently gained interest ."]}
{"orig_sents": ["2", "4", "0", "3", "1"], "shuf_sents": ["We describe a family of greedy agglomerative model selection algorithms that take just one pass through the data to learn a fully probabilistic , hierarchical community model .", "In practice , the run time of our algorithms are two orders of magnitude faster than the Infinite Relational Model , achieving comparable or better accuracy .", "We propose an efficient Bayesian nonparametric model for discovering hierarchical community structure in social networks .", "In the worst case , Our algorithms scale quadratically in the number of vertices of the network , but independent of the number of nested communities .", "Our model is a tree-structured mixture of potentially exponentially many stochastic blockmodels ."]}
{"orig_sents": ["7", "1", "5", "3", "2", "6", "4", "0"], "shuf_sents": ["We illustrate the performance of these models using neural data .", "Maximum entropy ( or `` maxent '' ) models , which seek to explain dependencies in terms of low-order interactions between neurons , have enjoyed remarkable success in modeling such patterns , particularly for small groups of neurons .", "We construct universal models using a Dirichlet process centered on a well-behaved parametric base measure , which naturally combines the flexibility of a histogram and the parsimony of a parametric model .", "To overcome these limitations , we propose a family of `` universal '' models for binary spike patterns , where universality refers to the ability to model arbitrary distributions over all 2m binary patterns .", "We also establish a condition for equivalence between the cascaded logistic and the 2nd-order maxent or `` Ising '' model , making cascaded logistic a reasonable choice for base measure in a universal model .", "However , these models are computationally intractable for large populations , and low-order maxent models have been shown to be inadequate for some datasets .", "We derive computationally efficient inference methods using Bernoulli and cascaded logistic base measures , which scale tractably to large populations .", "Probabilistic models for binary spike patterns provide a powerful tool for understanding the statistical dependencies in large-scale neural recordings ."]}
{"orig_sents": ["0", "4", "3", "1", "2", "5"], "shuf_sents": ["Point processes are popular models of neural spiking behavior as they provide a statistical distribution over temporal sequences of spikes and help to reveal the complexities underlying a series of recorded action potentials .", "We show that this model is a natural extension of the popular generalized linear model to sets of interacting neurons .", "The model is extended to incorporate gain control or divisive normalization , and the modulation of neural spiking based on periodic phenomena .", "We develop a novel model based on a determinantal point process over latent embeddings of neurons that effectively captures and helps visualize complex inhibitory and competitive interaction .", "However , the most common neural point process models , the Poisson process and the gamma renewal process , do not capture interactions and correlations that are critical to modeling populations of neurons .", "Applied to neural spike recordings from the rat hippocampus , we see that the model captures inhibitory relationships , a dichotomy of classes of neurons , and a periodic modulation by the theta rhythm known to be present in the data ."]}
{"orig_sents": ["1", "6", "4", "5", "0", "3", "2"], "shuf_sents": ["Second , what are the neural encoding mechanisms that can produce such individual neural representations from streams of pixel images ?", "The macaque Superior Temporal Sulcus ( STS ) is a brain area that receives and integrates inputs from both the ventral and dorsal visual processing streams ( thought to specialize in form and motion processing respectively ) .", "Interestingly , even using inputs from a single stream , both actor-invariance and action-invariance can be accounted for , by having different linear weights .", "We find that a simple model , one that simply computes a linear weighted sum of ventral and dorsal responses to short action `` snippets '' , produces surprisingly good fits to the neural data .", "This paper addresses two questions .", "First , what are the invariance properties of individual neural representations ( rather than the population representation ) in STS ?", "For the processing of articulated actions , prior work has shown that even a small population of STS neurons contains sufficient information for the decoding of actor invariant to action , action invariant to actor , as well as the specific conjunction of actor and action ."]}
{"orig_sents": ["7", "6", "8", "0", "2", "1", "4", "3", "5"], "shuf_sents": ["We develop a new technique for calculating firing rates in optimal balanced networks .", "We can calculate firing rates by treating balanced network dynamics as an algorithm for optimising signal representation .", "These are particularly interesting networks because they provide an optimal spike-based signal representation while producing cortex-like spiking activity through a dynamic balance of excitation and inhibition .", "Our firing rate calculation relates network firing rates directly to network input , connectivity and function .", "We identify this algorithm and then calculate firing rates by finding the solution to the algorithm .", "This allows us to explain the function and underlying mechanism of tuning curves in a variety of systems .", "This is an important problem because firing rates are a key measure of network activity , in both the study of neural computation and neural network dynamics .", "How are firing rates in a spiking network related to neural input , connectivity and network function ?", "However , it is a difficult problem , because the spiking mechanism of individual neurons is highly non-linear , and these individual neurons interact strongly through connectivity ."]}
{"orig_sents": ["4", "5", "3", "1", "2", "0"], "shuf_sents": ["Our results underline that learning processes in realistic networks of spiking neurons depend crucially on the interactions of synaptic plasticity mechanisms with the dynamics of participating neurons .", "We also show that with these simple yet biologically realistic dynamics Tempotrons and Chronotrons are learned .", "The proposed mechanism enables incremental associative learning from a continuous stream of patterns and might therefore underly the acquisition of long term memories in cortex .", "Here we prove that spike-timing-dependent plasticity having an anti-Hebbian form for excitatory synapses as well as a spike-timing-dependent plasticity of Hebbian shape for inhibitory synapses are sufficient for realizing the original Perceptron Learning Rule if these respective plasticity mechanisms act in concert with the hyperpolarisation of the post-synaptic neurons .", "Recent extensions of the Perceptron as the Tempotron and the Chronotron suggest that this theoretical concept is highly relevant for understanding networks of spiking neurons in the brain .", "It is not known , however , how the computational power of the Perceptron might be accomplished by the plasticity mechanisms of real synapses ."]}
{"orig_sents": ["3", "6", "5", "2", "4", "1", "0"], "shuf_sents": ["Our result suggests that the brain may implement optimal information integration distributively at each local estimator through the reciprocal connections between cortical regions .", "Our model successfully explains the experimental finding that both MSTd and VIP achieve Bayesian multisensory integration , though each of them only receives a single cue as direct external input .", "Each network serves as a local estimator and receives an independent cue , either the visual or the vestibular , as direct input for the external stimulus .", "Psychophysical experiments have demonstrated that the brain integrates information from multiple sensory cues in a near Bayesian optimal manner .", "We find that positive reciprocal interactions can improve the decoding accuracy of each individual network as if it implements Bayesian inference from two cues .", "We consider two reciprocally connected networks , mimicking the integration of heading direction information between the dorsal medial superior temporal ( MSTd ) and the ventral intraparietal ( VIP ) areas .", "The present study proposes a novel mechanism to achieve this ."]}
{"orig_sents": ["1", "2", "0", "4", "3"], "shuf_sents": ["We demonstrate that stimuli of different dimensions can be faithfully multiplexed and encoded in the spike domain and derive tractable algorithms for decoding each stimulus from the common pool of spikes .", "We investigate a spiking neuron model of multisensory integration .", "Multiple stimuli from different sensory modalities are encoded by a single neural circuit comprised of a multisensory bank of receptive fields in cascade with a population of biophysical spike generators .", "We provide an example of multisensory integration using natural audio and video and discuss the performance of the proposed decoding and identification algorithms .", "We also show that the identification of multisensory processing in a single neuron is dual to the recovery of stimuli encoded with a population of multisensory neurons , and prove that only a projection of the circuit onto input stimuli can be identified ."]}
{"orig_sents": ["6", "7", "2", "8", "1", "3", "4", "0", "5"], "shuf_sents": ["Our results demonstrate that the proposed network architecture can perform a deterministic search for the optimal solution to problems with non-convex cost functions .", "If there is no solution that satisfies all constraints , the network state changes in a seemingly random manner and its trajectory approximates a sampling procedure that selects a variable assignment with a probability that increases with the fraction of constraints satisfied by this assignment .", "Constraints over the variables are encoded in the network connectivity .", "External evidence , or input to the network , can force variables to specific values .", "When new inputs are applied , the network re-evaluates the entire set of variables in its search for states that satisfy the maximum number of constraints , while being consistent with the external input .", "The network is inspired by canonical microcircuit models of the cortex and suggests possible dynamical mechanisms to solve constraint satisfaction problems that can be present in biological networks , or implemented in neuromorphic electronic circuits .", "We present a recurrent neuronal network , modeled as a continuous-time dynamical system , that can solve constraint satisfaction problems .", "Discrete variables are represented by coupled Winner-Take-All ( WTA ) networks , and their values are encoded in localized patterns of oscillations that are learned by the recurrent weights in these networks .", "Although there are no sources of noise , the network can escape from local optima in its search for solutions that satisfy all constraints by modifying the effective network connectivity through oscillations ."]}
{"orig_sents": ["0", "2", "1", "3", "4"], "shuf_sents": ["We solve the mean field equations for a stochastic Hopfield network with temperature ( noise ) in the presence of strong , i.e. , multiply stored , patterns , and use this solution to obtain the storage capacity of such a network .", "We show that the critical temperature for stability of a strong pattern is equal to its degree or multiplicity , when the sum of the squares of degrees of the patterns is negligible compared to the network size .", "Our result provides for the first time a rigorous solution of the mean filed equations for the standard Hopfield model and is in contrast to the mathematically unjustifiable replica technique that has been used hitherto for this derivation .", "In the case of a single strong pattern , when the ratio of the number of all stored pattens and the network size is a positive constant , we obtain the distribution of the overlaps of the patterns with the mean field and deduce that the storage capacity for retrieving a strong pattern exceeds that for retrieving a simple pattern by a multiplicative factor equal to the square of the degree of the strong pattern .", "This square law property provides justification for using strong patterns to model attachment types and behavioural prototypes in psychology and psychotherapy ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["Local competition among neighboring neurons is common in biological neural networks ( NNs ) .", "In this paper , we apply the concept to gradient-based , backprop-trained artificial multilayer NNs .", "NNs with competing linear units tend to outperform those with non-competing nonlinear units , and avoid catastrophic forgetting when training sets change over time ."]}
{"orig_sents": ["3", "1", "0", "2", "4"], "shuf_sents": ["RNADE learns a distributed representation of the data , while having a tractable expression for the calculation of densities .", "Our model calculates the density of a datapoint as the product of onedimensional conditionals modeled using mixture density networks with shared parameters .", "A tractable likelihood allows direct comparison with other methods and training by standard gradientbased optimizers .", "We introduce RNADE , a new model for joint density estimation of real-valued vectors .", "We compare the performance of RNADE on several datasets of heterogeneous and perceptual data , finding it outperforms mixture models in all but one case ."]}
{"orig_sents": ["5", "2", "0", "3", "1", "4"], "shuf_sents": ["We extend previous Bayesian nonparametric models of neural spiking to jointly detect and cluster neurons using a Gamma process model .", "Via exploratory data analysis -- using data with partial ground truth as well as two novel data sets -- we find several features of our model collectively contribute to our improved performance including : ( i ) accounting for colored noise , ( ii ) detecting overlapping spikes , ( iii ) tracking waveform dynamics , and ( iv ) using multiple channels .", "In electrophysiology experiments , this classically proceeds in a two-step process : ( i ) threshold the waveforms to detect putative spikes and ( ii ) cluster the waveforms into single units ( neurons ) .", "Importantly , we develop an online approximate inference scheme enabling real-time analysis , with performance exceeding the previous state-of-theart .", "We hope to enable novel experiments simultaneously measuring many thousands of neurons and possibly adapting stimuli dynamically to probe ever deeper into the mysteries of the brain .", "With simultaneous measurements from ever increasing populations of neurons , there is a growing need for sophisticated tools to recover signals from individual neurons ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["This paper considers the problem of transferring experimental findings learned from multiple heterogeneous domains to a target domain , in which only limited experiments can be performed .", "We further provide different graphical and algorithmic conditions for computing the transport formula in this setting , that is , a way of fusing the observational and experimental information scattered throughout different domains to synthesize a consistent estimate of the desired effects in the target domain .", "We reduce questions of transportability from multiple domains and with limited scope to symbolic derivations in the causal calculus , thus extending the original setting of transportability introduced in , which assumes only one domain with full experimental information available .", "We also consider the issue of minimizing the variance of the produced estimand in order to increase power ."]}
{"orig_sents": ["9", "5", "2", "4", "8", "7", "3", "1", "6", "0"], "shuf_sents": ["TiMINo is applied to artificial and real data and code is provided .", "We show empirically that when the data are causally insufficient or the model is misspecified , the method avoids incorrect answers .", "These models require independent residual time series , whereas traditional methods like Granger causality exploit the variance of residuals .", "( 2 ) Practical : If there are no feedback loops between time series , we propose an algorithm based on non-linear independence tests of time series .", "This work contains two main contributions : ( 1 ) Theoretical : By restricting the model class ( e.g .", "We study a class of restricted Structural Equation Models for time series that we call Time Series Models with Independent Noise ( TiMINo ) .", "We extend the theoretical and the algorithmic part to situations in which the time series have been measured with different time delays .", "They cover lagged and instantaneous effects that can be nonlinear and unfaithful , and non-instantaneous feedbacks between the time series .", "to additive noise ) we provide general identifiability results .", "Causal inference uses observational data to infer the causal structure of the data generating system ."]}
{"orig_sents": ["3", "2", "0", "1", "4"], "shuf_sents": ["We obtain an efficient learning algorithm for a family of Bayesian networks that we call quartet-learnable .", "For each latent variable , the existence of a singly-coupled quartet allows us to uniquely identify and learn all parameters involving that latent variable .", "Unsupervised learning of these models is a form of discrete factor analysis , enabling the discovery of hidden variables and their causal relationships with observed data .", "We give a polynomial-time algorithm for provably learning the structure and parameters of bipartite noisy-or Bayesian networks of binary variables where the top layer is completely hidden .", "We give a proof of the polynomial sample complexity of our learning algorithm , and experimentally compare it to variational EM ."]}
{"orig_sents": ["1", "3", "5", "6", "4", "0", "8", "2", "7"], "shuf_sents": ["Inspired by recent advances in spectral learning methods , we propose to study this problem from a different perspective : moment matching and spectral decomposition .", "Learning dynamic models from observed data has been a central issue in many scientific studies or engineering tasks .", "To the best of our knowledge , this is the first formal guarantee on learning from non-sequence data .", "The usual setting is that data are collected sequentially from trajectories of some dynamical system operation .", "Existing methods for learning dynamic model from non-sequence data are mostly based on Expectation-Maximization , which involves non-convex optimization and is thus hard to analyze .", "In quite a few modern scientific modeling tasks , however , it turns out that reliable sequential data are rather difficult to gather , whereas out-of-order snapshots are much easier to obtain .", "Examples include the modeling of galaxies , chronic diseases such Alzheimer 's , or certain biological processes .", "Preliminary simulation results confirm our theoretical findings .", "Under that framework , we identify reasonable assumptions on the generative process of non-sequence data , and propose learning algorithms based on the tensor decomposition method to provably recover firstorder Markov models and hidden Markov models ."]}
{"orig_sents": ["2", "5", "4", "0", "1", "3"], "shuf_sents": ["In addition , we relate the posterior distributions to computational properties of the MAP predictors .", "We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts .", "In this work we develop efficient methods for learning random MAP predictors for structured label problems .", "We also describe label-augmented posterior models that can use efficient MAP approximations , such as those arising from linear program relaxations .", "We show that any smooth posterior distribution would suffice to define a smooth PAC-Bayesian risk bound suitable for gradient methods .", "In particular , we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods ."]}
{"orig_sents": ["4", "5", "3", "2", "1", "0", "6"], "shuf_sents": ["The KL divergence is optimized using the belief propagation algorithm , with complexity exponential in only the cluster size of the graph .", "In particular , by exploiting the graph structure of graph-based MDPs , we propose a factored variational value iteration algorithm in which the value function is first approximated by the multiplication of local-scope value functions , then solved by minimizing a Kullback-Leibler ( KL ) divergence .", "We present a new variational framework to describe and solve the planning problem of MDPs , and derive both exact and approximate planning algorithms .", "However , the complexity of exactly solving a graph-based MDP usually grows exponentially in the number of variables , which limits their application .", "Markov Decision Processes ( MDPs ) are extremely useful for modeling and solving sequential decision making problems .", "Graph-based MDPs provide a compact representation for MDPs with large numbers of random variables .", "Experimental comparison on different models shows that our algorithm outperforms existing approximation algorithms at finding good policies ."]}
{"orig_sents": ["3", "1", "4", "0", "2"], "shuf_sents": ["We derive an upper bound for the Kullback-Leibler divergence , which yields a fast closed-form solution via decoupled optimization .", "Our approach unifies the integrated nested Laplace approximation ( INLA ) under the variational framework .", "Our method is a reliable analytic alternative to Markov chain Monte Carlo ( MCMC ) , and it results in a tighter evidence lower bound than that of mean-field variational Bayes ( VB ) method .", "We present a non-factorized variational method for full posterior inference in Bayesian hierarchical models , with the goal of capturing the posterior variable dependencies via efficient and possibly parallel computation .", "The proposed method is applicable in more challenging scenarios than typically assumed by INLA , such as Bayesian Lasso , which is characterized by the non-differentiability of the 1 norm arising from independent Laplace priors ."]}
{"orig_sents": ["4", "0", "6", "3", "7", "1", "5", "8", "2"], "shuf_sents": ["However , Bayesian learning is often obstructed by computational difficulty : the rigorous Bayesian learning is intractable in many models , and its variational Bayesian ( VB ) approximation is prone to suffer from local minima .", "Thanks to this property , the optimization problem of VB-LRSC can be separated into small subproblems , each of which has only a small number of unknown variables .", "Experimental results show the usefulness of our approach .", "LRSC extracts a low-dimensional structure of data by embedding samples into the union of low-dimensional subspaces , and its variational Bayesian variant has shown good performance .", "When a probabilistic model and its prior are given , Bayesian learning offers inference with automatic parameter tuning .", "Our exact global solver relies on another key property that the stationary condition of each subproblem consists of a set of polynomial equations , which is solvable with the homotopy method .", "In this paper , we overcome this difficulty for low-rank subspace clustering ( LRSC ) by providing an exact global solver and its efficient approximation .", "We first prove a key property that the VBLRSC model is highly redundant .", "For further computational efficiency , we also propose an efficient approximate variant , of which the stationary condition can be written as a polynomial equation with a single variable ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["Expectation Propagation ( EP ) is a popular approximate posterior inference algorithm that often provides a fast and accurate alternative to sampling-based methods .", "However , while the EP framework in theory allows for complex nonGaussian factors , there is still a significant practical barrier to using them within EP , because doing so requires the implementation of message update operators , which can be difficult and require hand-crafted approximations .", "We address the practical concerns that arise in the process , and we provide empirical analysis on several challenging and diverse factors , indicating that there is a space of factors where this approach appears promising .", "In this work , we study the question of whether it is possible to automatically derive fast and accurate EP updates by learning a discriminative model ( e.g. , a neural network or random forest ) to map EP message inputs to EP message outputs ."]}
{"orig_sents": ["3", "0", "4", "2", "1"], "shuf_sents": ["Our objective is to propose a canonical model which is easy to train , contains a reduced number of parameters and can scale up to very large databases .", "Besides , it can be successfully trained on a large scale data set with 1M entities , 25k relationships and more than 17M training samples .", "Despite its simplicity , this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases .", "We consider the problem of embedding entities and relationships of multirelational data in low-dimensional vector spaces .", "Hence , we propose TransE , a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities ."]}
{"orig_sents": ["0", "2", "1", "6", "5", "4", "3"], "shuf_sents": ["Stochastic block models characterize observed network relationships via latent community memberships .", "We introduce a new model for these phenomena , the hierarchical Dirichlet process relational model , which allows nodes to have mixed membership in an unbounded set of communities .", "In large social networks , we expect entities to participate in multiple communities , and the number of communities to grow with the network size .", "We also showcase an analysis of LittleSis , a large network of who-knows-who at the heights of business and government .", "Compared to state-of-the-art online learning methods for parametric relational models , we show significantly improved perplexity and link prediction accuracy for sparse networks with tens of thousands of nodes .", "Focusing on assortative models of undirected networks , we also propose an efficient structured mean field variational bound , and online methods for automatically pruning unused communities .", "To allow scalable learning , we derive an online stochastic variational inference algorithm ."]}
{"orig_sents": ["6", "4", "7", "5", "1", "3", "0", "2"], "shuf_sents": ["This approach has a very remarkable consequence -- methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant .", "If the loss function satisfies a simple symmetry condition , we show that the method leads to an efficient algorithm for empirical minimization .", "On a synthetic non-separable dataset , our methods achieve over 88 % accuracy even when 40 % of the labels are corrupted , and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets .", "Second , by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss , we suggest the use of a simple weighted surrogate loss , for which we are able to obtain strong empirical risk bounds .", "Moreover , random label noise is class-conditional -- the flip probability depends on the class .", "First , we provide a simple unbiased estimator of any loss , and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels .", "In this paper , we theoretically study the problem of binary classification in the presence of random classification noise -- the learner , instead of seeing the true labels , sees labels that have independently been flipped with some small probability .", "We provide two approaches to suitably modify any given surrogate loss function ."]}
{"orig_sents": ["4", "3", "2", "1", "0"], "shuf_sents": ["Numerical experiments show that the proposed algorithm outperforms Lloyd 's K-means algorithm .", "We have also successfully applied the proposed algorithm to a clustering problem , by reformulating it as a low-rank matrix reconstruction problem with an additional structural property .", "We propose an efficient approximate message passing algorithm , derived from the belief propagation algorithm , to perform the Bayesian inference for matrix reconstruction .", "We formulate the problem in the Bayesian framework , which allows us to exploit structural properties of matrices in addition to low-rankedness , such as sparsity .", "We study the problem of reconstructing low-rank matrices from their noisy observations ."]}
{"orig_sents": ["7", "4", "3", "8", "0", "2", "1", "9", "5", "6"], "shuf_sents": ["In contrast to prior work , we allow for both hierarchical and heterarchical relations of lower-level to higher-level concepts .", "Finally , we describe an optimization scheme that allows to optimize the decomposition over all levels jointly , rather than in a greedy level-by-level fashion .", "In addition , we learn the nature of these relations rather than imposing them .", "For example , in the neurosciences image sequence considered here , there are the semantic concepts of pixel neuron assembly that should find their counterpart in the unsupervised analysis .", "In some applications , however , there is a natural hierarchy of concepts that ought to be reflected in the unsupervised analysis .", "Experiments show that the proposed model fully recovers the structure from difficult synthetic data designed to imitate the experimental data .", "More importantly , bilevel SHMF yields plausible interpretations of real-world Calcium imaging data .", "Bilinear approximation of a matrix is a powerful paradigm of unsupervised learning .", "Driven by this concrete problem , we propose a decomposition of the matrix of observations into a product of more than two sparse matrices , with the rank decreasing from lower to higher levels .", "The proposed bilevel SHMF ( sparse heterarchical matrix factorization ) is the first formalism that allows to simultaneously interpret a calcium imaging sequence in terms of the constituent neurons , their membership in assemblies , and the time courses of both neurons and assemblies ."]}
{"orig_sents": ["2", "0", "4", "3", "1"], "shuf_sents": ["A prominent methodology for this problem is based on a generalization of trace norm regularization , which has been used extensively for learning low rank matrices , to the tensor setting .", "Experiments on one synthetic dataset and two real datasets indicate that the proposed method improves significantly over tensor trace norm regularization in terms of estimation error , while remaining computationally tractable .", "We study the problem of learning a tensor from a set of linear measurements .", "We then describe a technique to solve the associated regularization problem , which builds upon the alternating direction method of multipliers .", "In this paper , we highlight some limitations of this approach and propose an alternative convex relaxation on the Euclidean ball ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["We present a maximum margin framework that clusters data using latent variables .", "Using latent representations enables our framework to model unobserved information embedded in the data .", "We implement our idea by large margin learning , and develop an alternating descent algorithm to effectively solve the resultant non-convex optimization problem .", "We instantiate our latent maximum margin clustering framework with tag-based video clustering tasks , where each video is represented by a latent tag model describing the presence or absence of video tags .", "Experimental results obtained on three standard datasets show that the proposed method outperforms non-latent maximum margin clustering as well as conventional clustering approaches ."]}
{"orig_sents": ["3", "6", "1", "4", "2", "7", "5", "0"], "shuf_sents": ["This similarity measure enables us to identify different types of interactions in electrophysiological neural time series .", "Here we provide a general framework for the statistical analysis of these dependencies when random variables are sampled from stationary time-series of arbitrary objects .", "This framework enables us to develop an independence test between time series , as well as a similarity measure to compare different types of coupling .", "Many applications require the analysis of complex interactions between time series .", "To achieve this goal , we study the properties of the Kernel Cross-Spectral Density ( KCSD ) operator induced by positive definite kernels on arbitrary input domains .", "assumptions , showing improvements in terms of detection errors , as well as the suitability of this approach for testing dependency in complex dynamical systems .", "These interactions can be non-linear and involve vector valued as well as complex data structures such as graphs or strings .", "The performance of our test is compared to the HSIC test using i.i.d ."]}
{"orig_sents": ["2", "4", "3", "1", "0"], "shuf_sents": ["We also illustrate with empirical evidence that the estimated low rank embeddings lead to improved performance in density estimation .", "In this paper , we propose a hierarchical low rank decomposition of kernels embeddings which can exploit such low rank structures in data while being robust to model misspecification .", "Kernel embedding of distributions has led to many recent advances in machine learning .", "Furthermore , no prior work in kernel embedding literature has addressed the issue of robust embedding when the latent and low rank information are misspecified .", "However , latent and low rank structures prevalent in real world distributions have rarely been taken into account in this setting ."]}
{"orig_sents": ["2", "3", "4", "1", "0", "5"], "shuf_sents": ["A further important advantage of the B-tests is their asymptotically Normal null distribution : this is by contrast with the U-statistic , which is degenerate under the null hypothesis , and for which estimates of the null distribution are computationally demanding .", "In this respect , the B-test family combines favorable properties of previously proposed MMD two-sample tests : B-tests are more powerful than a linear time test where blocks are just pairs of samples , yet they are more computationally efficient than a quadratic time test where a single large block incorporating all the samples is used to compute a U-statistic .", "A family of maximum mean discrepancy ( MMD ) kernel two-sample tests is introduced .", "Members of the test family are called Block-tests or B-tests , since the test statistic is an average over MMDs computed on subsets of the samples .", "The choice of block size allows control over the tradeoff between test power and computation time .", "Recent results on kernel selection for hypothesis testing transfer seamlessly to the B-tests , yielding a means to optimize test power via kernel choice ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["We study in this paper flat and hierarchical classification strategies in the context of large-scale taxonomies .", "This bound provides an explanation to several empirical results reported in the literature , related to the performance of flat and hierarchical classifiers .", "We finally illustrate the theoretical developments through several experiments conducted on two widely used taxonomies .", "To this end , we first propose a multiclass , hierarchical data dependent bound on the generalization error of classifiers deployed in large-scale taxonomies .", "We then introduce another type of bound targeting the approximation error of a family of classifiers , and derive from it features used in a meta-classifier to decide which nodes to prune ( or flatten ) in a large-scale taxonomy ."]}
{"orig_sents": ["1", "3", "5", "2", "4", "0"], "shuf_sents": ["Our approach is provably robust , has sublinear training and inference complexity with respect to the number of labels , and compares favorably to state-of-the-art algorithms on two large scale multilabel datasets .", "This paper presents an approach to multilabel classification ( MLC ) with a large number of labels .", "We show that a naive application of Bloom filters in MLC is not robust to individual binary classifiers ' errors .", "Our approach is a reduction to binary classification in which label sets are represented by low dimensional binary vectors .", "We then present an approach that exploits a specific feature of real-world datasets when the number of labels is large : many labels ( almost ) never appear together .", "This representation follows the principle of Bloom filters , a space-efficient data structure originally designed for approximate membership testing ."]}
{"orig_sents": ["5", "0", "2", "1", "3", "4"], "shuf_sents": ["A common approach is to express these dependencies in terms of a copula function .", "To account for this , a Bayesian framework for the estimation of conditional copulas is proposed .", "Typically the copula function is assumed to be constant but this may be inaccurate when there are covariates that could have a large influence on the dependence structure of the data .", "In this framework the parameters of a copula are non-linearly related to some arbitrary conditioning variables .", "We evaluate the ability of our method to predict time-varying dependencies on several equities and currencies and observe consistent performance gains compared to static copula models and other timevarying copula methods .", "The estimation of dependencies between multiple variables is a central problem in the analysis of financial time series ."]}
{"orig_sents": ["4", "0", "6", "3", "1", "2", "5"], "shuf_sents": ["We present a fully Bayesian approach to inference and learning ( i.e .", "To enable efficient inference , we marginalize over the transition dynamics function and , instead , infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers .", "Once a sample from the smoothing distribution is computed , the state transition predictive distribution can be formulated analytically .", "We place a Gaussian process prior over the state transition dynamics , resulting in a flexible model able to capture complex dynamical phenomena .", "State-space models are successfully used in many areas of science , engineering and economics to model time series and dynamical systems .", "Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity .", "state estimation and system identification ) in nonlinear nonparametric state-space models ."]}
{"orig_sents": ["0", "7", "2", "5", "3", "1", "6", "4"], "shuf_sents": ["Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efficiency .", "Lastly , we propose an adaptation of a recently developed acquisition function , entropy search , to the cost-sensitive , multi-task setting .", "Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization .", "We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation .", "Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost .", "We show that this method significantly speeds up the optimization process when compared to the standard single-task approach .", "We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyperparameter settings for a large dataset .", "In this paper , we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to find optimal hyperparameter settings more efficiently ."]}
{"orig_sents": ["2", "0", "1", "3"], "shuf_sents": ["The algorithm estimates an inducing set and the hyperparameters using a single objective , either the marginal likelihood or a variational free energy .", "The space and time complexity are linear in training set size , and the algorithm can be applied to large regression problems on discrete or continuous domains .", "We propose an efficient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression .", "Empirical evaluation shows state-ofart performance in discrete cases and competitive results in the continuous case ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We consider this technique for learning Mahalanobis distance metrics in a Gaussian process regression setting and provide experimental evaluations and comparisons with existing methods by considering datasets with high-dimensional inputs .", "We introduce a novel variational method that allows to approximately integrate out kernel hyperparameters , such as length-scales , in Gaussian process regression .", "This approach consists of a novel variant of the variational framework that has been recently developed for the Gaussian process latent variable model which additionally makes use of a standardised representation of the Gaussian process ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["Multi-task prediction methods are widely used to couple regressors or classification models by sharing information across related tasks .", "The resulting Gaussian model has a covariance term in form of a sum of Kronecker products , for which efficient parameter inference and out of sample prediction are feasible .", "We propose a multi-task Gaussian process approach for modeling both the relatedness between regressors and the task correlations in the residuals , in order to more accurately identify true sharing between regressors .", "On both synthetic examples and applications to phenotype prediction in genetics , we find substantial benefits of modeling structured noise compared to established alternatives ."]}
{"orig_sents": ["1", "5", "0", "3", "6", "2", "4"], "shuf_sents": ["Here we present Bayes least squares and empirical Bayesian entropy rate estimators for binary spike trains using hierarchical Dirichlet process ( HDP ) priors .", "Entropy rate quantifies the amount of disorder in a stochastic process .", "Our approach mitigates this difficulty by using a hierarchical prior to share statistical power across Markov chains of different depths .", "Our estimator leverages the fact that the entropy rate of an ergodic Markov Chain with known transition probabilities can be calculated analytically , and many stochastic processes that are non-Markovian can still be well approximated by Markov processes of sufficient depth .", "We present both a fully Bayesian and empirical Bayes entropy rate estimator based on this model , and demonstrate their performance on simulated and real neural spike train data .", "For spiking neurons , the entropy rate places an upper bound on the rate at which the spike train can convey stimulus information , and a large literature has focused on the problem of estimating entropy rate from spike train data .", "Choosing an appropriate depth of Markov model presents challenges due to possibly long time dependencies and short data sequences : a deeper model can better account for long time dependencies , but is more difficult to infer from limited data ."]}
{"orig_sents": ["6", "5", "2", "9", "7", "8", "0", "1", "4", "3"], "shuf_sents": [", L } associated with X , we consider the mutual information with respect to Y and C , I ( Y ; C ) .", "New analytic expressions for the gradient of I ( Y ; X ) and I ( Y ; C ) are presented , with gradient performed with respect to the measurement matrix .", "The projection matrix is designed by maximizing mutual information between Y and X , I ( Y ; X ) .", "Example results are presented for compressive topic modeling of a document corpora ( word counting ) , and hyperspectral compressive sensing for chemical classification ( photon counting ) .", "Connections are made to the more widely studied Gaussian measurement model .", "The projections are performed on the vector Poisson rate , X Rn+ , and the observed data are a vector of counts , Y Zm + .", "We consider design of linear projection measurements for a vector Poisson signal model .", ".", ".", "When there is a latent class label C { 1 , ."]}
{"orig_sents": ["3", "1", "2", "0"], "shuf_sents": ["We provide corollaries showcasing our unified framework for varied statistical models such as linear regression , multiple regression and principal component analysis , over varied superposition structures .", "We allow for any number and types of structures , and any statistical model .", "We consider the general class of M -estimators that minimize the sum of any loss function , and an instance of what we call a `` hybrid '' regularization , that is the infimal convolution of weighted regularization functions , one for each structural component .", "We provide a unified framework for the high-dimensional analysis of `` superposition-structured '' or `` dirty '' statistical models : where the model parameters are a superposition of structurally constrained parameters ."]}
{"orig_sents": ["4", "0", "1", "2", "5", "6", "3"], "shuf_sents": ["One can sample from the posterior of mixture assignments by Monte Carlo methods or find its maximum a posteriori solution by optimization .", "However , in some problems the posterior is diffuse and it is hard to interpret the sampled partitionings .", "In this paper , we introduce novel statistics based on block sizes for representing sample sets of partitionings and feature allocations .", "Experiments on various infinite mixture posteriors as well as a feature allocation dataset demonstrate that the proposed statistics are useful in practice .", "Infinite mixture models are commonly used for clustering .", "We develop an element-based definition of entropy to quantify segmentation among their elements .", "Then we propose a simple algorithm called entropy agglomeration ( EA ) to summarize and visualize this information ."]}
{"orig_sents": ["2", "0", "1"], "shuf_sents": ["The algorithm is derived via a lowvariance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM , and provides a hard clustering with convergence guarantees similar to those of the k-means algorithm .", "Empirical results from a synthetic test with moving Gaussian clusters and a test with real ADS-B aircraft trajectory data demonstrate that the algorithm requires orders of magnitude less computational time than contemporary probabilistic and hard clustering algorithms , while providing higher accuracy on the examined datasets .", "This paper presents a novel algorithm , based upon the dependent Dirichlet process mixture model ( DDPMM ) , for clustering batch-sequential data containing an unknown number of evolving clusters ."]}
{"orig_sents": ["2", "6", "1", "5", "0", "4", "3"], "shuf_sents": ["Our result is based on a number of new insights to rigid structures alignment , clustering , and prototype reconstruction , and is practically efficient with quality guarantee .", "Existing results on this problem have mainly focused on the graph domain .", "In this paper , we study the following new variant of prototype learning , called k-prototype learning problem for 3D rigid structures : Given a set of 3D rigid structures , find a set of k rigid structures so that each of them is a prototype for a cluster of the given rigid structures and the total cost ( or dissimilarity ) is minimized .", "Experiments suggest that our approach can effectively learn prototypes in both types of data .", "We validate our approach using two type of data sets , random data and biological data of chromosome territories .", "In this paper , we present the first algorithm for learning multiple prototypes from 3D rigid structures .", "Prototype learning is a core problem in machine learning and has a wide range of applications in many areas ."]}
{"orig_sents": ["0", "1", "3", "4", "2"], "shuf_sents": ["This paper provides new algorithms for distributed clustering for two popular center-based objectives , k-median and k-means .", "These algorithms have provable guarantees and improve communication complexity over existing approaches .", "Experimental results on large scale data sets show that this approach outperforms other coreset-based distributed clustering algorithms .", "Following a classic approach in clustering by , we reduce the problem of finding a clustering with low cost to the problem of finding a coreset of small size .", "We provide a distributed method for constructing a global coreset which improves over the previous methods by reducing the communication complexity , and which works over general communication topologies ."]}
{"orig_sents": ["3", "1", "0", "2"], "shuf_sents": ["This paper presents a general framework for multiclass total variation clustering that does not rely on recursion .", "While these algorithms perform well for bi-partitioning tasks , their recursive extensions yield unimpressive results for multiclass clustering tasks .", "The results greatly outperform previous total variation algorithms and compare well with state-of-the-art NMF approaches .", "Ideas from the image processing literature have recently motivated a new set of clustering algorithms that rely on the concept of total variation ."]}
{"orig_sents": ["4", "6", "3", "5", "1", "2", "0"], "shuf_sents": ["We demonstrate the robustness benefits of our approach with some experimental results and prove for the important case of clustering that our approach has a non-trivial breakdown point , i.e. , is guaranteed to be robust to a fixed percentage of adversarial unbounded outliers .", "This enhances robustness by making assumptions on class balance .", "We further provide generalization bounds and explain how the new iterations may be computed efficiently .", "However this approach is unfortunately sensitive to outliers and large noise : a single exceptional point may take over one of the models .", "We consider the general problem of Multiple Model Learning ( MML ) from data , from the statistical and algorithmic perspectives ; this problem includes clustering , multiple regression and subspace clustering as special cases .", "We propose a different general formulation that seeks for each model a distribution over data points ; the weights are regularized to be sufficiently spread out .", "A common approach to solving new MML problems is to generalize Lloyd 's algorithm for clustering ( or Expectation-Maximization for soft clustering ) ."]}
{"orig_sents": ["5", "3", "4", "2", "1", "0", "6"], "shuf_sents": ["Moreover , our results show how the `` star shape '' in the eigenvectors-a common feature of empirical networks-can be explained by the Degree-Corrected Stochastic Blockmodel and the Extended Planted Partition model , two statistical models that allow for highly heterogeneous degrees .", "The current paper extends the previous statistical estimation results to the more canonical spectral clustering algorithm in a way that removes any assumption on the minimum degree and provides guidance on the choice of the tuning parameter .", "proposed inspired variations on the algorithm that artificially inflate the node degrees for improved statistical performance .", "Recently , Chaudhuri et al .", "and Amini et al .", "Spectral clustering is a fast and popular algorithm for finding clusters in networks .", "Throughout , the paper characterizes and justifies several of the variations of the spectral clustering algorithm in terms of these models ."]}
{"orig_sents": ["0", "1", "2", "3", "4"], "shuf_sents": ["Suppose k centers are fit to m points by heuristically minimizing the k-means cost ; what is the corresponding fit over the source distribution ?", "This question is resolved here for distributions with p 4 bounded moments ; in particular , the difference between the sample cost and distribution cost decays with m and p as mmin { -1/4 , -1/2+2/p } .", "The essential technical contribution is a mechanism to uniformly control deviations in the face of unbounded parameter sets , cost functions , and source distributions .", "To further demonstrate this mechanism , a soft clustering variant of k-means cost is also considered , namely the log likelihood of a Gaussian mixture , subject to the constraint that all covariance matrices have bounded spectrum .", "Lastly , a rate with refined constants is provided for k-means instances possessing some cluster structure ."]}
{"orig_sents": ["6", "2", "7", "5", "3", "1", "4", "0"], "shuf_sents": ["This leads to the first differentially-private active learning algorithms with exponential label savings over the passive case .", "These results combined with our generic conversion lead to the first computationally-efficient algorithms for actively learning some of these concept classes in the presence of random classification noise that provide exponential improvement in the dependence on the error over their passive counterparts .", "The framework is based on active learning algorithms that are statistical in the sense that they rely on estimates of expectations of functions of filtered random examples .", "We show that commonly studied concept classes including thresholds , rectangles , and linear separators can be efficiently actively learned in our framework .", "In addition , we show that our algorithms can be automatically converted to efficient active differentially-private algorithms .", "We show that any efficient active statistical learning algorithm can be automatically converted to an efficient active learning algorithm which is tolerant to random classification noise as well as other forms of `` uncorrelated '' noise .", "We describe a framework for designing efficient active learning algorithms that are tolerant to random classification noise and differentially-private .", "It builds on the powerful statistical query framework of Kearns ."]}
{"orig_sents": ["1", "3", "2", "5", "0", "4"], "shuf_sents": ["In particular , we give a novel PAC generalization bound for mixtures of learnable processes with a generalization error that is not worse than that of each mixture component .", "We informally call a stochastic process learnable if it admits a generalization error approaching zero in probability for any concept class with finite VC-dimension ( IID processes are the simplest example ) .", "In this paper , we argue that it is natural in predictive PAC to condition not on the past observations but on the mixture component of the sample path .", "A mixture of learnable processes need not be learnable itself , and certainly its generalization error need not decay at the same rate .", "We also provide a characterization of mixtures of absolutely regular ( -mixing ) processes , of independent probability-theoretic interest .", "This definition not only matches what a realistic learner might demand , but also allows us to sidestep several otherwise grave problems in learning from dependent data ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We present the first result for kernel regression where the procedure adapts locally at a point x to both the unknown local dimension of the metric space X and the unknown Holder-continuity of the regression function at x .", "The result holds with high probability simultaneously at all points x in a general metric space X of unknown structure ."]}
{"orig_sents": ["0", "2", "3", "1", "5", "4"], "shuf_sents": ["The Lasso is a cornerstone of modern multivariate data analysis , yet its performance suffers in the common situation in which covariates are correlated .", "In this paper we propose an agnostic framework for comparing Preconditioned Lasso algorithms to the Lasso without having to choose .", "This limitation has led to a growing number of Preconditioned Lasso algorithms that pre-multiply X and y by matrices PX , Py prior to running the standard Lasso .", "A direct comparison of these and similar Lasso-style algorithms to the original Lasso is difficult because the performance of all of these methods depends critically on an auxiliary penalty parameter .", "Additionally , our theory reveals fragilities of these algorithms to which we provide partial solutions .", "We apply our framework to three Preconditioned Lasso instances and highlight cases when they will outperform the Lasso ."]}
{"orig_sents": ["4", "3", "5", "0", "1", "2"], "shuf_sents": ["O ( np ) and our best method , Uluru , gives an error bound of O ( p/n ) which is independent of the amount of subsampling as long as it is above a threshold .", "We provide theoretical bounds for our algorithms in the fixed design ( with Randomized Hadamard preconditioning ) as well as sub-Gaussian random design setting .", "We also compare the performance of our methods on synthetic and real-world datasets and show that if observations are i.i.d. , sub-Gaussian then one can directly subsample without the expensive Randomized Hadamard preconditioning without loss of accuracy .", "We propose three methods which solve the big data problem by subsampling the covariance matrix using either a single or two stage estimation .", "We address the problem of fast estimation of ordinary least squares ( OLS ) from large amounts of data ( n p ) .", "All three run in the order of size of input i.e ."]}
{"orig_sents": ["1", "2", "0", "3"], "shuf_sents": ["Our algorithm Subsampled Randomized Hadamard Transform- Dual Ridge Regression ( SRHT-DRR ) runs in time O ( np log ( n ) ) and works by preconditioning the design matrix by a Randomized Walsh-Hadamard Transform with a subsequent subsampling of features .", "We propose a fast algorithm for ridge regression when the number of features is much larger than the number of observations ( p n ) .", "The standard way to solve ridge regression in this setting works in the dual space and gives a running time of O ( n2 p ) .", "We provide risk bounds for our SRHT-DRR algorithm in the fixed design setting and show experimental results on synthetic and real datasets ."]}
{"orig_sents": ["2", "0", "3", "1"], "shuf_sents": ["Although results in supervised and reinforcement learning show that transfer may significantly improve the learning performance , most of the literature on transfer is focused on batch learning tasks .", "We introduce a novel bandit algorithm based on a method-of-moments approach for estimating the possible tasks and derive regret bounds for it .", "Learning from prior tasks and transferring that experience to improve future performance is critical for building lifelong learning agents .", "In this paper we study the problem of sequential transfer in online learning , notably in the multi-armed bandit framework , where the objective is to minimize the total regret over a sequence of tasks by transferring knowledge from prior tasks ."]}
{"orig_sents": ["0", "3", "1", "4", "2"], "shuf_sents": ["We consider the stochastic multi-armed bandit problem with a prior distribution on the reward distributions .", "We first show that Thompson Sampling attains an optimal prior-free bound in the sense that for any prior distribution its Bayesian regret is bounded from above by 14 nK .", "We also study the case of priors for the setting of Bubeck et al . 20 ( where the optimal mean is known as well as a lower bound on the smallest gap ) and we show that in this case the regret of Thompson Sampling is in fact uniformly bounded over time , thus showing that Thompson Sampling can greatly take advantage of the nice properties of these priors .", "We are interested in studying prior-free and priordependent regret bounds , very much in the same spirit than the usual distributionfree and distribution-dependent bounds for the non-Bayesian stochastic bandit .", "This result is unimprovable in the sense that there exists a prior distribution such that any algorithm has a Bayesian regret bounded from below by ."]}
{"orig_sents": ["1", "4", "2", "3", "0", "5"], "shuf_sents": ["This two-target algorithm achieves a long-term average regret in 2n for a large parameter m and a known time horizon n. This regret is optimal andstrictly less than the regret achieved by the best known algorithms , which is in 2 n. The results are extended to any mean-reward distribution whose support contains 1 and to unknown time horizons .", "We consider an infinite-armed bandit problem with Bernoulli rewards .", "Rewards 0 and 1 are referred to as a success and a failure , respectively .", "We propose a novel algorithm where the decision to exploit any arm is based on two successive targets , namely , the total number of successes until the first failure and until the first m failures , respectively , where m is a fixed parameter .", "The mean rewards are independent , uniformly distributed over .", "Numerical experiments show the performance of the algorithm for finite time horizons ."]}
{"orig_sents": ["2", "3", "0", "4", "1"], "shuf_sents": ["Our proof builds on previous work , but also makes extensive use of closed forms for Kullback-Leibler divergence and Fisher information ( through the Jeffreys prior ) available in an exponential family .", "Moreover our analysis covers some distributions for which no optimistic algorithm has yet been proposed , including heavy-tailed exponential families .", "Thompson Sampling has been demonstrated in many complex bandit models , however the theoretical guarantees available for the parametric multi-armed bandit are still limited to the Bernoulli case .", "Here we extend them by proving asymptotic optimality of the algorithm using the Jeffreys prior for 1-dimensional exponential family bandits .", "This allow us to give a finite time exponential concentration inequality for posterior distributions on exponential families that may be of interest in its own right ."]}
{"orig_sents": ["5", "3", "0", "1", "2", "4"], "shuf_sents": ["To address this , we present a novel approach for MCTS using Bayesian mixture modeling and inference based Thompson sampling and apply it to the problem of online planning in MDPs .", "Our algorithm , named Dirichlet-NormalGamma MCTS ( DNG-MCTS ) , models the uncertainty of the accumulated reward for actions in the search tree as a mixture of Normal distributions .", "We perform inferences on the mixture in Bayesian settings by choosing conjugate priors in the form of combinations of Dirichlet and NormalGamma distributions and select the best action at each decision node using Thompson sampling .", "One of the key challenges is the trade-off between exploration and exploitation .", "Experimental results confirm that our algorithm advances the state-of-the-art UCT approach with better values on several benchmark problems .", "Monte-Carlo tree search ( MCTS ) has been drawing great interest in recent years for planning and learning under uncertainty ."]}
{"orig_sents": ["1", "2", "3", "0"], "shuf_sents": ["The key insights are that local differences in link numbers can be used to estimate a local function of the gradient of p , and that integrating this function along shortest paths leads to an estimate of the underlying density .", "Consider an unweighted k-nearest neighbor graph on n points that have been sampled i.i.d .", "from some unknown density p on Rd .", "We prove how one can estimate the density p just from the unweighted adjacency matrix of the graph , without knowing the points themselves or any distance or similarity scores ."]}
{"orig_sents": ["3", "2", "0", "1"], "shuf_sents": ["We show that this structure can be exploited to further accelerate the solution of the regression problem , achieving running times that are faster than `` input sparsity '' .", "We present empirical results confirming both the practical value of our modeling framework , as well as speedup benefits of randomized regression .", "These problems involve Vandermonde matrices which arise naturally in various statistical modeling settings , including classical polynomial fitting problems , additive models and approximations to recently developed randomized techniques for scalable kernel methods .", "Motivated by the desire to extend fast randomized techniques to nonlinear lp regression , we consider a class of structured regression problems ."]}
{"orig_sents": ["4", "5", "0", "1", "3", "2"], "shuf_sents": ["It still lacks of efforts in studying them in a distributed framework .", "We make a progress along the line by presenting a distributed stochastic dual coordinate ascent algorithm in a star network , with an analysis of the tradeoff between computation and communication .", "Moreover , we compare the proposed algorithm with distributed stochastic gradient descent methods and distributed alternating direction methods of multipliers for optimizing SVMs in the same distributed framework , and observe competitive performances .", "We verify our analysis by experiments on real data sets .", "We present and study a distributed optimization algorithm by employing a stochastic dual coordinate ascent method .", "Stochastic dual coordinate ascent methods enjoy strong theoretical guarantees and often have better performances than stochastic gradient descent methods in optimizing regularized loss minimization problems ."]}
{"orig_sents": ["1", "4", "2", "0", "3", "5", "7", "6"], "shuf_sents": ["This can lead to miscalibration of predictive intervals , which can be substantially too narrow or wide depending on the time .", "In modeling multivariate time series , it is important to allow time-varying smoothness in the mean and covariance process .", "If such locally adaptive smoothness is not accounted for , one can obtain misleading inferences and predictions , with over-smoothing across erratic time intervals and under-smoothing across times exhibiting slow variation .", "We propose a continuous multivariate stochastic process for time series having locally varying smoothness in both the mean and covariance matrix .", "In particular , there may be certain time intervals exhibiting rapid changes and others in which changes are slow .", "This process is constructed utilizing latent dictionary functions in time , which are given nested Gaussian process priors and linearly related to the observed data through a sparse mapping .", "The performance is assessed in simulations and illustrated in a financial application .", "Using a differential equation representation , we bypass usual computational bottlenecks in obtaining MCMC and online algorithms for approximate Bayesian inference ."]}
{"orig_sents": ["1", "4", "3", "6", "0", "2", "5"], "shuf_sents": ["We establish nonasymptotic performance guarantees of both weighted majority voting and nearest-neighbor classification under our model accounting for how much of the time series we observe and the model complexity .", "For classifying time series , a nearest-neighbor approach is widely used in practice with performance often competitive with or better than more elaborate methods such as neural networks , decision trees , and support vector machines .", "Experimental results on synthetic data show weighted majority voting achieving the same misclassification rate as nearest-neighbor classification while observing less of the time series .", "Our guiding hypothesis is that in many applications , such as forecasting which topics will become trends on Twitter , there are n't actually that many prototypical time series to begin with , relative to the number of time series we have access to , e.g. , topics become trends on Twitter only in a few distinct manners whereas we can collect massive amounts of Twitter data .", "We develop theoretical justification for the effectiveness of nearest-neighbor-like classification of time series .", "We then use weighted majority to forecast which news topics on Twitter become trends , where we are able to detect such `` trending topics '' in advance of Twitter 79 % of the time , with a mean early advantage of 1 hour and 26 minutes , a true positive rate of 95 % , and a false positive rate of 4 % .", "To operationalize this hypothesis , we propose a latent source model for time series , which naturally leads to a `` weighted majority voting '' classification rule that can be approximated by a nearest-neighbor classifier ."]}
{"orig_sents": ["1", "3", "4", "2", "0", "6", "5"], "shuf_sents": ["The MLDS models each tensor observation in the time series as the multilinear projection of the corresponding member of a sequence of latent tensors .", "Data in the sciences frequently occur as sequences of multidimensional arrays called tensors .", "We present the multilinear dynamical system ( MLDS ) for modeling tensor time series and an expectation-maximization ( EM ) algorithm to estimate the parameters .", "How can hidden , evolving trends in such data be extracted while preserving the tensor structure ?", "The model that is traditionally used is the linear dynamical system ( LDS ) with Gaussian noise , which treats the latent state and observation at each time slice as a vector .", "Compared to the LDS with an equal number of parameters , the MLDS achieves higher prediction accuracy and marginal likelihood for both artificial and real datasets .", "The latent tensors are again evolving with respect to a multilinear projection ."]}
{"orig_sents": ["1", "0", "4", "2", "3", "5"], "shuf_sents": ["While this data is often either proprietary or sensitive , aggregated data , notably row and column marginals , is often viewed as much less sensitive , and may be furnished for analysis .", "Numerous datasets ranging from group memberships within social networks to purchase histories on e-commerce sites are represented by binary matrices .", "We do this for all the cells of H simultaneously , without generating realizations , but rather via implicitly sampling the datasets that satisfy the input marginals .", "The end result is an efficient algorithm with asymptotic running time the same as that required by standard sampling techniques to generate a single dataset from the same dataspace .", "Here , we investigate how these data can be exploited to make inferences about the underlying matrix H. Instead of assuming a generative model for H , we view the input marginals as constraints on the dataspace of possible realizations of H and compute the probability density function of particular entries H ( i , j ) of interest .", "Our experimental evaluation demonstrates the efficiency and the efficacy of our framework in multiple settings ."]}
{"orig_sents": ["0", "3", "1", "2"], "shuf_sents": ["We propose a general framework for reconstructing and denoising single entries of incomplete and noisy entries .", "In the noiseless case our algorithm is exact .", "For rank-one matrices , the new algorithm is fast , admits a highly-parallel implementation , and produces an error minimizing estimate that is qualitatively close to our theoretical and the state-of-the-art Nuclear Norm and OptSpace methods .", "We describe : effective algorithms for deciding if and entry can be reconstructed and , if so , for reconstructing and denoising it ; and a priori bounds on the error of each entry , individually ."]}
{"orig_sents": ["2", "0", "5", "3", "1", "4"], "shuf_sents": ["Unfortunately , domain modeling is a laborious and error-prone task , thus real world agents have to plan with incomplete domain models .", "In this paper , we first introduce annotations expressing the knowledge of the domain incompleteness and formalize the notion of plan robustness with respect to an incomplete domain model .", "Most current planners assume complete domain models and focus on generating correct plans .", "In such cases , the goal should be to synthesize plans that are robust with respect to any known incompleteness of the domain .", "We then show an approach to compiling the problem of finding robust plans to the conformant probabilistic planning problem , and present experimental results with Probabilistic-FF planner .", "While domain experts can not guarantee completeness , often they are able to circumscribe the incompleteness of the model by providing annotations as to which parts of the domain model may be incomplete ."]}
{"orig_sents": ["0", "1", "3", "2"], "shuf_sents": ["We consider the task of nearest-neighbor search with the class of binary-spacepartitioning trees , which includes kd-trees , principal axis trees and random projection trees , and try to rigorously answer the question `` which tree to use for nearestneighbor search ? ''", "To this end , we present the theoretical results which imply that trees with better vector quantization performance have better search performance guarantees .", "We demonstrate , both theoretically and empirically , that large margin partitions can improve tree search performance .", "We also explore another factor affecting the search performance - margins of the partitions in these trees ."]}
{"orig_sents": ["6", "1", "4", "2", "5", "0", "3", "7"], "shuf_sents": ["Practical examples of this task include traffic monitoring systems in cities , where we need to infer the traffic volume on single link on a road network from a limited number of observation points .", "A Markov chain is characterized by initial-state probabilities and a state-transition probability matrix .", "This paper tackles an inverse version of the problem : we find those probabilities from partial observations at a limited number of states .", "We formulate this task as a regularized optimization problem , which is efficiently solved using the notion of natural gradient .", "In the traditional setting , a major goal is to study properties of a Markov chain when those probabilities are known .", "The observations include the frequency of visiting a state and the rate of reaching a state from another .", "The Markov chain is a convenient tool to represent the dynamics of complex systems such as traffic and social systems , where probabilistic transition takes place between internal states .", "Using synthetic and real-world data sets including city traffic monitoring data , we demonstrate the effectiveness of our method ."]}
{"orig_sents": ["6", "0", "3", "5", "1", "4", "2"], "shuf_sents": ["If the conditional expectations in the DP recursions are estimated via kernel regression , however , the historical sample paths enter the solution procedure directly as they determine the evaluation points of the cost-to-go functions .", "To mitigate these small sample effects , we propose a robust data-driven DP scheme , which replaces the expectations in the DP recursions with worst-case expectations over a set of distributions close to the best estimate .", "We also demonstrate that the proposed robust DP algorithm dominates various non-robust schemes in out-of-sample tests across several application domains .", "The resulting data-driven DP scheme is asymptotically consistent and admits an efficient computational solution when combined with parametric value function approximations .", "We show that the arising minmax problems in the DP recursions reduce to tractable conic programs .", "If training data is sparse , however , the estimated cost-to-go functions display a high variability and an optimistic bias , while the corresponding control policies perform poorly in out-of-sample tests .", "In stochastic optimal control the distribution of the exogenous noise is typically unknown and must be inferred from limited data before dynamic programming ( DP ) -based solution schemes can be applied ."]}
{"orig_sents": ["4", "5", "1", "2", "3", "0"], "shuf_sents": ["We also develop a variational method for inferring the parameters of the ( non-exponential family ) Rice distribution .", "We develop variational approximations to the posterior on change point times ( formulated as run lengths ) for efficient inference when the underlying model is not in the exponential family , and does not have tractable posterior predictive distributions .", "In doing so , we develop improvements to online variational inference .", "We apply our methodology to a tracking problem using radar data with a signal-to-noise feature that is Rice distributed .", "The Bayesian online change point detection ( BOCPD ) algorithm provides an efficient way to do exact inference when the parameters of an underlying model may suddenly change over time .", "BOCPD requires computation of the underlying model 's posterior predictives , which can only be computed online in O ( 1 ) time and memory for exponential family models ."]}
{"orig_sents": ["3", "2", "4", "0", "1"], "shuf_sents": ["For this purpose , we introduce a new global convex optimization program that finds all estimated sets at once and show that it can be solved efficiently .", "We prove the correctness of our method and present empirical results that demonstrate its superiority over existing methods .", "Our method can be regarded as a natural extension of the one-class SVM ( OCSVM ) algorithm that finds multiple parallel separating hyperplanes in a reproducing kernel Hilbert space .", "In this paper we introduce a novel method that can efficiently estimate a family of hierarchical dense sets in high-dimensional distributions .", "We call our method q-OCSVM , as it can be used to estimate q quantiles of a highdimensional distribution ."]}
{"orig_sents": ["2", "3", "0", "1"], "shuf_sents": ["Starting from a trivial initial grammar , our approach iteratively induces compositions and reconfigurations in a unified manner and optimizes the posterior probability of the grammar .", "In our empirical evaluation , we applied our approach to learning event grammars and image grammars and achieved comparable or better performance than previous approaches .", "Stochastic And-Or grammars compactly represent both compositionality and reconfigurability and have been used to model different types of data such as images and events .", "We present a unified formalization of stochastic And-Or grammars that is agnostic to the type of the data being modeled , and propose an unsupervised approach to learning the structures as well as the parameters of such grammars ."]}
{"orig_sents": ["0", "2", "1", "3"], "shuf_sents": ["Distance-based approaches to outlier detection are popular in data mining , as they do not require to model the underlying probability distribution , which is particularly challenging for high-dimensional data .", "We report the surprising observation that a simple , sampling-based scheme outperforms state-of-the-art techniques in terms of both efficiency and effectiveness .", "We present an empirical comparison of various approaches to distance-based outlier detection across a large number of datasets .", "To better understand this phenomenon , we provide a theoretical analysis why the sampling-based approach outperforms alternative methods based on k-nearest neighbor search ."]}
{"orig_sents": ["1", "0", "2", "3"], "shuf_sents": ["Here we present a Hierarchical Bayesian model based on compositionality and causality that can learn a wide range of natural ( although simple ) visual concepts , generalizing in human-like ways from just one image .", "People can learn a new visual class from just one example , yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems .", "We evaluated performance on a challenging one-shot classification task , where our model achieved a human-level error rate while substantially outperforming two deep learning models .", "We also tested the model on another conceptual task , generating new examples , by using a `` visual Turing test '' to show that our model produces human-like performance ."]}
{"orig_sents": ["9", "2", "0", "8", "4", "7", "6", "1", "3", "5"], "shuf_sents": ["In this paper , we intend to make this principle scalable .", "First , we propose a new stochastic proximal gradient method , which experimentally matches state-of-the-art solvers for large-scale 1 logistic regression .", "Because of its simplicity and its wide applicability , this principle has been very popular in statistics and in signal processing .", "Second , we develop an online DC programming algorithm for non-convex sparse estimation .", "When applied to convex optimization problems under suitable assumptions , we show that it achieves an expected convergence rate of O ( 1/ n ) after n iterations , and of O ( 1/n ) for strongly convex functions .", "Finally , we demonstrate the effectiveness of our approach for solving large-scale structured matrix factorization problems .", "We develop several efficient algorithms based on our framework .", "Equally important , our scheme almost surely converges to stationary points for a large class of non-convex problems .", "We introduce a stochastic majorization-minimization scheme which is able to deal with largescale or possibly infinite data sets .", "Majorization-minimization algorithms consist of iteratively minimizing a majorizing surrogate of an objective function ."]}
{"orig_sents": ["5", "7", "2", "6", "0", "3", "4", "1"], "shuf_sents": ["Specifically , we formulate the data recovery problem as a joint robust principal component analysis problem on the two data matrices , with common principal components shared across matrices and individual principal components specific to each data matrix .", "Our empirical results over image denoising tasks show the proposed method can effectively recover images with random large errors , and significantly outperform both standard PCA and robust PCA with rank constraints .", "In this paper , we tackle the challenge problem of recovering data corrupted with errors of high magnitude by developing a novel robust transfer principal component analysis method .", "The formulated optimization problem is a minimization problem over a convex objective function but with non-convex rank constraints .", "We develop an efficient proximal projected gradient descent algorithm to solve the proposed optimization problem with convergence guarantees .", "Principal component analysis ( PCA ) , a well-established technique for data analysis and processing , provides a convenient form of dimensionality reduction that is effective for cleaning small Gaussian noises presented in the data .", "Our method is based on the assumption that useful information for the recovery of a corrupted data matrix can be gained from an uncorrupted related data matrix .", "However , the applicability of standard principal component analysis in real scenarios is limited by its sensitivity to large errors ."]}
{"orig_sents": ["2", "1", "5", "3", "4", "6", "0"], "shuf_sents": ["Comprehensive simulations on subspace recovering and tracking demonstrate the robustness and efficiency advantages of the OR-PCA over online PCA and batch RPCA methods .", "This prevents them from efficiently processing big data .", "Robust PCA methods are typically based on batch optimization and have to load all the samples into memory during optimization .", "The proposed OR-PCA is based on stochastic optimization of an equivalent reformulation of the batch RPCA .", "Indeed , we show that OR-PCA provides a sequence of subspace estimations converging to the optimum of its batch counterpart and hence is provably robust to sparse corruption .", "In this paper , we develop an Online Robust PCA ( OR-PCA ) that processes one sample per time instance and hence its memory cost is independent of the number of samples , significantly enhancing the computation and storage efficiency .", "Moreover , OR-PCA can naturally be applied for tracking dynamic subspace ."]}
{"orig_sents": ["2", "4", "3", "0", "1"], "shuf_sents": ["Two classical such schemes are due to Krasulina ( 1969 ) and Oja ( 1983 ) .", "We give finite-sample convergence rates for both .", "We consider a situation in which we see samples Xn Rd drawn i.i.d .", "We wish to compute the top eigenvector of A in an incremental fashion - with an algorithm that maintains an estimate of the top eigenvector in O ( d ) space , and incrementally adjusts the estimate with each new data point that arrives .", "from some distribution with mean zero and unknown covariance A ."]}
{"orig_sents": ["0", "4", "3", "1", "2"], "shuf_sents": ["Principal geodesic analysis ( PGA ) is a generalization of principal component analysis ( PCA ) for dimensionality reduction of data on a Riemannian manifold .", "To compute maximum likelihood estimates of the parameters in our model , we develop a Monte Carlo Expectation Maximization algorithm , where the expectation is approximated by Hamiltonian Monte Carlo sampling of the latent variables .", "We demonstrate the ability of our method to recover the ground truth parameters in simulated sphere data , as well as its effectiveness in analyzing shape variability of a corpus callosum data set from human brain images .", "Inspired by probabilistic PCA , we present a latent variable model for PGA that provides a probabilistic framework for factor analysis on manifolds .", "Currently PGA is defined as a geometric fit to the data , rather than as a probabilistic model ."]}
{"orig_sents": ["8", "5", "7", "0", "9", "2", "1", "4", "6", "3"], "shuf_sents": ["The two main contributions of this work are as follows : 1 .", "We propose a very simple and efficient fixed-point GI-ICA ( Gradient Iteration ICA ) algorithm , which is compatible with quasi-orthogonalization , as well as with the usual PCA-based whitening in the noiseless case .", "2 .", "We also present a number of experimental comparisons with the existing methods , showing superior results on noisy data and very competitive performance in the noiseless case .", "The algorithm is based on a special form of gradient iteration ( different from gradient descent ) .", "This is partially due to a common first step that typically consists of whitening , i.e. , applying Principal Component Analysis ( PCA ) and rescaling the components to have identity covariance , which is not invariant under Gaussian noise .", "We provide an analysis of our algorithm demonstrating fast convergence following from the basic properties of cumulants .", "In our paper we develop the first practical algorithm for Independent Component Analysis that is provably invariant under Gaussian noise .", "The performance of standard algorithms for Independent Component Analysis quickly deteriorates under the addition of Gaussian noise .", "We develop and implement an efficient , Gaussian noise invariant decorrelation ( quasi-orthogonalization ) algorithm using Hessians of the cumulant functions ."]}
{"orig_sents": ["3", "1", "2", "5", "4", "6", "0"], "shuf_sents": ["This endows online RPCA with scalability for large scale data .", "Due to their sensitiveness to outliers , previous online PCA algorithms fail in this case and their results can be arbitrarily skewed by the outliers .", "Here we propose the online robust PCA algorithm , which is able to improve the PCs estimation upon an initial one steadily , even when faced with a constant fraction of outliers .", "We consider the online Principal Component Analysis ( PCA ) where contaminated samples ( containing outliers ) are revealed sequentially to the Principal Components ( PCs ) estimator .", "Actually , under mild conditions , online RPCA achieves the maximal robustness with a 50 % breakdown point .", "We show that the final result of the proposed online RPCA has an acceptable degradation from the optimum .", "Moreover , online RPCA is shown to be efficient for both storage and computation , since it need not re-explore the previous samples as in traditional robust PCA algorithms ."]}
{"orig_sents": ["5", "2", "0", "6", "4", "3", "1"], "shuf_sents": ["We establish a near-optimal convergence rate , in terms of the sparsity , ambient dimension , and sample size , for estimation of the principal subspace of a general covariance matrix without assuming the spiked covariance model .", "We demonstrate this with an application to Kendall 's tau correlation matrices and transelliptical component analysis .", "The convex problem can be solved efficiently using alternating direction method of multipliers ( ADMM ) .", "We also provide a general theoretical framework for analyzing the statistical properties of the method for arbitrary input matrices that extends the applicability and provable guarantees to a wide array of settings .", "even when the solution is not rank 1 .", "We propose a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-d projection matrices ( the Fantope ) .", "In the special case of d = 1 , our result implies the near-optimality of DSPCA ( d'Aspremont et al. )"]}
{"orig_sents": ["5", "2", "3", "0", "6", "4", "1"], "shuf_sents": ["The proposed methodology is a variant of principal component regression ( PCR ) .", "This expansion phenomenon appears to be somewhat novel and contrasts with shrinkage methods ( c < 1 ) , which are far more common in big data analyses .", "Associated with each observation yi is a very highdimensional vector xi Rd , which provides context for yi and enables us to predict subsequent observations , given their own context .", "One of the salient features of our analysis is that the problems studied here are easier when the dimension of xi is large ; in other words , prediction becomes easier when more context is provided .", "For instance , we show that classical PCR estimators may be inconsistent in the specified setting , unless they are multiplied by a scalar c > 1 ; that is , unless the classical estimator is expanded .", "We model a `` one-shot learning '' situation , where very few observations y1 , ... , yn R are available .", "Our rigorous analysis sheds new light on PCR ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We introduce the Randomized Dependence Coefficient ( RDC ) , a measure of nonlinear dependence between random variables of arbitrary dimension based on the Hirschfeld-Gebelein-Renyi Maximum Correlation Coefficient .", "RDC is defined in terms of correlation of random non-linear copula projections ; it is invariant with respect to marginal distribution transformations , has low computational cost and is easy to implement : just five lines of R code , included at the end of the paper ."]}
{"orig_sents": ["2", "5", "6", "3", "8", "0", "4", "1", "7"], "shuf_sents": ["Interestingly , we find that the optimization task of SAM-LRB can be transformed into the same form as in Robust PCA .", "Besides the supervised case , we extend SAM-LRB to favor unsupervised and multifaceted scenarios .", "The sparse additive model for text modeling involves the sum-of-exp computing , whose cost is consuming for large scales .", "Particularly , employing a double majorization bound , we approximate log-likelihood into a quadratic lower-bound without the log-sumexp terms .", "Consequently , parameters of supervised SAM-LRB can be efficiently learned using an existing algorithm for Robust PCA based on accelerated proximal gradient .", "Moreover , the assumption of equal background across all classes/topics may be too strong .", "This paper extends to propose sparse additive model with low rank background ( SAM-LRB ) and obtains simple yet efficient estimation .", "Experiments on three real data demonstrate the effectiveness and efficiency of SAM-LRB , compared with a few state-of-the-art models .", "The constraints of low rank and sparsity are then simply embodied by nuclear norm and 1 -norm regularizers ."]}
{"orig_sents": ["3", "0", "2", "4", "1", "5", "6"], "shuf_sents": ["Recently , it has been observed that for many text corpora documents evolve into one another in a smooth way , with some features dropping and new ones being introduced .", "This may be problematic especially for lower dimensional grids .", "The counting grid models this spatial metaphor literally : it is a grid of word distributions learned in such a way that a document 's own distribution of features can be modeled as the sum of the histograms found in a window into the grid .", "In text analysis documents are often represented as disorganized bags of words ; models of such count features are typically based on mixing a small number of topics .", "The major drawback of this method is that it is essentially a mixture and all the content must be generated by a single contiguous area on the grid .", "In this paper , we overcome this issue by introducing the Componential Counting Grid which brings the componential nature of topic models to the basic counting grid .", "We evaluated our approach on document classification and multimodal retrieval obtaining state of the art results on standard benchmarks ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["We demonstrate the effectiveness and efficiency of our algorithms on both synthetic and real data sets .", "Nonnegative matrix factorization ( NMF ) is a popular data analysis method , the objective of which is to approximate a matrix with all nonnegative components into the product of two nonnegative matrices .", "Furthermore , we extend the mfNMF algorithm to incorporate a regularizer based on the Dirichlet distribution to encourage the sparsity of the components of the obtained factors .", "Our sparse mfNMF algorithm affords a closed form and an intuitive interpretation , and is more efficient in comparison with previous works that use fix point iterations .", "In this work , we describe a new simple and efficient algorithm for multi-factor nonnegative matrix factorization ( mfNMF ) problem that generalizes the original NMF problem to more than two factors ."]}
{"orig_sents": ["1", "2", "8", "7", "6", "0", "4", "3", "5"], "shuf_sents": ["We propose an architecture that uses a rich feedback loop between extraction and prediction .", "Discriminative methods for learning structured models have enabled wide-spread use of very rich feature representations .", "However , the computational cost of feature extraction is prohibitive for large-scale or time-sensitive applications , often dominating the cost of inference in the models .", "We demonstrate significant speedups over state-of-the-art methods on two challenging datasets .", "The run-time control policy is learned using efficient value-function approximation , which adaptively determines the value of information of features at the level of individual variables for each input .", "For articulated pose estimation in video , we achieve a more accurate state-of-the-art model that is also faster , with similar results on an OCR task .", "We address the key challenge of learning to control fine-grained feature extraction adaptively , exploiting nonhomogeneity of the data .", "Such feature selection methods control computation statically and miss the opportunity to finetune feature extraction to each input at run-time .", "Significant efforts have been devoted to sparsity-based model selection to decrease this cost ."]}
{"orig_sents": ["2", "5", "4", "0", "1", "3"], "shuf_sents": ["We address this through our second and main contribution , symbolic Opportunistic Policy Iteration ( OPI ) , which is a novel convergent algorithm lying between VI and MPI , that applies policy constraints if it does not increase the size of the value function representation , and otherwise performs VI backups .", "We also give a memory bounded version of this algorithm allowing a space-time tradeoff .", "This paper addresses the scalability of symbolic planning under uncertainty with factored states and actions .", "Empirical results show significantly improved scalability over state-of-the-art symbolic planners .", "Unfortunately , a naive approach to enforce policy constraints can lead to large memory requirements , sometimes making symbolic MPI worse than VI .", "Our first contribution is a symbolic implementation of Modified Policy Iteration ( MPI ) for factored actions that views policy evaluation as policy-constrained value iteration ( VI ) ."]}
{"orig_sents": ["0", "5", "6", "2", "3", "1", "4", "7"], "shuf_sents": ["We present four major results towards solving decentralized partially observable Markov decision problems ( DecPOMDPs ) culminating in an algorithm that outperforms all existing algorithms on all but one standard infinite-horizon benchmark problems .", "( 3 ) We present a method to transform any DecPOMDP into a DecPOMDP with bounded beliefs ( the number of beliefs is a free parameter ) using optimal ( not lossless ) belief compression .", "( 2 ) We show that a DecPOMDP with bounded belief can be converted to a POMDP ( albeit with actions exponential in the number of beliefs ) .", "These actions correspond to strategies of a CBG .", "( 4 ) We show that the combination of these results opens the door for new classes of DecPOMDP algorithms based on previous POMDP algorithms .", "( 1 ) We give an integer program that solves collaborative Bayesian games ( CBGs ) .", "The program is notable because its linear relaxation is very often integral .", "We choose one such algorithm , point-based valued iteration , and modify it to produce the first tractable value iteration method for DecPOMDPs that outperforms existing algorithms ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["We present a general template of MCTS algorithms for these games , which can be instantiated by various selection methods .", "We empirically evaluate this claim using regret matching and Exp3 as the selection methods on randomly generated games and empirically selected worst case games .", "We formally prove that if a selection method is -Hannan consistent in a matrix game and satisfies additional requirements on exploration , then the MCTS algorithm eventually converges to an approximate Nash equilibrium ( NE ) of the extensive-form game .", "We confirm the formal result and show that additional MCTS variants also converge to approximate NE on the evaluated games .", "We study Monte Carlo tree search ( MCTS ) in zero-sum extensive-form games with perfect information and simultaneous moves ."]}
{"orig_sents": ["2", "1", "0"], "shuf_sents": ["We then propose simple bias-correction methods with benefits to both the search engine and the advertisers .", "In this paper , we show that the naive application of MAB algorithms to search advertising for advertisement selection will produce sample selection bias that harms the search engine by decreasing expected revenue and `` estimation of the largest mean '' ( ELM ) bias that harms the advertisers by increasing game-theoretic player-regret .", "In search advertising , the search engine needs to select the most profitable advertisements to display , which can be formulated as an instance of online learning with partial feedback , also known as the stochastic multi-armed bandit ( MAB ) problem ."]}
{"orig_sents": ["3", "0", "2", "1", "4", "5"], "shuf_sents": ["First , we recover the Mirror Prox algorithm for offline optimization , prove an extension to Holder-smooth functions , and apply the results to saddle-point type problems .", "This addresses a question of Daskalakis et al .", "Next , we prove that a version of Optimistic Mirror Descent ( which has a close relation to the Exponential Weights algorithm ) can be used by two strongly-uncoupled players in a finite zero-sum matrix game to converge to the minimax equilibrium at the rate of O ( ( log T ) T ) .", "We provide several applications of Optimistic Mirror Descent , an online learning algorithm based on the idea of predictable sequences .", "Further , we consider a partial information version of the problem .", "We then apply the results to convex programming and exhibit a simple algorithm for the approximate Max Flow problem ."]}
{"orig_sents": ["3", "0", "4", "1", "2"], "shuf_sents": ["The player strives to minimize regret , the difference between his loss and the loss of a post-hoc benchmark strategy .", "The problem is cast as a sequential multi-stage zero-sum game , and we give a thorough analysis of the minimax behavior of the game , providing characterizations for the value of the game , as well as both the player 's and the adversary 's optimal strategy .", "We show how these objects can be computed efficiently under certain circumstances , and by selecting an appropriate benchmark , we construct a novel hedging strategy for an unconstrained betting game .", "We design and analyze minimax-optimal algorithms for online linear optimization games where the player 's choice is unconstrained .", "While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set , we consider a very broad range of benchmark functions ."]}
{"orig_sents": ["1", "3", "5", "2", "4", "0"], "shuf_sents": ["We show that a positive cost for observing the label significantly increases the regret of the problem .", "This paper introduces the online probing problem : In each round , the learner is able to purchase the values of a subset of feature values .", "We consider two variations of this problem , depending on whether the learner can observe the label for free or not .", "After the learner uses this information to come up with a prediction for the given round , he then has the option of paying to see the loss function that he is evaluated against .", "We provide algorithms and upper and lower bounds on the regret for both variants .", "Either way , the learner pays for both the errors of his predictions and also whatever he chooses to observe , including the cost of observing the loss function for the given round and the cost of the observed features ."]}
{"orig_sents": ["4", "2", "5", "0", "3", "1"], "shuf_sents": ["We analyse regret w.r.t .", "We characterise the achievable and Pareto optimal trade-offs , and the corresponding optimal strategies for each sample size both exactly for each finite horizon and asymptotically .", "In the common case of large but structured expert sets we typically wish to keep the regret especially small compared to simple experts , at the cost of modest additional overhead compared to more complex others .", "each individual expert as a multi-objective criterion in the simple but fundamental case of absolute loss .", "Performance guarantees for online learning algorithms typically take the form of regret bounds , which express that the cumulative loss overhead compared to the best expert in hindsight is small .", "We study which such regret trade-offs can be achieved , and how ."]}
{"orig_sents": ["6", "0", "5", "1", "3", "2", "4"], "shuf_sents": ["We measure the player 's performance using a new notion of regret , also known as policy regret , which better captures the adversary 's adaptiveness to the player 's behavior .", "In particular , we show that with switch 2/3 ing costs , the attainable rate with bandit feedback is ( T ) .", "Via a novel reduction from experts to bandits , we also 2/3 ) regret even in the full show that a bounded memory adversary can force ( T information case , proving that switching costs are easier to control than bounded memory adversaries .", "Interestingly , this rate is significantly worse than the ( T ) rate attainable with switching costs in the full-information case .", "Our lower bounds rely on a new stochastic adversary strategy that generates loss processes with strong dependencies .", "In a setting where losses are allowed to drift , we characterize -- in a nearly complete manner -- the power of adaptive adversaries with bounded memories and switching costs .", "We study the power of different types of adaptive ( nonoblivious ) adversaries in the setting of prediction with expert advice , under both full-information and bandit feedback ."]}
{"orig_sents": ["4", "2", "3", "0", "1"], "shuf_sents": ["We carefully calibrate the exploration-exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization , and obtain the first subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations .", "Numerical results demonstrate the effectiveness of our approach in difficult scenarios .", "We address this notoriously hard challenge , under the assumptions that the function varies only along some low-dimensional subspace and is smooth ( i.e. , it has a low norm in a Reproducible Kernel Hilbert Space ) .", "In particular , we present the SI-BO algorithm , which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Confidence sampling for optimization of the function .", "Many applications in machine learning require optimizing unknown functions defined over a high-dimensional space from noisy samples that are expensive to obtain ."]}
{"orig_sents": ["6", "4", "1", "8", "3", "2", "0", "7", "5"], "shuf_sents": ["To address this , we investigate two additional novel variants of the Poisson distribution and their corresponding joint graphical model distributions .", "Existing classes of Poisson graphical models , which arise as the joint distributions that correspond to Poisson distributed node-conditional distributions , have a major drawback : they can only model negative conditional dependencies for reasons of normalizability given its infinite domain .", "While this model can accommodate a wider range of conditional dependencies , some limitations still remain .", "We begin by discussing two strategies for truncating the Poisson distribution and show that only one of these leads to a valid joint distribution .", "These standard instances , however , are ill-suited to modeling count data , which are increasingly ubiquitous in big-data settings such as genomic sequencing data , user-ratings data , spatial incidence data , climate studies , and site visits .", "One can learn the graph structure of our models via penalized neighborhood selection , and we demonstrate the performance of our methods by learning simulated networks as well as a network from microRNA-sequencing data .", "Undirected graphical models , such as Gaussian graphical models , Ising , and multinomial/categorical graphical models , are widely used in a variety of applications for modeling distributions over a large number of variables .", "Our three novel approaches provide classes of Poisson-like graphical models that can capture both positive and negative conditional dependencies between count-valued variables .", "In this paper , our objective is to modify the Poisson graphical model distribution so that it can capture a rich dependence structure between count-valued variables ."]}
{"orig_sents": ["5", "3", "2", "4", "1", "0"], "shuf_sents": ["We develop a class of tractable penalized M -estimators to learn these CRF distributions from data , as well as a unified sparsistency analysis for this general class of CRFs showing exact structure recovery can be achieved with high probability .", "Also in particular , it addresses the common CRF problem of specifying `` feature '' functions determining the interactions between response variables and covariates .", "We thus introduce a novel subclass of CRFs , derived by imposing node-wise conditional distributions of response variables conditioned on the rest of the responses and the covariates as arising from univariate exponential families .", "Popular instances of this class of models , such as categorical-discrete CRFs , Ising CRFs , and conditional Gaussian based CRFs , are not well suited to the varied types of response variables in many applications , including count-valued responses .", "This allows us to derive novel multivariate CRFs given any univariate exponential distribution , including the Poisson , negative binomial , and exponential distributions .", "Conditional random fields , which model the distribution of a multivariate response conditioned on a set of covariates using undirected graphs , are widely used in a variety of multivariate prediction applications ."]}
{"orig_sents": ["3", "1", "0", "2", "4"], "shuf_sents": ["In this paper , we present a class of graph kernels with computational complexity O ( n2 ( m + log n + 2 + d ) ) , where is the graph diameter , m is the number of edges , and d is the dimension of the node attributes .", "For instance , the popular shortest path kernel scales as O ( n4 ) , where n is the number of nodes .", "Due to the sparsity and small diameter of real-world graphs , these kernels typically scale comfortably to large graphs .", "While graphs with continuous node attributes arise in many applications , stateof-the-art graph kernels for comparing continuous-attributed graphs suffer from a high runtime complexity .", "In our experiments , the presented kernels outperform state-of-the-art kernels in terms of speed and accuracy on classification benchmark datasets ."]}
{"orig_sents": ["7", "0", "4", "3", "1", "2", "5", "6"], "shuf_sents": ["Beyond its wide applicability , graph structured anomaly detection serves as a case study in the difficulty of balancing computational complexity with statistical power .", "We demonstrate a connection between LESS and maximum a-posteriori inference in Markov random fields , which provides us with a poly-time algorithm for LESS .", "Using electrical network theory , we are able to control type 1 error for LESS and prove conditions under which LESS is risk consistent .", "Because this test is computationally infeasible , we provide a relaxation , called the Lovasz extended scan statistic ( LESS ) that uses submodularity to approximate the intractable generalized likelihood ratio .", "In this work , we develop from first principles the generalized likelihood ratio test for determining if there is a well connected region of activation over the vertices in the graph in Gaussian noise .", "Finally , we consider specific graph models , the torus , knearest neighbor graphs , and -random graphs .", "We show that on these graphs our results provide near-optimal performance by matching our results to known lower bounds .", "The detection of anomalous activity in graphs is a statistical problem that arises in many applications , such as network surveillance , disease outbreak detection , and activity monitoring in social networks ."]}
{"orig_sents": ["4", "0", "2", "3", "5", "1"], "shuf_sents": ["Understanding of such structure and analysis of the loss defined over such structure help reveal important properties of the target function over a graph .", "Simulations on synthetic and real datasets confirm the potential of the proposed theory and tool .", "In this paper , we show that the variation of the target function across a cut can be upper and lower bounded by the ratio of its harmonic loss and the cut cost .", "We use this to develop an analytical tool and analyze five popular graph-based models : absorbing random walks , partially absorbing random walks , hitting times , pseudo-inverse of the graph Laplacian , and eigenvectors of the Laplacian matrices .", "We find that various well-known graph-based models exhibit a common important harmonic structure in its target function - the value of a vertex is approximately the weighted average of the values of its adjacent neighbors .", "Our analysis sheds new insights into several open questions related to these models , and provides theoretical justifications and guidelines for their practical use ."]}
{"orig_sents": ["3", "1", "7", "2", "6", "5", "0", "4"], "shuf_sents": ["By incorporating efficient inference into the learning steps , we can obtain a learning algorithm using alternating low-rank corrections with complexity O ( kn2 + n2 log n ) per iteration .", "In this paper , we study the family of GGMs with small feedback vertex sets ( FVSs ) , where an FVS is a set of nodes whose removal breaks all the cycles .", "We propose efficient structure learning algorithms for two cases : 1 ) All nodes are observed , which is useful in modeling social or flight networks where the FVS nodes often correspond to a small number of highly influential nodes , or hubs , while the rest of the networks is modeled by a tree .", "Gaussian Graphical Models ( GGMs ) or Gauss Markov random fields are widely used in many applications , and the trade-off between the modeling capacity and the efficiency of learning and inference has been an important research problem .", "We perform experiments using both synthetic data as well as real data of flight delays to demonstrate the modeling capacity with FVSs of various sizes .", "2 ) The FVS nodes are latent variables , where structure learning is equivalent to decomposing an inverse covariance matrix ( exactly or approximately ) into the sum of a tree-structured matrix and a low-rank matrix .", "Regardless of the maximum degree , without knowing the full graph structure , we can exactly compute the maximum likelihood estimate with complexity O ( kn2 + n2 log n ) if the FVS is known or in polynomial time if the FVS is unknown but has bounded size .", "Exact inference such as computing the marginal distributions and the partition function has complexity O ( k 2 n ) using message-passing algorithms , where k is the size of the FVS , and n is the total number of nodes ."]}
{"orig_sents": ["5", "2", "3", "4", "1", "0"], "shuf_sents": ["We demonstrate the efficacy of our approach on a computer vision energy minimization benchmark .", "Based on the information obtained from the solution of the convex relaxation , our method confines application of the combinatorial solver to a small fraction of the initial graphical model , which allows to optimally solve much larger problems .", "Although combinatorial methods , which return a provably optimal integral solution of the problem , made a significant progress in the past decade , they are still typically unable to cope with large-scale datasets .", "On the other hand , large scale datasets are often defined on sparse graphs and convex relaxation methods , such as linear programming relaxations then provide good approximations to integral solutions .", "We propose a novel method of combining combinatorial and convex programming techniques to obtain a global solution of the initial combinatorial problem .", "We consider energy minimization for undirected graphical models , also known as the MAP-inference problem for Markov random fields ."]}
{"orig_sents": ["4", "0", "2", "1", "5", "3"], "shuf_sents": ["Exact lifted inference methods , like their propositional counterparts , work by recursively decomposing the model and the problem .", "However , there is currently no equivalent structure nor analogous complexity results for lifted inference .", "In the propositional case , there exist formal structures , such as decomposition trees ( dtrees ) , that represent such a decomposition and allow us to determine the complexity of inference a priori .", "We show how these trees can characterize a lifted inference solution for a probabilistic logical model ( in terms of a sequence of lifted operations ) , and make a theoretical analysis of the complexity of lifted inference in terms of the novel notion of lifted width for the tree .", "Lifting attempts to speedup probabilistic inference by exploiting symmetries in the model .", "In this paper , we introduce FO-dtrees , which upgrade propositional dtrees to the first-order level ."]}
{"orig_sents": ["2", "5", "1", "0", "3", "4"], "shuf_sents": ["We generalize an existing belief propagation framework of Kingman 's coalescent to the beta coalescent , which models a wider range of tree structures .", "Unfortunately , this is inappropriate for data better described by bushier trees .", "Discovering hierarchical regularities in data is a key problem in interacting with large datasets , modeling cognition , and encoding knowledge .", "Because of the complex combinatorial search over possible structures , we develop new sampling schemes using sequential Monte Carlo and Dirichlet process mixture models , which render inference efficient and tractable .", "We present results on synthetic and real data that show the beta coalescent outperforms Kingman 's coalescent and is qualitatively better at capturing data in bushy hierarchies .", "A previous Bayesian solution -- Kingman 's coalescent -- provides a probabilistic model for data represented as a binary tree ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["We present an MCMC sampler for Dirichlet process mixture models that can be parallelized to achieve significant computational gains .", "Empirical results illustrate that the new sampler exhibits better convergence properties than current methods .", "Unlike some previous parallel samplers , the proposed sampler enforces the correct stationary distribution of the Markov chain without the need for finite approximations .", "Each cluster is augmented with two subclusters to construct likely split moves .", "We combine a nonergodic , restricted Gibbs iteration with split/merge proposals in a manner that produces an ergodic Markov chain ."]}
{"orig_sents": ["0", "1", "2"], "shuf_sents": ["Inspired by a two-level theory from political science that unifies agenda setting and ideological framing , we propose supervised hierarchical latent Dirichlet allocation ( S H L DA ) , which jointly captures documents ' multi-level topic structure and their polar response variables .", "Our model extends the nested Chinese restaurant processes to discover tree-structured topic hierarchies and uses both per-topic hierarchical and per-word lexical regression parameters to model response variables .", "S H L DA improves prediction on political affiliation and sentiment tasks in addition to providing insight into how topics under discussion are framed ."]}
{"orig_sents": ["5", "0", "6", "4", "3", "1", "2"], "shuf_sents": ["A critical challenge of cross language learning arises from the fact that words of different languages are in disjoint feature spaces .", "The proposed method is evaluated by conducting a set of experiments with cross language sentiment classification tasks on Amazon product reviews .", "The experimental results demonstrate that the proposed learning method outperforms a number of other cross language representation learning methods , especially when the number of parallel bilingual documents is small .", "We use a projected gradient descent algorithm to solve the formulated matrix completion problem with convergence guarantees .", "Specifically , we first formulate a matrix completion problem to produce a complete parallel document-term matrix for all documents in two languages , and then induce a low dimensional cross-lingual document representation by applying latent semantic indexing on the obtained matrix .", "Cross language text classification is an important learning task in natural language processing .", "In this paper , we propose a two-step representation learning method to bridge the feature spaces of different languages by exploiting a set of parallel bilingual documents ."]}
{"orig_sents": ["5", "3", "1", "2", "0", "4"], "shuf_sents": ["We achieve results comparable to the best ones reported , which were obtained on a cluster , using four times less data and more than an order of magnitude less computing time .", "We propose a simple and scalable new approach to learning word embeddings based on training log-bilinear models with noise-contrastive estimation .", "Our approach is simpler , faster , and produces better results than the current state-of-theart method .", "The best results are obtained by learning high-dimensional embeddings from very large quantities of data , which makes scalability of the training method a critical factor .", "We also investigate several model types and find that the embeddings learned by the simpler models perform at least as well as those learned by the more complex ones .", "Continuous-valued word embeddings learned by neural language models have recently been shown to capture semantic and syntactic information about words very well , setting performance records on several word similarity tasks ."]}
{"orig_sents": ["2", "3", "0", "6", "4", "5", "1"], "shuf_sents": ["In this paper we study the effect of a hierarchy of recurrent neural networks on processing time series .", "We also offer an analysis of the different emergent time scales .", "Time series often have a temporal hierarchy , with information that is spread out over multiple time scales .", "Common recurrent neural networks , however , do not explicitly accommodate such a hierarchy , and most research on them has been focusing on training algorithms rather than on their basic architecture .", "This architecture allows us to perform hierarchical processing on difficult temporal tasks , and more naturally capture the structure of time series .", "We show that they reach state-of-the-art performance for recurrent networks in character-level language modeling when trained with simple stochastic gradient descent .", "Here , each layer is a recurrent network which receives the hidden state of the previous layer as input ."]}
{"orig_sents": ["8", "0", "6", "5", "3", "4", "1", "7", "2"], "shuf_sents": ["Here we develop a generative model that captures the regularities present in images composed of repeating elements of a few different types .", "We perform extensive experiments on simulated images and the inference algorithm consistently recovers a large proportion of the cells with a small number of false positives .", "The flexibility of the block-based representation is reflected in the variability of the recovered cell shapes .", "We extend the KSVD learning algorithm to subspaces by retaining several principal vectors from the SVD decomposition instead of just one .", "Good models with little cross-talk between subspaces can be obtained by learning the blocks incrementally .", "For inference we use a variant of convolutional matching pursuit adapted to block-based representations .", "Formally , the model can be described as convolutional sparse block coding .", "We fit the convolutional model to noisy GCaMP6 two-photon images of spiking neurons and to Nissl-stained slices of cortical tissue and show that it recovers cell body locations without supervision .", "Biological tissue is often composed of cells with similar morphologies replicated throughout large volumes and many biological applications rely on the accurate identification of these cells and their locations from image data ."]}
{"orig_sents": ["3", "0", "1", "2", "8", "4", "6", "7", "5"], "shuf_sents": ["Due to the nature of the individual experiments , based on eliciting neural response from a small number of stimuli , this link is incomplete , and unidirectional from the causal point of view .", "To come to conclusions on the function implied by the activation of brain regions , it is necessary to combine a wide exploration of the various brain functions and some inversion of the statistical inference .", "Here we introduce a methodology for accumulating knowledge towards a bidirectional link between observed brain activity and the corresponding function .", "Imaging neuroscience links brain activation maps to behavior and cognition via correlational studies .", "Technically , the challenges are to find commonality between the studies without denaturing the richness of the corpus .", "To that end , we propose a method that predicts the experimental paradigms across different studies .", "The key elements that we contribute are labeling the tasks performed with a cognitive ontology , and modeling the long tail of rare paradigms in the corpus .", "To our knowledge , our approach is the first demonstration of predicting the cognitive content of completely new brain images .", "We rely on a large corpus of imaging studies and a predictive engine ."]}
{"orig_sents": ["2", "1", "4", "7", "3", "6", "5", "0"], "shuf_sents": ["Experiments show that advantages of using our fixed-point algorithms .", "This paper develops ( conic ) geometric optimisation on the cone of hpd matrices , which allows us to globally optimise a large class of nonconvex functions of hpd matrices .", "Hermitian positive definite ( hpd ) matrices recur throughout machine learning , statistics , and optimisation .", "We present key results that help recognise g-convexity and also the additional structure alluded to above .", "Specifically , we first use the Riemannian manifold structure of the hpd cone for studying functions that are nonconvex in the Euclidean sense but are geodesically convex ( g-convex ) , hence globally optimisable .", "To our knowledge , ours are the most general results on geometric optimisation of hpd matrices known so far .", "We illustrate our ideas by applying them to likelihood maximisation for a broad family of elliptically contoured distributions : for this maximisation , we derive novel , parameter free fixed-point algorithms .", "We then go beyond g-convexity , and exploit the conic geometry of hpd matrices to identify another class of functions that remain amenable to global optimisation without requiring g-convexity ."]}
{"orig_sents": ["0", "3", "2", "1", "5", "4"], "shuf_sents": ["Recently , Valiant and Valiant showed that a class of distributional properties , which includes such practically relevant properties as entropy , the number of distinct elements , and distance metrics between pairs of distributions , can be estimated given a sublinear sized sample .", "Perhaps unsurprisingly , the key step in our approach is to first use the sample to characterize the `` unseen '' portion of the distribution .", "We propose a novel modification of this approach and show : 1 ) theoretically , this estimator is optimal ( to constant factors , over worst-case instances ) , and 2 ) in practice , it performs exceptionally well for a variety of estimation tasks , on a variety of natural distributions , for a wide range of parameters .", "Specifically , given a sample consisting of independent draws from any distribution over at most n distinct elements , these properties can be estimated accurately using a sample of size O ( n/ log n ) .", "This approach is robust , general , and theoretically principled ; we expect that it may be fruitfully used as a component within larger machine learning and data analysis systems .", "This goes beyond such tools as the Good-Turing frequency estimation scheme , which estimates the total probability mass of the unobserved portion of the distribution : we seek to estimate the shape of the unobserved portion of the distribution ."]}
{"orig_sents": ["0", "3", "2", "1"], "shuf_sents": ["This paper extends factorized asymptotic Bayesian ( FAB ) inference for latent feature models ( LFMs ) .", "FAB/LFMs have several desirable properties ( e.g. , automatic hidden states selection and parameter identifiability ) and empirically perform better than state-of-the-art Indian Buffet processes in terms of model selection , prediction , and computational efficiency .", "Our asymptotic analysis of the Hessian matrix of LFMs shows that FIC of LFMs has the same form as those of mixture models .", "FAB inference has not been applicable to models , including LFMs , without a specific condition on the Hessian matrix of a complete loglikelihood , which is required to derive a `` factorized information criterion '' ( FIC ) ."]}
{"orig_sents": ["2", "1", "3", "0", "4"], "shuf_sents": ["In this paper , we present LoSST , a novel , heuristic structure learning algorithm that tracks changes in graphical model structure or parameters in a dynamic , real-time manner .", "In real-world environments , however , such changes often occur without warning or signal .", "Structure learning algorithms for graphical models have focused almost exclusively on stable environments in which the underlying generative process does not change ; that is , they assume that the generating model is globally stationary .", "Real-world data often come from generating models that are only locally stationary .", "We show by simulation that the algorithm performs comparably to batch-mode learning when the generating graphical structure is globally stationary , and significantly better when it is only locally stationary ."]}
{"orig_sents": ["1", "2", "0", "4", "3"], "shuf_sents": ["Thus it not only is asymptotically tuning free , but also achieves an improved finite sample performance .", "We propose a semiparametric method for estimating sparse precision matrix of high dimensional elliptical distribution .", "The proposed method calibrates regularizations when estimating each column of the precision matrix .", "We present numerical results on both simulated and real datasets to support our theory and illustrate the effectiveness of the proposed estimator .", "Theoretically , we prove that the proposed method achieves the parametric rates of convergence in both parameter estimation and model selection ."]}
{"orig_sents": ["7", "1", "2", "6", "5", "3", "0", "4"], "shuf_sents": ["We also present a heuristic scheme that further improves the efficiency of A* lasso without significantly compromising the quality of solutions .", "The constraint that the estimated Bayesian network structure must be a directed acyclic graph ( DAG ) makes the problem challenging because of the huge search space of network structures .", "Most previous methods were based on a two-stage approach that prunes the search space in the first stage and then searches for a network structure satisfying the DAG constraint in the second stage .", "Our approach substantially improves the computational efficiency of the well-known exact methods based on dynamic programming .", "We demonstrate our approach on data simulated from benchmark Bayesian networks and real data .", "In this paper , we propose a single-stage method , called A* lasso , that recovers the optimal sparse Bayesian network structure by solving a single optimization problem with A* search algorithm that uses lasso in its scoring system .", "Although this approach is effective in a lowdimensional setting , it is difficult to ensure that the correct network structure is not pruned in the first stage in a high-dimensional setting .", "We address the problem of learning a sparse Bayesian network structure for continuous variables in a high-dimensional space ."]}
{"orig_sents": ["2", "4", "1", "0", "3"], "shuf_sents": ["We generalize the notion of irrepresentable to geometrically decomposable penalties and develop a general framework for establishing consistency and model selection consistency of M-estimators with such penalties .", "can be expressed as a sum of support functions over convex sets .", "Penalized M-estimators are used in diverse areas of science and engineering to fit high-dimensional models with some low-dimensional structure .", "We then use this framework to derive results for some special cases of interest in bioinformatics and statistical learning .", "Often , the penalties are geometrically decomposable , i.e ."]}
{"orig_sents": ["5", "3", "1", "4", "2", "0"], "shuf_sents": ["Our modeling approach offers promise for gaining insights into co-adaptation as well as improving user learning of BCI control in practical settings .", "We present an approach to model this process of co-adaptation between the encoding model of the neural signal and the decoding algorithm as a multi-agent formulation of the linear quadratic Gaussian ( LQG ) control problem .", "We then propose a novel , modified decoder update rule which is aware of the fact that the encoder is also changing and show it can improve simulated co-adaptation dynamics .", "Feedback to the user provides information which permits the neural tuning to also adapt .", "In simulation we characterize how decoding performance improves as the neural encoding and adaptive decoder optimize , qualitatively resembling experimentally demonstrated closed-loop improvement .", "In a closed-loop brain-computer interface ( BCI ) , adaptive decoders are used to learn parameters suited to decoding the user 's neural response ."]}
{"orig_sents": ["0", "5", "1", "3", "6", "2", "7", "4"], "shuf_sents": ["Movement Primitives ( MP ) are a well-established approach for representing modular and re-usable robot movement generators .", "A major goal in robot learning is to combine multiple MPs as building blocks in a modular control architecture to solve complex tasks .", "Our probabilistic approach allows for the derivation of new operations which are essential for implementing all aforementioned properties in one framework .", "To this effect , a MP representation has to allow for blending between motions , adapting to altered task variables , and co-activating multiple MPs in parallel .", "We evaluate and compare our approach to existing methods on several simulated as well as real robot scenarios .", "Many state-of-the-art robot learning successes are based MPs , due to their compact representation of the inherently continuous and high dimensional robot movements .", "We present a probabilistic formulation of the MP concept that maintains a distribution over trajectories .", "In order to use such a trajectory distribution for robot movement control , we analytically derive a stochastic feedback controller which reproduces the given trajectory distribution ."]}
{"orig_sents": ["1", "4", "2", "3", "0"], "shuf_sents": ["We demonstrate that the resulting algorithm can outperform prior methods on two challenging locomotion tasks .", "In order to learn effective control policies for dynamical systems , policy search methods must be able to discover successful executions of the desired task .", "We present a method that uses trajectory optimization as a powerful exploration strategy that guides the policy search .", "A variational decomposition of a maximum likelihood policy objective allows us to use standard trajectory optimization algorithms such as differential dynamic programming , interleaved with standard supervised learning for the policy itself .", "While random exploration can work well in simple domains , complex and highdimensional tasks present a serious challenge , particularly when combined with high-dimensional policies that make parameter-space exploration infeasible ."]}
{"orig_sents": ["5", "1", "6", "0", "3", "4", "2"], "shuf_sents": ["The key novelty of our approach lies in the type of feedback expected from the user : the human user does not need to demonstrate optimal trajectories as training data , but merely needs to iteratively provide trajectories that slightly improve over the trajectory currently proposed by the system .", "This is challenging because the criterion defining a good trajectory varies with users , tasks and environments .", "We demonstrate the generalizability of our algorithm on a variety of grocery checkout tasks , for whom , the preferences were not only influenced by the object being manipulated but also by the surrounding environment.1", "We argue that this co-active preference feedback can be more easily elicited from the user than demonstrations of optimal trajectories , which are often challenging and non-intuitive to provide on high degrees of freedom manipulators .", "Nevertheless , theoretical regret bounds of our algorithm match the asymptotic rates of optimal trajectory algorithms .", "We consider the problem of learning good trajectories for manipulation tasks .", "In this paper , we propose a co-active online learning framework for teaching robots the preferences of its users for object manipulation tasks ."]}
{"orig_sents": ["6", "5", "2", "1", "3", "0", "4"], "shuf_sents": ["It has the added benefit of being closest in performance to the optimal Bayesian model than all the other heuristic models that have the same computational complexity ( all are significantly less complex than the optimal model ) .", "Our result shows that subjects ' choices , on a trial-totrial basis , are best captured by a `` forgetful '' Bayesian iterative learning model in combination with a partially myopic decision policy known as Knowledge Gradient .", "We compare human behavior to a variety of models that vary in their representational and computational complexity .", "This model accounts for subjects ' trial-by-trial choice better than a number of other previously proposed models , including optimal Bayesian learning and risk minimization , -greedy and win-stay-lose-shift .", "These results constitute an advancement in the theoretical understanding of how humans negotiate the tension between exploration and exploitation in a noisy , imperfectly known environment .", "We investigate this behavior in the context of a multi-armed bandit task .", "How humans achieve long-term goals in an uncertain environment , via repeated trials and noisy observations , is an important problem in cognitive science ."]}
{"orig_sents": ["8", "5", "1", "6", "7", "0", "4", "2", "3"], "shuf_sents": ["Here , we propose a myopic approximation to C-DAC , which also takes behavioral costs into account , but achieves a significant reduction in complexity by looking only one step ahead .", "Recently , we proposed a goal-directed , context-sensitive , Bayesian control strategy for active sensing , C-DAC ( ContextDependent Active Controller ) ( Ahmad & Yu , 2013 ) .", "We find that C-DAC and its myopic variant both achieve better fit to human data than Infomax ( Butko & Movellan , 2010 ) , which maximizes expected cumulative future information gain .", "In summary , this work provides novel experimental results that differentiate theoretical models for human active sensing , as well as a novel active sensing algorithm that retains the context-sensitivity of the optimal controller while achieving significant computational savings .", "We also present data from a human active visual search experiment , and compare the performance of the various models against human behavior .", "Understanding the computational basis of natural active sensing is important both for advancing brain sciences and for developing more powerful artificial systems .", "In contrast to previously proposed algorithms for human active vision , which tend to optimize abstract statistical objectives and therefore can not adapt to changing behavioral context or task goals , C-DAC directly minimizes behavioral costs and thus , automatically adapts itself to different task conditions .", "However , C-DAC is limited as a model of human active sensing , given its computational/representational requirements , especially for more complex , real-world situations .", "Humans and animals readily utilize active sensing , or the use of self-motion , to focus sensory and cognitive resources on the behaviorally most relevant stimuli and events in the environment ."]}
{"orig_sents": ["0", "4", "2", "1", "3"], "shuf_sents": ["This paper addresses the problem of automatic generation of features for value function approximation in reinforcement learning .", "We provide a finite sample analysis of the proposed method , and prove that projections logarithmic in the dimension of the original space guarantee a contraction in the error .", "We propose a simple , fast and robust algorithm based on random projections , which generates BEBFs for sparse feature spaces .", "Empirical results demonstrate the strength of this method in domains in which choosing a good state representation is challenging .", "Bellman Error Basis Functions ( BEBFs ) have been shown to improve policy evaluation , with a convergence rate similar to that of value iteration ."]}
{"orig_sents": ["1", "2", "0"], "shuf_sents": ["We devise an algorithm that is adaptive to potentially adversarial behavior and show that it achieves similar regret bounds as the purely stochastic case .", "An important challenge in Markov decision processes is to ensure robustness with respect to unexpected or adversarial system behavior while taking advantage of well-behaving parts of the system .", "We consider a problem setting where some unknown parts of the state space can have arbitrary transitions while other parts are purely stochastic ."]}
{"orig_sents": ["1", "0", "3", "2", "4"], "shuf_sents": ["In this paper we address a drawback of natural actor-critics that limits their real-world applicability -- their lack of safety guarantees .", "Natural actor-critics form a popular class of policy search algorithms for finding locally optimal policies for Markov decision processes .", "In the context of reinforcement learning , this allows for natural actor-critic algorithms that are guaranteed to remain within a known safe region of policy space .", "We present a principled algorithm for performing natural gradient descent over a constrained domain .", "While deriving our class of constrained natural actor-critic algorithms , which we call Projected Natural ActorCritics ( PNACs ) , we also elucidate the relationship between natural gradient descent and mirror descent ."]}
{"orig_sents": ["5", "1", "7", "6", "3", "0", "4", "2", "8"], "shuf_sents": ["The algorithm is conceptually simple , computationally efficient and allows an agent to encode prior knowledge S AT ) bound on expected regret , in a natural way .", "We study an alternative approach for efficient exploration : posterior sampling for reinforcement learning ( PSRL ) .", "This bound is one of the first for an algorithm not based on optimism , and close to the state of the art for any reinforcement learning algorithm .", "PSRL then follows the policy that is optimal for this sample during the episode .", "We establish an O ( where T is time , is the episode length and S and A are the cardinalities of the state and action spaces .", "Most provably-efficient reinforcement learning algorithms introduce optimism about poorly-understood states and actions to encourage exploration .", "At the start of each episode , PSRL updates a prior distribution over Markov decision processes and takes one sample from this posterior .", "This algorithm proceeds in repeated episodes of known duration .", "We show through simulation that PSRL significantly outperforms existing algorithms with similar regret bounds ."]}
{"orig_sents": ["3", "4", "5", "6", "2", "0", "1", "7"], "shuf_sents": ["In this paper , we propose to determine the learning rate by maximizing a lower bound to the expected performance gain .", "Focusing on Gaussian policies , we derive a lower bound that is second-order polynomial of the step size , and we show how a simplified version of such lower bound can be maximized when the gradient is estimated from trajectory samples .", "Step-size value is usually chosen by hand tuning and still little attention has been paid to its automatic selection .", "In the last decade , policy gradient methods have significantly grown in popularity in the reinforcement-learning field .", "In particular , they have been largely employed in motor control and robotic applications , thanks to their ability to cope with continuous state and action domains and partial observable problems .", "Policy gradient researches have been mainly focused on the identification of effective gradient directions and the proposal of efficient estimation algorithms .", "Nonetheless , the performance of policy gradient methods is determined not only by the gradient direction , since convergence properties are strongly influenced by the choice of the step size : small values imply slow convergence rate , while large values may lead to oscillations or even divergence of the policy parameters .", "The properties of the proposed approach are empirically evaluated in a linear-quadratic regulator problem ."]}
{"orig_sents": ["0", "4", "3", "2", "1"], "shuf_sents": ["A long term goal of Interactive Reinforcement Learning is to incorporate nonexpert human feedback to solve complex tasks .", "We compare Advise to state-of-the-art approaches and show that it can outperform them and is robust to infrequent and inconsistent human feedback .", "We introduce Advise , a Bayesian approach that attempts to maximize the information gained from human feedback by utilizing it as direct policy labels .", "In this paper we argue for an alternate , more effective characterization of human feedback : Policy Shaping .", "Some state-of-the-art methods have approached this problem by mapping human information to rewards and values and iterating over them to compute better control policies ."]}
{"orig_sents": ["0", "1", "3", "4", "2"], "shuf_sents": ["Approximate dynamic programming approaches to the reinforcement learning problem are often categorized into greedy value function methods and value-based policy gradient methods .", "As our first main result , we show that an important subset of the latter methodology is , in fact , a limiting special case of a general formulation of the former methodology ; optimistic policy iteration encompasses not only most of the greedy value function methods but also natural actor-critic methods , and permits one to directly interpolate between them .", "Consequently , in the context of approximations ( either in state estimation or in value function representation ) , the majority of greedy value function methods seem to be deemed to suffer either from the risk of oscillation/chattering or from the presence of systematic sub-optimality .", "The resulting continuum adjusts the strength of the Markov assumption in policy improvement and , as such , can be seen as dual in spirit to the continuum in TD ( ) -style algorithms in policy evaluation .", "As our second main result , we show for a substantial subset of softgreedy value function approaches that , while having the potential to avoid policy oscillation and policy chattering , this subset can never converge toward an optimal policy , except in a certain pathological case ."]}
{"orig_sents": ["3", "2", "8", "1", "7", "4", "0", "5", "6"], "shuf_sents": ["Experiments show strong results , compared with two of the fastest online POMDP algorithms .", "Our Regularized DESPOT ( R-DESPOT ) algorithm searches the DESPOT for a policy , while optimally balancing the size of the policy and its estimated value obtained under the sampled scenarios .", "This paper presents an online POMDP algorithm that alleviates these difficulties by focusing the search on a set of randomly sampled scenarios .", "POMDPs provide a principled framework for planning under uncertainty , but are computationally intractable , due to the `` curse of dimensionality '' and the `` curse of history '' .", "We also give an anytime algorithm that approximates R-DESPOT .", "Source code along with experimental settings are available at http : //bigbird.comp .", "nus.edu.sg/pmwiki/farm/appl/ .", "We give an output-sensitive performance bound for all policies derived from a DESPOT , and show that R-DESPOT works well if a small optimal policy exists .", "A Determinized Sparse Partially Observable Tree ( DESPOT ) compactly captures the execution of all policies on these scenarios ."]}
{"orig_sents": ["6", "1", "5", "2", "4", "3", "0"], "shuf_sents": ["Although the CBMPI 's results are similar to those of the CE method in the large board , CBMPI uses considerably fewer ( almost 1/6 ) samples ( calls to the generative model ) than CE .", "A look at the literature of this game shows that while ADP algorithms that have been ( almost ) entirely based on approximating the value function ( value function based ) have performed poorly in Tetris , the methods that search directly in the space of policies by learning the policy parameters using an optimization black box , such as the cross entropy ( CE ) method , have achieved the best reported results .", "So , in order to obtain a good performance with ADP , we should use ADP algorithms that search in a policy space , instead of the more traditional ones that search in a value function space .", "Our experimental results show that for the first time an ADP algorithm , namely CBMPI , obtains the best results reported in the literature for Tetris in both small 10 x 10 and large 10 x 20 boards .", "In this paper , we put our conjecture to test by applying such an ADP algorithm , called classification-based modified policy iteration ( CBMPI ) , to the game of Tetris .", "This makes us conjecture that Tetris is a game in which good policies are easier to represent , and thus , learn than their corresponding value functions .", "Tetris is a video game that has been widely used as a benchmark for various optimization techniques including approximate dynamic programming ( ADP ) algorithms ."]}
{"orig_sents": ["3", "1", "2", "0", "4"], "shuf_sents": ["Specifically , we use good guidance reward functions learned on previous tasks in the sequence to incrementally train a reward mapping function that maps task-specifying reward functions into good initial guidance reward functions for subsequent tasks .", "A novel aspect of our transfer approach is that we reuse reward functions .", "While this may seem counterintuitive , we build on the insight of recent work on the optimal rewards problem that guiding an agent 's behavior with reward functions other than the task-specifying reward function can help overcome computational bounds of the agent .", "We consider how to transfer knowledge from previous tasks ( MDPs ) to a current task in long-lived and bounded agents that must solve a sequence of tasks over a finite lifetime .", "We demonstrate that our approach can substantially improve the agent 's performance relative to other approaches , including an approach that transfers policies ."]}
{"orig_sents": ["5", "0", "2", "6", "4", "3", "1"], "shuf_sents": ["In contrast to most existing trackers which only learn the appearance of the tracked object online , we take a different approach , inspired by recent advances in deep learning architectures , by putting more emphasis on the ( unsupervised ) feature learning problem .", "Comparison with the state-of-the-art trackers on some challenging benchmark video sequences shows that our deep learning tracker is more accurate while maintaining low computational cost with real-time performance when our MATLAB implementation of the tracker is used with a modest graphics processing unit ( GPU ) .", "Specifically , by using auxiliary natural images , we train a stacked denoising autoencoder offline to learn generic image features that are more robust against variations .", "Both the feature extractor and the classifier can be further tuned to adapt to appearance changes of the moving object .", "Online tracking involves a classification neural network which is constructed from the encoder part of the trained autoencoder as a feature extractor and an additional classification layer .", "In this paper , we study the challenging problem of tracking the trajectory of a moving object in a video with possibly very complex background .", "This is then followed by knowledge transfer from offline training to the online tracking process ."]}
{"orig_sents": ["1", "2", "5", "4", "3", "0"], "shuf_sents": ["However , when evaluated on a large dataset , this dependency is very weak and the benefit of conditioning flow estimation on the local intensity pattern is marginal .", "Motivated by recent progress in natural image statistics , we use newly available datasets with ground truth optical flow to learn the local statistics of optical flow and compare the learned models to prior models assumed by computer vision researchers .", "We find that a Gaussian mixture model ( GMM ) with 64 components provides a significantly better model for local flow statistics when compared to commonly used models .", "In accordance with the assumptions often made in computer vision , the model learns that flow boundaries are more likely at intensity boundaries .", "We also learn a model that jointly models the local intensity pattern and the local optical flow .", "We investigate the source of the GMM 's success and show it is related to an explicit representation of flow boundaries ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["However , association fields only depend on the pairwise statistics of edges in natural scenes .", "An analysis using a probabilistic spectral embedding reveals curvature-dependent components .", "We develop a spectral test of the sufficiency of pairwise statistics and show there is significant higher order structure .", "Association field models have attempted to explain human contour grouping performance , and to explain the mean frequency of long-range horizontal connections across cortical columns in V1 ."]}
{"orig_sents": ["9", "8", "7", "3", "2", "10", "4", "11", "0", "12", "1", "5", "6"], "shuf_sents": ["We find that the model extracts the components , and that it can correctly identify the occlusive components with the hidden variables of the model .", "By using reverse correlation , we estimate the receptive fields associated with the model 's hidden units .", "Here , we for the first time apply a model with non-linear feature superposition and explicit position encoding for patches .", "All probabilistic generative models with explicit position encoding have so far assumed a linear superposition of components to encode image patches .", "In order to account for occlusions , the non-linear model encodes patches qualitatively very different from linear models by using component representations separated into mask and feature parameters .", "We find many Gabor-like or globular receptive fields as well as fields sensitive to more complex structures .", "Our results show that probabilistic models that capture occlusions and invariances can be trained efficiently on image patches , and that the resulting encoding represents an alternative model for the neural encoding of images in the primary visual cortex .", "Some earlier models used a separate encoding of features and their positions to facilitate invariant data encoding and recognition .", "By far most approaches to unsupervised learning of visual features , such as sparse coding or ICA , account for translations by representing the same features at different positions .", "We study optimal image encoding based on a generative approach with non-linear feature combinations and explicit position encoding .", "By avoiding linear superpositions , the studied model represents a closer match to component occlusions which are ubiquitous in natural images .", "We first investigated encodings learned by the model using artificial data with mutually occluding components .", "On natural image patches , the model learns component masks and features for typical image components ."]}
{"orig_sents": ["2", "1", "0", "4", "7", "9", "6", "3", "8", "5"], "shuf_sents": ["Our work makes three contributions towards addressing this problem .", "The complex interplay between the task and the visual stimulus is believed to determine human eye movements , yet it is not fully understood , making it difficult to develop reliable eye movement prediction systems .", "Human eye movements provide a rich source of information into the human visual information processing .", "Based on such encodings , we quantitatively show that given unconstrained read-world stimuli , task instructions have significant influence on the human visual search patterns and are stable across subjects .", "First , we complement one of the largest and most challenging static computer vision datasets , VOC 2012 Actions , with human eye movement recordings collected under the primary task constraint of action recognition , as well as , separately , for context recognition , in order to analyze the impact of different tasks .", "The methodology achieves state of the art scanpath modeling results .", "Our methods can automatically determine the number , the spatial support and the transitions between AOIs , in addition to their locations .", "Our dataset is unique among the eyetracking datasets of still images in terms of large scale ( over 1 million fixations recorded in 9157 images ) and different task controls .", "Finally , we leverage powerful machine learning techniques and computer vision features in order to learn task-sensitive reward functions from eye movement data within models that allow to effectively predict the human visual search patterns based on inverse optimal control .", "Second , we propose Markov models to automatically discover areas of interest ( AOI ) and introduce novel sequential consistency metrics based on them ."]}
{"orig_sents": ["2", "5", "3", "1", "4", "0"], "shuf_sents": ["In addition , our model can produce top-down saliency maps conditioned on the classification label and localized latent paths .", "This is achieved by incorporating eye gaze , along with the classification , into the structured loss within the latent SVM learning framework .", "We propose a weakly-supervised structured learning approach for recognition and spatio-temporal localization of actions in video .", "Instead of using spatial annotations in the form of bounding boxes to guide the latent model during training , we utilize human gaze data in the form of a weak supervisory signal .", "Experiments on a challenging benchmark dataset , UCF-Sports , show that our model is more accurate , in terms of classification , and achieves state-of-the-art results in localization .", "As part of the proposed approach , we develop a generalization of the Max-Path search algorithm which allows us to efficiently search over a structured space of multiple spatio-temporal paths while also incorporating context information into the model ."]}
{"orig_sents": ["3", "5", "1", "6", "0", "4", "2"], "shuf_sents": ["For example , our model is able to enforce the condition that if a set of pixels take same object label , e.g .", "In this work we explore such joint estimation of intrinsic scene properties recovered from an image , together with the estimation of the objects and attributes present in the scene .", "We cast the problem in an energy minimization framework and demonstrate the qualitative and quantitative improvement in the overall accuracy on the NYU and Pascal datasets .", "Many methods have been proposed to solve the problems of recovering intrinsic scene properties such as shape , reflectance and illumination from a single image , and object class segmentation separately .", "table , most likely those pixels would receive similar reflectance values .", "While these two problems are mutually informative , in the past not many papers have addressed this topic .", "In this way , our unified framework is able to capture the correlations between intrinsic properties ( reflectance , shape , illumination ) , objects ( table , tv-monitor ) , and materials ( wooden , plastic ) in a given scene ."]}
{"orig_sents": ["7", "5", "1", "3", "6", "2", "4", "0"], "shuf_sents": ["Results on varied datasets show that , compared to decision forests and several other baselines , decision jungles require dramatically less memory while considerably improving generalization .", "For certain applications , for example on mobile or embedded processors , memory is a limited resource , and so the exponential growth of trees limits their depth , and thus their potential accuracy .", "We present and compare two new node merging algorithms that jointly optimize both the features and the structure of the DAGs efficiently .", "This paper proposes decision jungles , revisiting the idea of ensembles of rooted decision directed acyclic graphs ( DAGs ) , and shows these to be compact and powerful discriminative models for classification .", "During training , node splitting and node merging are driven by the minimization of exactly the same objective function , here the weighted sum of entropies at the leaves .", "However , they face a fundamental limitation : given enough data , the number of nodes in decision trees will grow exponentially with depth .", "Unlike conventional decision trees that only allow one path to every node , a DAG in a decision jungle allows multiple paths from the root to each leaf .", "Randomized decision trees and forests have a rich history in machine learning and have seen considerable success in application , perhaps particularly so for computer vision ."]}
{"orig_sents": ["6", "3", "5", "7", "1", "0", "4", "2"], "shuf_sents": ["We use the boosting-trick to learn a non-linear mapping of the observations in each task , with no need for specific a-priori knowledge of its global analytical form .", "Unlike previous approaches that learn task-specific decision boundaries , our method learns a single decision boundary in a shared feature space , common to all tasks .", "We evaluate our approach on two challenging bio-medical datasets and achieve a significant improvement over the state of the art .", "However , there are many problems when this assumption is grossly violated , as in bio-medical applications where different acquisitions can generate drastic variations in the appearance of the data due to changing experimental conditions .", "This yields a more parameter-free domain adaptation approach that successfully leverages learning on new tasks where labeled data is scarce .", "This problem is accentuated with 3D data , for which annotation is very time-consuming , limiting the amount of data that can be labeled in new acquisitions for training .", "A common assumption in machine vision is that the training and test samples are drawn from the same distribution .", "In this paper we present a multitask learning algorithm for domain adaptation based on boosting ."]}
{"orig_sents": ["4", "2", "0", "1", "3"], "shuf_sents": ["We introduce a novel parametric method of clustering superpixels by modeling mixture of Weibulls on Earth Mover 's Distance statistics , then taking the normalized number of proto-objects following partitioning as our estimate of clutter perception .", "We validated this model using a new 90-image dataset of real world scenes rank ordered by human raters for clutter , and showed that our method not only predicted clutter extremely well ( Spearman 's = 0.8038 , p < 0.001 ) , but also outperformed all existing clutter perception models and even a behavioral object segmentation ground truth .", "Our approach models clutter as the number of proto-objects segmented from an image , with proto-objects defined as groupings of superpixels that are similar in intensity , color , and gradient orientation features .", "We conclude that the number of proto-objects in an image affects clutter perception more than the number of objects or features .", "Visual clutter , the perception of an image as being crowded and disordered , affects aspects of our lives ranging from object detection to aesthetics , yet relatively little effort has been made to model this important and ubiquitous percept ."]}
{"orig_sents": ["5", "4", "7", "1", "6", "3", "0", "2"], "shuf_sents": ["We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches , and compare our method against prior work on the Paris Street View dataset of .", "In this work , we pose visual element discovery as discriminative mode seeking , drawing connections to the the well-known and well-studied mean-shift algorithm .", "We also evaluate our method on the task of scene classification , demonstrating state-of-the-art performance on the MIT Scene-67 dataset .", "One advantage of our formulation is that it requires only a single pass through the data .", "Several approaches have been proposed to discover mid-level visual elements , that are both 1 ) representative , i.e. , frequently occurring within a visual dataset , and 2 ) visually discriminative .", "Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical `` visual words '' , but lower than full-blown semantic objects .", "Given a weakly-labeled image collection , our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels .", "However , the current approaches are rather ad hoc and difficult to analyze and evaluate ."]}
{"orig_sents": ["0", "5", "1", "4", "6", "7", "2", "3", "8"], "shuf_sents": ["How do humans perceive the speed of a coherent motion stimulus that contains motion energy in multiple spatiotemporal frequency bands ?", "We formalized this hypothesis with a Bayesian observer model that combines the likelihood functions provided by the individual channel responses ( cues ) .", "The proposed Bayesian model fits the data well , accounting for the full psychometric functions of both simple and combined stimuli .", "Fits are improved if we assume that the channel responses are subject to divisive normalization .", "We experimentally validated the model with a 2AFC speed discrimination experiment that measured subjects ' perceived speed of drifting sinusoidal gratings with different contrasts and spatial frequencies , and of various combinations of these single gratings .", "Here we tested the idea that perceived speed is the result of an integration process that optimally combines speed information across independent spatiotemporal frequency channels .", "We found that the perceived speeds of the combined stimuli are independent of the relative phase of the underlying grating components .", "The results also show that the discrimination thresholds are smaller for the combined stimuli than for the individual grating components , supporting the cue combination hypothesis .", "Our results provide an important step toward a more complete model of visual motion perception that can predict perceived speeds for coherent motion stimuli of arbitrary spatial structure ."]}
{"orig_sents": ["4", "1", "3", "0", "2", "5"], "shuf_sents": ["In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text .", "This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows .", "We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors , and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training .", "One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions .", "Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories .", "Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18 % across thousands of novel labels never seen by the visual model ."]}
{"orig_sents": ["0", "3", "5", "2", "4", "1"], "shuf_sents": ["Learning a visual concept from a small number of positive examples is a significant challenge for machine learning algorithms .", "We compare the performance of our system to several baseline algorithms , and show a significant advantage results from combining visual classifiers with the ability to identify an appropriate level of abstraction using Bayesian generalization .", "We present an algorithm for learning visual concepts directly from images , using probabilistic predictions generated by visual classifiers as the input to a Bayesian generalization model .", "Current methods typically fail to find the appropriate level of generalization in a concept hierarchy for a given set of visual examples .", "As no existing challenge data tests this paradigm , we collect and make available a new , large-scale dataset for visual concept learning using the ImageNet hierarchy as the source of possible concepts , with human annotators to provide ground truth labels as to whether a new image is an instance of each concept using a paradigm similar to that used in experiments studying word learning in children .", "Recent work in cognitive science on Bayesian models of generalization addresses this challenge , but prior results assumed that objects were perfectly recognized ."]}
{"orig_sents": ["2", "5", "7", "1", "6", "0", "8", "3", "4"], "shuf_sents": ["First , we empirically confirm theoretical predictions ( from ) for the case of 2D affine transformations .", "The model 's wiring can be learned from videos of transforming objects -- or any other grouping of images into sets by their depicted object .", "One approach to computer object recognition and modeling the brain 's ventral stream involves unsupervised learning of representations that are invariant to common transformations .", "Surprisingly , it can also tolerate clutter `` transformations '' which map an image of a face on one background to an image of the same face on a different background .", "Motivated by these empirical findings , we tested the same model on face verification benchmark tasks from the computer vision literature : Labeled Faces in the Wild , PubFig and a new dataset we gathered -- achieving strong performance in these highly unconstrained cases as well .", "However , applications of these ideas have usually been limited to 2D affine transformations , e.g. , translation and scaling , since they are easiest to solve via convolution .", "Through a series of successively more complex empirical tests , we study the invariance/discriminability properties of this model with respect to different transformations .", "In accord with a recent theory of transformationinvariance , we propose a model that , while capturing other common convolutional networks as special cases , can also be used with arbitrary identitypreserving transformations .", "Next , we apply the model to non-affine transformations ; as expected , it performs well on face verification tasks requiring invariance to the relatively smooth transformations of 3D rotation-in-depth and changes in illumination direction ."]}
{"orig_sents": ["4", "0", "2", "1", "3"], "shuf_sents": ["In this paper we go one step further and address the problem of object detection using DNNs , that is not only classifying but also precisely localizing objects of various classes .", "We define a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications .", "We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks .", "State-of-the-art performance of the approach is shown on Pascal VOC .", "Deep Neural Networks ( DNNs ) have recently shown outstanding performance on image classification tasks ."]}
{"orig_sents": ["4", "1", "3", "0", "5", "2"], "shuf_sents": ["Our procedure allows speed and accuracy to be traded off in two ways : by choosing the number of Vector Quantization levels , and by choosing to rescore windows or not .", "We describe a method that achieves a substantial end-to-end speedup over the best current methods , without loss of accuracy .", "We demonstrate our method to speed up the original Exemplar SVM detector by an order of magnitude and Deformable Part models by two orders of magnitude with no loss of accuracy .", "Our method is a combination of approximating scores by vector quantizing feature windows and a number of speedup techniques including cascade .", "Applying linear templates is an integral part of many object detection systems and accounts for a significant portion of computation time .", "Our method can be directly plugged into any recognition system that relies on linear templates ."]}
{"orig_sents": ["7", "0", "6", "4", "5", "2", "8", "3", "9", "1"], "shuf_sents": ["Transferring knowledge from known categories to novel classes with no or only a few labels is far less researched even though it is a common scenario .", "Our approach consistently outperforms state-of-the-art transfer and semi-supervised approaches on all datasets .", "Second , we exploit the manifold structure of novel classes .", "Third , we improve the local neighborhood in such graph structures by replacing the raw feature-based representation with a mid-level object- or attribute-based representation .", "Our proposed approach Propagated Semantic Transfer combines three techniques .", "First , we transfer information from known to novel categories by incorporating external knowledge , such as linguistic or expertspecified information , e.g. , by a mid-level layer of semantic attributes .", "In this work , we extend transfer learning with semi-supervised learning to exploit unlabeled instances of ( novel ) categories with no or only a few labeled instances .", "Category models for objects or activities typically rely on supervised learning requiring sufficiently large training sets .", "More specifically we adapt a graph-based learning algorithm - so far only used for semi-supervised learning - to zero-shot and few-shot learning .", "We evaluate our approach on three challenging datasets in two different applications , namely on Animals with Attributes and ImageNet for image classification and on MPII Composites for activity recognition ."]}
{"orig_sents": ["4", "1", "6", "2", "3", "5", "0"], "shuf_sents": ["We extensively evaluate our approach on object recognition and human activity recognition tasks .", "However , image data is difficult to manually divide into the discrete domains required by adaptation algorithms , and the standard practice of equating datasets with domains is a weak proxy for all the real conditions that alter the statistics in complex ways ( lighting , pose , background , resolution , etc . )", "Our formulation imposes two key properties on domains : maximum distinctiveness and maximum learnability .", "By maximum distinctiveness , we require the underlying distributions of the identified domains to be different from each other to the maximum extent ; by maximum learnability , we ensure that a strong discriminative model can be learned from the domain .", "In visual recognition problems , the common data distribution mismatches between training and testing make domain adaptation essential .", "We devise a nonparametric formulation and efficient optimization procedure that can successfully discover domains among both training and test data .", "We propose an approach to automatically discover latent domains in image or video datasets ."]}
{"orig_sents": ["4", "5", "0", "2", "3", "1"], "shuf_sents": ["Specifically , we extend the knearest-neighbor classifier by formulating the decision function for each data point as a weighted voting among the neighbors from all tasks where the weights are task-specific .", "Experiments on some toy data and real-world datasets demonstrate the effectiveness of our proposed methods .", "By defining a regularizer to enforce the task-specific weight matrix to approach a symmetric one , a regularized objective function is proposed and an efficient coordinate descent method is developed to solve it .", "For regression problems , we extend the kernel regression to multi-task setting in a similar way to the classification case .", "All the existing multi-task local learning methods are defined on homogeneous neighborhood which consists of all data points from only one task .", "In this paper , different from existing methods , we propose local learning methods for multitask classification and regression problems based on heterogeneous neighborhood which is defined on data points from all tasks ."]}
{"orig_sents": ["7", "4", "1", "5", "0", "2", "3", "6"], "shuf_sents": ["The same model can be used in this setting with few modifications .", "However , expectation propagation offers an approximate alternative .", "Furthermore , the assumptions made are less restrictive than in other multi-task methods : The different tasks must share feature selection dependencies , but can have different relevant features and model coefficients .", "Experiments with real and synthetic data show that this model performs better than other multi-task alternatives from the literature .", "Exact inference is intractable in this model .", "Because the process of estimating feature selection dependencies may suffer from over-fitting in the model proposed , additional data from a multi-task learning scenario are considered for induction .", "The experiments also show that the model is able to induce suitable feature selection dependencies for the problems considered , only from the training data .", "A probabilistic model based on the horseshoe prior is proposed for learning dependencies in the process of identifying relevant features for prediction ."]}
{"orig_sents": ["0", "2", "3", "1", "4"], "shuf_sents": ["We introduce an extended formulation of multi-task learning ( MTL ) called parametric task learning ( PTL ) that can systematically handle infinitely many tasks parameterized by a continuous parameter .", "We show that our PTL formulation is useful in various scenarios such as learning under non-stationarity , cost-sensitive learning , and quantile regression .", "Our key finding is that , for a certain class of PTL problems , the path of the optimal task-wise solutions can be represented as piecewise-linear functions of the continuous task parameter .", "Based on this fact , we employ a parametric programming technique to obtain the common shared representation across all the continuously parameterized tasks .", "We demonstrate the advantage of our approach in these scenarios ."]}
{"orig_sents": ["0", "1"], "shuf_sents": ["We propose a boosting method , DirectBoost , a greedy coordinate descent algorithm that builds an ensemble classifier of weak classifiers through directly minimizing empirical classification error over labeled training examples ; once the training classification error is reduced to a local coordinatewise minimum , DirectBoost runs a greedy coordinate ascent algorithm that continuously adds weak classifiers to maximize any targeted arbitrarily defined margins until reaching a local coordinatewise maximum of the margins in a certain sense .", "Experimental results on a collection of machine-learning benchmark datasets show that DirectBoost gives better results than AdaBoost , LogitBoost , LPBoost with column generation and BrownBoost , and is noise tolerant when it maximizes an n th order bottom sample margin ."]}
{"orig_sents": ["3", "0", "2", "1"], "shuf_sents": ["This novel approach lies in the area between offline and online ensemble approaches and can be seen either as a restriction of the former or an enhancement of the latter .", "We propose an efficient algorithmic implementation which makes it tractable in practice , and demonstrate its efficiency experimentally on several compute-vision data-sets , on which it outperforms both online and offline methods in a memory constrained setting .", "We identify some basic strategies that can be used to populate this reservoir and present our main contribution , dubbed Greedy Edge Expectation Maximization ( GEEM ) , that maintains the reservoir content in the case of Boosting by viewing the samples through their projections into the weak classifier response space .", "We propose to train an ensemble with the help of a reservoir in which the learning algorithm can store a limited number of samples ."]}
{"orig_sents": ["5", "6", "1", "4", "0", "3", "2"], "shuf_sents": ["In the process , we extend traditional framework of locality sensitive hashing ( LSH ) to handle higher-order similarities , which could be of independent theoretical interest .", "We show that approximate R3way similarity search problems admit fast algorithms with provable guarantees , analogous to the pairwise case .", "In addition , we demonstrate the advantage of R3way resemblance over the pairwise case in improving retrieval quality .", "The applicability of R3way search is shown on the `` Google Sets '' application .", "Our analysis and speedup guarantees naturally extend to k-way resemblance .", "We go beyond the notion of pairwise similarity and look into search problems with k-way similarity functions .", "In this paper , we focus on problems related to 1 S2 S3 | 3-way Jaccard similarity : R3way = |S |S1 S2 S3 | , S1 , S2 , S3 C , where C is a size n collection of sets ( or binary vectors ) ."]}
